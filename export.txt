# GuignoMap - Export fichiers Python (core seulement)
# Généré le 2025-09-19 16:42:19  
# Fichiers inclus : guignomap/, tools/, legacy/ + racine
# Exclusions : scripts/, tests/, .venv/, __pycache__/
#
# ============================================================================
# STRUCTURE DU PROJET (tree optimisé)
# ============================================================================
#
# GuignoMap/
# ├── 📁 .streamlit/
# │   ├── config.toml
# │   ├── secrets.toml.example
# │   └── SECRETS_SAMPLE.toml        [NOUVEAU v4.2]
# ├── 📁 .vscode/
# │   ├── launch.json
# │   ├── settings.json
# │   └── tasks.json
# ├── 📁 docs/
# │   ├── DATA_GOUVERNANCE.md         [NOUVEAU v4.2]
# │   └── PHASE1_AUDIT_DATAFRAME.md
# ├── 📁 exports/                    [Éphémère - CSV/Excel]
# │   ├── status_counts_*.csv
# │   ├── unassigned_*.csv
# │   └── maintenance/
# ├── 📁 guignomap/                  [MODULE CORE]
# │   ├── __init__.py
# │   ├── app.py                     [PRINCIPAL - Interface Streamlit]
# │   ├── auth.py                    [Authentification bcrypt]
# │   ├── backup.py                  [Système sauvegarde]
# │   ├── config_mode.py             [NOUVEAU v4.2 - Modes demo/client]
# │   ├── config_ville.py            [Configuration ville]
# │   ├── database.py                [CORRIGÉ v4.2 - Couche SQLite]
# │   ├── db.py                      [Legacy compatibility]
# │   ├── imports.py                 [Pipeline import données]
# │   ├── osm.py                     [Interface OpenStreetMap]
# │   ├── reports.py                 [Génération rapports]
# │   ├── utils.py                   [Utilitaires généraux]
# │   ├── validators.py              [Validation données]
# │   ├── guigno_map.db              [Base principale - Gitignored]
# │   ├── guigno_map.sample.db       [Base échantillon - Tracked]
# │   └── 📁 assets/
# │       ├── logo.png
# │       ├── banner.png
# │       └── styles.css
# ├── 📁 imports/                    [Données ville]
# │   └── mascouche_adresses.xlsx
# ├── 📁 legacy/                     [Compatibilité]
# │   ├── config.py
# │   └── 📁 storage/
# │       ├── __init__.py
# │       ├── cloud.py
# │       └── local.py
# ├── 📁 scripts/                    [Outils CLI - Exclus export]
# │   ├── maintenance_weekly.ps1     [NOUVEAU v4.2]
# │   ├── import_city_excel.py
# │   ├── verify_*.py
# │   └── ...
# ├── 📁 tests/                      [Tests unitaires - Exclus export]
# │   ├── test_critical_paths.py
# │   ├── test_sqlite_performance.py
# │   └── ...
# ├── 📁 tools/                      [Utilitaires]
# │   └── quick_sanity.py            [Contrôle sanité]
# ├── check_admin.py                 [Vérification admin]
# ├── streamlit_app.py               [Point d'entrée Streamlit]
# ├── requirements.txt               [Dépendances Python]
# ├── runtime.txt                    [Version Python Cloud]
# ├── README_DEPLOIEMENT_CLOUD.md    [NOUVEAU v4.2 - Guide Cloud]
# ├── .gitignore                     [Exclusions Git]
# └── export.txt                     [CE FICHIER - Code source core]
#
# Total fichiers core : 20 fichiers Python (hors scripts/tests)
# Version : GuignoMap v4.2+ avec modes d'exécution et corrections runtime
#
# ============================================================================
# ENVIRONNEMENT TECHNIQUE ET DÉPENDANCES
# ============================================================================
#
# 🖥️ SYSTÈME D'EXPLOITATION
# ---------------------------
# OS: Windows 10 Home (Build 2009)
# Architecture: x64 (pas WSL - Windows natif)
# Shell: PowerShell 5.1
# 
# 🐍 VERSIONS PYTHON
# -------------------
# Python système: 3.13.6
# Python venv (.venv): 3.13.6
# Python Cloud (runtime.txt): 3.12 (pour Streamlit Cloud)
# 
# 📦 DÉPENDANCES PRINCIPALES (requirements.txt)
# ----------------------------------------------
# streamlit>=1.33,<1.40        → Interface web (v1.39.1 installée)
# pandas>=2.2.0                → Manipulation données (v2.3.2 installée)
# folium==0.20.0               → Cartes interactives
# streamlit-folium>=0.21.0     → Intégration Streamlit-Folium (v0.25.1)
# overpy==0.7                  → API OpenStreetMap
# plotly>=5.18.0               → Graphiques interactifs (v6.3.0)
# xlsxwriter==3.2.8            → Export Excel
# reportlab==4.4.3             → Génération PDF
# passlib[argon2]==1.7.4       → Authentification sécurisée
# 
# 📋 DÉPENDANCES COMPLÈTES INSTALLÉES (pip list)
# -----------------------------------------------
# altair==5.5.0                 [Graphiques Streamlit]
# argon2-cffi==25.1.0           [Hachage passwords]
# argon2-cffi-bindings==25.1.0  [Bindings Argon2]
# attrs==25.3.0                 [Classes Python]
# blinker==1.9.0                [Signaux Streamlit]
# boto3==1.34.162               [AWS SDK - optionnel]
# botocore==1.34.162            [AWS Core]
# branca==0.8.1                 [Templates Folium]
# cachetools==5.5.2             [Cache LRU]
# certifi==2025.8.3             [Certificats SSL]
# cffi==2.0.0                   [Foreign Function Interface]
# charset-normalizer==3.4.3     [Détection encodage]
# click==8.3.0                  [CLI framework]
# colorama==0.4.6               [Couleurs terminal Windows]
# et_xmlfile==2.0.0             [XML Excel]
# flake8==7.3.0                 [Linting Python]
# folium==0.20.0                [Cartes Leaflet]
# gitdb==4.0.12                 [Git database]
# GitPython==3.1.45             [Git interface Python]
# idna==3.10                    [Encodage domaines internationaux]
# iniconfig==2.1.0              [Configuration INI]
# Jinja2==3.1.6                 [Templates]
# jmespath==1.0.1               [JSON query]
# jsonschema==4.25.1            [Validation JSON]
# jsonschema-specifications==2025.9.1 [Specs JSON Schema]
# markdown-it-py==4.0.0         [Markdown parser]
# MarkupSafe==3.0.2             [Échappement HTML]
# mccabe==0.7.0                 [Complexité cyclomatique]
# mdurl==0.1.2                  [URLs Markdown]
# narwhals==2.5.0               [API DataFrame unifiée]
# numpy==2.3.3                  [Calcul numérique]
# openpyxl==3.1.5               [Lecture/écriture Excel]
# overpy==0.7                   [API Overpass OSM]
# packaging==24.2               [Gestion packages]
# pandas==2.3.2                 [Analyse données]
# passlib==1.7.4                [Hachage passwords]
# pillow==10.4.0                [Traitement images]
# pip==25.2                     [Gestionnaire packages]
# plotly==6.3.0                 [Graphiques interactifs]
# pluggy==1.6.0                 [Système plugins]
# protobuf==5.29.5              [Sérialisation Google]
# pyarrow==21.0.0               [Apache Arrow Python]
# pycodestyle==2.14.0           [Style code Python]
# pycparser==2.23               [Parser C]
# pydeck==0.9.1                 [Visualisation 3D Streamlit]
# pyflakes==3.4.0               [Détection erreurs Python]
# Pygments==2.19.2              [Coloration syntaxique]
# pytest==8.4.2                 [Framework tests]
# python-dateutil==2.9.0.post0 [Extensions dates]
# pytz==2025.2                  [Fuseaux horaires]
# referencing==0.36.2           [Références JSON Schema]
# reportlab==4.4.3              [Génération PDF]
# requests==2.32.5              [HTTP client]
# rich==13.9.4                  [Terminal riche]
# rpds-py==0.27.1               [Structures données persistantes]
# ruff==0.13.0                  [Linter/formatter Python ultra-rapide]
# s3transfer==0.10.4            [Transferts S3]
# six==1.17.0                   [Compatibilité Python 2/3]
# smmap==5.0.2                  [Memory mapping]
# streamlit==1.39.1             [Framework web app]
# streamlit-folium==0.25.1      [Intégration cartes]
# tenacity==9.1.2               [Retry logic]
# toml==0.10.2                  [Parser TOML]
# tornado==6.5.2                [Serveur web async]
# typing_extensions==4.15.0     [Extensions typage]
# tzdata==2025.2                [Base données fuseaux horaires]
# urllib3==2.5.0                [HTTP client bas niveau]
# watchdog==5.0.3               [Surveillance fichiers]
# xlsxwriter==3.2.8             [Écriture Excel]
# xyzservices==2025.4.0         [Services cartographiques]
#
# 🛠️ OUTILS DE DÉVELOPPEMENT
# ---------------------------
# Linting: flake8 (7.3.0) + ruff (0.13.0)
# Tests: pytest (8.4.2)
# Formatage: ruff (intégré)
# Git: GitPython (3.1.45)
# 
# 📊 STATISTIQUES
# ---------------
# Total packages installés: 70 packages
# Taille venv estimée: ~500MB
# Python wheels: Tous compatibles Windows x64
# 
# ⚙️ CONFIGURATION STREAMLIT CLOUD
# ---------------------------------
# runtime.txt: Python 3.12 (compatible Cloud)
# requirements.txt: Versions fixées pour reproductibilité
# secrets.toml: Configuration sécurisée (non trackée)
#
# ============================================================================
# FICHIERS DE CONFIGURATION ET DESIGN
# ============================================================================

# ===== requirements.txt =====
# Dépendances principales du projet
streamlit>=1.33,<1.40
pandas>=2.2.0
folium==0.20.0
streamlit-folium>=0.21.0
overpy==0.7
plotly>=5.18.0
xlsxwriter==3.2.8
reportlab==4.4.3

# Authentication - Argon2
passlib[argon2]==1.7.4

# Storage - S3/Cloud (optionnel pour exports)
# boto3==1.34.*

# ===== .streamlit/config.toml =====
# Configuration thème et performance Streamlit
[theme]
# Thème sombre avec les couleurs du Relais
base = "dark"
primaryColor = "#A9CF3B"              # Vert du Relais
backgroundColor = "#0F1318"           # Fond très sombre
secondaryBackgroundColor = "#1A1F26"  # Fond secondaire
textColor = "#F2F3F5"                 # Texte clair
font = "sans serif"

[client]
# Configuration minimale de la toolbar
toolbarMode = "minimal"
showErrorDetails = false

[runner]
# Optimisations de performance
magicEnabled = true

[server]
# Configuration serveur
headless = true
runOnSave = true
maxUploadSize = 10
enableXsrfProtection = true

# ===== .streamlit/SECRETS_SAMPLE.toml =====
# Échantillon des secrets pour Streamlit Cloud
# Instructions:
# 1. Copiez le contenu de ce fichier
# 2. Collez dans "App secrets" de votre app Streamlit Cloud
# 3. Adaptez les valeurs selon votre environnement

# MODE D'EXÉCUTION
# "demo"   = Mode démonstration (fallback intelligent vers DB sample)
# "client" = Mode production (exige guigno_map.db principal)
MODE = "demo"

# AUTHENTIFICATION
# Permet le fallback bcrypt pour compatibilité anciennes installations
ALLOW_BCRYPT_FALLBACK = true

# CONFIGURATION OPTIONNELLE STREAMLIT CLOUD
# Désactive les logs de debug pour améliorer les performances
# [logger]
# level = "WARNING"

# Force l'encodage UTF-8 pour éviter les problèmes de caractères
# PYTHONUTF8 = "1"

# NOTES DE DÉPLOIEMENT
# - Le mode "demo" est recommandé pour Streamlit Cloud
# - Les fichiers uploadés ne sont pas persistants sur Cloud
# - Utilisez les boutons de téléchargement pour sauvegarder les exports
# - La base de données est créée automatiquement en mode demo

# ===== .devcontainer/devcontainer.json =====
# Configuration GitHub Codespaces et VS Code Remote
{
  "name": "Python 3",
  "image": "mcr.microsoft.com/devcontainers/python:1-3.11-bullseye",
  "customizations": {
    "codespaces": {
      "openFiles": [
        "README.md",
        "guignomap/app.py"
      ]
    },
    "vscode": {
      "settings": {},
      "extensions": [
        "ms-python.python",
        "ms-python.vscode-pylance"
      ]
    }
  },
  "updateContentCommand": "[ -f packages.txt ] && sudo apt update && sudo apt upgrade -y && sudo xargs apt install -y <packages.txt; [ -f requirements.txt ] && pip3 install --user -r requirements.txt; pip3 install --user streamlit; echo '✅ Packages installed and Requirements met'",
  "postAttachCommand": {
    "server": "streamlit run guignomap/app.py --server.enableCORS false --server.enableXsrfProtection false"
  },
  "portsAttributes": {
    "8501": {
      "label": "Application",
      "onAutoForward": "openPreview"
    }
  },
  "forwardPorts": [
    8501
  ]
}

# ===== guignomap/assets/styles.css =====
# Styles personnalisés pour l'interface GuignoMap (633 lignes)
/* ========================================
   GUIGNO-MAP - STYLES PERSONNALISÉS
   Le Relais de Mascouche
   ======================================== */

/* Import Google Fonts */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=Manrope:wght@700;800&display=swap');

/* ========================================
   VARIABLES CSS & THÈME
   ======================================== */
:root {
    /* Couleurs principales du Relais */
    --relais-rouge: #8B0000;
    --relais-rouge-light: #a52a2a;
    --relais-or: #FFD700;
    --relais-or-light: #FFE44D;
    
    /* Couleurs de statut */
    --status-green: #22c55e;
    --status-orange: #f59e0b;
    --status-red: #ef4444;
    --status-gray: #9ca3af;
    
    /* Couleurs de base */
    --bg-dark: #0e1117;
    --bg-secondary: #151b22;
    --bg-card: #1a1f2e;
    --border-color: #222a33;
    --text-primary: #fafafa;
    --text-secondary: #cbd5e1;
    --text-muted: #8b92a4;
    
    /* Espacements */
    --spacing-xs: 0.25rem;
    --spacing-sm: 0.5rem;
    --spacing-md: 1rem;
    --spacing-lg: 1.5rem;
    --spacing-xl: 2rem;
    
    /* Border radius */
    --radius-sm: 8px;
    --radius-md: 12px;
    --radius-lg: 16px;
    --radius-xl: 20px;
}

/* Design moderne avec thème sombre Le Relais */
/* Header avec gradient rouge/or, cartes modernes */
/* Boutons avec effets hover, métriques stylisées */
/* Tableaux personnalisés, tabs élégants */
/* Animations CSS3, responsive design */
/* Support dark/light mode automatique */
/* Variables CSS pour cohérence du design */
/* Police Inter + Manrope pour typography moderne */

# Remarque: CSS complet (633 lignes) avec tous les styles
# pour header, cartes, boutons, formulaires, tableaux,
# animations et responsive design du thème Le Relais

# ===== guignomap/osm_addresses.json =====
# Base de données des adresses OpenStreetMap (30 546 lignes)
# Structure: { "Nom_Rue": [{"number": "XX", "lat": XX.XX, "lon": XX.XX, "type": "node"}] }
# Exemple d'entrées pour "Montée Masson":
{
  "Montée Masson": [
    {
      "number": "10",
      "lat": 45.721144,
      "lon": -73.621438,
      "type": "node"
    },
    {
      "number": "20",
      "lat": 45.721324,
      "lon": -73.621326,
      "type": "node"
    }
    # ... (environ 30 000+ adresses géolocalisées)
  ]
}

# Remarque: Fichier volumineux (30 546 lignes) contenant
# toutes les adresses de Mascouche avec coordonnées GPS
# précises extraites d'OpenStreetMap via l'API Overpass

# ===== .gitignore =====
# Configuration des exclusions Git pour le projet
# ---- Python / Streamlit / Tools
__pycache__/
*.py[cod]
*.pyo
*.pyd
*.so
*.dylib
*.egg-info/
.eggs/
.build/
dist/
build/
.cache/
.coverage*
.pytest_cache/
.mypy_cache/
.ipynb_checkpoints/
.idea/
.vscode/
.DS_Store
Thumbs.db

# ---- Environnement
.venv/
venv/
.env
.env.*

# ---- Databases
guignomap/guigno_map.db
!guignomap/guigno_map.sample.db
*.log

# ---- OSM Cache
guignomap/osm_cache.json

# ---- Streamlit
.streamlit/secrets.toml

# ---- Exports et backups
exports/
backups/

# ---- OS cruft
*.swp
*.tmp

# Remarque: .gitignore exclut les fichiers sensibles/temporaires
# - Base de données principale (mais garde la sample)
# - Secrets Streamlit (sécurité)
# - Cache Python et environnements virtuels
# - Exports et backups (fichiers générés)
# - Fichiers système et temporaires

#
# ============================================================================
# FIN DE L'EXPORT - FICHIERS DE CONFIGURATION
# ============================================================================

# ============================================================================
# check_admin.py
# ============================================================================

#!/usr/bin/env python3
"""
Script temporaire pour vérifier le mot de passe admin
"""
import sqlite3
from pathlib import Path

# Chemin vers la base de données
db_path = Path("guignomap/guigno_map.db")

if not db_path.exists():
    print(f"❌ Base de données non trouvée: {db_path}")
    exit(1)

# Connexion à la base
try:
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # Vérifier la structure de la table teams
    cursor.execute("PRAGMA table_info(teams)")
    columns = cursor.fetchall()
    print("📋 Structure de la table teams:")
    for col in columns:
        print(f"   {col}")
    
    # Rechercher l'équipe admin
    cursor.execute("SELECT * FROM teams WHERE name = 'admin'")
    admin_team = cursor.fetchone()
    
    if admin_team:
        print(f"\n✅ Équipe admin trouvée:")
        print(f"   Données: {admin_team}")
    else:
        print("\n❌ Aucune équipe admin trouvée")
        
        # Lister toutes les équipes
        cursor.execute("SELECT * FROM teams LIMIT 5")
        teams = cursor.fetchall()
        print("\n📋 Premières équipes dans la base:")
        for team in teams:
            print(f"   {team}")
    
    conn.close()
    
except Exception as e:
    print(f"❌ Erreur: {e}")

# ============================================================================
# streamlit_app.py
# ============================================================================

# coding: utf-8
import os, sys
os.environ.setdefault("PYTHONUTF8", "1")
try:
    sys.stdout.reconfigure(encoding="utf-8")
except Exception:
    pass

import pathlib, importlib, traceback
import streamlit as st

ROOT = pathlib.Path(__file__).resolve().parent
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

try:
    app = importlib.import_module("guignomap.app")
    for fn_name in ("main", "run", "render"):
        fn = getattr(app, fn_name, None)
        if callable(fn):
            fn()
            break
    else:
        st.caption("GuignoMap chargé (mode import).")
except Exception:
    st.error("Erreur de démarrage :")
    st.code(traceback.format_exc())
    import platform, streamlit, sqlalchemy
    st.write({
        "python": platform.python_version(),
        "streamlit": streamlit.__version__,
        "sqlalchemy": sqlalchemy.__version__,
        "secrets_keys": list(getattr(st, "secrets", {}).keys()),
    })

# ============================================================================
# guignomap\__init__.py
# ============================================================================



# ============================================================================
# guignomap\app.py
# ============================================================================

"""
Guigno-Map - Application de gestion de collecte de denrées
Le Relais de Mascouche
Version 3.0 - Production
"""

# pyright: reportCallIssue=false

import os
import sys
os.environ.setdefault("PYTHONUTF8", "1")
try:
    sys.stdout.reconfigure(encoding="utf-8")
except Exception:
    pass

from pathlib import Path
import time
from datetime import datetime
import pandas as pd
import streamlit as st

# Configuration du path pour les imports
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import guignomap.config_ville as config_ville

# Monkey-patch supprimé - utilisation de composants Streamlit natifs

# Configuration Streamlit (doit être la première commande Streamlit)
st.set_page_config(
    page_title=f"Guigno-Map | Relais de {config_ville.VILLE_NOM}",
    page_icon="🎁",
    layout="wide",
    initial_sidebar_state="expanded"
)

import folium
from streamlit_folium import st_folium

# Import des modules locaux
from guignomap import database as db
from guignomap.validators import validate_and_clean_input
from guignomap.osm import build_geometry_cache, load_geometry_cache, build_addresses_cache, load_addresses_cache, CACHE_FILE
from guignomap.utils import to_dataframe

# --- Utilitaire de compatibilité pandas Styler ---
from typing import Callable, Any

def style_map_compat(df: pd.DataFrame, fn: Callable[[Any], str], subset: Any = None):
    """Applique un style cellule-à-cellule en utilisant Styler.map si disponible,
    sinon fallback dynamique vers applymap sans exposer l'attribut (OK pour Pylance).
    
    Args:
        df: DataFrame à styliser
        fn: Fonction qui prend une valeur cellule et retourne une string CSS
        subset: Colonnes à cibler (ex: ['status'] ou None pour toutes)
    """
    styler = df.style
    if hasattr(styler, "map"):
        # Pandas 2.4+ : utilise la nouvelle API map()
        return styler.map(fn, subset=subset)
    # Pandas < 2.4 : fallback vers applymap (sans référence statique)
    return getattr(styler, "applymap")(fn, subset=subset)

# --- Mapping des statuts pour l'affichage ---
STATUS_TO_LABEL = {"a_faire": "À faire", "en_cours": "En cours", "terminee": "Terminée"}
LABEL_TO_STATUS = {v: k for k, v in STATUS_TO_LABEL.items()}

ASSETS = Path(__file__).parent / "assets"

# Initialisation session
if "auth" not in st.session_state:
    st.session_state.auth = None

# ============================================
# COMPOSANTS UI
# ============================================

def inject_css():
    """Charge le CSS depuis le fichier externe"""
    css_file = ASSETS / "styles.css"
    if css_file.exists():
        css = css_file.read_text(encoding="utf-8")
        st.markdown(f"<style>{css}</style>", unsafe_allow_html=True)

def render_header():
    """Header moderne avec logo Guignolée et design festif"""
    
    # Container principal avec fond festif
    st.markdown("""
    <div style="
        background: linear-gradient(135deg, #c41e3a 0%, #165b33 100%);
        border-radius: 20px;
        padding: 2rem;
        margin-bottom: 2rem;
        position: relative;
        overflow: hidden;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    ">
        <!-- Flocons de neige animés en CSS -->
        <div style="position: absolute; width: 100%; height: 100%; opacity: 0.1;">
            <span style="position: absolute; top: 10%; left: 10%; font-size: 2rem;">❄️</span>
            <span style="position: absolute; top: 20%; left: 80%; font-size: 1.5rem;">❄️</span>
            <span style="position: absolute; top: 60%; left: 30%; font-size: 1.8rem;">❄️</span>
        </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([2, 5, 2])
    
    with col1:
        # Logo Guignolée
        if (ASSETS / "guignolee.png").exists():
            st.image(str(ASSETS / "guignolee.png"), width=150)
    
    with col2:
        st.markdown("""
        <div style="text-align: center;">
            <h1 style="
                color: white;
                font-family: 'Manrope', sans-serif;
                font-size: 2.5rem;
                margin: 0;
                text-shadow: 3px 3px 6px rgba(0,0,0,0.5);
                letter-spacing: 2px;
            ">🎅 GUIGNOLÉE 2025 🎁</h1>
            <p style="
                color: #FFD700;
                font-size: 1.2rem;
                margin: 0.5rem 0 0 0;
                font-weight: 600;
            ">Le Relais de Mascouche - 1er décembre</p>
            <p style="
                color: rgba(255,255,255,0.9);
                font-size: 1rem;
                margin-top: 0.5rem;
            ">Système de gestion de collecte</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        # Stats en temps réel
        stats = db.extended_stats()
        # Normalisation anti-KeyError (valeurs par défaut)
        stats = stats or {}
        total = int(stats.get('total') or stats.get('count') or 0)
        done = int(stats.get('done') or stats.get('completed') or 0)
        # Réinjecte pour la suite de l'UI si d'autres blocs lisent ces clés
        stats['total'] = total
        stats['done'] = done
        progress = (done / total * 100) if total > 0 else 0
        
        st.markdown(f"""
        <div style="
            background: rgba(255,255,255,0.2);
            border-radius: 15px;
            padding: 1rem;
            text-align: center;
        ">
            <div style="color: #FFD700; font-size: 2rem; font-weight: bold;">
                {progress:.0f}%
            </div>
            <div style="color: white; font-size: 0.9rem;">
                Complété
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

def render_login_card(role="benevole"):
    """Carte de connexion moderne avec design festif"""
    
    # Container de connexion stylisé
    st.markdown("""
    <div style="
        max-width: 400px;
        margin: 3rem auto;
        background: linear-gradient(135deg, rgba(255,255,255,0.1), rgba(255,255,255,0.05));
        backdrop-filter: blur(10px);
        border: 2px solid rgba(255,215,0,0.3);
        border-radius: 20px;
        padding: 2rem;
        box-shadow: 0 20px 40px rgba(0,0,0,0.3);
    ">
    """, unsafe_allow_html=True)
    
    # Icône et titre
    if role == "superviseur" or role == "gestionnaire":
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <div style="font-size: 3rem;">👤</div>
            <h2 style="color: #FFD700; margin: 1rem 0;">Espace Gestionnaire</h2>
            <p style="color: #cbd5e1;">Gérez la collecte et les équipes</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_gestionnaire", clear_on_submit=False):
            password = st.text_input(
                "🔑 Mot de passe",
                type="password",
                placeholder="Entrez le mot de passe gestionnaire"
            )
            
            col1, col2, col3 = st.columns([1,2,1])
            with col2:
                submit = st.form_submit_button(
                    "🔓 Connexion",
                    
                )
            
            if submit:
                if db.verify_team("ADMIN", password):
                    st.session_state.auth = {"role": "supervisor", "team_id": "ADMIN"}
                    st.success("✅ Bienvenue dans l'espace gestionnaire!")
                    st.snow()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("❌ Mot de passe incorrect")
    
    else:  # Bénévole
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <div style="font-size: 3rem;">🎄</div>
            <h2 style="color: #FFD700; margin: 1rem 0;">Espace Bénévole</h2>
            <p style="color: #cbd5e1;">Accédez à vos rues assignées</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_benevole", clear_on_submit=False):
            col1, col2 = st.columns(2)
            
            with col1:
                team_id = st.text_input(
                    "👥 Identifiant d'équipe",
                    placeholder="Ex: EQ001"
                )
            
            with col2:
                password = st.text_input(
                    "🔑 Mot de passe",
                    type="password",
                    placeholder="Mot de passe équipe"
                )
            
            col1, col2, col3 = st.columns([1,2,1])
            with col2:
                submit = st.form_submit_button(
                    "🎄 Connexion"
                )
            
            if submit:
                if db.verify_team(team_id, password):
                    st.session_state.auth = {"role": "volunteer", "team_id": team_id}
                    st.success(f"✅ Bienvenue équipe {team_id}!")
                    st.snow()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("❌ Identifiants incorrects")
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    # Aide en bas
    st.markdown("""
    <div style="text-align: center; margin-top: 2rem; color: #8b92a4;">
        <small>
        Besoin d'aide? Contactez votre gestionnaire<br>
        📞 450-474-4133
        </small>
    </div>
    """, unsafe_allow_html=True)

def render_metrics(stats):
    """Affiche les métriques principales"""
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Rues", stats['total'])
    
    with col2:
        st.metric("Rues Terminées", stats['done'])
    
    with col3:
        st.metric("En Cours", stats.get('partial', 0))
    
    with col4:
        st.metric("Progression", f"{progress:.1f}%")

def render_dashboard_gestionnaire(geo):
    """Dashboard moderne pour gestionnaires avec KPIs visuels"""
    
    # KPIs principaux en cartes colorées
    stats = db.extended_stats()
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    st.markdown("### 📊 Tableau de bord en temps réel")
    
    # Ligne de KPIs avec icônes festives
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #22c55e, #16a34a);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(34,197,94,0.3);
        ">
            <div style="font-size: 2.5rem;">🏘️</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats['total']}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Total Rues</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(59,130,246,0.3);
        ">
            <div style="font-size: 2.5rem;">✅</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats['done']}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Terminées</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #f59e0b, #d97706);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(245,158,11,0.3);
        ">
            <div style="font-size: 2.5rem;">⏳</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats.get('partial', 0)}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">En cours</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        # Nombre d'équipes actives
        teams_count = len(db.teams())
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #8b5cf6, #7c3aed);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(139,92,246,0.3);
        ">
            <div style="font-size: 2.5rem;">👥</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{teams_count}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Équipes</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col5:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #c41e3a, #165b33);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(196,30,58,0.3);
        ">
            <div style="font-size: 2.5rem;">🎯</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{progress:.0f}%</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Progression</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Barre de progression visuelle
    st.markdown("### 🎄 Progression globale")
    st.progress(progress / 100)
    
    # Graphique par secteur (si disponible)
    st.markdown("### 📈 Performance par équipe")
    try:
        teams_stats = db.stats_by_team()
        if teams_stats:  # Liste non vide
            # Convertir en DataFrame pour plotly
            import pandas as pd
            teams_df = pd.DataFrame(teams_stats)
            
            # Calculer le pourcentage de progression
            teams_df['progress'] = ((teams_df['completed'] / teams_df['total_streets']) * 100).fillna(0)
            
            # Graphique en barres colorées
            import plotly.express as px
            fig = px.bar(
                teams_df, 
                x='id', 
                y='progress',
                color='progress',
                color_continuous_scale=['#ef4444', '#f59e0b', '#22c55e'],
                labels={'team': 'Équipe', 'progress': 'Progression (%)'},
                title="Performance des équipes"
            )
            fig.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Aucune statistique d'équipe disponible")
    except Exception:
        st.warning("Graphiques non disponibles (module plotly manquant)")
        # Fallback vers un tableau simple
        try:
            teams_stats = db.stats_by_team()
            if teams_stats:  # Liste non vide
                st.dataframe(to_dataframe(teams_stats), use_container_width=True)
        except:
            st.info("Aucune statistique d'équipe disponible")

def add_persistent_legend(m):
    """Ajoute une légende persistante pour les 4 états des rues via contrôle HTML"""
    legend_html = """
    <div id='gm-legend' class='leaflet-control-layers leaflet-control' 
         style='position: absolute; bottom: 10px; right: 10px; z-index: 1000;
                background: white; border: 2px solid rgba(0,0,0,0.2); 
                border-radius: 5px; padding: 10px; box-shadow: 0 1px 5px rgba(0,0,0,0.2);
                font-family: "Helvetica Neue", Arial, Helvetica, sans-serif; 
                font-size: 12px; line-height: 18px; color: #333;'>
        <strong style='margin-bottom: 8px; display: block;'>Légende</strong>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #28a745; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Terminée</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #f1c40f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>En cours</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #ff4d4f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Assignée (à faire)</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px dashed #ff4d4f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Non assignée</span>
        </div>
    </div>
    """
    m.get_root().html.add_child(folium.Element(legend_html))

def create_map(df, geo):
    """Crée la carte Folium centrée sur la ville avec toutes les rues"""
    # 1) Coercition sûre en DataFrame
    if not isinstance(df, pd.DataFrame):
        try:
            df = pd.DataFrame(df)
        except Exception:
            df = pd.DataFrame([])
    
    # Limites de la ville
    bounds = config_ville.VILLE_BOUNDS
    center = config_ville.VILLE_CENTRE
    
    # Créer la carte
    m = folium.Map(
        location=center,
        zoom_start=13,  # Zoom optimisé pour voir toute la ville
        tiles="https://{s}.tile.openstreetmap.fr/osmfr/{z}/{x}/{y}.png",
        attr='© OpenStreetMap France',
        control_scale=True,
        max_bounds=True,
        min_zoom=11,
        max_zoom=18,
        prefer_canvas=True,
        zoom_control=True,
        scrollWheelZoom=True
    )
    
    # Ajouter plusieurs couches de fond
    folium.TileLayer(
        tiles='https://{s}.tile.openstreetmap.fr/osmfr/{z}/{x}/{y}.png',
        attr='© OpenStreetMap France',
        name='OSM France (Détaillé)',
        overlay=False,
        control=True
    ).add_to(m)

    folium.TileLayer(
        tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager/{z}/{x}/{y}.png',
        attr='© CARTO',
        name='CARTO Voyager',
        overlay=False,
        control=True
    ).add_to(m)

    folium.TileLayer(
        tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Street_Map/MapServer/tile/{z}/{y}/{x}',
        attr='© Esri',
        name='Esri WorldStreetMap',
        overlay=False,
        control=True
    ).add_to(m)

    # Ajouter le contrôle des couches
    folium.LayerControl().add_to(m)
    
    # Définir les limites de la carte sur la ville
    m.fit_bounds([[bounds["south"], bounds["west"]], 
                  [bounds["north"], bounds["east"]]])
    
    if not geo:
        st.warning("Aucune donnée géométrique disponible")
        return m
    
    # Construire le lookup des infos DB
    street_info = {}
    if not df.empty:  # DataFrame non vide
        for idx, row in df.iterrows():
            name = str(row.get('name', '')) if pd.notna(row.get('name', '')) else ''
            status = row.get('status', 'a_faire')
            status = status if pd.notna(status) else 'a_faire'
            team = row.get('team', '')
            team = team if pd.notna(team) else ''
            notes = str(row.get('notes', '0')) if pd.notna(row.get('notes', '0')) else '0'
            
            street_info[name] = {
                'status': status,
                'team': str(team).strip() if team else '',
                'notes': notes
            }
    
    # Couleurs par statut
    status_colors = {
        'terminee': '#22c55e',  # Vert
        'en_cours': '#f59e0b',  # Orange
        'a_faire': '#ef4444'    # Rouge
    }
    
    # Compteurs pour stats
    stats = {"total": 0, "assigned": 0, "unassigned": 0}
    
    # Ajouter TOUTES les rues de la géométrie
    for name, paths in geo.items():
        stats["total"] += 1
        
        # Info depuis DB ou défaut (rouge pointillé)
        info = street_info.get(name, {
            'status': 'a_faire',
            'team': '',
            'notes': '0'
        })
        
        status = info['status']
        team = info['team']
        notes = info['notes']
        
        # Style: TOUJOURS pointillé si pas d'équipe
        has_team = bool(team)
        color = status_colors.get(status, '#ef4444')  # Rouge par défaut
        opacity = 0.9 if has_team else 0.7
        dash = None if has_team else '8,12'  # Pointillés si non assigné
        weight = 7 if has_team else 5
        
        if has_team:
            stats["assigned"] += 1
        else:
            stats["unassigned"] += 1
        
        # Tooltip informatif
        tooltip_html = f"""
        <div style='font-family: sans-serif'>
            <strong style='font-size: 14px'>{name}</strong><br>
            <span style='color: {color}'>'óè Statut: {status.replace('_', ' ').title()}</span><br>
            <span>📋 Équipe: {team if team else '⚠️ NON ASSIGNÉE'}</span><br>
            <span>📝 Notes: {notes}</span>
        </div>
        """
        
        # Ajouter chaque segment de la rue
        for path in paths:
            if path and len(path) >= 2:
                folium.PolyLine(
                    path,
                    color=color,
                    weight=weight,
                    opacity=opacity,
                    dash_array=dash,
                    tooltip=folium.Tooltip(tooltip_html, sticky=True)
                ).add_to(m)
    
    # Ajouter un marqueur au centre-ville
    folium.Marker(
        config_ville.VILLE_CENTRE,
        popup=f"Centre-ville de {config_ville.VILLE_NOM}",
        tooltip="Centre-ville",
        icon=folium.Icon(color='red', icon='info-sign')
    ).add_to(m)
    
    # Ajouter la légende persistante
    add_persistent_legend(m)
    
    return m


# ============================================
# UTILITAIRES EXPORT
# ============================================

def export_excel_professionnel(conn):
    """Export Excel avec mise en forme professionnelle"""
    try:
        from reports import ReportGenerator
        generator = ReportGenerator()
        return generator.generate_excel()
    except ImportError:
        # Fallback si les dépendances ne sont pas installées
        return db.export_to_csv()


# ============================================
# FONCTIONNALITÉS AVANCÉES
# ============================================

def detect_mobile():
    """Détecte si l'utilisateur est sur mobile"""
    try:
        # Récupérer les paramètres de l'URL pour forcer le mode mobile
        query_params = st.experimental_get_query_params()
        if 'mobile' in query_params:
            return True
        
        # Mobile-first approach pour l'instant
        return True
    except:
        return False

def show_notification(message, type="success"):
    """Affiche une notification stylisée"""
    icons = {
        "success": "✅",
        "error": "❌",
        "warning": "⚠️",
        "info": "ℹ️"
    }
    colors = {
        "success": "#22c55e",
        "error": "#ef4444", 
        "warning": "#f59e0b",
        "info": "#3b82f6"
    }
    
    st.markdown(f"""
    <div style="
        position: fixed;
        top: 20px;
        right: 20px;
        background: {colors[type]};
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 10px;
        box-shadow: 0 5px 15px rgba(0,0,0,0.3);
        z-index: 9999;
        animation: slideIn 0.3s ease-out;
    ">
        <strong>{icons[type]} {message}</strong>
    </div>
    <style>
    @keyframes slideIn {{
        from {{ transform: translateX(100%); opacity: 0; }}
        to {{ transform: translateX(0); opacity: 1; }}
    }}
    </style>
    """, unsafe_allow_html=True)

def show_team_badges(team_id):
    """Affiche les badges de réussite de l'équipe"""
    try:
        df = db.list_streets(team=team_id)
        done = len(df[df['status'] == 'terminee'])
        total = len(df)
        
        badges = []
        if done >= 1:
            badges.append("🏆 Première rue!")
        if done >= total * 0.25:
            badges.append("🥉 25% complété")
        if done >= total * 0.5:
            badges.append("🥈 50% complété")
        if done >= total * 0.75:
            badges.append("🥇 75% complété")
        if done == total:
            badges.append("🏆 CHAMPION!")
        
        if badges:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #FFD700, #FFA500);
                padding: 1rem;
                border-radius: 10px;
                text-align: center;
                margin: 1rem 0;
            ">
                <strong>Vos badges:</strong><br>
                <div style="font-size: 2rem; margin-top: 0.5rem;">
                    {' '.join(badges)}
                </div>
            </div>
            """, unsafe_allow_html=True)
    except:
        pass

def generate_sms_list(conn):
    """Génère une liste de téléphones pour SMS de groupe"""
    try:
        # Cette fonction nécessiterait une table de téléphones
        # Pour l'instant, retourne un exemple
        return "# Liste des téléphones bénévoles\n# 450-XXX-XXXX\n# 438-XXX-XXXX"
    except:
        return "Liste non disponible"

def page_export_gestionnaire(conn):
    """Section export avec formats multiples"""
    
    st.markdown("### 📊 Centre d'export des données")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>🧾 Rapport PDF</h4>
            <p><small>Format professionnel pour présentation</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            from reports import ReportGenerator
            generator = ReportGenerator()
            pdf_data = generator.generate_pdf()
            st.download_button(
                "📥 Télécharger PDF",
                pdf_data,
                "rapport_guignolee_2025.pdf",
                "application/pdf",
                
            )
        except ImportError:
            st.button("PDF (Installer reportlab)", disabled=True)
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>📊 Excel détaillé</h4>
            <p><small>Avec graphiques et mise en forme</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            excel_data = export_excel_professionnel(conn)
            st.download_button(
                "📥 Télécharger Excel",
                excel_data,
                "guignolee_2025.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                
            )
        except:
            st.button("Excel (Non disponible)", disabled=True)
    
    with col3:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>📄 Liste SMS</h4>
            <p><small>Téléphones des bénévoles</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        sms_list = generate_sms_list(conn)
        st.download_button(
            "📥 Liste téléphones",
            sms_list,
            "telephones_benevoles.txt",
            "text/plain",
            
        )


# ============================================
# PAGES
# ============================================

def page_accueil(conn, geo):
    """Page d'accueil"""
    st.markdown("### 🎁 Bienvenue sur Guigno-Map!")
    st.info("Sélectionnez votre mode dans le menu de gauche pour commencer.")
    
    st.markdown("---")
    st.markdown("#### 📊 Aperçu de la collecte")
    
    stats = db.extended_stats()
    render_metrics(stats)
    
    df_all = db.list_streets()
    if not df_all.empty:  # Liste non vide
        m = create_map(df_all, geo)
        st_folium(m, height=800, width=None, returned_objects=[])

def page_accueil_v2(geo):
    """Page d'accueil festive avec compte à rebours"""
    
    # Compte à rebours jusqu'au 1er décembre
    target = datetime(2025, 12, 1, 8, 0, 0)
    now = datetime.now()
    diff = target - now
    
    if diff.days > 0:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #c41e3a, #165b33);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h2 style="color: #FFD700; margin: 0;">⏰ Compte à rebours Guignolée</h2>
            <div style="font-size: 3rem; color: white; margin: 1rem 0;">
                {diff.days} jours {diff.seconds//3600} heures
            </div>
            <p style="color: rgba(255,255,255,0.9);">avant le grand jour!</p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #FFD700, #FFA500);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h2 style="color: #c41e3a; margin: 0;">🎉 C'EST AUJOURD'HUI!</h2>
            <div style="font-size: 2rem; color: #165b33; margin: 1rem 0;">
                Bonne Guignolée 2025!
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # Hero section festif
    st.markdown("""
    <div style="
        text-align: center;
        padding: 3rem 1rem;
        background: linear-gradient(135deg, rgba(196,30,58,0.1), rgba(22,91,51,0.1));
        border-radius: 20px;
        margin-bottom: 2rem;
    ">
        <h1 style="font-size: 3rem; margin: 0;">🎄 Bienvenue sur Guigno-Map 🎄</h1>
        <p style="font-size: 1.3rem; color: #666; margin: 1rem 0;">
            Votre plateforme digitale pour la Guignolée 2025
        </p>
        <p style="color: #888;">
            Gérez efficacement votre collecte de denrées avec une interface moderne
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Stats visuelles améliorées
    stats = db.extended_stats()
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    st.markdown("### 📊 État de la collecte en temps réel")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #22c55e, #16a34a);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(34,197,94,0.3);
        ">
            <div style="font-size: 3rem;">🏘️</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats['total']}</div>
            <div>Total Rues</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(59,130,246,0.3);
        ">
            <div style="font-size: 3rem;">✅</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats['done']}</div>
            <div>Complétées</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #f59e0b, #d97706);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(245,158,11,0.3);
        ">
            <div style="font-size: 3rem;">⏳</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats.get('partial', 0)}</div>
            <div>En Cours</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #c41e3a, #165b33);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(196,30,58,0.3);
        ">
            <div style="font-size: 3rem;">🎯</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{progress:.0f}%</div>
            <div>Progression</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Barre de progression globale
    st.markdown("### 🎄 Progression globale de la collecte")
    st.progress(progress / 100)
    
    # Carte festive
    st.markdown(f"### 🗺️ Vue d'ensemble de {config_ville.VILLE_NOM}")
    df_all = db.list_streets()
    if not df_all.empty:  # Liste non vide
        m = create_map(df_all, geo)
        st_folium(m, height=750, width=None, returned_objects=[])
    
    # CSS pour réduire l'espace après la carte
    st.markdown("""
    <style>
    div[data-testid="stVerticalBlock"] > div:has(iframe) {
        margin-bottom: 0 !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Call to action
    st.markdown("""
    <div style="
        text-align: center;
        padding: 2rem;
        background: linear-gradient(135deg, rgba(255,215,0,0.1), rgba(255,215,0,0.05));
        border: 2px solid rgba(255,215,0,0.3);
        border-radius: 15px;
        margin-top: 1rem;
    ">
        <h3>🎅 Prêt à participer ?</h3>
        <p>Choisissez votre rôle dans le menu de gauche pour commencer</p>
        <p style="font-size: 0.9rem; color: #666;">
            Bénévoles : Accédez à vos rues assignées<br>
            Gestionnaires : Supervisez toute la collecte
        </p>
    </div>
    """, unsafe_allow_html=True)

def page_benevole(geo):
    """Interface bénévole moderne avec vue limitée"""
    
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        render_login_card("benevole")
        return
    
    team_id = st.session_state.auth["team_id"]
    
    # Header d'équipe personnalisé
    st.markdown(f"""
    <div style="
        background: linear-gradient(135deg, #165b33, #c41e3a);
        padding: 1.5rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
    ">
        <h2 style="color: white; margin: 0;">🎅 Équipe {team_id}</h2>
        <p style="color: #FFD700; margin: 0.5rem 0 0 0;">Bonne collecte!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Stats de l'équipe
    df_team = db.list_streets(team=team_id)
    if df_team.empty:  # Liste vide
        st.warning("Aucune rue assignée. Contactez votre superviseur.")
        return
    
    done = len(df_team[df_team['status'] == 'terminee'])
    total = len(df_team)
    progress = (done / total * 100) if total > 0 else 0
    
    # Mini dashboard équipe
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("📌 Vos rues", total)
    with col2:
        st.metric("✅ Complétées", done)
    with col3:
        st.metric("🎯 Progression", f"{progress:.0f}%")
    
    # Système de badges
    show_team_badges(team_id)
    
    # Barre de progression
    st.progress(progress / 100)
    
    # Tabs modernisés
    tab1, tab2, tab3 = st.tabs(["🗺️ Ma carte", "📝 Collecte", "📊 Historique"])
    
    with tab1:
        # CARTE LIMITÉE AUX RUES DE L'ÉQUIPE
        st.markdown("### Vos rues assignées")
        
        # Créer une carte avec SEULEMENT les rues de l'équipe
        m = folium.Map(
            location=[45.7475, -73.6005],
            zoom_start=14,
            tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager/{z}/{x}/{y}.png',
            attr='© CARTO'
        )
        
        # Filtrer geo pour n'afficher QUE les rues de l'équipe
        team_streets = df_team['name'].tolist()
        
        for street_name in team_streets:
            if street_name in geo:
                status = df_team[df_team['name'] == street_name]['status'].iloc[0]
                
                # Couleurs selon statut
                colors = {
                    'terminee': '#22c55e',
                    'en_cours': '#f59e0b',
                    'a_faire': '#ef4444'
                }
                color = colors.get(status, '#ef4444')
                
                # Ajouter les segments de cette rue
                for path in geo[street_name]:
                    if path and len(path) >= 2:
                        folium.PolyLine(
                            path,
                            color=color,
                            weight=8,  # Plus épais pour mobile
                            opacity=0.9,
                            tooltip=f"{street_name} - {status.replace('_', ' ').title()}"
                        ).add_to(m)
        
        # Centrer sur les rues de l'équipe
        if team_streets and team_streets[0] in geo:
            first_street = geo[team_streets[0]][0]
            if first_street:
                m.location = first_street[0]
        
        st_folium(m, height=650, width=None, returned_objects=[])
    
    with tab2:
        st.markdown("### ✅ Checklist de collecte")
        
        # Liste interactive des rues
        for _, row in df_team.iterrows():
            name = str(row.get('name', '')) if pd.notna(row.get('name', '')) else ''
            status = row.get('status', 'a_faire')
            status = status if pd.notna(status) else 'a_faire'
            notes = str(row.get('notes', '0')) if pd.notna(row.get('notes', '0')) else '0'
            
            # Carte de rue stylisée
            status_emoji = {'terminee': '✅', 'en_cours': '🚶', 'a_faire': '⭕'}
            status_color = {'terminee': '#22c55e', 'en_cours': '#f59e0b', 'a_faire': '#ef4444'}
            
            with st.expander(f"{status_emoji.get(status, '⭕')} **{name}** ({notes} notes)"):
                
                # Changement rapide de statut
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("⭕ À faire", key=f"todo_{name}"):
                        db.set_status(name, 'a_faire')
                        st.rerun()
                with col2:
                    if st.button("⏳ En cours", key=f"progress_{name}"):
                        db.set_status(name, 'en_cours')
                        st.rerun()
                with col3:
                    if st.button("✅ Terminée", key=f"done_{name}"):
                        db.set_status(name, 'terminee')
                        st.rerun()
                
                st.markdown("---")
                
                # Ajout de note rapide
                st.markdown("**Ajouter une note:**")
                with st.form(f"note_{name}", clear_on_submit=True):
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        num = st.text_input("N°", placeholder="123")
                    with col2:
                        note = st.text_input("Note", placeholder="Personne absente")
                    
                    if st.form_submit_button("'ûï Ajouter"):
                        if num and note:
                            db.add_note_for_address(name, team_id, num, note)
                            st.success("Note ajoutée!")
                            st.rerun()
                
                # Notes existantes
                notes_list = db.get_street_addresses_with_notes(name)
                if notes_list:  # Liste non vide
                    st.markdown("**Notes existantes:**")
                    for n in notes_list:
                        st.markdown(f"• **{n['address_number']}** : {n['comment']}")

                # ===== 📌 Adresses de la rue (nouveau) =====
                with st.expander("📌 Adresses de la rue", expanded=False):
                    if st.button("Afficher les adresses", key=f"show_addr_{name}"):
                        try:
                            addrs = db.get_addresses_by_street(name)
                        except Exception:
                            addrs = []
                        if addrs:
                            import pandas as pd
                            df_addr = pd.DataFrame(addrs)
                            st.dataframe(df_addr.head(300), use_container_width=True)
                            # Ajout note rapide liée à un numéro
                            colA, colB = st.columns([1,3])
                            with colA:
                                sel_num = st.selectbox(
                                    "Numéro",
                                    options=[a["house_number"] for a in addrs][:300],
                                    key=f"addr_sel_{name}",
                                )
                            with colB:
                                txt_note = st.text_input(
                                    "Note", key=f"addr_note_{name}", placeholder="Ex.: Absent / Don / Refus…"
                                )
                            if st.button("'ûï Ajouter note", key=f"addr_add_{name}"):
                                ok = False
                                # team_id déjà dispo dans la fonction (variable plus haut)
                                try:
                                    ok = bool(db.add_note_for_address(name, team_id, sel_num, txt_note))
                                except Exception:
                                    try:
                                        ok = bool(db.add_street_note(name, team_id, sel_num, txt_note))
                                    except Exception:
                                        ok = False
                                if ok:
                                    st.success(f"Note ajoutée pour {name} #{sel_num}")
                                    st.rerun()
                                else:
                                    st.error("Échec de l'ajout de note")
                        else:
                            st.info("Aucune adresse trouvée pour cette rue")
    
    with tab3:
        st.markdown("### 📊 Votre historique")
        try:
            notes = db.get_team_notes(team_id)
            if notes:  # Liste non vide
                st.dataframe(to_dataframe(notes), use_container_width=True)
            else:
                st.info("Aucune note encore")
        except:
            st.info("Historique non disponible")

def page_benevole_v2(geo):
    """Interface bénévole moderne v4.1 avec vue 'Mes rues'"""
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        # Afficher la page de connexion bénévole
        return page_benevole(geo)
    
    # Interface bénévole connecté avec tabs
    st.header("🎅 Espace Bénévole")
    team_id = st.session_state.auth.get("team", "Équipe inconnue")
    st.markdown(f"**Équipe:** {team_id}")
    
    # Tabs pour bénévoles
    tabs = st.tabs([
        "🏘️ Mes rues",
        "🗺️ Carte de terrain", 
        "📝 Journal d'activité"
    ])
    
    with tabs[0]:
        # Nouvelle vue "Mes rues" v4.1
        page_benevole_mes_rues()
    
    with tabs[1]:
        # Carte traditionnelle (réutilise l'ancienne interface)
        page_benevole(geo)
    
    with tabs[2]:
        # Journal d'activité de l'équipe
        st.markdown("### 📝 Journal d'activité de votre équipe")
        try:
            # Afficher les activités récentes de l'équipe  
            activities = db.recent_activity(20)
            
            if activities:
                team_activities = [a for a in activities if a.get('team_id') == team_id]
                for activity in team_activities:
                    action = activity.get('action', '')
                    details = activity.get('details', '')
                    created_at = activity.get('created_at', '')
                    st.markdown(f"**{created_at}** - {action}: {details}")
            else:
                st.info("Aucune activité enregistrée pour votre équipe")
                
        except Exception as e:
            st.info("Journal d'activité temporairement indisponible")
            st.caption(f"Erreur: {e}")

def ui_assign_addresses_admin():
    """UI d'assignation par adresses avec filtres, pagination et stats complètes (admin seulement)"""
    # Vérifier les permissions admin
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        st.error("⛔ Accès réservé aux administrateurs")
        return
    
    st.subheader("📍 Assignation d'adresses", anchor=False)
    
    # === STATISTIQUES GLOBALES ===
    try:
        stats = db.stats_addresses()
        
        # Affichage des métriques en haut
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total adresses", f"{stats['total']:,}")
        
        with col2:
            st.metric("Non assignées", f"{stats['unassigned']:,}")
        
        with col3:
            st.metric("Assignées", f"{stats['assigned']:,}")
        
        with col4:
            st.metric("Géocodées", f"{stats['percent_geocoded']}%")
        
        # Répartition par équipe dans un expander
        if stats['per_team']:
            with st.expander(f"📊 Répartition par équipe ({len(stats['per_team'])} équipes actives)", expanded=False):
                team_df = pd.DataFrame([
                    {'Équipe': team, 'Adresses': count, 'Pourcentage': round(count/stats['total']*100, 1)}
                    for team, count in sorted(stats['per_team'].items(), key=lambda x: x[1], reverse=True)
                ])
                st.dataframe(team_df, use_container_width=True, hide_index=True)
        
    except Exception as e:
        st.error(f"❌ Erreur lors du chargement des statistiques: {e}")
        stats = {'total': 0, 'unassigned': 0, 'assigned': 0, 'percent_geocoded': 0.0, 'per_team': {}}
    
    st.divider()
    
    # === FILTRES ===
    st.markdown("### 🔍 Filtres et recherche")
    
    with st.container():
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            search_text = st.text_input(
                "🔍 Recherche globale", 
                value="",
                placeholder="Ex: Avenue Dupuis, 123, Boulevard...",
                key="search_filter_addr",
                help="Recherche dans le nom de rue et numéro"
            )
        
        with col2:
            street_filter = st.text_input(
                "🛣️ Filtrer par rue", 
                value="",
                placeholder="Ex: Avenue, Cantin...",
                key="street_filter_addr",
                help="Filtre spécifique sur le nom de rue"
            )
        
        with col3:
            # Récupération des secteurs disponibles
            try:
                with db.get_conn() as conn:
                    sectors = conn.execute("""
                        SELECT DISTINCT sector 
                        FROM addresses 
                        WHERE sector IS NOT NULL AND sector != ''
                        ORDER BY sector
                    """).fetchall()
                    sector_options = ["Tous"] + [s[0] for s in sectors]
            except Exception:
                sector_options = ["Tous"]
            
            selected_sector = st.selectbox(
                "🏘️ Secteur",
                options=sector_options,
                index=0,
                key="sector_filter_addr",
                help="Filtrer par secteur géographique"
            )
    
    # === CONFIGURATION DE LA PAGINATION ===
    col1, col2 = st.columns([1, 1])
    with col1:
        limit_per_page = st.selectbox(
            "📄 Adresses par page",
            options=[20, 50, 100, 200],
            index=1,  # 50 par défaut
            key="limit_per_page"
        )
    
    # === RÉCUPÉRATION DES ADRESSES ===
    try:
        # Construire les paramètres de filtrage
        filter_params = {
            'limit': limit_per_page,
            'search': search_text.strip() if search_text.strip() else None,
            'street': street_filter.strip() if street_filter.strip() else None,
            'sector': selected_sector if selected_sector != "Tous" else None
        }
        
        # Récupérer les adresses non assignées
        unassigned_df = db.get_unassigned_addresses(**filter_params)
        
        if unassigned_df.empty:
            filter_desc = []
            if search_text.strip(): filter_desc.append(f"recherche '{search_text}'")
            if street_filter.strip(): filter_desc.append(f"rue '{street_filter}'")
            if selected_sector != "Tous": filter_desc.append(f"secteur '{selected_sector}'")
            
            if filter_desc:
                st.info(f"🔍 Aucune adresse non assignée trouvée pour: {', '.join(filter_desc)}")
            else:
                st.success("✅ Toutes les adresses sont assignées !")
            return
        
        # === SÉLECTION DES ÉQUIPES ===
        try:
            teams_list = db.list_teams()
            team_options = [f"{team['name']} ({team['id']})" for team in teams_list if team['id'] != 'ADMIN']
        except Exception:
            team_options = []
        
        if not team_options:
            st.warning("⚠️ Aucune équipe disponible pour l'assignation")
            return
        
        col1, col2 = st.columns([2, 1])
        with col1:
            selected_team = st.selectbox(
                "� Équipe destinataire",
                options=team_options,
                index=0,
                key="team_selector_addr",
                help="Équipe qui recevra les adresses sélectionnées"
            )
        
        # === TABLE AVEC SÉLECTION MULTIPLE ===
        st.markdown(f"### 📍 Adresses non assignées ({len(unassigned_df)} trouvées)")
        
        # Préparer les données pour l'affichage avec sélection
        display_df = unassigned_df.copy()
        display_df['Sélectionner'] = False
        display_df = display_df[['Sélectionner', 'id', 'street_name', 'house_number', 'sector']]
        display_df.columns = ['Sélectionner', 'ID', 'Rue', 'Numéro', 'Secteur']
        
        # Table interactive avec sélection
        edited_df = st.data_editor(
            display_df,
            column_config={
                "Sélectionner": st.column_config.CheckboxColumn(
                    "Sélectionner",
                    help="Cochez pour sélectionner cette adresse",
                    default=False,
                ),
                "ID": st.column_config.NumberColumn("ID", disabled=True),
                "Rue": st.column_config.TextColumn("Rue", disabled=True),
                "Numéro": st.column_config.TextColumn("Numéro", disabled=True),
                "Secteur": st.column_config.TextColumn("Secteur", disabled=True),
            },
            disabled=["ID", "Rue", "Numéro", "Secteur"],
            hide_index=True,
            use_container_width=True,
            key="address_selection_table"
        )
        
        # Récupérer les adresses sélectionnées
        selected_mask = edited_df['Sélectionner']
        selected_addresses = edited_df[selected_mask]
        
        if len(selected_addresses) > 0:
            st.info(f"📋 {len(selected_addresses)} adresse(s) sélectionnée(s)")
            
            # === BOUTONS D'ACTION ===
            col1, col2, col3 = st.columns([1, 1, 1])
            
            with col1:
                if st.button(
                    f"🎯 Assigner à {selected_team.split('(')[0].strip()}",
                    type="primary",
                    use_container_width=True,
                    key="assign_button"
                ):
                    try:
                        # Extraire l'ID de l'équipe
                        team_id = selected_team.split("(")[-1].rstrip(")")
                        selected_ids = selected_addresses['ID'].tolist()
                        
                        # Assigner les adresses
                        success_count = db.assign_addresses_to_team(selected_ids, team_id)
                        
                        if success_count > 0:
                            st.success(f"✅ {success_count} adresse(s) assignée(s) à l'équipe {team_id}")
                            st.info("🔄 Rechargement des données...")
                            
                            # Log du succès (print pour debug)
                            print(f"Admin: {success_count} addresses assigned to team {team_id}")
                            
                            # Rafraîchir
                            time.sleep(1)
                            st.rerun()
                        else:
                            st.error("❌ Aucune adresse n'a pu être assignée")
                            print(f"Failed to assign addresses to team {team_id}")
                            
                    except Exception as e:
                        st.error(f"❌ Erreur lors de l'assignation: {e}")
                        print(f"Error assigning addresses: {e}")
            
            with col2:
                # Bouton de sélection rapide
                if st.button("☑️ Tout sélectionner", use_container_width=True):
                    # Forcer la sélection de toutes les lignes
                    for i in range(len(edited_df)):
                        edited_df.loc[i, 'Sélectionner'] = True
                    st.rerun()
            
            with col3:
                # Bouton de déselection
                if st.button("⬜ Tout désélectionner", use_container_width=True):
                    # Forcer la déselection
                    for i in range(len(edited_df)):
                        edited_df.loc[i, 'Sélectionner'] = False
                    st.rerun()
        
        # === GESTION DES ÉQUIPES (SECTION RÉINITIALISATION) ===
        if stats['per_team']:
            st.divider()
            st.markdown("### 🔄 Gestion des assignations")
            
            col1, col2 = st.columns([2, 1])
            with col1:
                team_to_clear = st.selectbox(
                    "🗑️ Réinitialiser toutes les assignations d'une équipe",
                    options=["Sélectionner une équipe..."] + team_options,
                    index=0,
                    key="team_clear_selector",
                    help="ATTENTION: Ceci désassignera TOUTES les adresses de l'équipe"
                )
            
            with col2:
                if team_to_clear != "Sélectionner une équipe...":
                    team_clear_id = team_to_clear.split("(")[-1].rstrip(")")
                    team_clear_name = team_to_clear.split("(")[0].strip()
                    
                    if st.button(
                        f"⚠️ Confirmer réinitialisation",
                        type="secondary",
                        use_container_width=True,
                        help=f"Désassigner toutes les adresses de {team_clear_name}"
                    ):
                        try:
                            cleared_count = db.clear_team_assignments(team_clear_id)
                            
                            if cleared_count > 0:
                                st.success(f"✅ {cleared_count} adresse(s) désassignée(s) de l'équipe {team_clear_name}")
                                st.info("🔄 Rechargement des données...")
                                
                                # Log du succès (print pour debug)
                                print(f"Admin: {cleared_count} addresses cleared from team {team_clear_id}")
                                
                                time.sleep(1)
                                st.rerun()
                            else:
                                st.info(f"ℹ️ Aucune adresse n'était assignée à l'équipe {team_clear_name}")
                                
                        except Exception as e:
                            st.error(f"❌ Erreur lors de la réinitialisation: {e}")
                            print(f"Error clearing team assignments: {e}")
        
        # === AFFICHAGE CARTE (si dans config_ville) ===
        if len(selected_addresses) > 0:
            st.divider()
            st.markdown("### 🗺️ Localisation des adresses sélectionnées")
            
            # Vérifier si on a des coordonnées
            geocoded_count = 0
            try:
                for _, addr in selected_addresses.iterrows():
                    addr_full = unassigned_df[unassigned_df['id'] == addr['ID']].iloc[0]
                    if pd.notna(addr_full.get('latitude')) and pd.notna(addr_full.get('longitude')):
                        geocoded_count += 1
            except:
                pass
            
            if geocoded_count > 0:
                # Utiliser les coordonnées moyennes ou centre ville
                center = [config_ville.VILLE_CENTRE[0], config_ville.VILLE_CENTRE[1]]
                zoom = 13
                
                # Créer la carte
                m = folium.Map(location=center, zoom_start=zoom, tiles="OpenStreetMap")
                
                # Ajouter les limites de la ville si disponibles
                if hasattr(config_ville, 'VILLE_BOUNDS'):
                    bounds = config_ville.VILLE_BOUNDS
                    folium.Rectangle(
                        bounds=[[bounds['south'], bounds['west']], [bounds['north'], bounds['east']]],
                        color='blue',
                        fill=False,
                        weight=2,
                        opacity=0.3
                    ).add_to(m)
                
                # Ajouter les marqueurs
                for _, addr in selected_addresses.iterrows():
                    try:
                        addr_full = unassigned_df[unassigned_df['id'] == addr['ID']].iloc[0]
                        if pd.notna(addr_full.get('latitude')) and pd.notna(addr_full.get('longitude')):
                            folium.Marker(
                                location=[addr_full['latitude'], addr_full['longitude']],
                                popup=f"{addr['Rue']} {addr['Numéro']}",
                                tooltip=f"{addr['Rue']} {addr['Numéro']}",
                                icon=folium.Icon(color='red', icon='home')
                            ).add_to(m)
                    except:
                        continue
                
                st_folium(m, height=400, width=None, returned_objects=[])
                st.caption(f"📍 {geocoded_count}/{len(selected_addresses)} adresses géolocalisées affichées")
            else:
                st.info("ℹ️ Aucune adresse sélectionnée n'est géolocalisée pour l'affichage sur carte")
    
    except Exception as e:
        st.error(f"❌ Erreur lors du chargement des adresses: {e}")
        print(f"Error in ui_assign_addresses_admin: {e}")
        st.info("Fonctionnalité temporairement indisponible")


def page_gestionnaire_v2(geo):
    """Interface gestionnaire moderne (ancien superviseur)"""
    st.header("👤 Tableau de Bord Gestionnaire")
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        render_login_card("gestionnaire")
        return
    
    # Dashboard moderne
    render_dashboard_gestionnaire(geo)
    
    # Tabs
    tabs = st.tabs([
        "📊 Vue d'ensemble",
        "👥 Équipes",
        "🗺️ Assignation",
        "📊 Export",
        "🛠️ Tech"
    ])
    
    with tabs[0]:
        # Carte générale
        st.markdown("### Carte générale")
        df_all = db.list_streets()
        if not df_all.empty:  # Liste non vide
            m = create_map(df_all, geo)
            st_folium(m, height=800, width=None, returned_objects=[])
        
        # Activité récente
        st.markdown("### Activité récente")
        try:
            recent = db.recent_activity(limit=10)
            if recent:  # Liste non vide
                st.dataframe(to_dataframe(recent), use_container_width=True)
            else:
                st.info("Aucune activité récente")
        except:
            st.info("Historique d'activité non disponible")
    
    with tabs[1]:
        # Gestion des équipes
        st.subheader("👥 Gestion des équipes", anchor=False)
        
        # === Formulaire de création d'équipe (robuste) ===
        with st.expander("➕ Créer une nouvelle équipe", expanded=False):
            with st.form("create_team_form", clear_on_submit=True):
                team_id_in = st.text_input(
                    "Identifiant d'équipe", 
                    key="new_team_id", 
                    placeholder="Ex: EQUIPE1",
                    help="Lettres et chiffres uniquement, max 20 caractères"
                )
                team_name_in = st.text_input(
                    "Nom d'équipe", 
                    key="new_team_name", 
                    placeholder="Ex: Équipe Centre",
                    help="Nom descriptif de l'équipe"
                )
                
                # Toggle pour afficher/masquer les mots de passe
                show_pw = st.checkbox("Afficher les mots de passe", value=False)
                pw_type = "default" if show_pw else "password"
                
                pwd_in = st.text_input(
                    "Mot de passe", 
                    type=pw_type, 
                    key="new_team_pwd", 
                    placeholder="Minimum 4 caractères",
                    help="Tout caractère accepté, min 4 / max 128"
                )
                pwd_conf = st.text_input(
                    "Confirmer le mot de passe", 
                    type=pw_type, 
                    key="new_team_pwd_conf", 
                    placeholder="Retapez le mot de passe",
                    help="Doit correspondre au mot de passe ci-dessus"
                )
                
                submitted = st.form_submit_button("✅ Créer l'équipe")

            if submitted:
                # Validation avec validators.py
                ok_id, team_id = validate_and_clean_input("team_id", team_id_in)
                ok_name, team_name = validate_and_clean_input("text", team_name_in)
                ok_pw, password = validate_and_clean_input("password", pwd_in)
                
                if not ok_id:
                    st.error("❌ Identifiant d'équipe invalide (lettres/chiffres, max 20)")
                elif not ok_name:
                    st.error("❌ Nom d'équipe invalide ou vide")
                elif not ok_pw:
                    st.error("❌ Mot de passe invalide (minimum 4 caractères)")
                elif pwd_in != pwd_conf:
                    st.error("❌ Les mots de passe ne correspondent pas")
                else:
                    # Tentative de création avec db.create_team
                    try:
                        created = db.create_team(team_id, team_name, password)
                        if created:
                            st.toast(f"✅ Équipe {team_id} créée avec succès", icon="✅")
                            st.rerun()
                        else:
                            st.error("❌ Échec de création (ID déjà existant ?)")
                    except Exception as e:
                        st.error(f"❌ Erreur lors de la création: {e}")
        
        # === Liste des équipes (sans doublon de titre) ===
        try:
            teams_df = db.get_all_teams()
            if teams_df:  # Liste non vide
                st.dataframe(to_dataframe(teams_df), use_container_width=True)
            else:
                st.info("Aucune équipe créée")
        except Exception:
            st.info("Liste des équipes non disponible")

        # === 🔐 Modifier / réinitialiser le mot de passe ===
        with st.expander("🔐 Modifier / réinitialiser le mot de passe", expanded=False):
            # récupérer les équipes
            try:
                teams = db.get_teams_list()
                options = [f"{t[1]} ({t[0]})" for t in teams] if teams else []
            except Exception:
                options = []
            
            with st.form("pwd_team_form", clear_on_submit=False):
                choice = st.selectbox("Équipe", options=options, index=0 if options else None)
                show = st.checkbox("Afficher le mot de passe", value=False)
                ty = "default" if show else "password"
                new1 = st.text_input("Nouveau mot de passe", type=ty, key="pwd_new1")
                new2 = st.text_input("Confirmer", type=ty, key="pwd_new2")
                colU, colR = st.columns(2)
                do_update = colU.form_submit_button("✅ Mettre à jour", use_container_width=True)
                do_reset  = colR.form_submit_button("🎲 Réinitialiser (aléatoire)", use_container_width=True)
            
            # traitement
            team_id = ""
            if choice:
                team_id = choice.split("(")[-1].rstrip(")")
            
            if do_update:
                if not team_id:
                    st.error("Aucune équipe sélectionnée")
                elif len(new1) < 4:
                    st.error("Mot de passe trop court (min 4 caractères)")
                elif new1 != new2:
                    st.error("La confirmation ne correspond pas")
                else:
                    try:
                        ok = db.update_team_password(team_id, new1)
                        if ok:
                            st.success(f"Mot de passe mis à jour pour {team_id}")
                            st.rerun()
                        else:
                            st.error("Échec de la mise à jour")
                    except Exception as e:
                        st.error(f"Erreur: {e}")
            
            if do_reset:
                if not team_id:
                    st.error("Aucune équipe sélectionnée")
                else:
                    try:
                        newpwd = db.reset_team_password(team_id)
                        if newpwd:
                            st.success(f"Nouveau mot de passe généré pour {team_id}")
                            st.code(newpwd)  # à copier maintenant; ne sera plus affiché ensuite
                        else:
                            st.error("Échec de la réinitialisation")
                    except Exception as e:
                        st.error(f"Erreur: {e}")
    
    with tabs[2]:
        # Assignation v4.1
        page_assignations_v41()
    
    with tabs[3]:
        # Assignation par adresses
        ui_assign_addresses_admin()
    
    with tabs[4]:
        # Export amélioré v4.1
        page_export_gestionnaire_v41()

    with tabs[5]:
        st.markdown("### 🛠 Opérations techniques (protégées)")

        # -- PIN stocké dans secrets (config.toml -> [secrets] TECH_PIN="xxxx")
        TECH_PIN = st.secrets.get("TECH_PIN", "1234")  # Fallback pour dev

        if "tech_ok" not in st.session_state:
            st.session_state.tech_ok = False

        if not st.session_state.tech_ok:
            pin = st.text_input("Entrer le PIN technique", type="password")
            if st.button("Déverrouiller"):
                if TECH_PIN and pin == TECH_PIN:
                    st.session_state.tech_ok = True
                    st.success("Accès technique déverrouillé.")
                    st.rerun()
                else:
                    st.error("PIN invalide.")
            st.stop()

        st.info("⚠️ Ces actions sont lourdes et n'affectent pas les statuts/notes. Elles régénèrent les caches OSM.")

        # --- Reconstruire le cache géométrique (lourd)
        with st.expander("🔄 Reconstruire cache OSM (géométries)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirm = st.checkbox("Je comprends les implications")
            with col2:
                safety = st.text_input('Écrire "REBUILD" pour confirmer')

            if st.button("Lancer la reconstruction"):
                if confirm and safety.strip().upper() == "REBUILD":
                    with st.spinner("Construction du cache…"):
                        build_geometry_cache()       # reconstruit le fichier osm_cache.json
                        st.cache_data.clear()        # purge cache Streamlit
                    st.success("✅ Cache OSM mis à jour (géométries).")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Reconstruire/Importer le cache des adresses
        with st.expander("📍 Mettre à jour les adresses (OSM)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirmA = st.checkbox("Je confirme")
            with col2:
                safetyA = st.text_input('Écrire "IMPORT" pour confirmer')

            if st.button("Lancer la mise à jour des adresses"):
                if confirmA and safetyA.strip().upper() == "IMPORT":
                    with st.spinner("Téléchargement des adresses OSM…"):
                        build_addresses_cache()
                        addr_cache = load_addresses_cache()
                        count = db.import_addresses_from_cache(addr_cache)
                    st.success(f"✅ {count} adresses importées depuis OSM.")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Gestion des backups
        with st.expander("🗃️ Gestion des backups", expanded=False):
            backup_mgr = db.get_backup_manager()  # BackupManager pour DB SQLite
            
            col1, col2 = st.columns([2, 1])
            with col1:
                if st.button("🔄 Créer un backup manuel"):
                    backup_file = backup_mgr.create_backup("manual")
                    if backup_file:
                        st.success(f"Backup créé : {Path(backup_file).name}")
            
            with col2:
                if st.button("✅ Voir les backups"):
                    backups = backup_mgr.list_backups()
                    if backups:
                        for backup in backups[:5]:  # Montrer les 5 derniers
                            st.text(f"• {backup['name']} ({backup['size']})")
                    else:
                        st.info("Aucun backup disponible")

def page_superviseur(conn, geo):
    """Interface superviseur"""
    st.header("🎯 Tableau de Bord Superviseur")
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        render_login_card("superviseur")
        return
    
    # Dashboard moderne
    render_dashboard_gestionnaire(geo)
    
    # Tabs
    tabs = st.tabs([
        "📊 Vue d'ensemble",
        "👥 Équipes",
        "🗺️ Assignation",
        "📊 Export",
        "🛠️ Tech"
    ])
    
    with tabs[0]:
        # Carte générale
        st.markdown("### Carte générale")
        df_all = db.list_streets()
        if not df_all.empty:  # Liste non vide
            m = create_map(df_all, geo)
            st_folium(m, height=800, width=None, returned_objects=[])
        
        # Activité récente
        st.markdown("### Activité récente")
        recent = db.recent_activity(limit=10)
        if recent:  # Liste non vide
            st.dataframe(to_dataframe(recent), use_container_width=True)
    
    with tabs[1]:
        # Gestion des équipes
        st.markdown("### Gestion des équipes")
        
        with st.expander("Créer une équipe"):
            with st.form("new_team", clear_on_submit=True):
                new_id = st.text_input("Identifiant")
                new_name = st.text_input("Équipe")
                new_pass = st.text_input("Mot de passe", type="password")
                new_pass_confirm = st.text_input("Confirmer le mot de passe", type="password")
                
                # Validation du mot de passe
                password_valid = True
                error_messages = []
                
                if new_pass or new_pass_confirm:  # Si au moins un champ est rempli
                    if len(new_pass) < 4:
                        password_valid = False
                        error_messages.append("Le mot de passe doit contenir au moins 4 caractères")
                    
                    if new_pass != new_pass_confirm:
                        password_valid = False
                        error_messages.append("Les mots de passe ne correspondent pas")
                
                # Affichage des erreurs
                if error_messages:
                    for msg in error_messages:
                        st.error(msg)
                
                # Bouton désactivé si validation échoue
                button_disabled = not (all([new_id, new_name, new_pass, new_pass_confirm]) and password_valid)
                
                if st.form_submit_button("Créer", disabled=button_disabled):
                    if all([new_id, new_name, new_pass]) and password_valid:
                        if db.create_team(new_id, new_name, new_pass):
                            st.success(f"Équipe {new_id} créée")
                            st.rerun()
        
        # Liste des équipes
        teams_df = db.get_all_teams()
        if teams_df:  # Liste non vide
            st.dataframe(to_dataframe(teams_df), use_container_width=True)
    
    with tabs[2]:
        # Assignation
        st.markdown("### Assignation des rues")
        
        unassigned = db.get_unassigned_streets()
        
        if unassigned:  # Liste non vide
            with st.form("assign"):
                team = st.selectbox("Équipe", db.teams())
                streets = st.multiselect("Rues", unassigned)
                
                if st.form_submit_button("Assigner"):
                    if team and streets:
                        db.assign_streets_to_team(streets, team)
                        st.success("Rues assignées!")
                        st.rerun()
        else:
            st.success("Toutes les rues sont assignées!")
        
        # Tableau des assignations
        df_all = db.list_streets()
        if not df_all.empty:  # Liste non vide
            st.dataframe(
                df_all[['name', 'sector', 'team', 'status']],
                use_container_width=True
            )
    
    with tabs[3]:
        # Export
        st.markdown("### Export des données")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                "📊 Export rues (CSV)",
                db.export_to_csv(),
                "rapport_rues.csv",
                "text/csv",
                
            )
        
        with col2:
            st.download_button(
                "📊 Export notes (CSV)",
                db.export_notes_csv(),
                "rapport_notes.csv",
                "text/csv",
                
            )

    with tabs[4]:
        st.markdown("### 🛠 Opérations techniques (protégées)")

        # -- PIN stocké dans secrets (config.toml -> [secrets] TECH_PIN="xxxx")  
        TECH_PIN = st.secrets.get("TECH_PIN", "1234")  # Fallback pour dev

        if "tech_ok" not in st.session_state:
            st.session_state.tech_ok = False

        if not st.session_state.tech_ok:
            pin = st.text_input("Entrer le PIN technique", type="password")
            if st.button("Déverrouiller"):
                if TECH_PIN and pin == TECH_PIN:
                    st.session_state.tech_ok = True
                    st.success("Accès technique déverrouillé.")
                    st.rerun()
                else:
                    st.error("PIN invalide.")
            st.stop()

        st.info("⚠️ Ces actions sont lourdes et n'affectent pas les statuts/notes. Elles régénèrent les caches OSM.")

        # --- Reconstruire le cache géométrique (lourd)
        with st.expander("🔄 Reconstruire cache OSM (géométries)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirm = st.checkbox("Je comprends les implications")
            with col2:
                safety = st.text_input('Écrire "REBUILD" pour confirmer')

            if st.button("Lancer la reconstruction"):
                if confirm and safety.strip().upper() == "REBUILD":
                    with st.spinner("Construction du cache…"):
                        build_geometry_cache()       # reconstruit le fichier osm_cache.json
                        st.cache_data.clear()        # purge cache Streamlit
                    st.success("✅ Cache OSM mis à jour (géométries).")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Reconstruire/Importer le cache des adresses
        with st.expander("📍 Mettre à jour les adresses (OSM)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirmA = st.checkbox("Je confirme")
            with col2:
                safetyA = st.text_input('Écrire "IMPORT" pour confirmer')

            if st.button("Lancer la mise à jour des adresses"):
                if confirmA and safetyA.strip().upper() == "IMPORT":
                    with st.spinner("Téléchargement des adresses OSM…"):
                        build_addresses_cache()
                        addr_cache = load_addresses_cache()
                        count = db.import_addresses_from_cache(addr_cache)
                    st.success(f"✅ {count} adresses importées depuis OSM.")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

# ============================================
# MAIN
# ============================================

# ================================================================================
# NOUVELLES FONCTIONS v4.1 - SUPERVISEUR ET BÉNÉVOLE
# ================================================================================

def page_assignations_v41():
    """Assignations : au choix par secteur (bulk) OU par rue (manuel)."""
    st.subheader("🗺️ Assignations", anchor=False)

    tabs = st.tabs(["🎯 Par secteur (rapide)", "🧭 Par rue (manuel)", "📋 Assignation simple"])

    # ========== TAB 1 : BULK PAR SECTEUR (inchangé) ==========
    with tabs[0]:
        try:
            unassigned_count = db.get_unassigned_streets_count()
        except Exception:
            # fallback si la fonction n'existe pas
            _df = db.list_streets()
            unassigned_count = int((_df["team"].isna() | (_df["team"] == "")).sum()) if not _df.empty else 0

        if unassigned_count > 0:
            st.info(f"⚠️ {unassigned_count} rue(s) non assignée(s)")

        with st.container():
            c1, c2, c3 = st.columns([1, 1.2, 0.7], vertical_alignment="bottom")

            with c1:
                try:
                    liste_secteurs = db.get_sectors_list()
                except Exception:
                    liste_secteurs = []
                secteur = st.selectbox(
                    "SECTEUR À ASSIGNER",
                    options=[""] + (liste_secteurs or []),
                    index=0,
                    key="assign_sector_v41",
                )

            with c2:
                try:
                    teams = db.get_teams_list()  # [(id, name), ...]
                except Exception:
                    teams = [(t, t) for t in (db.teams() or [])]
                team_display = st.selectbox(
                    "ÉQUIPE",
                    options=[""] + [f"{name} ({tid})" for (tid, name) in teams],
                    index=0,
                    key="assign_team_v41",
                )
                team = ""
                if team_display and team_display != "":
                    team = team_display.split("(")[-1].rstrip(")")

            with c3:
                if st.button("Assigner tout le secteur", use_container_width=True, disabled=not (secteur and team)):
                    try:
                        nb = db.bulk_assign_sector(secteur, team)
                        if nb > 0:
                            st.toast(f"✅ {nb} rue(s) assignée(s) à {team}", icon="✅")
                            st.rerun()
                        else:
                            st.toast("ℹ️ Aucune rue non assignée dans ce secteur", icon="ℹ️")
                    except Exception as e:
                        st.error(f"Erreur lors de l'assignation: {e}")

        st.markdown("### 📋 État des assignations")
        try:
            df = db.list_streets()
            if not df.empty:
                df_disp = df.assign(
                    Statut=df["status"].map(STATUS_TO_LABEL).fillna("À faire")
                ).rename(columns={"name": "Rue", "sector": "Secteur", "team": "Équipe"})[
                    ["Rue", "Secteur", "Équipe", "Statut"]
                ]
                st.dataframe(df_disp, use_container_width=True)
            else:
                st.info("Aucune rue trouvée")
        except Exception as e:
            st.error(f"Erreur d'affichage: {e}")

    # ========== TAB 2 : ASSIGNATION MANUELLE PAR RUE ==========
    with tabs[1]:
        # Équipe cible
        try:
            teams = db.get_teams_list()
        except Exception:
            teams = [(t, t) for t in (db.teams() or [])]
        team_display = st.selectbox(
            "ÉQUIPE CIBLE",
            options=[f"{name} ({tid})" for (tid, name) in teams] if teams else [],
            index=0 if teams else None,
            key="team_for_streets",
        )
        team_id = team_display.split("(")[-1].rstrip(")") if team_display else None

        # Source de rues (non assignées ou toutes)
        src = st.radio("Source", ["Rues non assignées", "Toutes les rues"], horizontal=True)

        # Données rues
        df = db.list_streets()
        if df.empty:
            st.info("Aucune rue dans la base.")
            return

        # Filtres
        q = st.text_input("🔎 Filtrer par nom (contient)…", "")
        sectors = sorted([s for s in df["sector"].dropna().unique().tolist() if str(s).strip()])
        sector_filter = st.selectbox("Secteur (optionnel)", options=["(Tous)"] + sectors, index=0)

        # Filtrage selon la source
        if src.startswith("Rues non"):
            mask_unassigned = df["team"].isna() | (df["team"].astype(str).str.strip() == "")
            work = df[mask_unassigned].copy()
        else:
            work = df.copy()

        # Appliquer filtres texte/secteur
        if q:
            work = work[work["name"].astype(str).str.contains(q, case=False, na=False)]
        if sector_filter != "(Tous)":
            work = work[work["sector"] == sector_filter]

        options = sorted(work["name"].dropna().unique().tolist())
        selected = st.multiselect("Rues à assigner", options=options, default=[])

        st.caption(f"{len(options)} rue(s) listée(s) • {len(selected)} sélectionnée(s)")
        do_overwrite = st.checkbox("Réassigner même si déjà affectée (écrase l'équipe actuelle)", value=True)

        colA, colB = st.columns([1, 1])
        with colA:
            if st.button("✅ Assigner les rues sélectionnées", use_container_width=True,
                         disabled=not (team_id and selected)):
                try:
                    if team_id:  # Vérification supplémentaire
                        db.assign_streets_to_team(selected, team_id)
                        st.success(f"{len(selected)} rue(s) assignée(s) à {team_id}")
                        st.rerun()
                except Exception as e:
                    st.error(f"Assignation échouée: {e}")

        with colB:
            # Affichage d'aperçu des rues choisies
            if selected:
                st.write("Aperçu :")
                st.dataframe(
                    work[work["name"].isin(selected)][["name", "sector", "team", "status"]]
                    .rename(columns={"name": "Rue", "sector": "Secteur", "team": "Équipe", "status": "Statut"}),
                    use_container_width=True
                )

    # ========== TAB 3 : ASSIGNATION SIMPLE PAR RUE ==========
    with tabs[2]:
        st.markdown("### 📋 Assignation par rue (simple)")
        
        # Récupérer les équipes disponibles  
        try:
            teams = db.get_teams_list()  # [(id, name), ...]
        except Exception:
            teams = [(t, t) for t in (db.teams() or [])]
        
        # Récupérer les rues non assignées
        try:
            unassigned_streets = db.get_unassigned_streets()
        except Exception:
            unassigned_streets = []
        
        if not teams:
            st.warning("Aucune équipe disponible. Créez d'abord une équipe.")
            return
            
        if not unassigned_streets:
            st.success("✅ Toutes les rues sont déjà assignées !")
            return
        
        # Interface de sélection
        with st.container():
            col1, col2 = st.columns([1, 2])
            
            with col1:
                team_options = [f"{name} ({tid})" for (tid, name) in teams]
                selected_team_display = st.selectbox(
                    "Équipe",
                    options=[""] + team_options,
                    index=0,
                    key="simple_assign_team"
                )
                
                # Extraire l'ID de l'équipe
                team_id = ""
                if selected_team_display and selected_team_display != "":
                    team_id = selected_team_display.split("(")[-1].rstrip(")")
            
            with col2:
                selected_streets = st.multiselect(
                    "Rues à assigner",
                    options=unassigned_streets,
                    default=[],
                    key="simple_assign_streets"
                )
        
        # Option de réassignation (masquée pour simplification)
        # do_overwrite = st.checkbox("Réassigner si déjà affectée", value=False)
        
        # Informations et validation
        st.caption(f"📊 {len(unassigned_streets)} rue(s) non assignée(s) • {len(selected_streets)} sélectionnée(s)")
        
        # Validation et bouton
        if not team_id or not selected_streets:
            if st.button("Assigner", disabled=True, use_container_width=True):
                pass
            if not team_id and not selected_streets:
                st.error("Sélectionnez au moins une rue et une équipe.")
            elif not team_id:
                st.error("Sélectionnez une équipe.")
            elif not selected_streets:
                st.error("Sélectionnez au moins une rue.")
        else:
            if st.button("Assigner", use_container_width=True):
                try:
                    # Appel à la fonction d'assignation
                    db.assign_streets_to_team(selected_streets, team_id)
                    st.toast(f"✅ {len(selected_streets)} rue(s) assignée(s) à {team_id}", icon="✅")
                    st.rerun()
                except Exception as e:
                    st.error(f"Erreur lors de l'assignation: {e}")


def page_export_gestionnaire_v41():
    """Page d'export v4.1 avec nouvelles fonctionnalités"""
    st.markdown("### 📥 Export des données")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Export CSV standard
        try:
            st.download_button(
                "📊 Export CSV Standard",
                db.export_to_csv(),
                "rapport_rues.csv",
                "text/csv",
                
            )
        except Exception as e:
            st.button("📊 CSV (Erreur)", disabled=True)
            st.caption(f"Erreur: {e}")
    
    with col2:
        # Export Excel professionnel
        try:
            from reports import ReportGenerator
            generator = ReportGenerator()
            excel_data = generator.generate_excel()
            st.download_button(
                "📊 Export Excel Pro",
                excel_data,
                "guignolee_2025_rapport.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                
            )
        except ImportError:
            st.button("📊 Excel (Installer xlsxwriter)", disabled=True)
        except Exception as e:
            st.button("📊 Excel (Erreur)", disabled=True)
            st.caption(f"Erreur: {e}")
    
    with col3:
        # Export PDF professionnel
        try:
            from reports import ReportGenerator
            generator = ReportGenerator()
            pdf_data = generator.generate_pdf()
            st.download_button(
                "📄 Export PDF Pro",
                pdf_data,
                "guignolee_2025_rapport.pdf",
                "application/pdf",
                
            )
        except ImportError:
            st.button("📄 PDF (Installer reportlab)", disabled=True)
        except Exception as e:
            st.button("📄 PDF (Erreur)", disabled=True)
            st.caption(f"Erreur: {e}")
    
    # Export CSV assignations (nouveau v4.1)
    st.markdown("---")
    st.markdown("### 📋 Export spécialisés v4.1")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Export CSV assignations
        try:
            assignations_data = db.get_assignations_export_data()
            if assignations_data:  # Liste non vide
                csv_data = pd.DataFrame(assignations_data).to_csv(index=False, encoding='utf-8')
                st.download_button(
                    "✅ Export CSV Assignations",
                    csv_data,
                    "assignations_secteurs.csv",
                    "text/csv", help="Colonnes: secteur, rue, équipe, statut"
                )
            else:
                st.button("📋 Assignations (Aucune donnée)", disabled=True)
        except Exception as e:
            st.button("✅ Assignations (Erreur)", disabled=True)
            st.caption(f"Erreur: {e}")
    
    with col2:
        # Export notes
        try:
            st.download_button(
                "📝 Export Notes",
                db.export_notes_csv(),
                "rapport_notes.csv",
                "text/csv",
                
            )
        except Exception as e:
            st.button("📝 Notes (Erreur)", disabled=True)
            st.caption(f"Erreur: {e}")
    
    # --- CSV d'assignation (export/import) ---
    st.markdown("---")
    st.markdown("### 📄 CSV d'assignation des rues")
    with st.expander("Exporter / Importer", expanded=False):
        c1, c2 = st.columns(2)
        with c1:
            if st.button("📤 Exporter le template (CSV)", use_container_width=True):
                try:
                    df = db.export_streets_template(include_assignments=False)
                    csv_data = df.to_csv(index=False).encode("utf-8")
                    st.download_button(
                        label="📥 Télécharger streets_template.csv",
                        data=csv_data,
                        file_name="streets_template.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                except Exception as e:
                    st.error(f"Erreur lors de l'export: {e}")
        with c2:
            up = st.file_uploader("📥 Importer votre CSV modifié", type=["csv"], key="csv_upload")
            if up is not None:
                try:
                    from io import BytesIO
                    # Convertir en BytesIO si nécessaire
                    if hasattr(up, 'read'):
                        file_content = up.read()
                        if isinstance(file_content, str):
                            file_like = BytesIO(file_content.encode('utf-8'))
                        else:
                            file_like = BytesIO(file_content)
                    else:
                        file_like = up
                    
                    res = db.upsert_streets_from_csv(file_like)
                    st.success(f"✅ Import terminé — inserted={res.get('inserted',0)}, updated={res.get('updated',0)}, skipped={res.get('skipped',0)}, errors={res.get('errors',0)}")
                    if res.get('inserted', 0) > 0 or res.get('updated', 0) > 0:
                        st.rerun()
                except Exception as e:
                    st.error(f"Erreur lors de l'import: {e}")

def page_benevole_mes_rues():
    """Vue 'Mes rues' pour bénévoles v4.1"""
    
    # Récupérer l'équipe du bénévole connecté
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        st.warning("Accès réservé aux bénévoles connectés")
        return
    
    team_id = st.session_state.auth.get("team")
    if not team_id:
        st.error("Équipe non identifiée")
        return
    
    st.markdown(f"### 🏘️ Mes rues assignées - Équipe {team_id}")
    
    try:
        # Récupérer les rues de l'équipe
        team_streets = db.get_team_streets(team_id)
        
        if not team_streets:  # Liste vide
            st.info("Aucune rue assignée à votre équipe pour le moment.")
            return
        
        # Afficher les statistiques de l'équipe
        total_streets = len(team_streets)
        done_streets = len([s for s in team_streets if s.get('status') == 'terminee'])
        in_progress = len([s for s in team_streets if s.get('status') == 'en_cours'])
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total rues", total_streets)
        with col2:
            st.metric("Terminées", done_streets)
        with col3:
            st.metric("En cours", in_progress)
        with col4:
            progress = (done_streets / total_streets * 100) if total_streets > 0 else 0
            st.metric("Progression", f"{progress:.1f}%")
        
        st.markdown("---")
        
        # Affichage par rue avec actions
        for street in team_streets:
            if isinstance(street, str):
                street_name = street
            else:
                street_name = street.get("name", street)
            street_name = street['street_name']
            current_status = street['status']
            notes_count = street['notes_count']
            
            with st.expander(f"🏘️ {street_name} ({street['sector']}) - {current_status.replace('_', ' ').title()}", 
                           expanded=current_status == 'en_cours'):
                
                col1, col2, col3 = st.columns([2, 1, 1])
                
                with col1:
                    st.markdown(f"**Secteur:** {street['sector']}")
                    st.markdown(f"**Statut actuel:** {current_status.replace('_', ' ').title()}")
                    if notes_count > 0:
                        st.markdown(f"**Notes existantes:** {notes_count}")
                
                with col2:
                    # Bouton "En cours"
                    if st.button(
                        "🔓 En cours", 
                        key=f"progress_{street_name}",
                        disabled=current_status == 'en_cours',
                        
                    ):
                        if db.update_street_status(street_name, 'en_cours', team_id):
                            st.toast(f"✅ {street_name} marquée en cours", icon="🚀")
                            st.rerun()
                        else:
                            st.error("Erreur lors de la mise à jour")
                
                with col3:
                    # Bouton "Terminée"
                    if st.button(
                        "✅ Terminée", 
                        key=f"done_{street_name}",
                        disabled=current_status == 'terminee',
                        
                    ):
                        if db.update_street_status(street_name, 'terminee', team_id):
                            st.toast(f"🎉 {street_name} terminée!", icon="🎉")
                            st.rerun()
                        else:
                            st.error("Erreur lors de la mise à jour")
                
                # Section notes
                st.markdown("**Gestion des notes:**")
                
                # Afficher les notes existantes
                existing_notes = db.get_street_notes_for_team(street_name, team_id)
                if existing_notes:
                    st.markdown("*Notes existantes:*")
                    for note in existing_notes:
                        st.markdown(f"• **#{list(note.values())[0] if isinstance(note, dict) else note[0]}** : {list(note.values())[1] if isinstance(note, dict) else note[1]} _{list(note.values())[2] if isinstance(note, dict) else note[2]}_")
                
                # Ajouter une nouvelle note
                with st.form(f"note_form_{street_name}"):
                    col_addr, col_note = st.columns([1, 3])
                    with col_addr:
                        address_number = st.text_input(
                            "N° civique", 
                            key=f"addr_{street_name}",
                            placeholder="123A"
                        )
                    with col_note:
                        comment = st.text_area(
                            "Commentaire", 
                            key=f"comment_{street_name}",
                            placeholder="Ex: Absent, refus, don reçu...",
                            max_chars=500,
                            height=80
                        )
                    
                    if st.form_submit_button("🗃️ Enregistrer note"):
                        if address_number and comment:
                            if db.add_street_note(street_name, team_id, address_number, comment):
                                st.toast(f"📝 Note ajoutée pour {street_name} #{address_number}", icon="📝")
                                st.rerun()
                            else:
                                st.error("Erreur lors de l'enregistrement de la note")
                        else:
                            st.warning("Veuillez remplir le numéro et le commentaire")
                            
    except Exception as e:
        st.error(f"Erreur lors du chargement de vos rues: {e}")
        st.info("Fonctionnalité temporairement indisponible")

def main():
    """Point d'entrée principal - Version 2.0 Guignolée"""
    
    # CSS moderne
    inject_css()
    
    # Connexion DB
    # Initialisation de la base de données
    db.init_db()
    
    # Pure SQLite database - no legacy dependencies
    
    # Cache géométrique
    @st.cache_data(ttl=None)
    def get_geo(_sig):
        data = load_geometry_cache()
        return data if data else {}
    
    sig = int(CACHE_FILE.stat().st_mtime_ns) if CACHE_FILE.exists() else 0
    geo = get_geo(sig)
    
    # Header festif
    render_header()
    
    # Navigation modernisée dans la sidebar
    with st.sidebar:
        # CSS pour la sidebar sans position absolue
        st.markdown("""
        <style>
        .css-1d391kg { padding-top: 1rem !important; }
        .stSidebar > div:first-child { padding-top: 1rem !important; }
        </style>
        """, unsafe_allow_html=True)
        
        # Logo en haut de la sidebar (position normale)
        logo_path = ASSETS / "logo.png"
        if logo_path.exists():
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.image(str(logo_path), width=150)
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
        else:
            # Placeholder centré
            st.markdown("""
            <div style="
                background: linear-gradient(135deg, #c41e3a, #165b33);
                border-radius: 15px;
                padding: 2rem;
                color: white;
                text-align: center;
                margin: 1rem 0;
                box-shadow: 0 4px 15px rgba(0,0,0,0.3);
            ">
                <div style="font-size: 2.5rem;">🎁</div>
                <div style="font-weight: bold; font-size: 1.2rem;">LOGO</div>
                <small>Espace réservé</small>
            </div>
            """, unsafe_allow_html=True)
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
        
        # Navigation
        st.markdown("### 🎄 Navigation")
        
        # Boutons de navigation stylisés
        if st.button("🏠 Accueil"):
            st.session_state.page = "accueil"
            st.rerun()
        
        if st.button("🎅 Bénévole"):
            st.session_state.page = "benevole"
            st.rerun()
            
        if st.button("👤 Gestionnaire"):
            st.session_state.page = "gestionnaire"  
            st.rerun()
        
        # Déconnexion si connecté
        if st.session_state.auth:
            st.markdown("---")
            if st.button("🚪 Déconnexion"):
                st.session_state.auth = None
                st.rerun()
        
        # Compteur temps réel
        st.markdown("---")
        
        # Affichage du mode
        try:
            from guignomap.config_mode import MODE, is_demo
            mode_display = "Démo (Cloud)" if is_demo() else "Client"
            mode_color = "#f59e0b" if is_demo() else "#22c55e"
            st.markdown(f"""
            <div style="
                background: {mode_color};
                color: white;
                padding: 0.5rem;
                border-radius: 8px;
                text-align: center;
                font-size: 0.9rem;
                margin-bottom: 1rem;
            ">
                <strong>Mode: {mode_display}</strong>
            </div>
            """, unsafe_allow_html=True)
        except Exception:
            pass
        
        stats = db.extended_stats()
        st.markdown(f"""
        <div style="text-align: center;">
            <h4>État de la collecte</h4>
            <div style="font-size: 2rem; color: #FFD700;">
                {stats['done']}/{stats['total']}
            </div>
            <small>Rues complétées</small>
        </div>
        """, unsafe_allow_html=True)
    
    # Routing pages
    page = st.session_state.get('page', 'accueil')
    
    if page == "accueil":
        page_accueil_v2(geo)
    elif page == "benevole":
        page_benevole_v2(geo)
    elif page == "gestionnaire":
        page_gestionnaire_v2(geo)
    
    # Footer festif
    st.markdown("""
    <div style="
        text-align: center;
        padding: 2rem;
        margin-top: 3rem;
        border-top: 2px solid rgba(255,215,0,0.3);
        color: #8b92a4;
    ">
        <p>
            🎄 Guignolée 2025 - Le Relais de Mascouche 🎄<br>
            <small>Ensemble, redonnons espoir | 📞 450-474-4133</small>
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Bannière en bas de page
    if (ASSETS / "banner.png").exists():
        st.image(str(ASSETS / "banner.png"))

if __name__ == "__main__":
    main()



# ============================================================================
# guignomap\auth.py
# ============================================================================

"""
Gestion des mots de passe avec Argon2 pour GuignoMap
Support de la migration depuis bcrypt et autres formats legacy
"""
import os
from typing import Tuple
from passlib.context import CryptContext

# Configuration passlib : Argon2 par défaut, bcrypt pour compatibilité legacy
pwd_context = CryptContext(
    schemes=["argon2", "bcrypt"],
    default="argon2",
    argon2__memory_cost=65536,  # 64 MB
    argon2__time_cost=3,        # 3 itérations
    argon2__parallelism=4,      # 4 threads
    bcrypt__rounds=12           # Pour compatibilité legacy
)


def _get_allow_bcrypt_fallback() -> bool:
    """Récupère la config ALLOW_BCRYPT_FALLBACK"""
    try:
        import streamlit as st
        return st.secrets.get("ALLOW_BCRYPT_FALLBACK", True)
    except:
        return True  # Par défaut autorisé pendant migration


def hash_password(password: str) -> str:
    """Hash un mot de passe avec Argon2"""
    if password is None or password == "":
        raise ValueError("Le mot de passe ne peut pas être vide")
    return pwd_context.hash(password)


def verify_password(password: str, hashed: str) -> Tuple[bool, bool]:
    """
    Vérifie un mot de passe contre son hash
    Supporte la migration automatique bcrypt → Argon2 et autres formats legacy
    
    Returns:
        Tuple (verification_ok, needs_rehash)
    """
    if password is None or password == "":
        raise ValueError("Le mot de passe ne peut pas être vide")
        
    try:
        # Vérifier d'abord avec passlib (supporte bcrypt et Argon2)
        try:
            # Vérifier si bcrypt est autorisé si c'est un hash bcrypt
            if hashed.startswith('$2') and not _get_allow_bcrypt_fallback():
                print("⚠️ Hash bcrypt détecté mais fallback désactivé")
                return False, False
                
            verification_ok = pwd_context.verify(password, hashed)
            if verification_ok:
                needs_rehash = pwd_context.needs_update(hashed)
                return True, needs_rehash
        except:
            pass  # Passlib ne reconnaît pas le format, essayer les formats legacy
        
        # Formats legacy qui nécessitent migration vers Argon2
        
        # 1) SHA-256 simple (64 hex chars)
        if len(hashed) == 64 and all(c in '0123456789abcdef' for c in hashed.lower()):
            import hashlib
            if hashed == hashlib.sha256(password.encode('utf-8')).hexdigest():
                return True, True  # Migration nécessaire
        
        # 2) MD5 (32 hex chars)
        if len(hashed) == 32 and all(c in '0123456789abcdef' for c in hashed.lower()):
            import hashlib
            if hashed == hashlib.md5(password.encode('utf-8')).hexdigest():
                return True, True  # Migration nécessaire
        
        # 3) PBKDF2 format Django
        if hashed.startswith('pbkdf2_sha256$'):
            try:
                parts = hashed.split('$')
                if len(parts) == 4:
                    _, iterations, salt, expected = parts
                    import hashlib
                    import base64
                    actual = hashlib.pbkdf2_hmac('sha256', password.encode(), salt.encode(), int(iterations))
                    if base64.b64encode(actual).decode() == expected:
                        return True, True  # Migration nécessaire
            except:
                pass
        
        return False, False
            
    except Exception as e:
        print(f"Erreur vérification mot de passe: {e}")
        return False, False


def verify_password_with_context(password: str, stored_hash: str, stored_plain: str = "", stored_salt: str = "") -> Tuple[bool, bool]:
    """
    Vérifie un mot de passe avec support des formats legacy complexes
    """
    try:
        # 1) Vérifier d'abord les formats standards
        verification_ok, needs_rehash = verify_password(password, stored_hash)
        if verification_ok:
            return True, needs_rehash
        
        # 2) SHA-256 avec salt environnement
        if stored_hash and len(stored_hash) == 64:
            import hashlib
            salt_env = os.environ.get("GM_PWD_SALT", "")
            if salt_env and stored_hash == hashlib.sha256((salt_env + password).encode('utf-8')).hexdigest():
                return True, True  # Migration nécessaire
        
        # 3) SHA-256 avec salt stocké
        if stored_salt and stored_hash:
            import hashlib
            if stored_hash == hashlib.sha256((stored_salt + password).encode('utf-8')).hexdigest():
                return True, True  # Migration nécessaire
        
        # 4) Mot de passe en clair (legacy)
        if stored_plain and stored_plain == password:
            return True, True  # Migration nécessaire
        
        return False, False
        
    except Exception as e:
        print(f"Erreur vérification mot de passe avec contexte: {e}")
        return False, False


def detect_hash_algo(hashed: str) -> str:
    """Détecte l'algorithme utilisé pour un hash"""
    if not hashed:
        return "empty"
    
    if hashed.startswith('$argon2'):
        return "argon2"
    elif hashed.startswith('$2b$') or hashed.startswith('$2a$') or hashed.startswith('$2y$'):
        return "bcrypt"
    elif hashed.startswith('pbkdf2_sha256$'):
        return "pbkdf2_sha256"
    elif len(hashed) == 64 and all(c in '0123456789abcdef' for c in hashed.lower()):
        return "sha256"
    elif len(hashed) == 32 and all(c in '0123456789abcdef' for c in hashed.lower()):
        return "md5"
    else:
        return "unknown"

# ============================================================================
# guignomap\backup.py
# ============================================================================

"""
Système de backup automatique pour GuignoMap
Sauvegarde la base de données et les caches
"""

import shutil
from pathlib import Path
from datetime import datetime
import json
import zipfile

class BackupManager:
    def __init__(self, db_path):
        self.db_path = Path(db_path)
        self.backup_dir = self.db_path.parent / "backups"
        self.backup_dir.mkdir(exist_ok=True)
        self.max_backups = 7  # Garder 7 jours de backups
        
    def create_backup(self, reason="manual"):
        """Crée un backup complet avec timestamp"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_{timestamp}_{reason}"
        backup_path = self.backup_dir / backup_name
        backup_path.mkdir(exist_ok=True)
        
        try:
            # Backup de la base de données
            db_backup = backup_path / "guigno_map.db"
            shutil.copy2(self.db_path, db_backup)
            
            # Backup des caches OSM
            for cache_file in ["osm_cache.json", "osm_addresses.json"]:
                cache_path = self.db_path.parent / cache_file
                if cache_path.exists():
                    shutil.copy2(cache_path, backup_path / cache_file)
            
            # Créer un ZIP
            zip_path = self.backup_dir / f"{backup_name}.zip"
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file in backup_path.iterdir():
                    zipf.write(file, file.name)
            
            # Nettoyer le dossier temporaire
            shutil.rmtree(backup_path)
            
            # Nettoyer les vieux backups
            self._cleanup_old_backups()
            
            # Log le backup
            self._log_backup(timestamp, reason)
            
            print(f"✅ Backup créé : {zip_path.name}")
            return str(zip_path)
            
        except Exception as e:
            print(f"'ùå Erreur backup : {e}")
            if backup_path.exists():
                shutil.rmtree(backup_path)
            return None
    
    def restore_backup(self, backup_file):
        """Restaure un backup spécifique"""
        backup_path = self.backup_dir / backup_file
        if not backup_path.exists():
            print(f"'ùå Backup introuvable : {backup_file}")
            return False
            
        try:
            # Créer un backup de sécurité avant restauration
            self.create_backup("pre_restore")
            
            # Extraire le ZIP
            temp_dir = self.backup_dir / "temp_restore"
            with zipfile.ZipFile(backup_path, 'r') as zipf:
                zipf.extractall(temp_dir)
            
            # Restaurer les fichiers
            for file in temp_dir.iterdir():
                target = self.db_path.parent / file.name
                shutil.copy2(file, target)
            
            # Nettoyer
            shutil.rmtree(temp_dir)
            
            print(f"✅ Backup restauré : {backup_file}")
            return True
            
        except Exception as e:
            print(f"'ùå Erreur restauration : {e}")
            return False
    
    def list_backups(self):
        """Liste tous les backups disponibles"""
        backups = []
        for file in self.backup_dir.glob("backup_*.zip"):
            stat = file.stat()
            backups.append({
                "name": file.name,
                "size": f"{stat.st_size / 1024 / 1024:.2f} MB",
                "date": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S")
            })
        return sorted(backups, key=lambda x: x["date"], reverse=True)
    
    def _cleanup_old_backups(self):
        """Supprime les backups de plus de 7 jours"""
        backups = sorted(self.backup_dir.glob("backup_*.zip"), key=lambda x: x.stat().st_mtime)
        while len(backups) > self.max_backups:
            oldest = backups.pop(0)
            oldest.unlink()
            print(f"🗑️ Ancien backup supprimé : {oldest.name}")
    
    def _log_backup(self, timestamp, reason):
        """Log les backups dans un fichier"""
        log_file = self.backup_dir / "backup_log.json"
        log = []
        if log_file.exists():
            with open(log_file, 'r', encoding='utf-8') as f:
                log = json.load(f)
        
        log.append({
            "timestamp": timestamp,
            "reason": reason,
            "date": datetime.now().isoformat()
        })
        
        # Garder seulement les 100 derniers logs
        log = log[-100:]
        
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(log, f, indent=2)

def auto_backup_before_critical(func):
    """Décorateur pour backup automatique avant opérations critiques"""
    def wrapper(*args, **kwargs):
        # Trouver la connexion DB dans les arguments
        conn = None
        for arg in args:
            if hasattr(arg, 'execute'):  # C'est une connexion SQLite
                conn = arg
                break
        
        if conn:
            try:
                # Créer un backup avant l'opération
                db_path = Path(__file__).parent / "guigno_map.db"
                backup_mgr = BackupManager(db_path)
                backup_mgr.create_backup(f"auto_{func.__name__}")
            except:
                pass  # Ne pas bloquer l'opération si le backup échoue
        
        return func(*args, **kwargs)
    return wrapper

# ============================================================================
# guignomap\config_mode.py
# ============================================================================

"""
GuignoMap - Configuration des modes d'exécution
Gère les modes demo/client avec fallback intelligent
"""
import os
import logging
from pathlib import Path
import sqlite3

# Détection du mode
def _get_mode():
    """Détermine le mode d'exécution depuis Streamlit secrets ou env vars"""
    try:
        import streamlit as st
        return st.secrets.get("MODE", "demo")
    except Exception:
        return os.environ.get("GUIGNOMAP_MODE", "demo")

MODE = _get_mode()

def is_demo():
    """Returns True si en mode démo"""
    return MODE == "demo"

def ensure_db_path():
    """
    Détermine le chemin de la DB selon le mode:
    - client: exige guigno_map.db présent
    - demo: fallback guigno_map.db -> guigno_map.sample.db -> création minimale
    """
    if MODE == "client":
        # Mode client: DB principale requise
        db_path = Path("guignomap/guigno_map.db")
        if not db_path.exists():
            raise FileNotFoundError(
                f"Mode client requiert la base de données {db_path}. "
                "Importez vos données ou basculez en mode demo."
            )
        return db_path
    
    elif MODE == "demo":
        # Mode démo: fallback intelligent
        primary_db = Path("guignomap/guigno_map.db")
        sample_db = Path("guignomap/guigno_map.sample.db")
        
        if primary_db.exists():
            logging.info(f"Mode démo: utilisation DB principale {primary_db}")
            return primary_db
        
        if sample_db.exists():
            logging.info(f"Mode démo: utilisation DB échantillon {sample_db}")
            return sample_db
        
        # Créer une DB minimale pour démo
        logging.warning(f"Mode démo: création DB minimale {sample_db}")
        _create_minimal_demo_db(sample_db)
        return sample_db
    
    else:
        raise ValueError(f"Mode '{MODE}' non supporté. Utilisez 'demo' ou 'client'.")

def _create_minimal_demo_db(db_path):
    """Crée une base de données minimale pour la démo"""
    db_path.parent.mkdir(exist_ok=True)
    
    with sqlite3.connect(db_path) as conn:
        # Table teams
        conn.execute("""
            CREATE TABLE IF NOT EXISTS teams (
                id TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                password_hash TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                active BOOLEAN DEFAULT 1
            )
        """)
        
        # Table streets
        conn.execute("""
            CREATE TABLE IF NOT EXISTS streets (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL UNIQUE,
                sector TEXT,
                team TEXT,
                status TEXT NOT NULL DEFAULT 'a_faire' 
                    CHECK (status IN ('a_faire', 'en_cours', 'terminee'))
            )
        """)
        
        # Table addresses
        conn.execute("""
            CREATE TABLE IF NOT EXISTS addresses (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                street_name TEXT NOT NULL,
                house_number TEXT,
                sector TEXT,
                latitude REAL,
                longitude REAL,
                team TEXT,
                addr_key TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (street_name) REFERENCES streets(name)
            )
        """)
        
        # Table notes
        conn.execute("""
            CREATE TABLE IF NOT EXISTS notes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                street_name TEXT NOT NULL,
                team_id TEXT NOT NULL,
                address_number TEXT,
                comment TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (street_name) REFERENCES streets(name),
                FOREIGN KEY (team_id) REFERENCES teams(id)
            )
        """)
        
        # Équipe admin par défaut
        conn.execute("""
            INSERT OR IGNORE INTO teams (id, name, password_hash) 
            VALUES ('ADMIN', 'Administrateur', '$2b$12$demo.hash.for.admin.access')
        """)
        
        # Quelques rues de démo
        demo_streets = [
            ("Rue de la Démo", "Centre", None, "a_faire"),
            ("Avenue Exemple", "Nord", None, "a_faire"), 
            ("Boulevard Test", "Sud", None, "a_faire")
        ]
        
        conn.executemany("""
            INSERT OR IGNORE INTO streets (name, sector, team, status) 
            VALUES (?, ?, ?, ?)
        """, demo_streets)
        
        conn.commit()
        logging.info(f"DB démo créée avec {len(demo_streets)} rues échantillon")

# Log du mode choisi à l'import
logging.info(f"GuignoMap démarré en mode: {MODE}")

# ============================================================================
# guignomap\config_ville.py
# ============================================================================

# guignomap/config_ville.py
# Paramètres par défaut : Mascouche
VILLE_NOM = "Mascouche"

# centre carte [lat, lon]
VILLE_CENTRE = [45.7475, -73.6005]

# limites de la carte
VILLE_BOUNDS = {
    "north": 45.78,
    "south": 45.70,
    "east": -73.55,
    "west": -73.70,
}

# éventuel zoom par défaut (si app.py l'utilise)
VILLE_ZOOM = 12

# ============================================================================
# guignomap\database.py
# ============================================================================

"""
GuignoMap - Database operations (SQLite Pure)
Unified database layer for GuignoMap
"""
import sqlite3
from pathlib import Path
import threading
from contextlib import contextmanager
from datetime import datetime
import pandas as pd
from typing import Optional, List, Dict
import functools

try:
    import streamlit as st
except ImportError:
    # Fallback pour tests sans Streamlit
    st = None

from guignomap.auth import hash_password, verify_password
from guignomap.backup import BackupManager
from guignomap.config_mode import ensure_db_path

# Flag d'initialisation globale
_DB_INITIALIZED = False
_DB_LOCK = threading.Lock()


# =============================================================================
# CACHE SYSTEM
# =============================================================================

def safe_cache(func):
    """Décorateur de cache compatible Streamlit/standalone"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        try:
            # Essayer d'utiliser st.cache_data si Streamlit est disponible
            import streamlit as st
            cached_func = st.cache_data(func)
            return cached_func(*args, **kwargs)
        except ImportError:
            # Fallback : cache simple en mémoire
            if not hasattr(wrapper, '_cache'):
                wrapper._cache = {}
            
            # Créer une clé de cache simple
            cache_key = str(args) + str(sorted(kwargs.items()))
            
            if cache_key in wrapper._cache:
                return wrapper._cache[cache_key]
            
            result = func(*args, **kwargs)
            wrapper._cache[cache_key] = result
            return result
    return wrapper


# =============================================================================
# CONNECTION MANAGEMENT
# =============================================================================

DB_PATH = ensure_db_path()
_local = threading.local()

def vacuum_database():
    """Maintenance de la base de données"""
    with get_conn() as conn:
        conn.execute("VACUUM")
        conn.execute("PRAGMA optimize")
        conn.execute("PRAGMA analysis_limit=1000")
        conn.execute("PRAGMA optimize")

def _get_conn_uncached():
    """Connexion SQLite thread-safe avec optimisations (version non-cachée)"""
    global _DB_INITIALIZED
    
    if not hasattr(_local, 'conn') or _local.conn is None:
        DB_PATH.parent.mkdir(exist_ok=True)
        _local.conn = sqlite3.connect(
            DB_PATH, 
            check_same_thread=False,
            timeout=30.0
        )
        _local.conn.row_factory = sqlite3.Row
        # Optimisations SQLite pour performance 1000+ équipes
        _local.conn.execute("PRAGMA journal_mode=WAL")
        _local.conn.execute("PRAGMA synchronous=NORMAL")
        _local.conn.execute("PRAGMA cache_size=-64000")  # 64MB cache
        _local.conn.execute("PRAGMA mmap_size=268435456")  # 256MB mmap
        _local.conn.execute("PRAGMA foreign_keys=ON")
        _local.conn.execute("PRAGMA temp_store=MEMORY")
        _local.conn.execute("PRAGMA optimize")  # Auto-optimisation
        
        # Initialisation exactement UNE FOIS
        with _DB_LOCK:
            if not _DB_INITIALIZED:
                initialize_database()
                _DB_INITIALIZED = True
                
    return _local.conn

def get_conn():
    """Connexion SQLite thread-safe avec cache Streamlit"""
    if st is not None:
        # En mode Streamlit: utilise cache_resource
        return _get_conn_cached()
    else:
        # En mode tests/CLI: utilise version non-cachée
        return _get_conn_uncached()

if st is not None:
    @st.cache_resource(show_spinner=False)
    def _get_conn_cached():
        """Version cachée pour Streamlit"""
        return _get_conn_uncached()
else:
    def _get_conn_cached():
        """Fallback quand Streamlit n'est pas disponible"""
        return _get_conn_uncached()

@contextmanager
def get_cursor():
    """Context manager pour cursor avec auto-commit"""
    conn = get_conn()
    cursor = conn.cursor()
    try:
        yield cursor
        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        cursor.close()


# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def _row_dicts(cur):
    """Helper pour convertir curseur en liste de dict"""
    cols = [d[0] for d in cur.description]
    return [dict(zip(cols, row)) for row in cur.fetchall()]

def _ensure_foreign_keys(conn):
    """Active les foreign keys pour cette connexion"""
    conn.execute("PRAGMA foreign_keys=ON")


# =============================================================================
# INITIALIZATION FUNCTIONS
# =============================================================================

def create_performance_indexes(conn=None):
    """Crée les INDEX pour optimiser les performances"""
    if conn is None:
        conn = get_conn()
    
    indexes = [
        # INDEX pour les requêtes fréquentes sur streets
        "CREATE INDEX IF NOT EXISTS idx_streets_team ON streets(team)",
        "CREATE INDEX IF NOT EXISTS idx_streets_status ON streets(status)", 
        "CREATE INDEX IF NOT EXISTS idx_streets_name ON streets(name)",
        "CREATE INDEX IF NOT EXISTS idx_streets_sector ON streets(sector)",
        
        # INDEX pour les requêtes fréquentes sur notes (street_name, pas street_id)
        "CREATE INDEX IF NOT EXISTS idx_notes_street_name ON notes(street_name)",
        "CREATE INDEX IF NOT EXISTS idx_notes_team_id ON notes(team_id)",
        "CREATE INDEX IF NOT EXISTS idx_notes_created ON notes(created_at DESC)",
        
        # INDEX pour teams 
        "CREATE INDEX IF NOT EXISTS idx_teams_name ON teams(name)",
        
        # INDEX pour activity_log (si elle existe)
        "CREATE INDEX IF NOT EXISTS idx_activity_created ON activity_log(created_at DESC)",
        "CREATE INDEX IF NOT EXISTS idx_activity_team ON activity_log(team_id)",
    ]
    
    for index_sql in indexes:
        try:
            conn.execute(index_sql)
        except Exception as e:
            print(f"Warning: Could not create index: {e}")

def initialize_database():
    """Initialise la base de données avec les données par défaut"""
    try:
        with get_conn() as conn:
            _ensure_foreign_keys(conn)
            
            # Création des INDEX pour optimiser les performances
            create_performance_indexes(conn)
            
            # Vérifier si l'admin existe
            admin_exists = conn.execute(
                "SELECT COUNT(*) FROM teams WHERE id = 'ADMIN'"
            ).fetchone()[0]
            
            if admin_exists == 0:
                # Créer l'équipe ADMIN avec mot de passe RELAIS2025
                admin_password_hash = hash_password("RELAIS2025")
                conn.execute("""
                    INSERT INTO teams(id, name, password_hash) 
                    VALUES ('ADMIN', 'Administrateur', ?)
                """, (admin_password_hash,))
                
                # Vérifier si des rues existent
                street_count = conn.execute("SELECT COUNT(*) FROM streets").fetchone()[0]
                
                conn.commit()
                return {
                    "status": "initialized", 
                    "message": f"Admin créé avec mot de passe RELAIS2025, {street_count} rues existantes"
                }
            else:
                # Admin existe déjà, vérifier le mot de passe
                current_hash = conn.execute(
                    "SELECT password_hash FROM teams WHERE id = 'ADMIN'"
                ).fetchone()[0]
                
                expected_hash = hash_password("RELAIS2025")
                if current_hash != expected_hash:
                    # Mise à jour du mot de passe
                    conn.execute(
                        "UPDATE teams SET password_hash = ? WHERE id = 'ADMIN'",
                        (expected_hash,)
                    )
                    conn.commit()
                    return {"status": "admin_password_updated", "message": "Mot de passe ADMIN mis à jour"}
                else:
                    return {"status": "already_initialized", "message": "Base déjà initialisée, ADMIN OK"}
                    
    except Exception as e:
        return {"status": "error", "message": str(e)}


# =============================================================================
# TEAM OPERATIONS
# =============================================================================

def team_exists(team_id: str) -> bool:
    """Vérifie si une équipe existe"""
    with get_conn() as conn:
        count = conn.execute(
            "SELECT COUNT(*) FROM teams WHERE id = ?", (team_id,)
        ).fetchone()[0]
        return count > 0

def create_team(team_id: str, team_name: str, password: str = "") -> dict:
    """Crée une nouvelle équipe"""
    try:
        with get_conn() as conn:
            _ensure_foreign_keys(conn)
            
            # Vérifier si l'équipe existe déjà
            if team_exists(team_id):
                return {"success": False, "message": "Équipe existe déjà"}
            
            password_hash = hash_password(password) if password else ""
            
            conn.execute("""
                INSERT INTO teams(id, name, password_hash) 
                VALUES (?, ?, ?)
            """, (team_id, team_name, password_hash))
            
            conn.commit()
            return {"success": True, "message": "Équipe créée avec succès"}
    except Exception as e:
        return {"success": False, "message": str(e)}

def authenticate_team(team_id: str, password: str) -> dict:
    """Authentifie une équipe"""
    try:
        with get_conn() as conn:
            result = conn.execute(
                "SELECT name, password_hash FROM teams WHERE id = ?",
                (team_id,)
            ).fetchone()
            
            if not result:
                return {"success": False, "message": "Équipe introuvable"}
            
            name, password_hash = result
            is_admin = team_id == 'ADMIN'  # ADMIN is admin by definition
            
            if not password_hash:  # Pas de mot de passe
                return {"success": True, "team_name": name, "is_admin": is_admin}
            
            if verify_password(password, password_hash):
                return {"success": True, "team_name": name, "is_admin": is_admin}
            else:
                return {"success": False, "message": "Mot de passe incorrect"}
    except Exception as e:
        return {"success": False, "message": str(e)}

@safe_cache
def list_teams() -> List[Dict]:
    """Liste toutes les équipes"""
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT t.id, t.name, t.active, 
                   COUNT(s.id) as assigned_streets
            FROM teams t
            LEFT JOIN streets s ON t.id = s.team
            GROUP BY t.id, t.name, t.active
            ORDER BY t.name
        """)
        return _row_dicts(cur)


# =============================================================================
# STREET OPERATIONS
# =============================================================================

@safe_cache
def list_streets(team: Optional[str] = None) -> pd.DataFrame:
    """Liste toutes les rues avec leurs détails"""
    with get_conn() as conn:
        if team:
            cur = conn.execute("""
                SELECT s.id, s.name, s.sector, s.status, s.team_id,
                       t.nom as team_name,
                       COUNT(n.id) as notes_count
                FROM streets s
                LEFT JOIN teams t ON s.team_id = t.id
                LEFT JOIN notes n ON s.id = n.street_id
                WHERE s.team_id = ?
                GROUP BY s.id, s.name, s.sector, s.status, s.team_id, t.nom
                ORDER BY s.name
            """, (team,))
        else:
            cur = conn.execute("""
                SELECT s.id, s.name, s.sector, s.status, s.team_id,
                       t.nom as team_name,
                       COUNT(n.id) as notes_count
                FROM streets s
                LEFT JOIN teams t ON s.team_id = t.id
                LEFT JOIN notes n ON s.id = n.street_id
                GROUP BY s.id, s.name, s.sector, s.status, s.team_id, t.nom
                ORDER BY s.name
            """)
        
        data = _row_dicts(cur)
        return pd.DataFrame(data)

def get_street_details(street_id: int) -> Optional[Dict]:
    """Récupère les détails d'une rue"""
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT s.*, t.nom as team_name
            FROM streets s
            LEFT JOIN teams t ON s.team_id = t.id
            WHERE s.id = ?
        """, (street_id,))
        
        result = cur.fetchone()
        if result:
            cols = [d[0] for d in cur.description]
            return dict(zip(cols, result))
        return None

def update_street_status(street_id: int, new_status: str, team_id: Optional[str] = None) -> dict:
    """Met à jour le statut d'une rue de façon robuste"""
    # Validation stricte des statuts autorisés (selon contrainte DB)
    valid_statuses = {"a_faire", "en_cours", "terminee"}
    if new_status not in valid_statuses:
        raise ValueError(f"Statut invalide '{new_status}'. Statuts autorisés: {valid_statuses}")
    
    with get_conn() as conn:
        _ensure_foreign_keys(conn)
        
        # UPDATE en un seul passage selon la présence de team_id
        if team_id:
            cursor = conn.execute("""
                UPDATE streets 
                SET status = ?, team = ?
                WHERE id = ?
            """, (new_status, team_id, street_id))
        else:
            cursor = conn.execute("""
                UPDATE streets 
                SET status = ?
                WHERE id = ?
            """, (new_status, street_id))
        
        # Vérifier que la rue existe (rowcount == 0 si id inexistant)
        if cursor.rowcount == 0:
            raise ValueError(f"Rue avec l'id {street_id} introuvable")
        
        conn.commit()
        return {"id": street_id, "status": new_status, "team": team_id}


# =============================================================================
# STATISTICS & REPORTING
# =============================================================================

@safe_cache
def extended_stats() -> Dict:
    """Statistiques étendues du projet"""
    with get_conn() as conn:
        # Compter par statut
        cur = conn.execute("SELECT status, COUNT(*) as count FROM streets GROUP BY status")
        status_counts = dict(cur.fetchall())
        
        total = sum(status_counts.values())
        done = status_counts.get('terminee', 0)
        partial = status_counts.get('en_cours', 0) + status_counts.get('partielle', 0)
        todo = status_counts.get('a_faire', 0)
        
        return {
            'total': total,
            'done': done,
            'partial': partial,
            'todo': todo,
            'progress_pct': (done / total * 100) if total > 0 else 0
        }

def stats_by_team() -> List[Dict]:
    """Statistiques par équipe"""
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT t.id, t.nom as team_name,
                   COUNT(s.id) as total_streets,
                   SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as completed,
                   SUM(CASE WHEN s.status IN ('en_cours', 'partielle') THEN 1 ELSE 0 END) as in_progress,
                   COUNT(n.id) as total_notes
            FROM teams t
            LEFT JOIN streets s ON t.id = s.team_id
            LEFT JOIN notes n ON s.id = n.street_id
            WHERE t.id != 'ADMIN'
            GROUP BY t.id, t.nom
            ORDER BY completed DESC, t.nom
        """)
        return _row_dicts(cur)

def recent_activity(limit: int = 20) -> List[Dict]:
    """Activité récente du système"""
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT team_id, action, details, created_at
            FROM activity_log 
            ORDER BY created_at DESC 
            LIMIT ?
        """, (limit,))
        return _row_dicts(cur)


# =============================================================================
# NOTES OPERATIONS
# =============================================================================

def add_note(street_id: int, team_id: str, content: str) -> bool:
    """Ajoute une note à une rue"""
    try:
        with get_conn() as conn:
            _ensure_foreign_keys(conn)
            
            conn.execute("""
                INSERT INTO notes(street_id, team_id, content, created_at)
                VALUES (?, ?, ?, CURRENT_TIMESTAMP)
            """, (street_id, team_id, content))
            
            # Log de l'activité
            conn.execute("""
                INSERT INTO activity_log(team_id, action, details, created_at)
                VALUES (?, 'note_added', ?, CURRENT_TIMESTAMP)
            """, (team_id, f"Note ajoutée sur rue ID {street_id}"))
            
            conn.commit()
            return True
    except Exception:
        return False

def get_street_notes(street_id: int) -> List[Dict]:
    """Récupère les notes d'une rue"""
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT n.*, t.nom as team_name
            FROM notes n
            LEFT JOIN teams t ON n.team_id = t.id
            WHERE n.street_id = ?
            ORDER BY n.created_at DESC
        """, (street_id,))
        return _row_dicts(cur)


# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def count_hash_algorithms() -> Dict[str, int]:
    """Compte les algorithmes de hash utilisés"""
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT 
                CASE 
                    WHEN password_hash LIKE 'scrypt:$%' THEN 'scrypt'
                    WHEN password_hash LIKE 'pbkdf2:sha256:$%' THEN 'pbkdf2_sha256'
                    WHEN password_hash LIKE '$2b$%' THEN 'bcrypt'
                    ELSE 'unknown'
                END as algorithm,
                COUNT(*) as count
            FROM teams 
            WHERE password_hash IS NOT NULL AND password_hash != ''
            GROUP BY algorithm
        """)
        return dict(cur.fetchall())

def health_check() -> Dict:
    """Vérification de santé de la base"""
    try:
        with get_conn() as conn:
            # Test de base
            conn.execute("SELECT 1").fetchone()
            
            # Comptes des tables principales
            teams_count = conn.execute("SELECT COUNT(*) FROM teams").fetchone()[0]
            streets_count = conn.execute("SELECT COUNT(*) FROM streets").fetchone()[0]
            notes_count = conn.execute("SELECT COUNT(*) FROM notes").fetchone()[0]
            
            return {
                "status": "healthy",
                "teams": teams_count,
                "streets": streets_count,
                "notes": notes_count,
                "timestamp": datetime.now().isoformat()
            }
    except Exception as e:
        return {"status": "error", "message": str(e)}


# =============================================================================
# BULK OPERATIONS
# =============================================================================

def bulk_assign_streets(team_id: str, sector: Optional[str] = None) -> Dict:
    """Assigne en lot des rues à une équipe"""
    try:
        with get_conn() as conn:
            _ensure_foreign_keys(conn)
            
            if sector:
                cur = conn.execute("""
                    UPDATE streets 
                    SET team_id = ?
                    WHERE sector = ? AND (team_id IS NULL OR team_id = '')
                """, (team_id, sector))
            else:
                cur = conn.execute("""
                    UPDATE streets 
                    SET team_id = ?
                    WHERE team_id IS NULL OR team_id = ''
                """, (team_id,))
            
            affected = cur.rowcount
            
            # Log de l'activité
            conn.execute("""
                INSERT INTO activity_log(team_id, action, details, created_at)
                VALUES (?, 'bulk_assign', ?, CURRENT_TIMESTAMP)
            """, (team_id, f"Assignation en lot: {affected} rues"))
            
            conn.commit()
            return {"success": True, "affected_count": affected}
    except Exception as e:
        return {"success": False, "message": str(e)}


# =============================================================================
# UTILITY QUERY FUNCTIONS (Legacy compatibility)
# =============================================================================

def execute_query(query, params=None):
    """Exécute une query avec gestion d'erreurs (legacy compatibility)"""
    with get_cursor() as cursor:
        if params:
            cursor.execute(query, params)
        else:
            cursor.execute(query)
        return cursor.fetchall()

def fetchone_query(query, params=None):
    """Exécute une query et retourne le premier résultat"""
    conn = get_conn()
    if params:
        result = conn.execute(query, params).fetchone()
    else:
        result = conn.execute(query).fetchone()
    return result

def fetchall_query(query, params=None):
    """Exécute une query et retourne tous les résultats"""
    conn = get_conn()
    if params:
        results = conn.execute(query, params).fetchall()
    else:
        results = conn.execute(query).fetchall()
    return results


# =============================================================================
# ALIAS & COMPATIBILITY FUNCTIONS
# =============================================================================

# Alias pour compatibilité avec l'ancienne API
init_db = initialize_database
verify_team = authenticate_team

def teams() -> List[str]:
    """Retourne la liste des noms d'équipes (compatibilité)"""
    teams_list = list_teams()
    return [team['name'] for team in teams_list if team['id'] != 'ADMIN']

def get_teams_list() -> List[tuple]:
    """Retourne liste des équipes sous forme (id, nom)"""
    teams_list = list_teams()
    return [(team['id'], team['name']) for team in teams_list]
    return [(team['id'], team['nom']) for team in teams_list if team['id'] != 'ADMIN']

def get_all_teams() -> pd.DataFrame:
    """Retourne DataFrame des équipes"""
    teams_list = list_teams()
    return pd.DataFrame(teams_list)

def set_status(street_name: str, status: str) -> bool:
    """Met à jour le statut d'une rue par nom (legacy)"""
    with get_conn() as conn:
        cur = conn.execute("SELECT id FROM streets WHERE name = ?", (street_name,))
        result = cur.fetchone()
        if result:
            try:
                update_street_status(result[0], status)
                return True
            except ValueError:
                return False
        return False

def get_unassigned_streets() -> List[Dict]:
    """Rues non assignées"""
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT id, name, sector FROM streets 
            WHERE team_id IS NULL OR team_id = ''
            ORDER BY name
        """)
        return _row_dicts(cur)

def get_unassigned_streets_count() -> int:
    """Nombre de rues non assignées"""
    with get_conn() as conn:
        count = conn.execute("""
            SELECT COUNT(*) FROM streets 
            WHERE team_id IS NULL OR team_id = ''
        """).fetchone()[0]
        return count

@safe_cache
def get_sectors_list() -> List[str]:
    """Liste des secteurs"""
    with get_conn() as conn:
        cur = conn.execute("SELECT DISTINCT sector FROM streets WHERE sector IS NOT NULL ORDER BY sector")
        return [row[0] for row in cur.fetchall()]

def assign_streets_to_team(street_names: List[str], team_id: str) -> int:
    """Assigne des rues à une équipe"""
    count = 0
    with get_conn() as conn:
        _ensure_foreign_keys(conn)
        for street_name in street_names:
            cur = conn.execute("""
                UPDATE streets SET team_id = ?
                WHERE name = ?
            """, (team_id, street_name))
            count += cur.rowcount
        conn.commit()
    return count

def bulk_assign_sector(sector: str, team_id: str) -> int:
    """Assigne toutes les rues d'un secteur à une équipe"""
    result = bulk_assign_streets(team_id, sector)
    return result.get("affected_count", 0)

def get_team_streets(team_id: str) -> List[Dict]:
    """Rues assignées à une équipe"""
    df = list_streets(team=team_id)
    return df.to_dict('records')

def add_street_note(street_name: str, team_id: str, address_num: str, content: str) -> bool:
    """Ajoute une note à une rue par nom"""
    with get_conn() as conn:
        cur = conn.execute("SELECT id FROM streets WHERE name = ?", (street_name,))
        result = cur.fetchone()
        if result:
            return add_note(result[0], team_id, f"{address_num}: {content}")
        return False

def get_street_notes_for_team(street_name: str, team_id: str) -> List[Dict]:
    """Notes d'une rue pour une équipe"""
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT n.*, t.nom as team_name
            FROM notes n
            LEFT JOIN teams t ON n.team_id = t.id
            LEFT JOIN streets s ON n.street_id = s.id
            WHERE s.name = ? AND n.team_id = ?
            ORDER BY n.created_at DESC
        """, (street_name, team_id))
        return _row_dicts(cur)

# Fonctions export (placeholders pour l'instant)
def export_to_csv():
    """Export CSV placeholder"""
    return "CSV export placeholder"

def export_notes_csv():
    """Export notes CSV placeholder"""
    return "Notes CSV export placeholder"

def export_streets_template(include_assignments=True):
    """Export template placeholder"""
    return pd.DataFrame()

def upsert_streets_from_csv(file_like):
    """Import CSV placeholder"""
    return {"success": False, "message": "Import not implemented"}

def get_assignations_export_data():
    """Export assignations placeholder"""
    return []

# Fonctions adresses (placeholders)
def get_street_addresses_with_notes(street_name):
    """Placeholder adresses avec notes"""
    return []

def get_addresses_by_street(street_name):
    """Placeholder adresses par rue"""
    return []

def add_note_for_address(street_name, team_id, address_num, content):
    """Placeholder note pour adresse"""
    return False

def get_team_notes(team_id):
    """Placeholder notes équipe"""
    return []

def update_team_password(team_id, new_password):
    """Met à jour le mot de passe d'une équipe"""
    try:
        with get_conn() as conn:
            password_hash = hash_password(new_password)
            conn.execute("""
                UPDATE teams SET password_hash = ? WHERE id = ?
            """, (password_hash, team_id))
            conn.commit()
            return True
    except Exception:
        return False

def reset_team_password(team_id):
    """Remet à zéro le mot de passe d'une équipe"""
    try:
        with get_conn() as conn:
            conn.execute("""
                UPDATE teams SET password_hash = '' WHERE id = ?
            """, (team_id,))
            conn.commit()
            return "password_reset"
    except Exception:
        return None

def import_addresses_from_cache(cache_data):
    """Import adresses depuis cache"""
    return 0

def get_backup_manager():
    """Retourne backup manager"""
    return BackupManager(str(DB_PATH))


# =============================================================================
# CACHE MANAGEMENT
# =============================================================================

def invalidate_caches():
    """Invalide tous les caches (Streamlit et fallback mémoire)"""
    try:
        # Si Streamlit est disponible, utiliser son système de cache
        import streamlit as st
        st.cache_data.clear()
    except ImportError:
        # Fallback : nettoyer les caches mémoire des fonctions @safe_cache
        import inspect
        
        # Parcourir toutes les fonctions du module actuel
        current_module = inspect.getmodule(invalidate_caches)
        for name, obj in inspect.getmembers(current_module):
            if callable(obj) and hasattr(obj, '_cache'):
                obj._cache.clear()


# =============================================================================
# ADDRESSES (import et lecture/assignation)
# =============================================================================

def assign_addresses_to_team(address_ids: list[int], team_id: str) -> int:
    """
    Assigne une liste d'adresses à une équipe
    
    Args:
        address_ids: Liste des IDs d'adresses à assigner
        team_id: Identifiant de l'équipe
    
    Returns:
        Nombre d'adresses effectivement assignées
    """
    if not address_ids:
        return 0
    
    with get_conn() as conn:
        _ensure_foreign_keys(conn)
        cursor = conn.cursor()
        placeholders = ','.join('?' for _ in address_ids)
        cursor.execute(f"""
            UPDATE addresses
            SET assigned_to = ?
            WHERE id IN ({placeholders})
        """, [str(team_id).strip()] + [int(aid) for aid in address_ids])
        conn.commit()
        rowcount = cursor.rowcount
        invalidate_caches()
        return rowcount


def count_unassigned_addresses() -> int:
    """Compte le nombre d'adresses non assignées"""
    with get_conn() as conn:
        _ensure_foreign_keys(conn)
        cur = conn.execute("""
            SELECT COUNT(*) 
            FROM addresses 
            WHERE assigned_to IS NULL OR assigned_to = ''
        """)
        return int(cur.fetchone()[0])

def get_unassigned_addresses(limit=100, sector=None, street=None, search=None):
    """
    Récupère les adresses non assignées avec filtres multiples
    
    Args:
        limit: Nombre max d'adresses à retourner (défaut: 100)
        sector: Filtre par secteur
        street: Filtre par nom de rue (LIKE)
        search: Recherche globale sur rue + numéro (LIKE)
    
    Returns:
        DataFrame avec colonnes: id, street_name, house_number, sector
    """
    with get_conn() as conn:
        where_conditions = ["(assigned_to IS NULL OR assigned_to = '')"]
        params = []
        
        if sector:
            where_conditions.append("sector = ?")
            params.append(str(sector).strip())
        
        if street:
            where_conditions.append("street_name LIKE ?")
            params.append(f"%{str(street).strip()}%")
        
        if search:
            search_term = f"%{str(search).strip()}%"
            where_conditions.append("(street_name LIKE ? OR house_number LIKE ?)")
            params.extend([search_term, search_term])
        
        where_clause = " AND ".join(where_conditions)
        params.append(str(limit))
        
        return pd.read_sql_query(f"""
            SELECT id, street_name, house_number, sector
            FROM addresses
            WHERE {where_clause}
            ORDER BY street_name ASC, CAST(house_number AS INTEGER) ASC NULLS LAST
            LIMIT ?
        """, conn, params=params)

def get_team_addresses(team_id: str, limit=500, search=None):
    """
    Récupère les adresses assignées à une équipe
    
    Args:
        team_id: Identifiant de l'équipe
        limit: Nombre max d'adresses (défaut: 500)
        search: Recherche sur rue + numéro (optionnel)
    
    Returns:
        DataFrame avec colonnes: id, street_name, house_number, postal_code, sector, assigned_to
    """
    with get_conn() as conn:
        where_conditions = ["assigned_to = ?"]
        params = [str(team_id).strip()]
        
        if search:
            search_term = f"%{str(search).strip()}%"
            where_conditions.append("(street_name LIKE ? OR house_number LIKE ?)")
            params.extend([search_term, search_term])
        
        where_clause = " AND ".join(where_conditions)
        params.append(str(limit))
        
        return pd.read_sql_query(f"""
            SELECT id, street_name, house_number, postal_code, sector, assigned_to
            FROM addresses
            WHERE {where_clause}
            ORDER BY street_name ASC, CAST(house_number AS INTEGER) ASC NULLS LAST
            LIMIT ?
        """, conn, params=params)


def search_addresses(query: str, limit: int = 500) -> pd.DataFrame:
    """Recherche d'adresses avec LIKE sur street_name/house_number"""
    if not query or not query.strip():
        return pd.DataFrame(columns=['id', 'street_name', 'house_number', 'sector'])
    
    with get_conn() as conn:
        search_term = f"%{str(query).strip()}%"
        return pd.read_sql_query("""
            SELECT id, street_name, house_number, sector
            FROM addresses
            WHERE street_name LIKE ? OR house_number LIKE ?
            ORDER BY street_name ASC, CAST(house_number AS INTEGER) ASC NULLS LAST
            LIMIT ?
        """, conn, params=[search_term, search_term, limit])


def clear_team_assignments(team_id: str) -> int:
    """
    Supprime toutes les assignations d'une équipe
    
    Args:
        team_id: Identifiant de l'équipe
    
    Returns:
        Nombre d'adresses désassignées
    """
    with get_conn() as conn:
        _ensure_foreign_keys(conn)
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE addresses
            SET assigned_to = NULL
            WHERE assigned_to = ?
        """, [str(team_id).strip()])
        conn.commit()
        rowcount = cursor.rowcount
        invalidate_caches()
        return rowcount


def stats_addresses() -> dict:
    """
    Statistiques globales sur les adresses
    
    Returns:
        Dict avec: total, unassigned, assigned, per_team, percent_geocoded
    """
    with get_conn() as conn:
        # Statistiques de base
        cursor = conn.cursor()
        
        # Total et non-assignées
        cursor.execute("SELECT COUNT(*) FROM addresses")
        total = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM addresses WHERE assigned_to IS NULL OR assigned_to = ''")
        unassigned = cursor.fetchone()[0]
        
        # Par équipe
        cursor.execute("""
            SELECT assigned_to, COUNT(*) as count
            FROM addresses
            WHERE assigned_to IS NOT NULL AND assigned_to != ''
            GROUP BY assigned_to
            ORDER BY count DESC
        """)
        per_team = dict(cursor.fetchall())
        
        # Pourcentage géocodé (approximation si colonnes lat/lon existent)
        try:
            cursor.execute("""
                SELECT COUNT(*) FROM addresses 
                WHERE latitude IS NOT NULL AND longitude IS NOT NULL
            """)
            geocoded = cursor.fetchone()[0]
            percent_geocoded = round((geocoded / total * 100), 1) if total > 0 else 0.0
        except:
            # Colonnes lat/lon n'existent pas
            percent_geocoded = 0.0
        
        return {
            'total': total,
            'unassigned': unassigned,
            'assigned': total - unassigned,
            'per_team': per_team,
            'percent_geocoded': percent_geocoded
        }


def test_address_helpers():
    """Tests rapides intégrés pour les helpers d'adresses - version déterministe"""
    try:
        total_before = count_unassigned_addresses()
        sample = get_unassigned_addresses(limit=3)
        assert len(sample) >= 3, f"Pas assez d'adresses non assignées pour le test (n={len(sample)})"
        ids = [int(x) for x in sample['id'].tolist()[:3]]

        updated = assign_addresses_to_team(ids, 'EQUIPE_TEST')
        assert updated >= 3, f"Moins de 3 lignes mises à jour (rowcount={updated})"

        # Vérifier qu'elles n'apparaissent plus dans les non assignées
        still_unassigned = get_unassigned_addresses(limit=10000)
        still_ids = set(int(x) for x in still_unassigned['id'].tolist())
        assert not any(i in still_ids for i in ids), "Des IDs assignés sont encore dans non-assignées"

        # Vérifier qu'elles sont bien visibles côté équipe
        team_df = get_team_addresses('EQUIPE_TEST')
        team_ids = set(int(x) for x in team_df['id'].tolist())
        assert all(i in team_ids for i in ids), "IDs non retrouvés côté équipe"

        total_after = count_unassigned_addresses()
        assert total_before - total_after >= 3, f"Réduction attendue >=3; avant={total_before} après={total_after}"

        print("✅ test_address_helpers: OK")
    except Exception as e:
        print("❌ Erreur test_address_helpers:", e)
        raise

# ============================================================================
# guignomap\db.py
# ============================================================================

"""
Database proxy module - redirects to unified database layer
"""
from guignomap.database import *


# ============================================================================
# guignomap\imports.py
# ============================================================================

"""
GuignoMap - Module d'import réutilisable pour adresses
Fonctions normalisées pour l'import de données d'adresses depuis Excel/CSV
"""
import re
import sqlite3
import pandas as pd
from datetime import datetime
from typing import Optional, Dict, Any
import unicodedata
import logging

from guignomap.database import get_conn, _ensure_foreign_keys


def normalize_text(txt: str) -> str:
    """
    Normalise un texte pour l'import :
    - Gère les valeurs 'nan' et None
    - Convertit en ASCII (gère accents/apostrophes)
    - Strip whitespace
    """
    if pd.isna(txt) or txt is None or str(txt).lower() in ['nan', 'none', '']:
        return ""
    
    # Convertir en string et strip
    text = str(txt).strip()
    
    # Normaliser les caractères Unicode (NFD = décomposition)
    # puis supprimer les diacritiques
    text = unicodedata.normalize('NFD', text)
    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
    
    # Remplacer les apostrophes typographiques et simples par des espaces
    # pour garantir la stabilité des clés d'adresse
    text = text.replace("'", " ").replace("'", " ").replace("`", " ")
    
    # Nettoyer les espaces multiples
    text = ' '.join(text.split())
    
    return text.strip()


def build_addr_key(street: str, number: str, postal: Optional[str] = None) -> str:
    """
    Construit une clé unique d'adresse normalisée :
    format: "street|number|postal" (lower, ascii, sans espaces)
    """
    street_norm = normalize_text(street).lower().replace(' ', '')
    number_norm = normalize_text(str(number)).lower().replace(' ', '')
    
    if postal and postal.strip():
        postal_norm = normalize_text(postal).lower().replace(' ', '')
        return f"{street_norm}|{number_norm}|{postal_norm}"
    else:
        return f"{street_norm}|{number_norm}|"


def detect_schema(df: pd.DataFrame, city: Optional[str] = None) -> Dict[str, str]:
    """
    Détecte automatiquement le schéma des colonnes dans un DataFrame :
    Retourne un mapping {street, number, postal?, sector?}
    """
    columns = df.columns.tolist()  # Garder les noms originaux
    columns_lower = [col.lower().strip() for col in columns]  # Version lower pour la recherche
    mapping = {}
    
    # Patterns de détection
    street_patterns = ['rue', 'street', 'voie', 'adresse', 'nom']
    number_patterns = ['nociv', 'numero', 'number', 'no', 'num', 'civic']
    postal_patterns = ['postal', 'code', 'zip']
    sector_patterns = ['secteur', 'sector', 'zone', 'district']
    
    def find_column(patterns, columns_list, original_columns):
        for pattern in patterns:
            for i, col in enumerate(columns_list):
                if pattern in col:
                    return original_columns[i]  # Retourner le nom original
        return None
    
    # Détection des colonnes principales
    street_col = find_column(street_patterns, columns_lower, columns)
    number_col = find_column(number_patterns, columns_lower, columns)
    postal_col = find_column(postal_patterns, columns_lower, columns)
    sector_col = find_column(sector_patterns, columns_lower, columns)
    
    if street_col:
        mapping['street'] = street_col
    if number_col:
        mapping['number'] = number_col
    if postal_col:
        mapping['postal'] = postal_col
    if sector_col:
        mapping['sector'] = sector_col
    
    logging.info(f"Schéma détecté pour {city or 'données'}: {mapping}")
    return mapping


def prepare_dataframe(df: pd.DataFrame, mapping: Dict[str, str], city: Optional[str] = None) -> pd.DataFrame:
    """
    Prépare un DataFrame pour l'import avec colonnes standardisées :
    [street_name, house_number, postal_code, sector, addr_key]
    """
    if 'street' not in mapping or 'number' not in mapping:
        raise ValueError("Mapping doit contenir au minimum 'street' et 'number'")
    
    # Création du DataFrame préparé
    prepared = pd.DataFrame()
    
    # Colonnes obligatoires
    prepared['street_name'] = df[mapping['street']].apply(normalize_text)
    prepared['house_number'] = df[mapping['number']].apply(lambda x: normalize_text(str(x)))
    
    # Colonnes optionnelles
    prepared['postal_code'] = ""
    if 'postal' in mapping and mapping['postal'] in df.columns:
        prepared['postal_code'] = df[mapping['postal']].apply(normalize_text)
    
    prepared['sector'] = ""
    if 'sector' in mapping and mapping['sector'] in df.columns:
        prepared['sector'] = df[mapping['sector']].apply(normalize_text)
    
    # Génération de la clé d'adresse
    prepared['addr_key'] = prepared.apply(
        lambda row: build_addr_key(row['street_name'], row['house_number'], row['postal_code']),
        axis=1
    )
    
    # Filtrer les lignes vides ou invalides
    initial_count = len(prepared)
    prepared = prepared[
        (prepared['street_name'] != "") & 
        (prepared['house_number'] != "") &
        (prepared['addr_key'] != "||")
    ].copy()
    
    filtered_count = initial_count - len(prepared)
    if filtered_count > 0:
        logging.warning(f"Filtré {filtered_count} lignes invalides/vides")
    
    # Supprimer les doublons basés sur addr_key
    duplicate_count = len(prepared) - len(prepared.drop_duplicates(subset=['addr_key']))
    if duplicate_count > 0:
        logging.warning(f"Supprimé {duplicate_count} doublons basés sur addr_key")
        prepared = prepared.drop_duplicates(subset=['addr_key'])
    
    logging.info(f"DataFrame préparé: {len(prepared)} adresses uniques")
    return prepared


def authoritative_swap(conn: sqlite3.Connection, df_prepared: pd.DataFrame) -> Dict[str, int]:
    """
    Swap atomique autoritatif des adresses :
    - Crée une table staging avec contrainte UNIQUE sur addr_key
    - Swap atomique avec la table addresses
    - Préserve assigned_to si la colonne existe
    - Ajoute les colonnes manquantes avec valeurs par défaut
    """
    _ensure_foreign_keys(conn)
    cursor = conn.cursor()
    
    try:
        # 1. Créer table staging
        cursor.execute("DROP TABLE IF EXISTS addresses_staging")
        cursor.execute("""
            CREATE TABLE addresses_staging (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                street_name TEXT NOT NULL,
                house_number TEXT NOT NULL,
                postal_code TEXT DEFAULT '',
                sector TEXT DEFAULT '',
                assigned_to TEXT DEFAULT NULL,
                latitude REAL DEFAULT NULL,
                longitude REAL DEFAULT NULL,
                osm_type TEXT DEFAULT NULL,
                addr_key TEXT NOT NULL UNIQUE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # 2. Vérifier si la table addresses existe et a une colonne assigned_to
        existing_assignments = {}
        try:
            cursor.execute("SELECT addr_key, assigned_to FROM addresses WHERE assigned_to IS NOT NULL AND assigned_to != ''")
            existing_assignments = {row[0]: row[1] for row in cursor.fetchall()}
            logging.info(f"Préservation de {len(existing_assignments)} assignations existantes")
        except sqlite3.OperationalError:
            logging.info("Table addresses n'existe pas ou pas de colonne assigned_to")
        
        # 3. Préparer les données pour l'insertion
        now = datetime.now().isoformat()
        insert_data = []
        
        for _, row in df_prepared.iterrows():
            addr_key = row['addr_key']
            assigned_to = existing_assignments.get(addr_key, None)
            
            insert_data.append((
                row['street_name'],
                row['house_number'],
                row.get('postal_code', ''),
                row.get('sector', ''),
                assigned_to,
                None,  # latitude
                None,  # longitude
                None,  # osm_type
                addr_key,
                now,   # created_at
                now    # updated_at
            ))
        
        # 4. Insertion en staging
        cursor.executemany("""
            INSERT INTO addresses_staging 
            (street_name, house_number, postal_code, sector, assigned_to, 
             latitude, longitude, osm_type, addr_key, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, insert_data)
        
        # 5. Créer les index sur staging
        cursor.execute("CREATE UNIQUE INDEX idx_staging_addr_key ON addresses_staging(addr_key)")
        cursor.execute("CREATE INDEX idx_staging_street_number ON addresses_staging(street_name, house_number)")
        
        # 6. Swap atomique des tables
        cursor.execute("DROP TABLE IF EXISTS addresses_old")
        cursor.execute("ALTER TABLE addresses RENAME TO addresses_old")
        cursor.execute("ALTER TABLE addresses_staging RENAME TO addresses")
        
        # 7. Nettoyer l'ancienne table
        cursor.execute("DROP TABLE IF EXISTS addresses_old")
        
        conn.commit()
        
        # 8. Statistiques
        final_count = len(df_prepared)
        preserved_assignments = len([a for a in existing_assignments.values() if a])
        
        stats = {
            'total_imported': final_count,
            'preserved_assignments': preserved_assignments,
            'new_unassigned': final_count - preserved_assignments
        }
        
        logging.info(f"Swap réussi: {stats}")
        return stats
        
    except Exception as e:
        conn.rollback()
        logging.error(f"Erreur lors du swap: {e}")
        raise

# ============================================================================
# guignomap\osm.py
# ============================================================================

"""
Module OSM pour Guigno-Map
Gère l'import et le cache des données OpenStreetMap pour Mascouche
"""

import io
import json
from pathlib import Path
import pandas as pd
import overpy

# Configuration
CACHE_FILE = Path(__file__).parent / "osm_cache.json"
ADDR_CACHE_FILE = Path(__file__).parent / "osm_addresses.json"

# Toutes les voies routières nommées de Mascouche
QUERY_STREETS_ALL = """
[out:json][timeout:300];
area["name"="Mascouche"]["boundary"="administrative"]->.a;
(
  way["highway"~"^(primary|secondary|tertiary|residential|service|unclassified|living_street|pedestrian|track|road|busway|footway|path)$"](area.a);
);
(._;>;);
out body;
"""
# Note: Récupère TOUS les types de voies incluant petites rues, allées, chemins piétonniers

# Requête pour les adresses
QUERY_ADDR_NODES = """
[out:json][timeout:180];
area["name"="Mascouche"]["boundary"="administrative"]->.a;
(
  node["addr:housenumber"]["addr:street"](area.a);
  way["addr:housenumber"]["addr:street"](area.a);
);
out tags center;
"""

def generate_streets_csv(city="Mascouche"):
    """
    Génère un CSV avec les noms des rues principales de la ville
    Filtre automatiquement les rues privées et les petites ruelles
    """
    try:
        api = overpy.Overpass()
        result = api.query(QUERY_STREETS_ALL)
        
        streets = []
        for way in result.ways:
            name = way.tags.get("name")
            if not name:
                continue
            g = getattr(way, "geometry", None)
            # garder si on a une vraie géométrie (>= 2 points)
            if isinstance(g, list) and len(g) >= 2:
                streets.append(name)

        streets = sorted(set(streets))
        
        # Assigner automatiquement des secteurs basés sur les patterns de noms
        sectors = []
        for street in streets:
            if any(word in street.lower() for word in ["montée", "chemin", "boulevard"]):
                sectors.append("Principal")
            elif any(word in street.lower() for word in ["avenue", "place", "croissant"]):
                sectors.append("Résidentiel")
            elif "rue" in street.lower():
                sectors.append("Centre")
            else:
                sectors.append("")
        
        df = pd.DataFrame({
            "name": streets,
            "sector": sectors,
            "team": [""] * len(streets)
        })
        
        buf = io.StringIO()
        df.to_csv(buf, index=False)
        print(f"✅ CSV généré avec {len(streets)} rues principales")
        return buf.getvalue().encode("utf-8")
        
    except Exception as e:
        print(f"'ùå Erreur OSM: {e}")
        # Retourner des données de test en cas d'erreur
        return create_fallback_csv()

def build_geometry_cache():
    """
    Construit le cache des géométries pour TOUTES les voies de Mascouche
    Force la résolution complète des nodes
    """
    try:
        print("🔄 Récupération complète de toutes les voies de Mascouche...")
        
        # IMPORTANT: Configurer l'API pour résoudre automatiquement les nodes manquants
        api = overpy.Overpass()
        
        # Requête améliorée qui force le retour des coordonnées
        query = """
        [out:json][timeout:300];
        area["name"="Mascouche"]["boundary"="administrative"]->.a;
        (
          way["highway"]["name"](area.a);
          way["highway"]["ref"](area.a);
        );
        (._;>;);
        out body;
        """
        
        print("📡 Connexion à OpenStreetMap (cela peut prendre 30-60 secondes)...")
        result = api.query(query)
        
        geo = {}
        stats = {"total": 0, "avec_geo": 0, "sans_geo": 0}
        
        # Construire un dictionnaire des nodes pour accès rapide
        nodes_dict = {}
        if hasattr(result, 'nodes'):
            for node in result.nodes:
                if hasattr(node, 'id') and hasattr(node, 'lat') and hasattr(node, 'lon'):
                    nodes_dict[node.id] = (float(node.lat), float(node.lon))
        
        print(f"📍 {len(nodes_dict)} nodes récupérés")
        
        ways = result.ways if hasattr(result, 'ways') else []
        print(f"📊 {len(ways)} voies trouvées dans OpenStreetMap")
        
        for way in ways:
            try:
                # Récupérer le nom ou ref
                if not hasattr(way, 'tags'):
                    continue
                    
                name = way.tags.get("name")
                if not name:
                    ref = way.tags.get("ref")
                    if ref:
                        name = f"Autoroute {ref}"
                    else:
                        continue
                
                stats["total"] += 1
                coords = []
                
                # Récupérer les IDs des nodes
                if hasattr(way, 'nd_ids'):
                    # Si on a les IDs des nodes, les résoudre
                    for node_id in way.nd_ids:
                        if node_id in nodes_dict:
                            lat, lon = nodes_dict[node_id]
                            coords.append([lat, lon])
                elif hasattr(way, 'nodes'):
                    # Si on a directement les nodes
                    for node in way.nodes:
                        if hasattr(node, 'lat') and hasattr(node, 'lon'):
                            coords.append([float(node.lat), float(node.lon)])
                        elif hasattr(node, 'id') and node.id in nodes_dict:
                            lat, lon = nodes_dict[node.id]
                            coords.append([lat, lon])
                
                if len(coords) >= 2:
                    if name not in geo:
                        geo[name] = []
                    geo[name].append(coords)
                    stats["avec_geo"] += 1
                else:
                    stats["sans_geo"] += 1
                    
            except Exception:
                continue
        
        print(f"✅ Résultat: {stats['avec_geo']} voies avec géométrie sur {stats['total']} trouvées")
        
        # Si on a récupéré des données, sauvegarder
        if geo:
            CACHE_FILE.write_text(json.dumps(geo, indent=2), encoding="utf-8")
            print(f"💾 Cache créé: {len(geo)} voies sauvegardées dans osm_cache.json")
            
            # Importer aussi automatiquement dans la DB
            try:
                from pathlib import Path
                import sys
                sys.path.append(str(Path(__file__).parent))
                import db
                
                db_path = Path(__file__).parent / "guigno_map.db"
                conn = db.get_conn(db_path)
                
                # Ajouter les rues manquantes à la DB
                for street_name in geo.keys():
                    cursor = conn.execute("SELECT COUNT(*) FROM streets WHERE name = ?", (street_name,))
                    if cursor.fetchone()[0] == 0:
                        conn.execute(
                            "INSERT INTO streets(name, sector, team, status) VALUES (?, '', '', 'a_faire')",
                            (street_name,)
                        )
                conn.commit()
                print("✅ Rues importées dans la base de données")
            except Exception as e:
                print(f"⚠️ Import DB: {e}")
            
            return geo
        
        # Si aucune donnée, utiliser un fallback étendu
        print("⚠️ Aucune donnée OSM, utilisation du fallback local")
        return get_extended_fallback()
            
    except Exception as e:
        print(f"'ùå Erreur: {e}")
        return get_extended_fallback()

def get_fallback_geometry():
    """Fallback avec les principales voies de Mascouche"""
    return {
        "Autoroute 25": [[[45.70, -73.65], [45.78, -73.58]]],
        "Autoroute 640": [[[45.76, -73.70], [45.76, -73.55]]],
        "Montée Masson": [[[45.730, -73.620], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.752, -73.590]]],
        "Chemin des Anglais": [[[45.74, -73.65], [45.75, -73.64]]],
        "Chemin Gascon": [[[45.75, -73.62], [45.76, -73.60]]],
        "Chemin Pincourt": [[[45.72, -73.64], [45.73, -73.63]]],
        "Chemin Newton": [[[45.73, -73.58], [45.74, -73.57]]],
        "Chemin Saint-Henri": [[[45.71, -73.61], [45.72, -73.60]]],
        "Chemin Saint-Pierre": [[[45.74, -73.59], [45.75, -73.58]]],
        "Avenue de la Gare": [[[45.745, -73.601], [45.748, -73.598]]],
        "Rue Dupras": [[[45.745, -73.602], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.749, -73.600]]],
        "Rue de l'Église": [[[45.747, -73.601], [45.750, -73.599]]],
        "Avenue des Érables": [[[45.755, -73.605], [45.758, -73.600]]],
        "Rue des Pins": [[[45.756, -73.603], [45.759, -73.598]]],
        "Rue Brien": [[[45.738, -73.605], [45.741, -73.600]]],
        "Rue Bohémier": [[[45.742, -73.607], [45.745, -73.604]]]
    }

def get_extended_fallback():
    """Fallback étendu avec les principales voies de Mascouche"""
    fallback = {
        # Autoroutes
        "Autoroute 25": [[[45.70, -73.65], [45.72, -73.63], [45.74, -73.61], [45.76, -73.59], [45.78, -73.58]]],
        "Autoroute 640": [[[45.76, -73.70], [45.76, -73.65], [45.76, -73.60], [45.76, -73.55]]],
        
        # Chemins principaux
        "Montée Masson": [[[45.730, -73.620], [45.740, -73.610], [45.750, -73.600], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.745, -73.605], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.747, -73.600], [45.752, -73.590]]],
        "Chemin des Anglais": [[[45.74, -73.65], [45.745, -73.645], [45.75, -73.64]]],
        "Chemin Gascon": [[[45.75, -73.62], [45.755, -73.615], [45.76, -73.60]]],
        "Chemin Pincourt": [[[45.72, -73.64], [45.725, -73.635], [45.73, -73.63]]],
        "Chemin Newton": [[[45.73, -73.58], [45.735, -73.575], [45.74, -73.57]]],
        "Chemin Saint-Henri": [[[45.71, -73.61], [45.715, -73.605], [45.72, -73.60]]],
        "Chemin Saint-Pierre": [[[45.74, -73.59], [45.745, -73.585], [45.75, -73.58]]],
        
        # Avenues
        "Avenue de la Gare": [[[45.745, -73.601], [45.747, -73.599], [45.748, -73.598]]],
        "Avenue Bourque": [[[45.742, -73.603], [45.744, -73.601], [45.746, -73.599]]],
        "Avenue Crépeau": [[[45.743, -73.602], [45.745, -73.600], [45.747, -73.598]]],
        "Avenue Garden": [[[45.751, -73.606], [45.753, -73.604], [45.755, -73.602]]],
        "Avenue de l'Esplanade": [[[45.748, -73.605], [45.750, -73.603], [45.752, -73.601]]],
        
        # Rues du centre
        "Rue Dupras": [[[45.745, -73.602], [45.747, -73.600], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.748, -73.602], [45.749, -73.600]]],
        "Rue de l'Église": [[[45.747, -73.601], [45.749, -73.599], [45.750, -73.598]]],
        "Rue Brien": [[[45.738, -73.605], [45.740, -73.603], [45.741, -73.600]]],
        "Rue Bohémier": [[[45.742, -73.607], [45.744, -73.605], [45.745, -73.604]]],
        
        # Rues résidentielles
        "Rue des Pins": [[[45.756, -73.603], [45.758, -73.601], [45.759, -73.598]]],
        "Avenue des Érables": [[[45.755, -73.605], [45.757, -73.603], [45.758, -73.600]]],
        "Rue Gravel": [[[45.738, -73.605], [45.740, -73.603], [45.741, -73.600]]]
    }
    
    # Sauvegarder le fallback
    CACHE_FILE.write_text(json.dumps(fallback, indent=2), encoding="utf-8")
    print(f"💾 Fallback sauvegardé avec {len(fallback)} voies principales")
    
    return fallback

def load_geometry_cache():
    """
    Charge le cache de géométries depuis le fichier JSON
    Crée un cache de base si le fichier n'existe pas
    """
    if not CACHE_FILE.exists():
        print("⚠️ Cache non trouvé, construction en cours...")
        return build_geometry_cache()  # build_geometry_cache() gère déjà le fallback en mémoire
    
    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
            print(f"✅ Cache chargé: {len(cache)} rues")
            return cache
    except Exception as e:
        print(f"'ùå Erreur chargement cache: {e}")
        # Ne pas écrire de fallback sur disque ! Utiliser build_geometry_cache() qui gère le fallback en mémoire
        return build_geometry_cache()

def create_fallback_csv():
    """
    Crée un CSV de fallback avec quelques rues principales de Mascouche
    Utilisé si l'API OSM est indisponible
    """
    fallback_streets = [
        ("Montée Masson", "Principal"),
        ("Chemin Sainte-Marie", "Principal"),
        ("Boulevard de Mascouche", "Principal"),
        ("Chemin des Anglais", "Principal"),
        ("Rue Dupras", "Centre"),
        ("Rue Saint-Pierre", "Centre"),
        ("Rue de l'Église", "Centre"),
        ("Avenue des Érables", "Résidentiel"),
        ("Rue des Pins", "Résidentiel"),
        ("Avenue Garden", "Résidentiel"),
    ]
    
    df = pd.DataFrame(fallback_streets, columns=["name", "sector"])
    df["team"] = ""
    
    buf = io.StringIO()
    df.to_csv(buf, index=False)
    print("⚠️ Mode fallback: 10 rues de test")
    return buf.getvalue().encode("utf-8")

def create_fallback_cache():
    """
    Crée un cache minimal pour tests
    """
    fallback_geo = {
        "Montée Masson": [[[45.730, -73.620], [45.750, -73.600], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.748, -73.602], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.747, -73.600], [45.752, -73.590]]],
        "Rue Dupras": [[[45.745, -73.602], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.749, -73.600]]],
        "Rue de l'Église": [[[45.747, -73.601], [45.750, -73.599]]],
        "Avenue des Érables": [[[45.755, -73.605], [45.758, -73.600]]],
        "Rue des Pins": [[[45.756, -73.603], [45.759, -73.598]]],
        "Avenue Garden": [[[45.753, -73.606], [45.756, -73.601]]],
        "Rue Gravel": [[[45.738, -73.605], [45.741, -73.600]]]
    }
    
    CACHE_FILE.write_text(json.dumps(fallback_geo, indent=2), encoding="utf-8")
    print("⚠️ Cache fallback créé avec 10 rues")

# Fonction utilitaire pour tests
def test_osm_connection():
    """
    Teste la connexion à l'API Overpass
    """
    try:
        api = overpy.Overpass()
        # Requête minimale pour tester
        result = api.query('[out:json];node(45.7475,-73.6005,45.7476,-73.6004);out;')
        print("'úÖ Connexion OSM OK")
        return True
    except:
        print("❌ Connexion OSM échouée")
        return False

# ========================================
# NOUVELLES FONCTIONS POUR LES ADRESSES
# ========================================

def build_addresses_cache():
    """
    Construit le cache des adresses OSM pour Mascouche
    Récupère addr:housenumber + addr:street depuis OSM
    """
    try:
        api = overpy.Overpass()
        result = api.query(QUERY_ADDR_NODES)
        
        addresses = {}
        
        # Traiter les nodes avec adresses
        for node in result.nodes:
            house_number = node.tags.get("addr:housenumber")
            street_name = node.tags.get("addr:street")
            
            if house_number and street_name:
                if street_name not in addresses:
                    addresses[street_name] = []
                addresses[street_name].append({
                    "number": str(house_number),  # Forcer en string
                    "lat": float(node.lat),
                    "lon": float(node.lon),
                    "type": "node"
                })
        
        # Traiter les ways avec adresses
        for way in result.ways:
            num = way.tags.get("addr:housenumber")
            street = way.tags.get("addr:street")
            if not num or not street:
                continue
            
            # Récupérer le centre du way
            lat = getattr(way, "center_lat", None)
            lon = getattr(way, "center_lon", None)
            
            # Fallback si center_lat/lon non disponibles
            if lat is None or lon is None:
                nodes = getattr(way, "nodes", []) or []
                if nodes:
                    try:
                        valid_lats = []
                        valid_lons = []
                        for n in nodes:
                            if hasattr(n, 'lat') and hasattr(n, 'lon'):
                                if n.lat is not None and n.lon is not None:
                                    valid_lats.append(float(n.lat))
                                    valid_lons.append(float(n.lon))
                        if valid_lats and valid_lons:
                            lat = sum(valid_lats) / len(valid_lats)
                            lon = sum(valid_lons) / len(valid_lons)
                    except Exception as e:
                        print(f"Erreur calcul centre pour way: {e}")
                        continue
            
            if lat is not None and lon is not None:
                addresses.setdefault(street, []).append({
                    "number": str(num),
                    "lat": float(lat),
                    "lon": float(lon),
                    "type": "way"
                })
        
        # Trier les adresses par numéro pour chaque rue
        for street_name in addresses:
            try:
                # Tri numérique intelligent
                addresses[street_name].sort(
                    key=lambda x: (
                        int(''.join(filter(str.isdigit, x["number"]))) 
                        if any(c.isdigit() for c in x["number"]) 
                        else float('inf')
                    )
                )
            except:
                # Si le tri échoue, garder l'ordre original
                pass
        
        # Sauvegarder le cache
        ADDR_CACHE_FILE.write_text(json.dumps(addresses, indent=2), encoding="utf-8")
        total_addresses = sum(len(addrs) for addrs in addresses.values())
        print(f"✅ Cache adresses créé: {len(addresses)} rues, {total_addresses} adresses")
        return addresses
        
    except Exception as e:
        print(f"'ùå Erreur construction cache adresses: {e}")
        # Créer un cache vide en cas d'erreur
        ADDR_CACHE_FILE.write_text(json.dumps({}), encoding="utf-8")
        return {}

def load_addresses_cache():
    """
    Charge le cache d'adresses depuis le fichier JSON
    """
    if not ADDR_CACHE_FILE.exists():
        print("⚠️ Cache adresses non trouvé")
        return {}
    
    try:
        with open(ADDR_CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
            total_addresses = sum(len(addrs) for addrs in cache.values())
            print(f"✅ Cache adresses chargé: {len(cache)} rues, {total_addresses} adresses")
            return cache
    except Exception as e:
        print(f"'ùå Erreur chargement cache adresses: {e}")
        return {}

# ============================================================================
# guignomap\reports.py
# ============================================================================

"""
Générateur de rapports Excel et PDF pour GuignoMap
"""

from pathlib import Path
from datetime import datetime
import pandas as pd
from reportlab.lib import colors
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib.enums import TA_CENTER
import xlsxwriter
from io import BytesIO
from guignomap.database import get_conn

# Mapping des statuts pour l'affichage (évite imports circulaires)
STATUS_TO_LABEL = {"a_faire": "À faire", "en_cours": "En cours", "terminee": "Terminée"}

# Fonctions SQLite pures pour les rapports
def extended_stats():
    with get_conn() as conn:
        cur = conn.execute("SELECT status, COUNT(*) as count FROM streets GROUP BY status")
        status_counts = dict(cur.fetchall())
        
        total = sum(status_counts.values())
        done = status_counts.get('terminee', 0)
        partial = status_counts.get('en_cours', 0) + status_counts.get('partielle', 0)
        todo = status_counts.get('a_faire', 0)
        
        return {
            'total': total,
            'done': done,
            'partial': partial,
            'todo': todo
        }

def list_streets():
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT s.name, s.sector, t.nom as team, s.status, 
                   COUNT(n.id) as notes
            FROM streets s 
            LEFT JOIN teams t ON s.team_id = t.id
            LEFT JOIN notes n ON s.id = n.street_id
            GROUP BY s.id, s.name, s.sector, t.nom, s.status
            ORDER BY s.name
        """)
        cols = [d[0] for d in cur.description]
        rows = [dict(zip(cols, row)) for row in cur.fetchall()]
        return rows

def stats_by_team():
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT t.nom as team_name,
                   COUNT(s.id) as total_streets,
                   SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done,
                   SUM(CASE WHEN s.status IN ('en_cours', 'partielle') THEN 1 ELSE 0 END) as in_progress,
                   COUNT(n.id) as total_notes
            FROM teams t
            LEFT JOIN streets s ON t.id = s.team_id
            LEFT JOIN notes n ON s.id = n.street_id
            WHERE t.id != 'ADMIN'
            GROUP BY t.id, t.nom
            ORDER BY t.nom
        """)
        cols = [d[0] for d in cur.description]
        return [dict(zip(cols, row)) for row in cur.fetchall()]

class ReportGenerator:
    def __init__(self):
        self.styles = getSampleStyleSheet()
        self._setup_custom_styles()
    
    def _setup_custom_styles(self):
        """Définit les styles personnalisés pour PDF"""
        self.styles.add(ParagraphStyle(
            name='CustomTitle',
            parent=self.styles['Heading1'],
            fontSize=24,
            textColor=colors.HexColor('#8B0000'),
            spaceAfter=30,
            alignment=TA_CENTER
        ))
        
        self.styles.add(ParagraphStyle(
            name='SectionTitle',
            parent=self.styles['Heading2'],
            fontSize=16,
            textColor=colors.HexColor('#8B0000'),
            spaceAfter=12,
            spaceBefore=12
        ))
    
    def generate_excel(self):
        """Génère un rapport Excel professionnel"""
        output = BytesIO()
        workbook = xlsxwriter.Workbook(output, {'remove_timezone': True})
        
        # Styles Excel
        header_format = workbook.add_format({
            'bold': True,
            'bg_color': '#8B0000',
            'font_color': 'white',
            'align': 'center',
            'valign': 'vcenter',
            'border': 1
        })
        
        cell_format = workbook.add_format({
            'align': 'center',
            'valign': 'vcenter',
            'border': 1
        })
        
        status_formats = {
            'terminee': workbook.add_format({'bg_color': '#90EE90', 'border': 1}),
            'en_cours': workbook.add_format({'bg_color': '#FFE4B5', 'border': 1}),
            'a_faire': workbook.add_format({'bg_color': '#FFB6C1', 'border': 1})
        }
        
        # Feuille 1 : Résumé
        summary_sheet = workbook.add_worksheet('Résumé Guignolée 2025')
        summary_sheet.set_column(0, 4, 20)  # A:E
        
        # Titre
        title_format = workbook.add_format({
            'bold': True,
            'font_size': 20,
            'font_color': '#8B0000',
            'align': 'center'
        })
        summary_sheet.merge_range(0, 0, 0, 4, 'GUIGNOLÉE 2025 - RELAIS DE MASCOUCHE', title_format)  # A1:E1
        summary_sheet.merge_range(1, 0, 1, 4, f'Rapport généré le {datetime.now().strftime("%d/%m/%Y à %H:%M")}', cell_format)  # A2:E2
        
        # Stats globales
        stats = extended_stats()
        
        row = 4
        summary_sheet.write(row, 0, 'STATISTIQUES GLOBALES', header_format)
        summary_sheet.merge_range(row, 1, row, 4, '', header_format)  # B{row+1}:E{row+1}
        
        row += 2
        summary_data = [
            ['Total des rues', stats['total']],
            ['Rues terminées', stats['done']],
            ['Rues en cours', stats.get('partial', 0)],
            ['Rues à faire', stats.get('todo', 0)],
            ['Progression globale', f"{(stats['done']/stats['total']*100) if stats['total'] > 0 else 0:.1f}%"],
            ['Total des notes', stats.get('total_notes', 0)],
            ['Adresses avec notes', stats.get('addresses_with_notes', 0)]
        ]
        
        for label, value in summary_data:
            summary_sheet.write(row, 0, label, cell_format)
            summary_sheet.write(row, 1, value, cell_format)
            row += 1
        
        # Feuille 2 : Détail des rues
        streets_sheet = workbook.add_worksheet('Détail des rues')
        streets_sheet.set_column(0, 0, 30)
        streets_sheet.set_column(1, 4, 15)
        
        # Headers
        headers = ['Rue', 'Secteur', 'Équipe', 'Statut', 'Notes']
        for col, header in enumerate(headers):
            streets_sheet.write(0, col, header, header_format)
        
        # Données
        street_data = list_streets()
        
        for idx, row in enumerate(street_data, 1):
            streets_sheet.write(idx, 0, row.get('name', ''), cell_format)
            streets_sheet.write(idx, 1, row.get('sector', ''), cell_format)
            streets_sheet.write(idx, 2, row.get('team', ''), cell_format)
            
            status = row.get('status', 'a_faire')
            format_to_use = status_formats.get(status, cell_format)
            status_label = STATUS_TO_LABEL.get(status, "À faire")
            streets_sheet.write(idx, 3, status_label, format_to_use)
            
            streets_sheet.write(idx, 4, row.get('notes', 0), cell_format)
        
        # Feuille 3 : Performance des équipes
        teams_sheet = workbook.add_worksheet('Performance équipes')
        teams_sheet.set_column(0, 5, 15)
        
        teams_data = stats_by_team()
        
        if teams_data:
            headers = ['Équipe', 'Total rues', 'Terminées', 'En cours', 'Notes', 'Progression %']
            for col, header in enumerate(headers):
                teams_sheet.write(0, col, header, header_format)
            
            for idx, row in enumerate(teams_data, 1):
                total = row.get('total_streets', 0)
                completed = row.get('completed', 0)
                in_progress = row.get('in_progress', 0)
                todo = row.get('todo', 0)
                progress = (completed / total * 100) if total > 0 else 0
                teams_sheet.write(idx, 0, row.get('name', ''), cell_format)
                teams_sheet.write(idx, 1, total, cell_format)
                teams_sheet.write(idx, 2, completed, cell_format)
                teams_sheet.write(idx, 3, in_progress, cell_format)
                teams_sheet.write(idx, 4, todo, cell_format)
                teams_sheet.write(idx, 5, f"{progress:.1f}%", cell_format)
        
        workbook.close()
        output.seek(0)
        return output.getvalue()
    
    def generate_pdf(self):
        """Génère un rapport PDF professionnel"""
        output = BytesIO()
        doc = SimpleDocTemplate(output, pagesize=A4)
        story = []
        
        # Page de titre
        story.append(Paragraph("GUIGNOLÉE 2025", self.styles['CustomTitle']))
        story.append(Paragraph("Le Relais de Mascouche", self.styles['Title']))
        story.append(Spacer(1, 0.2*inch))
        story.append(Paragraph(f"Rapport généré le {datetime.now().strftime('%d/%m/%Y à %H:%M')}", self.styles['Normal']))
        story.append(PageBreak())
        
        # Résumé
        story.append(Paragraph("Résumé de la collecte", self.styles['SectionTitle']))
        
        # Réutilise la fonction extended_stats déjà définie ci-dessus
        stats = extended_stats()
        
        summary_data = [
            ['Statistique', 'Valeur'],
            ['Total des rues', str(stats['total'])],
            ['Rues terminées', str(stats['done'])],
            ['Rues en cours', str(stats.get('partial', 0))],
            ['Rues à faire', str(stats.get('todo', 0))],
            ['Progression', f"{(stats['done']/stats['total']*100) if stats['total'] > 0 else 0:.1f}%"],
            ['Total notes', str(stats.get('total_notes', 0))]
        ]
        
        summary_table = Table(summary_data, colWidths=[3*inch, 2*inch])
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#8B0000')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 14),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(summary_table)
        story.append(PageBreak())
        
        # Performance des équipes
        story.append(Paragraph("Performance des équipes", self.styles['SectionTitle']))
        
        teams_data_list = stats_by_team()
        
        if teams_data_list:
            teams_data = [['Équipe', 'Total', 'Terminées', 'En cours', 'Progression']]
            for row in teams_data_list:
                total = row.get('total_streets', 0)
                completed = row.get('completed', 0)
                in_progress = row.get('in_progress', 0)
                progress = (completed / total * 100) if total > 0 else 0
                teams_data.append([
                    row.get('name', ''),
                    str(total),
                    str(completed),
                    str(in_progress),
                    f"{progress:.1f}%"
                ])
            
            teams_table = Table(teams_data, colWidths=[2*inch, 1*inch, 1*inch, 1*inch, 1.5*inch])
            teams_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#8B0000')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            story.append(teams_table)
        
        doc.build(story)
        output.seek(0)
        return output.getvalue()


def export_assignments_to_excel(outfile: str = "exports/assignments.xlsx") -> str:
    """
    Exporte les assignations de rues vers un fichier Excel.
    
    Args:
        outfile: Chemin du fichier de sortie
    
    Returns:
        Chemin du fichier créé
    """
    
    # Récupérer les données des rues directement depuis la DB
    with get_conn() as conn:
        cur = conn.execute("""
            SELECT id, name, sector, status, team
            FROM streets
            ORDER BY name
        """)
        cols = [d[0] for d in cur.description]
        rows = cur.fetchall()
        df = pd.DataFrame(rows, columns=cols)
    
    # Créer le dossier exports s'il n'existe pas
    Path("exports").mkdir(exist_ok=True)
    
    # Exporter vers Excel
    df.to_excel(outfile, index=False)
    
    return outfile

# ============================================================================
# guignomap\utils.py
# ============================================================================

"""
Utilitaires pour GuignoMap
Fonctions helper et adapteurs de données
"""
import pandas as pd
from typing import Any, Iterable

def to_dataframe(records: Any) -> pd.DataFrame:
    """Convertit divers types de données en DataFrame pandas"""
    if isinstance(records, pd.DataFrame):
        return records
    # RowMapping unique
    try:
        if hasattr(records, "keys") and hasattr(records, "__getitem__"):
            return pd.DataFrame([dict(records)])
    except Exception:
        pass
    # Séquences (list[dict]/list[Row]/list[ORM])
    if isinstance(records, Iterable):
        items = list(records)
        if items and not isinstance(items[0], dict):
            dicts = []
            for r in items:
                if hasattr(r, "__dict__"):
                    d = {k:v for k,v in r.__dict__.items() if not k.startswith("_sa_")}
                    dicts.append(d)
                else:
                    try: dicts.append(dict(r))
                    except Exception: dicts.append({"value": r})
            return pd.DataFrame(dicts)
        return pd.DataFrame(items)
    return pd.DataFrame([])

# ============================================================================
# guignomap\validators.py
# ============================================================================

"""
Validateurs et sanitizers pour GuignoMap
Protection contre injections et validation des formats
"""

import re
import html
from typing import Tuple

class InputValidator:
    """Classe de validation et sanitization des entrées"""
    
    @staticmethod
    def sanitize_text(text: str, max_length: int = 255) -> str:
        """Nettoie et limite un texte"""
        if not text:
            return ""
        # Supprimer les caractères de contrôle
        text = "".join(char for char in text if ord(char) >= 32 or char == '\n')
        # Échapper le HTML
        text = html.escape(text)
        # Limiter la longueur
        return text[:max_length].strip()
    
    @staticmethod
    def sanitize_street_name(name: str) -> str:
        """Valide et nettoie un nom de rue"""
        if not name:
            return ""
        # Garder seulement lettres, chiffres, espaces, tirets, apostrophes, accents
        name = re.sub(r'[^a-zA-ZÀ-ÿ0-9\s\-\'\.]', '', name)
        return name[:100].strip()
    
    @staticmethod
    def sanitize_team_id(team_id: str) -> str:
        """Valide un ID d'équipe"""
        if not team_id:
            return ""
        # Format: LETTRES + CHIFFRES seulement, max 20 caractères
        team_id = re.sub(r'[^A-Z0-9]', '', team_id.upper())
        return team_id[:20]
    
    @staticmethod
    def sanitize_address_number(number: str) -> str:
        """Valide un numéro civique"""
        if not number:
            return ""
        # Garder chiffres et lettres (ex: 123A)
        number = re.sub(r'[^0-9A-Za-z\-]', '', number)
        return number[:10]
    
    @staticmethod
    def validate_password(password: str) -> Tuple[bool, str]:
        """Valide la force d'un mot de passe - minimum 4 caractères"""
        if password is None:
            return False, "Mot de passe requis"
        if len(password) < 4:
            return False, "Minimum 4 caractères"
        if len(password) > 128:
            return False, "Maximum 128 caractères"
        return True, "OK"
    
    @staticmethod
    def validate_sector(sector: str) -> str:
        """Valide un secteur"""
        valid_sectors = ['Principal', 'Centre', 'Nord', 'Sud', 'Est', 'Ouest', 'Résidentiel', '']
        if sector not in valid_sectors:
            return ''
        return sector
    
    @staticmethod
    def validate_status(status: str) -> str:
        """Valide un statut de rue"""
        valid_statuses = ['a_faire', 'en_cours', 'terminee']
        if status not in valid_statuses:
            return 'a_faire'
        return status
    
    @staticmethod
    def sanitize_note(note: str) -> str:
        """Nettoie une note/commentaire"""
        if not note:
            return ""
        # Supprimer caractères dangereux mais garder ponctuation basique
        note = re.sub(r'[<>\"\'`;]', '', note)
        return note[:500].strip()
    
    @staticmethod
    def is_sql_safe(text: str) -> bool:
        """Vérifie qu'un texte ne contient pas de patterns SQL dangereux"""
        if not text:
            return True
        dangerous_patterns = [
            r'\bDROP\b', r'\bDELETE\b', r'\bINSERT\b', r'\bUPDATE\b',
            r'\bEXEC\b', r'\bEXECUTE\b', r'--', r'/\*', r'\*/', r';'
        ]
        text_upper = text.upper()
        for pattern in dangerous_patterns:
            if re.search(pattern, text_upper):
                return False
        return True

def validate_and_clean_input(input_type: str, value: str) -> Tuple[bool, str]:
    """Fonction principale de validation"""
    validator = InputValidator()
    
    if input_type == "team_id":
        clean = validator.sanitize_team_id(value)
        return bool(clean), clean
    
    elif input_type == "street_name":
        clean = validator.sanitize_street_name(value)
        if not validator.is_sql_safe(clean):
            return False, ""
        return bool(clean), clean
    
    elif input_type == "address":
        clean = validator.sanitize_address_number(value)
        return bool(clean), clean
    
    elif input_type == "note":
        clean = validator.sanitize_note(value)
        if not validator.is_sql_safe(clean):
            return False, ""
        return bool(clean), clean
    
    elif input_type == "sector":
        clean = validator.validate_sector(value)
        return True, clean
    
    elif input_type == "status":
        clean = validator.validate_status(value)
        return True, clean
    
    elif input_type == "password":
        valid, msg = validator.validate_password(value)
        return valid, value if valid else ""
    
    else:
        clean = validator.sanitize_text(value)
        return bool(clean), clean

# ============================================================================
# legacy\config.py
# ============================================================================

"""
Configuration centralisée pour GuignoMap v5.0
Accès unifié aux variables d'environnement, secrets Streamlit et paramètres applicatifs
"""
import os
from dataclasses import dataclass
try:
    import streamlit as st
    _SECRETS = dict(st.secrets) if hasattr(st, "secrets") else {}
except Exception:
    _SECRETS = {}

def _get(key, default=None, section=None):
    """Récupère une valeur par priorité: env -> secrets -> défaut"""
    # Priorité 1: Variable d'environnement
    env_value = os.getenv(key)
    if env_value is not None:
        return env_value
    
    # Priorité 2: Secrets Streamlit
    try:
        if section and section in _SECRETS:
            return _SECRETS[section].get(key, default)
        return _SECRETS.get(key, default)
    except (KeyError, AttributeError):
        return default


def _get_str(key, default="", section=None) -> str:
    """Récupère une valeur string avec garantie de type"""
    value = _get(key, default, section)
    return str(value) if value is not None else default


def _get_int(key, default=0, section=None) -> int:
    """Récupère une valeur int avec garantie de type"""
    value = _get(key, default, section)
    try:
        return int(value) if value is not None else default
    except (ValueError, TypeError):
        return default


def _get_bool(key, default=False, section=None) -> bool:
    """Récupère une valeur bool avec garantie de type"""
    value = _get(key, default, section)
    if isinstance(value, bool):
        return value
    if isinstance(value, str):
        return value.lower() in ('true', '1', 'yes', 'on')
    return bool(value) if value is not None else default


@dataclass
class Settings:
    """Configuration unifiée de l'application"""
    # Authentification technique
    TECH_PIN: str = _get_str("TECH_PIN", "")
    
    # Base de données
    DB_URL: str = _get_str("url", "sqlite:///guigno_map.db", "database")
    DB_POOL_SIZE: int = _get_int("pool_size", 5, "database")
    DB_MAX_OVERFLOW: int = _get_int("max_overflow", 10, "database")
    
    # Stockage S3
    S3_BUCKET: str = _get_str("s3_bucket", "guignomap-dev", "storage")
    S3_REGION: str = _get_str("s3_region", "us-east-1", "storage")
    S3_ACCESS_KEY: str = _get_str("s3_access_key", "", "storage")
    S3_SECRET_KEY: str = _get_str("s3_secret_key", "", "storage")
    CDN_BASE_URL: str = _get_str("cdn_base_url", "", "storage")
    
    # Authentification
    ALLOW_BCRYPT_FALLBACK: bool = _get_bool("allow_bcrypt_fallback", True, "auth")
    MIN_PASSWORD_LENGTH: int = _get_int("min_password_length", 4, "auth")
    PASSWORD_SALT: str = _get_str("password_salt", "", "auth")
    
    # Environnement
    ENV: str = _get_str("ENV", "local")


# Instance globale des paramètres
settings = Settings()


# === FONCTIONS DE COMPATIBILITÉ LEGACY (à supprimer progressivement) ===

def get_database_url():
    """Récupère l'URL de la base de données depuis les secrets"""
    return settings.DB_URL


def get_database_pool_config():
    """Configuration du pool de connexions PostgreSQL"""
    return {
        "pool_size": settings.DB_POOL_SIZE,
        "max_overflow": settings.DB_MAX_OVERFLOW
    }


def get_s3_config():
    """Configuration S3 pour le stockage cloud"""
    return {
        "bucket": settings.S3_BUCKET,
        "region": settings.S3_REGION,
        "access_key": settings.S3_ACCESS_KEY,
        "secret_key": settings.S3_SECRET_KEY
    }


def get_cdn_base_url():
    """URL de base CDN pour les assets (optionnel)"""
    return settings.CDN_BASE_URL


def get_auth_config():
    """Configuration de l'authentification"""
    return {
        "allow_bcrypt_fallback": settings.ALLOW_BCRYPT_FALLBACK,
        "min_password_length": settings.MIN_PASSWORD_LENGTH,
        "password_salt": settings.PASSWORD_SALT
    }


# Constantes pour accès direct (compatibilité)
ALLOW_BCRYPT_FALLBACK = settings.ALLOW_BCRYPT_FALLBACK

# ============================================================================
# legacy\storage\__init__.py
# ============================================================================

"""
Adapter de stockage pour GuignoMap v5.0
Sélection automatique entre cloud S3 et local selon configuration
"""
import os
from typing import Optional, Dict, Any
from pathlib import Path

try:
    from src.storage.cloud import (
        upload_osm_cache as cloud_upload_osm_cache,
        download_osm_cache as cloud_download_osm_cache,
        upload_backup_to_cloud as cloud_upload_backup,
        list_cloud_backups as cloud_list_backups,
        download_backup_from_cloud as cloud_download_backup
    )
    CLOUD_AVAILABLE = True
except ImportError as e:
    print(f"⚠️ Stockage cloud non disponible: {e}")
    CLOUD_AVAILABLE = False

from src.storage.local import (
    upload_osm_cache as local_upload_osm_cache,
    download_osm_cache as local_download_osm_cache,
    upload_backup_to_cloud as local_upload_backup,
    list_cloud_backups as local_list_backups,
    download_backup_from_cloud as local_download_backup
)


def is_cloud_storage_enabled() -> bool:
    """
    Détermine si le stockage cloud est activé
    Vérifie la présence des secrets S3 et la disponibilité des libs
    """
    if not CLOUD_AVAILABLE:
        return False
    
    try:
        from src.config import get_s3_config
        config = get_s3_config()
        
        # Vérifier que les clés essentielles sont présentes et non vides
        required_keys = ['bucket', 'access_key', 'secret_key']
        for key in required_keys:
            if not config.get(key) or config[key] in ['', 'xxx']:
                return False
        
        return True
    except Exception:
        return False


def get_storage_backend() -> str:
    """Retourne 'cloud' ou 'local' selon la configuration"""
    return 'cloud' if is_cloud_storage_enabled() else 'local'


# API unifiée pour le stockage
def upload_osm_cache(cache_data: Dict[Any, Any]) -> bool:
    """Upload du cache OSM (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("📡 Upload cache OSM vers S3...")
        return cloud_upload_osm_cache(cache_data)
    else:
        print("💾 Sauvegarde cache OSM en local...")
        return local_upload_osm_cache(cache_data)


def download_osm_cache() -> Optional[Dict[Any, Any]]:
    """Download du cache OSM (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("📡 Téléchargement cache OSM depuis S3...")
        return cloud_download_osm_cache()
    else:
        print("💾 Lecture cache OSM local...")
        return local_download_osm_cache()


def upload_backup(backup_path: Path) -> bool:
    """Upload d'un backup (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("📡 Upload backup vers S3...")
        return cloud_upload_backup(backup_path)
    else:
        print("💾 Copie backup en local...")
        return local_upload_backup(backup_path)


def list_backups() -> list:
    """Liste des backups disponibles (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("📡 Liste backups S3...")
        return cloud_list_backups()
    else:
        print("💾 Liste backups locaux...")
        return local_list_backups()


def download_backup(backup_key: str, local_path: Path) -> bool:
    """Download d'un backup (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("📡 Téléchargement backup depuis S3...")
        return cloud_download_backup(backup_key, local_path)
    else:
        print("💾 Copie backup depuis local...")
        return local_download_backup(backup_key, local_path)


def get_storage_info() -> Dict[str, Any]:
    """Informations sur le backend de stockage actuel"""
    backend = get_storage_backend()
    info = {
        'backend': backend,
        'cloud_available': CLOUD_AVAILABLE,
        'cloud_enabled': is_cloud_storage_enabled()
    }
    
    if backend == 'cloud':
        try:
            from src.config import get_s3_config
            config = get_s3_config()
            info.update({
                'bucket': config.get('bucket', ''),
                'region': config.get('region', ''),
                'cdn_enabled': bool(config.get('cdn_base_url', ''))
            })
        except:
            pass
    
    return info

# ============================================================================
# legacy\storage\cloud.py
# ============================================================================

"""
Stockage cloud S3 pour GuignoMap v5.0
Client boto3 pour osm_cache.json et backups
"""
import boto3
import json
import io
import os
import streamlit as st
from typing import Optional, Dict, Any, BinaryIO
from pathlib import Path
from datetime import datetime
from src.config import get_s3_config, get_cdn_base_url


class S3StorageClient:
    """Client S3 pour gérer osm_cache.json et backups"""
    
    def __init__(self):
        self.config = get_s3_config()
        self.cdn_base_url = get_cdn_base_url()
        self._client = None
    
    @property
    def client(self):
        """Client S3 avec lazy loading et cache Streamlit"""
        if self._client is None:
            try:
                self._client = boto3.client(
                    's3',
                    region_name=self.config['region'],
                    aws_access_key_id=self.config['access_key'],
                    aws_secret_access_key=self.config['secret_key']
                )
            except Exception as e:
                print(f"Erreur initialisation client S3: {e}")
                raise
        return self._client
    
    def upload_json_file(self, key: str, data: Dict[Any, Any], metadata: Optional[Dict[str, str]] = None) -> bool:
        """
        Upload d'un fichier JSON vers S3
        """
        try:
            json_content = json.dumps(data, ensure_ascii=False, indent=2)
            json_bytes = json_content.encode('utf-8')
            
            extra_args: Dict[str, Any] = {
                'ContentType': 'application/json',
                'ContentEncoding': 'utf-8'
            }
            
            if metadata:
                extra_args['Metadata'] = metadata
            
            self.client.put_object(
                Bucket=self.config['bucket'],
                Key=key,
                Body=json_bytes,
                **extra_args
            )
            
            print(f"✅ JSON uploadé vers S3: {key}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur upload JSON S3 {key}: {e}")
            return False
    
    def download_json_file(self, key: str) -> Optional[Dict[Any, Any]]:
        """
        Download d'un fichier JSON depuis S3
        """
        try:
            response = self.client.get_object(
                Bucket=self.config['bucket'],
                Key=key
            )
            
            content = response['Body'].read().decode('utf-8')
            data = json.loads(content)
            
            print(f"✅ JSON téléchargé depuis S3: {key}")
            return data
            
        except self.client.exceptions.NoSuchKey:
            print(f"ℹ️ Fichier JSON S3 non trouvé: {key}")
            return None
        except Exception as e:
            print(f"❌ Erreur download JSON S3 {key}: {e}")
            return None
    
    def upload_backup(self, backup_file_path: Path, s3_key: Optional[str] = None) -> bool:
        """
        Upload d'un fichier backup vers S3
        """
        try:
            if not backup_file_path.exists():
                print(f"❌ Fichier backup non trouvé: {backup_file_path}")
                return False
            
            # Générer la clé S3 si non fournie
            if not s3_key:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                s3_key = f"backups/{backup_file_path.stem}_{timestamp}{backup_file_path.suffix}"
            
            # Upload avec streaming pour gros fichiers
            with open(backup_file_path, 'rb') as f:
                self.client.upload_fileobj(
                    f,
                    self.config['bucket'],
                    s3_key,
                    ExtraArgs={
                        'ContentType': 'application/zip',
                        'Metadata': {
                            'original_filename': backup_file_path.name,
                            'upload_timestamp': datetime.utcnow().isoformat()
                        }
                    }
                )
            
            print(f"✅ Backup uploadé vers S3: {s3_key}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur upload backup S3: {e}")
            return False
    
    def download_backup(self, s3_key: str, local_path: Path) -> bool:
        """
        Download d'un backup depuis S3
        """
        try:
            # Créer le répertoire parent si nécessaire
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Download avec streaming
            with open(local_path, 'wb') as f:
                self.client.download_fileobj(
                    self.config['bucket'],
                    s3_key,
                    f
                )
            
            print(f"✅ Backup téléchargé depuis S3: {s3_key} → {local_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur download backup S3 {s3_key}: {e}")
            return False
    
    def list_backups(self, prefix: str = "backups/") -> list:
        """
        Liste des backups disponibles sur S3
        """
        try:
            response = self.client.list_objects_v2(
                Bucket=self.config['bucket'],
                Prefix=prefix
            )
            
            backups = []
            if 'Contents' in response:
                for obj in response['Contents']:
                    backups.append({
                        'key': obj['Key'],
                        'size': obj['Size'],
                        'last_modified': obj['LastModified'],
                        'filename': Path(obj['Key']).name
                    })
                
                # Trier par date de modification (plus récent en premier)
                backups.sort(key=lambda x: x['last_modified'], reverse=True)
            
            return backups
            
        except Exception as e:
            print(f"❌ Erreur liste backups S3: {e}")
            return []
    
    def delete_file(self, key: str) -> bool:
        """
        Suppression d'un fichier sur S3
        """
        try:
            self.client.delete_object(
                Bucket=self.config['bucket'],
                Key=key
            )
            print(f"✅ Fichier supprimé de S3: {key}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur suppression S3 {key}: {e}")
            return False
    
    def file_exists(self, key: str) -> bool:
        """
        Vérifier si un fichier existe sur S3
        """
        try:
            self.client.head_object(
                Bucket=self.config['bucket'],
                Key=key
            )
            return True
        except self.client.exceptions.NoSuchKey:
            return False
        except Exception as e:
            print(f"❌ Erreur vérification existence S3 {key}: {e}")
            return False
    
    def get_public_url(self, key: str, expires_in: int = 3600) -> Optional[str]:
        """
        Générer URL publique signée pour un fichier S3
        """
        try:
            # Si CDN configuré, utiliser l'URL CDN
            if self.cdn_base_url:
                return f"{self.cdn_base_url.rstrip('/')}/{key}"
            
            # Sinon, générer URL signée S3
            url = self.client.generate_presigned_url(
                'get_object',
                Params={'Bucket': self.config['bucket'], 'Key': key},
                ExpiresIn=expires_in
            )
            return url
            
        except Exception as e:
            print(f"❌ Erreur génération URL publique S3 {key}: {e}")
            return None


# Instance globale pour cache Streamlit
@st.cache_resource
def get_s3_client() -> S3StorageClient:
    """Factory avec cache Streamlit pour client S3"""
    return S3StorageClient()


# API simplifiée pour les fonctions métier
def upload_osm_cache(cache_data: Dict[Any, Any]) -> bool:
    """Upload du cache OSM vers S3"""
    client = get_s3_client()
    return client.upload_json_file(
        "osm_cache.json", 
        cache_data,
        metadata={
            'type': 'osm_cache',
            'updated_at': datetime.utcnow().isoformat()
        }
    )


def download_osm_cache() -> Optional[Dict[Any, Any]]:
    """Download du cache OSM depuis S3"""
    client = get_s3_client()
    return client.download_json_file("osm_cache.json")


def upload_backup_to_cloud(backup_path: Path) -> bool:
    """Upload d'un backup vers S3"""
    client = get_s3_client()
    return client.upload_backup(backup_path)


def list_cloud_backups() -> list:
    """Liste des backups cloud disponibles"""
    client = get_s3_client()
    return client.list_backups()


def download_backup_from_cloud(s3_key: str, local_path: Path) -> bool:
    """Download d'un backup depuis S3"""
    client = get_s3_client()
    return client.download_backup(s3_key, local_path)

# ============================================================================
# legacy\storage\local.py
# ============================================================================

"""
Stockage local pour GuignoMap v5.0  
Fallback avec API identique à cloud.py
"""
import json
import shutil
import os
from typing import Optional, Dict, Any
from pathlib import Path
from datetime import datetime


class LocalStorageClient:
    """Client stockage local avec API identique au client S3"""
    
    def __init__(self, base_path: Optional[Path] = None):
        # Répertoire de base pour le stockage local
        if base_path is None:
            base_path = Path(__file__).parent.parent.parent / "storage_local"
        
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
        
        # Sous-répertoires
        self.backups_dir = self.base_path / "backups"
        self.backups_dir.mkdir(exist_ok=True)
    
    def upload_json_file(self, key: str, data: Dict[Any, Any], metadata: Optional[Dict[str, str]] = None) -> bool:
        """
        Sauvegarde d'un fichier JSON en local
        """
        try:
            file_path = self.base_path / key
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Sauvegarder les données JSON
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # Sauvegarder les métadonnées si fournies
            if metadata:
                metadata_path = file_path.with_suffix('.metadata.json')
                with open(metadata_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"✅ JSON sauvé localement: {file_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur sauvegarde JSON local {key}: {e}")
            return False
    
    def download_json_file(self, key: str) -> Optional[Dict[Any, Any]]:
        """
        Lecture d'un fichier JSON local
        """
        try:
            file_path = self.base_path / key
            
            if not file_path.exists():
                print(f"ℹ️ Fichier JSON local non trouvé: {file_path}")
                return None
            
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"✅ JSON lu localement: {file_path}")
            return data
            
        except Exception as e:
            print(f"❌ Erreur lecture JSON local {key}: {e}")
            return None
    
    def upload_backup(self, backup_file_path: Path, s3_key: Optional[str] = None) -> bool:
        """
        Copie d'un fichier backup vers le répertoire local
        """
        try:
            if not backup_file_path.exists():
                print(f"❌ Fichier backup non trouvé: {backup_file_path}")
                return False
            
            # Générer le nom de destination si non fourni
            if not s3_key:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                dest_name = f"{backup_file_path.stem}_{timestamp}{backup_file_path.suffix}"
            else:
                # Extraire le nom du fichier de la clé S3
                dest_name = Path(s3_key).name
            
            dest_path = self.backups_dir / dest_name
            
            # Copier le fichier
            shutil.copy2(backup_file_path, dest_path)
            
            # Créer un fichier de métadonnées
            metadata = {
                'original_filename': backup_file_path.name,
                'original_path': str(backup_file_path),
                'upload_timestamp': datetime.utcnow().isoformat(),
                'size': backup_file_path.stat().st_size
            }
            
            metadata_path = dest_path.with_suffix(dest_path.suffix + '.metadata.json')
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"✅ Backup copié localement: {dest_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur copie backup local: {e}")
            return False
    
    def download_backup(self, s3_key: str, local_path: Path) -> bool:
        """
        Copie d'un backup depuis le stockage local
        """
        try:
            # Trouver le fichier source
            source_name = Path(s3_key).name
            source_path = self.backups_dir / source_name
            
            if not source_path.exists():
                print(f"❌ Backup local non trouvé: {source_path}")
                return False
            
            # Créer le répertoire de destination
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Copier le fichier
            shutil.copy2(source_path, local_path)
            
            print(f"✅ Backup copié depuis local: {source_path} → {local_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur copie backup depuis local {s3_key}: {e}")
            return False
    
    def list_backups(self, prefix: str = "backups/") -> list:
        """
        Liste des backups disponibles en local
        """
        try:
            backups = []
            
            # Lister tous les fichiers (sauf métadonnées)
            for backup_file in self.backups_dir.glob("*"):
                if backup_file.is_file() and not backup_file.name.endswith('.metadata.json'):
                    # Lire les métadonnées si disponibles
                    metadata_path = backup_file.with_suffix(backup_file.suffix + '.metadata.json')
                    metadata = {}
                    if metadata_path.exists():
                        try:
                            with open(metadata_path, 'r', encoding='utf-8') as f:
                                metadata = json.load(f)
                        except:
                            pass
                    
                    stat = backup_file.stat()
                    backups.append({
                        'key': f"backups/{backup_file.name}",
                        'size': stat.st_size,
                        'last_modified': datetime.fromtimestamp(stat.st_mtime),
                        'filename': backup_file.name,
                        'metadata': metadata
                    })
            
            # Trier par date de modification (plus récent en premier)
            backups.sort(key=lambda x: x['last_modified'], reverse=True)
            return backups
            
        except Exception as e:
            print(f"❌ Erreur liste backups locaux: {e}")
            return []
    
    def delete_file(self, key: str) -> bool:
        """
        Suppression d'un fichier local
        """
        try:
            file_path = self.base_path / key
            
            if file_path.exists():
                file_path.unlink()
                
                # Supprimer les métadonnées si elles existent
                metadata_path = file_path.with_suffix('.metadata.json')
                if metadata_path.exists():
                    metadata_path.unlink()
                
                print(f"✅ Fichier supprimé localement: {file_path}")
                return True
            else:
                print(f"ℹ️ Fichier local non trouvé: {file_path}")
                return False
            
        except Exception as e:
            print(f"❌ Erreur suppression fichier local {key}: {e}")
            return False
    
    def file_exists(self, key: str) -> bool:
        """
        Vérifier si un fichier existe en local
        """
        file_path = self.base_path / key
        return file_path.exists()
    
    def get_public_url(self, key: str, expires_in: int = 3600) -> Optional[str]:
        """
        Générer un chemin local pour un fichier (pas d'URL publique)
        """
        file_path = self.base_path / key
        if file_path.exists():
            return f"file://{file_path.absolute()}"
        return None


# Instance globale pour le stockage local
_local_client = None

def get_local_client() -> LocalStorageClient:
    """Factory pour client de stockage local"""
    global _local_client
    if _local_client is None:
        _local_client = LocalStorageClient()
    return _local_client


# API simplifiée pour les fonctions métier (identique à cloud.py)
def upload_osm_cache(cache_data: Dict[Any, Any]) -> bool:
    """Upload du cache OSM en local"""
    client = get_local_client()
    return client.upload_json_file(
        "osm_cache.json", 
        cache_data,
        metadata={
            'type': 'osm_cache',
            'updated_at': datetime.utcnow().isoformat()
        }
    )


def download_osm_cache() -> Optional[Dict[Any, Any]]:
    """Download du cache OSM depuis local"""
    client = get_local_client()
    return client.download_json_file("osm_cache.json")


def upload_backup_to_cloud(backup_path: Path) -> bool:
    """Upload d'un backup en local"""
    client = get_local_client()
    return client.upload_backup(backup_path)


def list_cloud_backups() -> list:
    """Liste des backups locaux disponibles"""
    client = get_local_client()
    return client.list_backups()


def download_backup_from_cloud(s3_key: str, local_path: Path) -> bool:
    """Download d'un backup depuis local"""
    client = get_local_client()
    return client.download_backup(s3_key, local_path)

# ============================================================================
# tools\quick_sanity.py
# ============================================================================

#!/usr/bin/env python3
"""
Quick sanity check script for GuignoMap v4.1
Generates audit CSV files and validates data integrity with assertions.
"""

import sqlite3
import csv
import sys
from datetime import datetime
from pathlib import Path

def main():
    """Main sanity check function with data integrity assertions."""
    # Paths
    db_path = Path("guignomap") / "guigno_map.db"
    exports_dir = Path("exports")
    
    # Create exports directory if missing
    exports_dir.mkdir(exist_ok=True)
    
    # Check if database exists
    if not db_path.exists():
        print(f"'ùå Database not found: {db_path}")
        print("ℹ️  Run the application first to create the database.")
        print("SANITY: FAIL - Database missing")
        return 1
    
    try:
        # Connect to database
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Generate timestamp for files
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        print("🔧 GuignoMap v4.1 - Quick Sanity Check with Assertions")
        print("=" * 60)
        
        # Check if required tables exist
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]
        
        if 'streets' not in tables:
            print("'ùå Table 'streets' not found")
            print("SANITY: FAIL - Missing streets table")
            return 1
        
        # === DATA COLLECTION ===
        
        # 1. Total streets count
        cursor.execute("SELECT COUNT(*) FROM streets")
        total_streets = cursor.fetchone()[0]
        
        # 2. Count unassigned streets (team IS NULL OR team = '')
        cursor.execute("SELECT COUNT(*) FROM streets WHERE team IS NULL OR team = ''")
        unassigned_count = cursor.fetchone()[0]
        
        # 3. Status distribution with counts
        cursor.execute("""
            SELECT 
                COALESCE(status, 'Non défini') as status,
                COUNT(*) as count
            FROM streets 
            GROUP BY status 
            ORDER BY count DESC
        """)
        status_counts = cursor.fetchall()
        
        # 4. Unassigned streets by sector (for CSV)
        cursor.execute("""
            SELECT 
                COALESCE(sector, 'Aucun') as sector,
                name
            FROM streets 
            WHERE team IS NULL OR team = ''
            ORDER BY sector, name
        """)
        unassigned_streets = cursor.fetchall()
        
        # 5. Top 10 streets (for display)
        cursor.execute("""
            SELECT 
                COALESCE(sector, 'Aucun') as sector,
                name,
                COALESCE(team, 'Non assignée') as team,
                COALESCE(status, 'Non défini') as status
            FROM streets 
            ORDER BY name 
            LIMIT 10
        """)
        top_streets = cursor.fetchall()
        
        # === ASSERTIONS & DATA INTEGRITY CHECKS ===
        
        sanity_pass = True
        fail_reasons = []
        
        # Assertion 1: Total should equal sum of status counts
        sum_status_counts = sum(count for _, count in status_counts)
        if total_streets != sum_status_counts:
            sanity_pass = False
            fail_reasons.append(f"Total streets ({total_streets}) != sum of status counts ({sum_status_counts})")
        
        # Assertion 2: Unassigned count should match COUNT(team IS NULL OR team = '')
        # (This is redundant since we're using the same query, but validates consistency)
        cursor.execute("SELECT COUNT(*) FROM streets WHERE team IS NULL OR team = ''")
        unassigned_recheck = cursor.fetchone()[0]
        if unassigned_count != unassigned_recheck:
            sanity_pass = False
            fail_reasons.append(f"Unassigned count inconsistent ({unassigned_count} vs {unassigned_recheck})")
        
        # Assertion 3: No negative counts
        for status, count in status_counts:
            if count < 0:
                sanity_pass = False
                fail_reasons.append(f"Negative count for status '{status}': {count}")
        
        # Assertion 4: Total should be positive if any data exists
        if status_counts and total_streets <= 0:
            sanity_pass = False
            fail_reasons.append(f"Invalid total streets count: {total_streets}")
        
        # === DISPLAY RESULTS ===
        
        print(f"📊 Total des rues: {total_streets}")
        print(f"📊 Rues non assignées: {unassigned_count}")
        print()
        
        print("📈 Répartition par statut:")
        for status, count in status_counts:
            print(f"  • {status}: {count}")
        print(f"  ✅ Somme des statuts: {sum_status_counts}")
        print()
        
        print("📍 Top 10 rues (alphabétique):")
        for sector, name, team, status in top_streets[:10]:
            print(f"  • {sector} | {name} | {team} | {status}")
        print()
        
        # === WRITE CSV FILES (ALWAYS) ===
        
        status_file = exports_dir / f"status_counts_{timestamp}.csv"
        unassigned_file = exports_dir / f"unassigned_{timestamp}.csv"
        
        try:
            # Status counts CSV
            with open(status_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['status', 'count'])
                writer.writerows(status_counts)
            
            # Unassigned streets CSV
            with open(unassigned_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['secteur', 'rue'])
                writer.writerows(unassigned_streets)
            
            print("📁 Fichiers CSV créés:")
            print(f"  • {status_file}")
            print(f"  • {unassigned_file}")
            print()
            
        except Exception as e:
            print(f"⚠️  Erreur lors de l'écriture des CSV: {e}")
            print()
        
        # === FINAL SANITY CHECK RESULT ===
        
        conn.close()
        
        if sanity_pass:
            print("✅ Tous les tests de cohérence sont passés")
            print("SANITY: PASS")
            return 0
        else:
            print("❌ Échec des tests de cohérence:")
            for reason in fail_reasons:
                print(f"  • {reason}")
            print("SANITY: FAIL - Data integrity issues")
            return 1
            
    except sqlite3.Error as e:
        print(f"❌ Erreur base de données: {e}")
        print("SANITY: FAIL - Database error")
        return 1
    except Exception as e:
        print(f"'ùå Erreur inattendue: {e}")
        print("SANITY: FAIL - Unexpected error")
        return 1

if __name__ == "__main__":
    sys.exit(main())


