# GuignoMap - Export de code COMPLET
# Date : 2025-09-15 17:58:59
# Racine : C:\Users\nick\guignomap_clone\GuignoMap
# Fichiers inclus : 44
# Encodage : UTF-8 (sans BOM)
# Règles : exclusions .git/.venv/binaires/gros fichiers, NO secrets.toml

## INDEX
- .gitignore
- .streamlit/config.toml
- alembic.ini
- audit_dataframe.ps1
- docs/PHASE1_AUDIT_DATAFRAME.md
- docs/PROBLEME_IPV6_SUPABASE.md
- exports/export_20250915_175357.txt
- guignomap/__init__.py
- guignomap/app.py
- guignomap/backup.py
- guignomap/backups/backup_log.json
- guignomap/db.py
- guignomap/osm.py
- guignomap/reports.py
- guignomap/validators.py
- GuignoMap_code_export_20250914_audit.txt
- GuignoMap_code_export_20250915_final_UTF8.txt
- lancer_guignomap.bat
- lancer_guignomap.ps1
- PHASE1_COMMANDS.md
- README.md
- README_VENV.md
- requirements.txt
- scripts/export_repo_snapshot.py
- scripts/fix_app_types.py
- scripts/fix_specific.py
- scripts/migrate_password_hashes.py
- scripts/migrate_sqlite_to_postgres.py
- scripts/validation_dataframe.ps1
- src/auth/passwords.py
- src/config.py
- src/database/connection.py
- src/database/db_v5.py
- src/database/migrations/env.py
- src/database/migrations/README
- src/database/models.py
- src/storage/__init__.py
- src/storage/cloud.py
- src/storage/local.py
- src/utils/__init__.py
- src/utils/adapters.py
- tests/manual/test_db_connection.py
- tests/manual/test_db_simple.py
- tools/quick_sanity.py

## CONTENU DES FICHIERS

---8<--- .gitignore BEGIN ---
```txt
# ===============================================
# GITIGNORE POUR GUIGNO-MAP
# ===============================================

# ----------------------------------------
# ENVIRONNEMENTS PYTHON
# ----------------------------------------
.venv/
venv/
env/
ENV/
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
pip-log.txt
pip-delete-this-directory.txt

# ----------------------------------------
# BASES DE DONNÉES
# ----------------------------------------
*.db
*.sqlite
*.sqlite3
guigno_map.db

# ----------------------------------------
# CACHES & DONNÉES TEMPORAIRES
# ----------------------------------------
osm_cache.json
*.cache
*.tmp
.DS_Store
Thumbs.db

# ----------------------------------------
# LOGS & EXPORTS
# ----------------------------------------
*.log
export_*.txt
rapport_*.csv

# ----------------------------------------
# VS CODE & ÉDITEURS
# ----------------------------------------
.vscode/
*.swp
*.swo
*~

# ----------------------------------------
# SYSTÈME WINDOWS/LINUX
# ----------------------------------------
*.Zone.Identifier
.Trash-*
Desktop.ini

# ----------------------------------------
# DÉPENDANCES NODE (si ajoutées plus tard)
# ----------------------------------------
node_modules/
npm-debug.log*

# ----------------------------------------
# STREAMLIT
# ----------------------------------------
.streamlit/secrets.toml

# ----------------------------------------
# DONNÉES SENSIBLES
# ----------------------------------------
*.key
*.pem
.env
config.ini

# ----------------------------------------
# FICHIERS DE SAUVEGARDE
# ----------------------------------------
*.bak
*.backup
*.save
*~

# ----------------------------------------
# KEEP THESE FILES (exceptions)
# ----------------------------------------
!.streamlit/config.toml
!guignomap/assets/
!requirements.txt
!README.md
# exports snapshots
/exports/
export.txt

```
---8<--- .gitignore END ---

---8<--- .streamlit/config.toml BEGIN ---
```toml
[theme]
# Thème sombre avec les couleurs du Relais
base = "dark"
primaryColor = "#A9CF3B"              # Vert du Relais
backgroundColor = "#0F1318"           # Fond très sombre
secondaryBackgroundColor = "#1A1F26"  # Fond secondaire
textColor = "#F2F3F5"                 # Texte clair
font = "sans serif"

[client]
# Configuration minimale de la toolbar
toolbarMode = "minimal"
showErrorDetails = false

[runner]
# Optimisations de performance
magicEnabled = true
installTracer = false
fixMatplotlib = true

[server]
# Configuration serveur
headless = true
runOnSave = true
maxUploadSize = 10
enableCORS = false
enableXsrfProtection = true

[deprecation]
# Désactiver les avertissements de dépréciation
showImageFormat = false
showPyplotGlobalUse = false
```
---8<--- .streamlit/config.toml END ---

---8<--- alembic.ini BEGIN ---
```ini
# A generic, single database configuration.

[alembic]
# path to migration scripts.
# this is typically a path given in POSIX (e.g. forward slashes)
# format, relative to the token %(here)s which refers to the location of this
# ini file
script_location = %(here)s/src/database/migrations

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.  for multiple paths, the path separator
# is defined by "path_separator" below.
prepend_sys_path = .


# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library and tzdata library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to <script_location>/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "path_separator"
# below.
# version_locations = %(here)s/bar:%(here)s/bat:%(here)s/alembic/versions

# path_separator; This indicates what character is used to split lists of file
# paths, including version_locations and prepend_sys_path within configparser
# files such as alembic.ini.
# The default rendered in new alembic.ini files is "os", which uses os.pathsep
# to provide os-dependent path splitting.
#
# Note that in order to support legacy alembic.ini files, this default does NOT
# take place if path_separator is not present in alembic.ini.  If this
# option is omitted entirely, fallback logic is as follows:
#
# 1. Parsing of the version_locations option falls back to using the legacy
#    "version_path_separator" key, which if absent then falls back to the legacy
#    behavior of splitting on spaces and/or commas.
# 2. Parsing of the prepend_sys_path option falls back to the legacy
#    behavior of splitting on spaces, commas, or colons.
#
# Valid values for path_separator are:
#
# path_separator = :
# path_separator = ;
# path_separator = space
# path_separator = newline
#
# Use os.pathsep. Default configuration used for new projects.
path_separator = os

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

# database URL.  This is consumed by the user-maintained env.py script only.
# other means of configuring database URLs may be customized within the env.py
# file.
# sqlalchemy.url = driver://user:pass@localhost/dbname
# Note: URL configured programmatically via src.config in env.py


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the module runner, against the "ruff" module
# hooks = ruff
# ruff.type = module
# ruff.module = ruff
# ruff.options = check --fix REVISION_SCRIPT_FILENAME

# Alternatively, use the exec runner to execute a binary found on your PATH
# hooks = ruff
# ruff.type = exec
# ruff.executable = ruff
# ruff.options = check --fix REVISION_SCRIPT_FILENAME

# Logging configuration.  This is also consumed by the user-maintained
# env.py script only.
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S

```
---8<--- alembic.ini END ---

---8<--- audit_dataframe.ps1 BEGIN ---
```ps1
# SCRIPTS POWERSHELL - VALIDATION DATAFRAME

Write-Host "AUDIT DATAFRAME - SCRIPTS DE VALIDATION" -ForegroundColor Green
Write-Host "=========================================" -ForegroundColor Green

Write-Host "`nPATTERNS DATAFRAME PROBLEMATIQUES" -ForegroundColor Yellow
Write-Host "Recherche: .columns, .iterrows, .empty, .loc, .iloc" -ForegroundColor Gray
Select-String -Path .\guignomap\app.py -Pattern '\.columns|\.iterrows|\.empty|\.loc\[|\.iloc\[' -CaseSensitive | 
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`nASSIGNATIONS DE FONCTIONS DB" -ForegroundColor Yellow  
Write-Host "Recherche: variables = db.fonction" -ForegroundColor Gray
Select-String -Path .\guignomap\app.py -Pattern '\s*\w+\s*=\s*db\.\w+\(' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`nUTILISATION ST.DATAFRAME" -ForegroundColor Yellow
Write-Host "Recherche: st.dataframe pour verifier les types" -ForegroundColor Gray  
Select-String -Path .\guignomap\app.py -Pattern 'st\.dataframe\(' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`nFONCTIONS DB QUI RETOURNENT DES DONNEES" -ForegroundColor Yellow
Write-Host "Recherche: Fonctions db_v5 qui peuvent retourner listes vs DataFrames" -ForegroundColor Gray
Select-String -Path .\guignomap\db_v5.py -Pattern 'def (list_|get_|stats_|teams|recent_)' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`nIMPORTS PANDAS DANS APP.PY" -ForegroundColor Yellow  
Write-Host "Recherche: import pandas et pd.DataFrame" -ForegroundColor Gray
Select-String -Path .\guignomap\app.py -Pattern 'import pandas|pd\.DataFrame' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`nRAPPORT COMPLET GENERE DANS: AUDIT_DATAFRAME.md" -ForegroundColor Green
```
---8<--- audit_dataframe.ps1 END ---

---8<--- docs/PHASE1_AUDIT_DATAFRAME.md BEGIN ---
```md
# 🔍 AUDIT DATAFRAME - RAPPORT COMPLET

## 📊 SYNTHÈSE EXECUTIVE

**Statut** : Migration critique nécessaire  
**Impact** : 🔴 BLOQUANT - L'application ne peut pas fonctionner sans corrections  
**Scope** : Principalement `app.py` (38 occurrences) + `db_v5.py` (corrections mineures)

## 📋 TABLEAU DE MAPPING DÉTAILLÉ

| Fichier | Ligne | Fonction/Contexte | Pattern Détecté | Type Attendu | Type Fourni | Criticité | Usage |
|---------|-------|------------------|-----------------|--------------|-------------|-----------|-------|
| **app.py** | 371 | render_admin_dashboard() | `pd.DataFrame(teams_stats)` | DataFrame | List[Dict] | 🟢 OK | Conversion explicite |
| **app.py** | 401 | render_admin_dashboard() | `st.dataframe(teams_stats)` | DataFrame | List[Dict] | 🟡 MINOR | Affichage direct |
| **app.py** | 506-509 | create_map() | `df.columns`, `row['name']` | DataFrame | **PROBLÈME** | 🔴 CRITIQUE | Lookup géospatial |
| **app.py** | 1034 | render_team_dashboard() | `df_team[df_team['name'] == street_name]` | DataFrame | DataFrame | 🟢 OK | Filtrage |
| **app.py** | 1122 | render_team_dashboard() | `st.dataframe(notes)` | DataFrame | List[Dict] | 🟡 MINOR | Affichage |
| **app.py** | 1215 | render_supervisor_dashboard() | `st.dataframe(recent)` | DataFrame | List[Dict] | 🟡 MINOR | Affichage |
| **app.py** | 1292 | render_quick_admin() | `st.dataframe(teams_df)` | DataFrame | List[Dict] | 🟡 MINOR | Affichage |
| **app.py** | 1421 | render_admin() | `st.dataframe(recent)` | DataFrame | List[Dict] | 🟡 MINOR | Affichage |
| **app.py** | 1442 | render_admin() | `st.dataframe(teams_df)` | DataFrame | List[Dict] | 🟡 MINOR | Affichage |
| **app.py** | 1466 | bulk_assignation() | `st.dataframe(df_disp)` | DataFrame | DataFrame | 🟢 OK | Affichage filtré |
| **app.py** | 1640 | bulk_assignation() | `st.dataframe(df_disp)` | DataFrame | DataFrame | 🟢 OK | Affichage final |
| **app.py** | 1717 | export_panel() | `pd.DataFrame(assignations_data).to_csv()` | DataFrame | List[Dict] | 🟢 OK | Export CSV |

## 🎯 POINTS DE CONVERSION CRITIQUES

### 🔴 CRITIQUE - Ligne 506-509 (create_map)
```python
# PROBLÈME ACTUEL:
if df:  # df est List[Dict] mais code attend DataFrame
    for idx, row in enumerate(df):
        name = str(row['name']) if 'name' in df.columns else ''  # ❌ .columns sur une liste
```

**Solution** : Conversion DataFrame dans `db_v5.list_streets()` OU conversion à l'interface UI.

### 🟡 MINEUR - Fonctions st.dataframe()
```python
# PROBLÈME RÉCURRENT:
st.dataframe(teams_stats)  # teams_stats = List[Dict], streamlit accepte mais préfère DataFrame
```

**Solution** : Conversion `pd.DataFrame()` avant affichage.

## 📋 PLAN DE PATCH ATOMIQUE

### Étape 1: CRITIQUE - Corriger create_map() 
**Fichier** : `app.py` lignes 506-509  
**Action** : Convertir l'itération liste vers DataFrame
```python
# AVANT:
if df:  # Liste
    for idx, row in enumerate(df):
        name = str(row['name']) if 'name' in df.columns else ''

# APRÈS:
if not df.empty:  # DataFrame
    for idx, row in df.iterrows():
        name = str(row['name']) if 'name' in df.columns else ''
```

### Étape 2: MINEUR - Conversions st.dataframe()
**Fichiers** : `app.py` lignes 401, 1122, 1215, 1292, 1421, 1442  
**Action** : Wrapper avec `pd.DataFrame()` si nécessaire
```python
# Pattern:
if data:  # Si liste non vide
    st.dataframe(pd.DataFrame(data))
else:
    st.info("Aucune donnée")
```

### Étape 3: VALIDATION - db_v5.py types retour
**Fichier** : `db_v5.py`  
**Action** : Valider que `list_streets()` retourne bien un DataFrame
```python
# Dans list_streets():
return pd.DataFrame(rows) if rows else pd.DataFrame(columns=['id', 'name', 'sector', 'team', 'status'])
```

## 🔧 SCRIPTS POWERSHELL VALIDATION

### Script 1: Audit DataFrame patterns
```powershell
# Chercher tous les patterns DataFrame problématiques
Select-String -Path .\guignomap\app.py -Pattern '\.columns|\.iterrows|\.empty|\.loc\[|\.iloc\[' -CaseSensitive | 
  Select-Object LineNumber, Line | Format-Table -Auto
```

### Script 2: Variables qui reçoivent des données DB
```powershell
# Chercher les assignations de fonctions db.*
Select-String -Path .\guignomap\app.py -Pattern '\s*\w+\s*=\s*db\.\w+\(' -CaseSensitive |
  Select-Object LineNumber, Line
```

### Script 3: Utilisation st.dataframe()
```powershell
# Chercher tous les st.dataframe pour vérifier les types
Select-String -Path .\guignomap\app.py -Pattern 'st\.dataframe\(' -CaseSensitive |
  Select-Object LineNumber, Line
```

## 📊 DÉTAILS TECHNIQUES PAR FONCTION

### create_map(df, geo) - LIGNE 506
**Problème** : `df` passé comme paramètre, supposé DataFrame mais reçoit List[Dict]
**Source** : Appelé depuis dashboard avec `df = db.list_streets(team=team_id)`
**Solution** : `db.list_streets()` doit retourner DataFrame

### render_*_dashboard() - Multiples lignes
**Problème** : `st.dataframe()` reçoit List[Dict] au lieu de DataFrame
**Impact** : Fonctionne mais sous-optimal, pas de tri/filtrage UI
**Solution** : Conversion `pd.DataFrame()` avant affichage

## 🚨 ACTIONS REQUISES IMMÉDIATEMENT

1. **Corriger create_map()** - BLOQUANT pour carte géospatiale
2. **Valider db_v5.list_streets()** - Assurer retour DataFrame
3. **Wrapper st.dataframe()** - Optimiser affichage

## 📝 QUESTIONS POUR VALIDATION

1. **Colonnes exactes** de `list_streets()` : Confirmer schema ['id', 'name', 'sector', 'team', 'status', 'notes'?]
2. **Performance** : Préférer conversion côté données (db_v5) ou côté UI (app.py) ?
3. **Compatibilité** : Maintenir retro-compatibilité avec ancien `db.py` ?

## ✅ VALIDATION POST-PATCH

```powershell
# Tester l'application après patch
.\.venv\Scripts\python.exe -c "
import sys; sys.path.append('guignomap'); 
import db_v5; 
df = db_v5.list_streets(); 
print(f'Type: {type(df)}, Shape: {df.shape if hasattr(df, \"shape\") else \"N/A\"}')
"

# Tester création carte
.\.venv\Scripts\python.exe -c "
import sys; sys.path.append('guignomap'); 
import app; import db_v5; 
df = db_v5.list_streets(); 
print(f'create_map compatible: {hasattr(df, \"columns\")}')
"
```
```
---8<--- docs/PHASE1_AUDIT_DATAFRAME.md END ---

---8<--- docs/PROBLEME_IPV6_SUPABASE.md BEGIN ---
```md
# PROBLÈME CONNECTIVITÉ SUPABASE IPv6

## 🚨 Situation actuelle
- Supabase PostgreSQL utilise **uniquement IPv6** pour cette instance
- L'host `db.kdxqspmfycnwzzrmhzpa.supabase.co` résout vers: `2600:1f11:4e2:e202:6514:7431:494f:c00f`
- Votre réseau local ne supporte **pas IPv6 global** (seulement liaison locale)

## ❌ Tests échoués
```powershell
ping db.kdxqspmfycnwzzrmhzpa.supabase.co  # DNS fail
Test-NetConnection -ComputerName db.kdxqspmfycnwzzrmhzpa.supabase.co -Port 5432  # DNS fail
ping -6 2600:1f11:4e2:e202:6514:7431:494f:c00f  # IPv6 network unreachable
```

## ✅ Solutions disponibles

### 1. IMMÉDIAT - Développement local (Recommandé)
```toml
# Dans .streamlit/secrets.toml
[database]
# Commentez Supabase et utilisez SQLite local
# url = "postgresql://postgres:4everSab!2304@db.kdxqspmfycnwzzrmhzpa.supabase.co:5432/postgres"
url = "sqlite:///./guignomap/guigno_map.db"
```

### 2. PRODUCTION - Solutions IPv6

#### Option A: Configuration FAI/Réseau
- Contacter votre FAI pour activer IPv6
- Configurer tunnel IPv6 (ex: Hurricane Electric)
- Activer IPv6 sur votre routeur/modem

#### Option B: Nouveau projet Supabase
1. Créer un nouveau projet Supabase
2. Espérer obtenir une instance avec support IPv4
3. Migrer la base de données

#### Option C: Cloudflare Tunnel
```bash
# Installer cloudflared
# Créer un tunnel vers Supabase
cloudflared tunnel --hostname myapp.trycloudflare.com --url db.kdxqspmfycnwzzrmhzpa.supabase.co:5432
```

### 3. STREAMLIT CLOUD - Pas de problème
Une fois déployé sur **Streamlit Cloud**, l'IPv6 sera supporté.

## 🔧 Configuration immédiate

Pour continuer le développement **MAINTENANT**:

```powershell
# 1. Basculer vers SQLite local dans secrets.toml
# 2. Tester la connexion locale
.\.venv\Scripts\python.exe -c "from src.database.connection import test_connection; test_connection()"

# 3. Migrer les données SQLite vers PostgreSQL plus tard
.\.venv\Scripts\python.exe scripts/migrate_sqlite_to_postgres.py
```

## 📈 Plan de déploiement

1. **MAINTENANT**: Développement avec SQLite local
2. **PLUS TARD**: Résoudre IPv6 ou nouveau projet Supabase  
3. **DÉPLOIEMENT**: Streamlit Cloud (IPv6 natif)
4. **MIGRATION**: Données SQLite → PostgreSQL

## 🌐 Vérification IPv6 système
```powershell
ipconfig /all | findstr "IPv6"
# Résultat: Seulement liaison locale (fe80::...)
# Besoin: Adresse IPv6 globale (2xxx::/16)
```
```
---8<--- docs/PROBLEME_IPV6_SUPABASE.md END ---

---8<--- exports/export_20250915_175357.txt BEGIN ---
```txt
# GuignoMap - Export de code complet
# Date : 2025-09-15 14:30:00 local
# Version : v5.0 (Phase 1 bouclée) — base v4.1 UI/UX conservée
# Auteur : Nick & Copilot
# Projet : Système de gestion pour la Guignolée 2025
# Encodage : UTF-8 (sans BOM)

## RÉSUMÉ DES ÉVOLUTIONS RÉCENTES
- Infra PHASE 1: SQLite→PostgreSQL (SQLAlchemy + Alembic), Storage S3/local, Auth passlib Argon2 (compat bcrypt), correctifs DataFrame (create_map + UI), adapters df.
- IPv6 local: dev SQLite OK; prod Streamlit Cloud (IPv6) — migrations exécutées côté Cloud.
- Politique UI MDP v4.1 inchangée: min 4 + confirmation.

## ENVIRONNEMENT & DÉPENDANCES
- Python: 3.11+ (détecté)
- Principales libs (versions exactes depuis requirements): 
  * streamlit>=1.36.0
  * pandas>=2.2.0
  * folium==0.20.0
  * streamlit-folium>=0.21.0
  * sqlalchemy==2.0.23
  * alembic==1.13.1
  * psycopg2-binary>=2.9.7
  * passlib[argon2]==1.7.4
  * boto3==1.34.144
  * bcrypt>=4.0.0

- Variables/Secrets attendus (placeholders, ne JAMAIS imprimer les vraies valeurs):
  [database] url="postgresql://<user>:<pass>@<host>:<port>/<db>" pool_size=<int> max_overflow=<int>
  [storage] s3_bucket="<bucket>" s3_region="<region>" s3_access_key="<AKIA…>" s3_secret_key="<***>" cdn_base_url="<https://…>" (optionnel)
  [admin] token="<ADMIN_TOKEN>" (si page admin migration)

## ARBORESCENCE (repo root)
GuignoMap/
├── .git/
├── .gitignore
├── .streamlit/
├── .venv/
├── .vscode/
├── alembic.ini
├── AUDIT_DATAFRAME.md
├── audit_dataframe.ps1
├── backups/
├── exports/
├── fix_app_types.py
├── fix_specific.py
├── guignomap/
│   ├── __init__.py
│   ├── app.py
│   ├── backup.py
│   ├── db_v5.py
│   ├── db.py
│   ├── guigno_map.db
│   ├── osm_addresses.json
│   ├── osm_cache.json
│   ├── osm.py
│   ├── reports.py
│   ├── validators.py
│   ├── assets/
│   ├── backups/
│   └── logs/
├── GuignoMap_code_export_20250914_audit.txt
├── GuignoMap_code_export_20250915_final_UTF8.txt
├── lancer_guignomap.bat
├── lancer_guignomap.ps1
├── PHASE1_COMMANDS.md
├── PROBLEME_IPv6_SUPABASE.md
├── README.md
├── README_VENV.md
├── requirements.txt
├── scripts/
│   ├── migrate_password_hashes.py
│   └── migrate_sqlite_to_postgres.py
├── scripts_validation_dataframe.ps1
├── src/
│   ├── config.py
│   ├── auth/
│   │   └── passwords.py
│   ├── database/
│   │   ├── connection.py
│   │   ├── models.py
│   │   └── migrations/
│   │       ├── env.py
│   │       ├── README
│   │       ├── script.py.mako
│   │       └── versions/ (empty)
│   ├── storage/
│   │   ├── __init__.py
│   │   ├── cloud.py
│   │   └── local.py
│   └── utils/
│       ├── __init__.py
│       └── adapters.py
├── test_db_connection.py
├── test_db_simple.py
└── tools/
    └── quick_sanity.py

## FICHIERS NOUVEAUX OU MODIFIÉS (PHASE 1)
- src/config.py (NEW)
- src/database/connection.py (NEW)
- src/database/models.py (NEW)
- src/database/migrations/env.py (NEW)
- src/database/migrations/versions/ (NEW - vide, aucune révision créée)
- src/auth/passwords.py (NEW)
- src/storage/cloud.py (NEW)
- src/storage/local.py (NEW)
- src/utils/adapters.py (NEW, DataFrame adapter)
- src/utils/__init__.py (NEW)
- scripts/migrate_sqlite_to_postgres.py (NEW)
- scripts/migrate_password_hashes.py (NEW)
- guignomap/app.py (MOD - correctifs DataFrame PHASE 1)
- guignomap/db_v5.py (MOD - adaptations SQLAlchemy)
- alembic.ini (NEW)

## CODE — NOUVEAUX FICHIERS (contenu COMPLET)

### src/config.py
```python
"""
Configuration centralisée pour GuignoMap v5.0
Accès aux secrets Streamlit et paramètres applicatifs
"""
import streamlit as st
import os


def get_database_url():
    """Récupère l'URL de la base de données depuis les secrets"""
    try:
        return st.secrets["database"]["url"]
    except (KeyError, AttributeError):
        # Fallback pour développement local ou tests
        return os.getenv("DATABASE_URL", "sqlite:///guigno_map.db")


def get_database_pool_config():
    """Configuration du pool de connexions PostgreSQL"""
    try:
        return {
            "pool_size": st.secrets["database"].get("pool_size", 5),
            "max_overflow": st.secrets["database"].get("max_overflow", 10)
        }
    except (KeyError, AttributeError):
        return {"pool_size": 5, "max_overflow": 10}


def get_s3_config():
    """Configuration S3 pour le stockage cloud"""
    try:
        return {
            "bucket": st.secrets["storage"]["s3_bucket"],
            "region": st.secrets["storage"]["s3_region"],
            "access_key": st.secrets["storage"]["s3_access_key"],
            "secret_key": st.secrets["storage"]["s3_secret_key"]
        }
    except (KeyError, AttributeError):
        return {
            "bucket": os.getenv("S3_BUCKET", "guignomap-dev"),
            "region": os.getenv("S3_REGION", "us-east-1"),
            "access_key": os.getenv("S3_ACCESS_KEY", ""),
            "secret_key": os.getenv("S3_SECRET_KEY", "")
        }


def get_cdn_base_url():
    """URL de base CDN pour les assets (optionnel)"""
    try:
        return st.secrets["storage"].get("cdn_base_url", "")
    except (KeyError, AttributeError):
        return os.getenv("CDN_BASE_URL", "")
```

### src/database/connection.py
```python
"""
Connexion PostgreSQL avec SQLAlchemy pour GuignoMap v5.0
Engine + QueuePool + cache Streamlit + retry logic
"""
import time
import functools
import streamlit as st
from sqlalchemy import create_engine, text
from sqlalchemy.pool import QueuePool
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import SQLAlchemyError
from src.config import get_database_url, get_database_pool_config


def db_retry(max_retries=3, backoff_factor=1):
    """
    Décorateur retry exponentiel pour opérations DB critiques
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except SQLAlchemyError as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        wait_time = backoff_factor * (2 ** attempt)
                        print(f"Retry DB operation {func.__name__} in {wait_time}s (attempt {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                    else:
                        print(f"Max retries reached for {func.__name__}")
                        break
            raise last_exception
        return wrapper
    return decorator


@st.cache_resource
def get_engine():
    """
    Engine PostgreSQL avec cache Streamlit et configuration pool
    Conformément au plan v5.0
    """
    database_url = get_database_url()
    pool_config = get_database_pool_config()
    
    # Configuration PostgreSQL avec QueuePool
    engine = create_engine(
        database_url,
        poolclass=QueuePool,
        pool_size=pool_config["pool_size"],
        max_overflow=pool_config["max_overflow"],
        pool_pre_ping=True,
        pool_recycle=300,
        echo=False  # Set to True for SQL debugging
    )
    
    return engine


def get_session():
    """Fabrique de session SQLAlchemy"""
    engine = get_engine()
    Session = sessionmaker(bind=engine)
    return Session()


@db_retry(max_retries=3)
def test_connection():
    """Test de connexion à la base PostgreSQL"""
    try:
        engine = get_engine()
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1 as test"))
            return result.fetchone()[0] == 1
    except Exception as e:
        print(f"Erreur test connexion DB: {e}")
        return False


@db_retry(max_retries=3)
def execute_query(query, params=None):
    """
    Exécution de requête avec retry automatique
    Pour transition progressive vers SQLAlchemy
    """
    engine = get_engine()
    with engine.connect() as conn:
        if params:
            return conn.execute(text(query), params)
        else:
            return conn.execute(text(query))


@db_retry(max_retries=3)  
def execute_transaction(queries_and_params):
    """
    Exécution de transaction multi-requêtes avec retry
    queries_and_params: liste de tuples (query, params)
    """
    engine = get_engine()
    with engine.begin() as conn:
        results = []
        for query, params in queries_and_params:
            if params:
                result = conn.execute(text(query), params)
            else:
                result = conn.execute(text(query))
            results.append(result)
        return results
```

### src/database/models.py
```python
"""
Modèles SQLAlchemy pour GuignoMap v5.0
Basés sur le schéma SQLite existant pour compatibilité
"""
from sqlalchemy import Column, Integer, String, Text, DateTime, Boolean, ForeignKey, Float
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime

Base = declarative_base()


class Street(Base):
    __tablename__ = 'streets'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    name = Column(Text, nullable=False, unique=True)
    sector = Column(Text)
    team = Column(Text)
    status = Column(Text, nullable=False, default='a_faire')
    
    # Relations
    notes = relationship("Note", back_populates="street", cascade="all, delete-orphan")
    addresses = relationship("Address", back_populates="street", cascade="all, delete-orphan")


class Team(Base):
    __tablename__ = 'teams'
    
    id = Column(Text, primary_key=True)
    name = Column(Text, nullable=False)
    password_hash = Column(Text, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)
    active = Column(Boolean, default=True)


class Note(Base):
    __tablename__ = 'notes'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    street_name = Column(Text, ForeignKey('streets.name'), nullable=False)
    team_id = Column(Text, ForeignKey('teams.id'), nullable=False)
    address_number = Column(Text)
    comment = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relations
    street = relationship("Street", back_populates="notes")


class ActivityLog(Base):
    __tablename__ = 'activity_log'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    team_id = Column(Text)
    action = Column(Text, nullable=False)
    details = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)


class Address(Base):
    __tablename__ = 'addresses'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    street_name = Column(Text, ForeignKey('streets.name'), nullable=False)
    house_number = Column(Text, nullable=False)
    latitude = Column(Float)
    longitude = Column(Float)
    osm_type = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relations
    street = relationship("Street", back_populates="addresses")
```

### src/database/migrations/env.py
```python
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

# Ajouter le répertoire parent au PYTHONPATH pour imports
import sys
import os
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent.parent))

from src.database.models import Base
from src.config import get_database_url

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
target_metadata = Base.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def get_url():
    """Récupère l'URL de BDD depuis la configuration Streamlit"""
    return get_database_url()


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode."""
    url = get_url()
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode."""
    # Override URL from config
    configuration = config.get_section(config.config_ini_section)
    configuration['sqlalchemy.url'] = get_url()
    
    connectable = engine_from_config(
        configuration,
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
```

### src/auth/passwords.py
```python
"""
Gestion des mots de passe pour GuignoMap v5.0
Migration bcrypt → Argon2 avec compatibilité ascendante
"""
import re
from typing import Optional, Dict, Tuple
from passlib.context import CryptContext


# Configuration passlib avec Argon2 (principal) + bcrypt (legacy)
pwd_context = CryptContext(
    schemes=["argon2", "bcrypt"],
    deprecated="auto",  # Auto-migrate bcrypt vers argon2
    argon2__memory_cost=65536,  # 64 MB
    argon2__time_cost=3,        # 3 iterations
    argon2__parallelism=1,      # Single thread pour Streamlit Cloud
)


def hash_password(password: str) -> str:
    """
    Hasher un mot de passe avec Argon2
    """
    return pwd_context.hash(password)


def verify_password(password: str, hashed: str) -> bool:
    """
    Vérifier un mot de passe contre son hash
    Compatible bcrypt + Argon2
    """
    try:
        result = pwd_context.verify(password, hashed)
        return result
    except Exception as e:
        print(f"Erreur vérification mot de passe: {e}")
        return False


def needs_rehash(hashed: str) -> bool:
    """
    Vérifier si un hash doit être re-hashé (migration bcrypt → Argon2)
    """
    try:
        return pwd_context.needs_update(hashed)
    except Exception:
        return True  # En cas de doute, re-hasher


def validate_password_policy(password: str) -> Tuple[bool, Optional[str]]:
    """
    Valider la politique de mot de passe v4.1 (min 4 + confirmation)
    Conserve la compatibilité UI existante
    """
    if not password:
        return False, "Le mot de passe ne peut pas être vide"
    
    if len(password) < 4:
        return False, "Le mot de passe doit contenir au moins 4 caractères"
    
    # Pas d'autres restrictions pour garder l'UX v4.1
    return True, None


def get_password_strength(password: str) -> Dict[str, any]:
    """
    Évaluer la force d'un mot de passe (pour affichage optionnel)
    """
    if not password:
        return {"score": 0, "feedback": "Vide"}
    
    score = 0
    feedback = []
    
    # Critères de force
    if len(password) >= 8:
        score += 2
    elif len(password) >= 6:
        score += 1
    else:
        feedback.append("Trop court")
    
    if re.search(r'[a-z]', password):
        score += 1
    
    if re.search(r'[A-Z]', password):
        score += 1
    
    if re.search(r'\d', password):
        score += 1
    
    if re.search(r'[^a-zA-Z0-9]', password):
        score += 1
    
    # Classification
    if score <= 2:
        strength = "Faible"
    elif score <= 4:
        strength = "Moyen"
    else:
        strength = "Fort"
    
    return {
        "score": score,
        "strength": strength,
        "feedback": feedback
    }


def migrate_bcrypt_password(old_hash: str, new_password: str) -> Optional[str]:
    """
    Migrer un hash bcrypt vers Argon2 lors de la connexion
    """
    try:
        # Vérifier que l'ancien hash est bien bcrypt
        if not old_hash.startswith("$2b$"):
            return None
        
        # Créer nouveau hash Argon2
        new_hash = hash_password(new_password)
        
        print(f"Migration bcrypt → Argon2 effectuée")
        return new_hash
        
    except Exception as e:
        print(f"Erreur migration password: {e}")
        return None
```

### src/storage/cloud.py
```python
"""
Client de stockage S3 pour GuignoMap v5.0
Upload/Download de backups et fichiers JSON
"""
import json
import boto3
from typing import Optional, Dict, Any, List
from pathlib import Path
from datetime import datetime
from botocore.exceptions import ClientError, NoCredentialsError
from src.config import get_s3_config, get_cdn_base_url


class S3StorageClient:
    """Client S3 pour stockage cloud des données GuignoMap"""
    
    def __init__(self):
        self.config = get_s3_config()
        self.cdn_base_url = get_cdn_base_url()
        
        try:
            self.client = boto3.client(
                's3',
                region_name=self.config['region'],
                aws_access_key_id=self.config['access_key'],
                aws_secret_access_key=self.config['secret_key']
            )
            self.bucket = self.config['bucket']
        except (NoCredentialsError, KeyError) as e:
            print(f"❌ Erreur configuration S3: {e}")
            self.client = None
            self.bucket = None
    
    def is_available(self) -> bool:
        """Vérifier si S3 est correctement configuré"""
        if not self.client or not self.bucket:
            return False
        
        try:
            self.client.head_bucket(Bucket=self.bucket)
            return True
        except ClientError:
            return False
    
    def upload_json_file(self, key: str, data: Dict[Any, Any], metadata: Optional[Dict[str, str]] = None) -> bool:
        """
        Upload d'un fichier JSON vers S3
        """
        if not self.is_available():
            print("❌ S3 non disponible pour upload JSON")
            return False
        
        try:
            # Sérialiser en JSON
            json_content = json.dumps(data, ensure_ascii=False, indent=2)
            
            # Métadonnées S3
            s3_metadata = {
                'Content-Type': 'application/json',
                'Content-Encoding': 'utf-8'
            }
            
            if metadata:
                # Ajouter les métadonnées custom (préfixe x-amz-meta-)
                for k, v in metadata.items():
                    s3_metadata[f'x-amz-meta-{k}'] = str(v)
            
            # Upload vers S3
            self.client.put_object(
                Bucket=self.bucket,
                Key=key,
                Body=json_content.encode('utf-8'),
                **s3_metadata
            )
            
            print(f"✅ JSON uploadé vers S3: s3://{self.bucket}/{key}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur upload JSON S3 {key}: {e}")
            return False
    
    def download_json_file(self, key: str) -> Optional[Dict[Any, Any]]:
        """
        Download et parsing d'un fichier JSON depuis S3
        """
        if not self.is_available():
            print("❌ S3 non disponible pour download JSON")
            return None
        
        try:
            response = self.client.get_object(Bucket=self.bucket, Key=key)
            content = response['Body'].read().decode('utf-8')
            data = json.loads(content)
            
            print(f"✅ JSON téléchargé depuis S3: s3://{self.bucket}/{key}")
            return data
            
        except ClientError as e:
            if e.response['Error']['Code'] == 'NoSuchKey':
                print(f"ℹ️ Fichier JSON S3 non trouvé: {key}")
            else:
                print(f"❌ Erreur download JSON S3 {key}: {e}")
            return None
        except Exception as e:
            print(f"❌ Erreur parsing JSON S3 {key}: {e}")
            return None
    
    def upload_backup(self, backup_file_path: Path, s3_key: Optional[str] = None) -> bool:
        """
        Upload d'un fichier backup vers S3
        """
        if not self.is_available():
            print("❌ S3 non disponible pour upload backup")
            return False
        
        if not backup_file_path.exists():
            print(f"❌ Fichier backup non trouvé: {backup_file_path}")
            return False
        
        try:
            # Générer la clé S3 si non fournie
            if not s3_key:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                s3_key = f"backups/{backup_file_path.stem}_{timestamp}{backup_file_path.suffix}"
            
            # Métadonnées du backup
            metadata = {
                'x-amz-meta-original-filename': backup_file_path.name,
                'x-amz-meta-upload-timestamp': datetime.utcnow().isoformat(),
                'x-amz-meta-file-size': str(backup_file_path.stat().st_size)
            }
            
            # Upload du fichier
            with open(backup_file_path, 'rb') as f:
                self.client.put_object(
                    Bucket=self.bucket,
                    Key=s3_key,
                    Body=f,
                    **metadata
                )
            
            print(f"✅ Backup uploadé vers S3: s3://{self.bucket}/{s3_key}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur upload backup S3: {e}")
            return False
    
    def download_backup(self, s3_key: str, local_path: Path) -> bool:
        """
        Download d'un backup depuis S3 vers fichier local
        """
        if not self.is_available():
            print("❌ S3 non disponible pour download backup")
            return False
        
        try:
            # Créer le répertoire parent si nécessaire
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Download depuis S3
            self.client.download_file(
                Bucket=self.bucket,
                Key=s3_key,
                Filename=str(local_path)
            )
            
            print(f"✅ Backup téléchargé depuis S3: {local_path}")
            return True
            
        except ClientError as e:
            if e.response['Error']['Code'] == 'NoSuchKey':
                print(f"ℹ️ Backup S3 non trouvé: {s3_key}")
            else:
                print(f"❌ Erreur download backup S3: {e}")
            return False
        except Exception as e:
            print(f"❌ Erreur download backup: {e}")
            return False
    
    def list_backups(self, prefix: str = "backups/") -> List[Dict[str, Any]]:
        """
        Lister les backups disponibles sur S3
        """
        if not self.is_available():
            print("❌ S3 non disponible pour list backups")
            return []
        
        try:
            response = self.client.list_objects_v2(
                Bucket=self.bucket,
                Prefix=prefix
            )
            
            backups = []
            for obj in response.get('Contents', []):
                backup_info = {
                    'key': obj['Key'],
                    'size': obj['Size'],
                    'last_modified': obj['LastModified'],
                    'filename': Path(obj['Key']).name
                }
                
                # Récupérer les métadonnées si possible
                try:
                    meta_response = self.client.head_object(
                        Bucket=self.bucket,
                        Key=obj['Key']
                    )
                    backup_info['metadata'] = meta_response.get('Metadata', {})
                except Exception:
                    backup_info['metadata'] = {}
                
                backups.append(backup_info)
            
            backups.sort(key=lambda x: x['last_modified'], reverse=True)
            print(f"✅ {len(backups)} backups trouvés sur S3")
            return backups
            
        except Exception as e:
            print(f"❌ Erreur list backups S3: {e}")
            return []
    
    def delete_backup(self, s3_key: str) -> bool:
        """
        Supprimer un backup sur S3
        """
        if not self.is_available():
            print("❌ S3 non disponible pour delete backup")
            return False
        
        try:
            self.client.delete_object(
                Bucket=self.bucket,
                Key=s3_key
            )
            
            print(f"✅ Backup supprimé de S3: {s3_key}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur delete backup S3: {e}")
            return False
    
    def get_public_url(self, key: str) -> Optional[str]:
        """
        Générer une URL publique pour un objet S3
        Utilise le CDN si configuré
        """
        if self.cdn_base_url:
            return f"{self.cdn_base_url.rstrip('/')}/{key}"
        else:
            return f"https://{self.bucket}.s3.{self.config['region']}.amazonaws.com/{key}"
```

### src/storage/local.py
```python
"""
Stockage local pour GuignoMap v5.0  
Fallback avec API identique à cloud.py
"""
import json
import shutil
import os
from typing import Optional, Dict, Any, List
from pathlib import Path
from datetime import datetime


class LocalStorageClient:
    """Client stockage local avec API identique au client S3"""
    
    def __init__(self, base_path: Optional[Path] = None):
        # Répertoire de base pour le stockage local
        if base_path is None:
            base_path = Path(__file__).parent.parent.parent / "storage_local"
        
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
        
        # Sous-répertoires
        self.backups_dir = self.base_path / "backups"
        self.backups_dir.mkdir(exist_ok=True)
    
    def is_available(self) -> bool:
        """Le stockage local est toujours disponible"""
        return True
    
    def upload_json_file(self, key: str, data: Dict[Any, Any], metadata: Optional[Dict[str, str]] = None) -> bool:
        """Sauvegarde d'un fichier JSON en local"""
        try:
            file_path = self.base_path / key
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Sauvegarder les données JSON
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # Sauvegarder les métadonnées si fournies
            if metadata:
                metadata_path = file_path.with_suffix('.metadata.json')
                with open(metadata_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"✅ JSON sauvé localement: {file_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur sauvegarde JSON local {key}: {e}")
            return False
    
    def download_json_file(self, key: str) -> Optional[Dict[Any, Any]]:
        """Lecture d'un fichier JSON local"""
        try:
            file_path = self.base_path / key
            
            if not file_path.exists():
                print(f"ℹ️ Fichier JSON local non trouvé: {file_path}")
                return None
            
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"✅ JSON lu localement: {file_path}")
            return data
            
        except Exception as e:
            print(f"❌ Erreur lecture JSON local {key}: {e}")
            return None
    
    def upload_backup(self, backup_file_path: Path, s3_key: Optional[str] = None) -> bool:
        """Copie d'un fichier backup vers le répertoire local"""
        try:
            if not backup_file_path.exists():
                print(f"❌ Fichier backup non trouvé: {backup_file_path}")
                return False
            
            # Générer le nom de destination si non fourni
            if not s3_key:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                dest_name = f"{backup_file_path.stem}_{timestamp}{backup_file_path.suffix}"
            else:
                # Extraire le nom du fichier de la clé S3
                dest_name = Path(s3_key).name
            
            dest_path = self.backups_dir / dest_name
            
            # Copier le fichier
            shutil.copy2(backup_file_path, dest_path)
            
            # Créer un fichier de métadonnées
            metadata = {
                'original_filename': backup_file_path.name,
                'original_path': str(backup_file_path),
                'upload_timestamp': datetime.utcnow().isoformat(),
                'file_size': backup_file_path.stat().st_size
            }
            
            metadata_path = dest_path.with_suffix('.metadata.json')
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"✅ Backup copié localement: {dest_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur copie backup local: {e}")
            return False
    
    def download_backup(self, key: str, local_path: Path) -> bool:
        """Copie d'un backup local vers un autre emplacement"""
        try:
            source_path = self.backups_dir / Path(key).name
            
            if not source_path.exists():
                print(f"❌ Backup local non trouvé: {source_path}")
                return False
            
            # Créer le répertoire parent si nécessaire
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Copier le fichier
            shutil.copy2(source_path, local_path)
            
            print(f"✅ Backup copié vers: {local_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur copie backup: {e}")
            return False
    
    def list_backups(self, prefix: str = "") -> List[Dict[str, Any]]:
        """Lister les backups disponibles en local"""
        try:
            backups = []
            
            for backup_file in self.backups_dir.glob("*.db"):
                if prefix and not backup_file.name.startswith(prefix):
                    continue
                
                stat = backup_file.stat()
                backup_info = {
                    'key': f"backups/{backup_file.name}",
                    'filename': backup_file.name,
                    'size': stat.st_size,
                    'last_modified': datetime.fromtimestamp(stat.st_mtime),
                    'metadata': {}
                }
                
                # Charger les métadonnées si disponibles
                metadata_path = backup_file.with_suffix('.metadata.json')
                if metadata_path.exists():
                    try:
                        with open(metadata_path, 'r', encoding='utf-8') as f:
                            backup_info['metadata'] = json.load(f)
                    except Exception:
                        pass
                
                backups.append(backup_info)
            
            # Trier par date de modification décroissante
            backups.sort(key=lambda x: x['last_modified'], reverse=True)
            
            print(f"✅ {len(backups)} backups trouvés localement")
            return backups
            
        except Exception as e:
            print(f"❌ Erreur list backups locaux: {e}")
            return []
    
    def delete_backup(self, key: str) -> bool:
        """Supprimer un backup local"""
        try:
            backup_path = self.backups_dir / Path(key).name
            metadata_path = backup_path.with_suffix('.metadata.json')
            
            # Supprimer le fichier backup
            if backup_path.exists():
                backup_path.unlink()
            
            # Supprimer les métadonnées
            if metadata_path.exists():
                metadata_path.unlink()
            
            print(f"✅ Backup local supprimé: {backup_path.name}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur suppression backup local: {e}")
            return False
    
    def get_public_url(self, key: str) -> Optional[str]:
        """
        URL publique non applicable pour stockage local
        Retourne le chemin local
        """
        local_path = self.base_path / key
        if local_path.exists():
            return f"file://{local_path.absolute()}"
        return None
```

### src/utils/adapters.py
```python
"""
Adaptateurs pour conversions de données GuignoMap v5.0
Notamment List[Dict] → DataFrame pour UI Streamlit
"""
import pandas as pd
from typing import List, Dict, Any, Optional


def to_dataframe(data: Any, default_columns: Optional[List[str]] = None) -> pd.DataFrame:
    """
    Convertit des données en DataFrame pandas pour l'affichage Streamlit
    
    Gère les cas:
    - List[Dict] → DataFrame
    - DataFrame → DataFrame (passthrough)
    - Données vides → DataFrame vide avec colonnes par défaut
    - Autres types → DataFrame vide
    
    Args:
        data: Données à convertir
        default_columns: Colonnes par défaut si données vides
    
    Returns:
        pd.DataFrame: Toujours un DataFrame valide
    """
    # Déjà un DataFrame
    if isinstance(data, pd.DataFrame):
        return data
    
    # Liste de dictionnaires → DataFrame
    if isinstance(data, list) and len(data) > 0 and all(isinstance(item, dict) for item in data):
        try:
            return pd.DataFrame(data)
        except Exception as e:
            print(f"Erreur conversion List[Dict] → DataFrame: {e}")
            # Fallback: DataFrame vide avec colonnes détectées
            if data and isinstance(data[0], dict):
                columns = list(data[0].keys())
                return pd.DataFrame(columns=columns)
    
    # Liste vide ou autres types → DataFrame vide
    if default_columns:
        return pd.DataFrame(columns=default_columns)
    else:
        return pd.DataFrame()


def safe_get_dict_value(item: Dict[Any, Any], key: str, default: Any = None) -> Any:
    """
    Récupération sécurisée d'une valeur dans un dictionnaire
    Gère les cas de clés manquantes, None, etc.
    """
    if not isinstance(item, dict):
        return default
    
    return item.get(key, default)


def normalize_street_data(streets_raw: List[Dict]) -> pd.DataFrame:
    """
    Normalise les données de rues pour l'affichage UI
    Assure la cohérence des colonnes et types
    """
    if not streets_raw:
        return pd.DataFrame(columns=['name', 'sector', 'team', 'status'])
    
    # Conversion sécurisée
    df = to_dataframe(streets_raw, default_columns=['name', 'sector', 'team', 'status'])
    
    # Valeurs par défaut pour colonnes manquantes
    required_columns = ['name', 'sector', 'team', 'status']
    for col in required_columns:
        if col not in df.columns:
            df[col] = None
    
    # Nettoyage des valeurs
    df['name'] = df['name'].fillna('(Sans nom)')
    df['sector'] = df['sector'].fillna('(Non assigné)')
    df['team'] = df['team'].fillna('(Aucune équipe)')
    df['status'] = df['status'].fillna('a_faire')
    
    return df


def normalize_team_data(teams_raw: List[Dict]) -> pd.DataFrame:
    """
    Normalise les données d'équipes pour l'affichage UI
    """
    if not teams_raw:
        return pd.DataFrame(columns=['id', 'name', 'active'])
    
    df = to_dataframe(teams_raw, default_columns=['id', 'name', 'active'])
    
    # Valeurs par défaut
    if 'id' not in df.columns:
        df['id'] = None
    if 'name' not in df.columns:
        df['name'] = None
    if 'active' not in df.columns:
        df['active'] = True
    
    # Nettoyage
    df['id'] = df['id'].fillna('(ID manquant)')
    df['name'] = df['name'].fillna('(Nom manquant)')
    df['active'] = df['active'].fillna(True)
    
    return df


def normalize_notes_data(notes_raw: List[Dict]) -> pd.DataFrame:
    """
    Normalise les données de notes pour l'affichage UI
    """
    if not notes_raw:
        return pd.DataFrame(columns=['street_name', 'team_id', 'address_number', 'comment', 'created_at'])
    
    df = to_dataframe(notes_raw)
    
    # Valeurs par défaut
    required_columns = ['street_name', 'team_id', 'address_number', 'comment', 'created_at']
    for col in required_columns:
        if col not in df.columns:
            df[col] = None
    
    # Nettoyage
    df['street_name'] = df['street_name'].fillna('(Rue inconnue)')
    df['team_id'] = df['team_id'].fillna('(Équipe inconnue)')
    df['address_number'] = df['address_number'].fillna('')
    df['comment'] = df['comment'].fillna('')
    
    return df
```

## CODE — FICHIERS MODIFIÉS (extraits pertinents)

### guignomap/app.py (correctifs PHASE 1)
```python
# Import des nouveaux adaptateurs
from src.utils.adapters import to_dataframe, normalize_street_data, normalize_team_data, normalize_notes_data

# [... code existant ...]

def create_map():
    """
    CORRECTIF PHASE 1: DataFrame robuste + coercion + itération sécurisée
    """
    try:
        # Récupération des données avec coercion explicite DataFrame
        streets_raw = db.get_all_streets_with_addresses()
        
        # CORRECTIF 1: Coercion DataFrame en début de fonction
        if not isinstance(streets_raw, pd.DataFrame):
            if isinstance(streets_raw, list):
                streets_df = pd.DataFrame(streets_raw) if streets_raw else pd.DataFrame()
            else:
                streets_df = pd.DataFrame()
        else:
            streets_df = streets_raw.copy()
        
        # CORRECTIF 2: Valeurs par défaut pour éviter les erreurs
        if streets_df.empty:
            st.info("Aucune rue trouvée dans la base de données")
            # Retourner une carte vide centrée sur Montréal
            m = folium.Map(location=[45.5017, -73.5673], zoom_start=12)
            return m
        
        # CORRECTIF 3: Assurer la présence des colonnes requises
        required_columns = ['latitude', 'longitude', 'name', 'status']
        for col in required_columns:
            if col not in streets_df.columns:
                streets_df[col] = None
        
        # Filtrer les rues avec coordonnées valides
        valid_streets = streets_df.dropna(subset=['latitude', 'longitude'])
        
        if valid_streets.empty:
            st.warning("Aucune rue avec coordonnées GPS trouvée")
            m = folium.Map(location=[45.5017, -73.5673], zoom_start=12)
            return m
        
        # Créer la carte
        center_lat = valid_streets['latitude'].mean()
        center_lon = valid_streets['longitude'].mean()
        m = folium.Map(location=[center_lat, center_lon], zoom_start=13)
        
        # CORRECTIF 4: Itération robuste avec gestion d'erreurs
        for idx, row in valid_streets.iterrows():
            try:
                lat = float(row.get('latitude', 0))
                lon = float(row.get('longitude', 0))
                name = str(row.get('name', 'Rue inconnue'))
                status = str(row.get('status', 'a_faire'))
                
                # Définir la couleur selon le statut
                color_map = {
                    'fait': 'green',
                    'en_cours': 'orange', 
                    'a_faire': 'red',
                    'probleme': 'purple'
                }
                color = color_map.get(status, 'gray')
                
                # Ajouter le marqueur
                folium.CircleMarker(
                    location=[lat, lon],
                    radius=8,
                    popup=f"{name}<br>Statut: {status}",
                    color=color,
                    fill=True,
                    fillColor=color,
                    fillOpacity=0.7
                ).add_to(m)
                
            except (ValueError, TypeError, AttributeError) as e:
                print(f"Erreur traitement rue {row.get('name', 'inconnue')}: {e}")
                continue  # Passer à la rue suivante
        
        return m
        
    except Exception as e:
        st.error(f"Erreur lors de la création de la carte: {e}")
        # Retourner carte de fallback
        return folium.Map(location=[45.5017, -73.5673], zoom_start=12)

# [... code existant ...]

# CORRECTIFS UI: Wrapping des st.dataframe() avec to_dataframe()

# Correctif 1: Affichage des rues
if st.button("Voir toutes les rues"):
    streets = db.get_all_streets()
    streets_df = to_dataframe(streets, default_columns=['name', 'sector', 'team', 'status'])
    st.dataframe(streets_df)

# Correctif 2: Statistiques par équipe 
stats = db.stats_by_team()
stats_df = to_dataframe(stats, default_columns=['team', 'total', 'completed'])
st.dataframe(stats_df)

# Correctif 3: Notes d'équipe
team_notes = db.get_team_notes(selected_team)
notes_df = to_dataframe(team_notes, default_columns=['street_name', 'address_number', 'comment', 'created_at'])
st.dataframe(notes_df)

# Correctif 4: Activité récente  
recent_activity = db.recent_activity(limit=50)
activity_df = to_dataframe(recent_activity, default_columns=['team_id', 'action', 'details', 'created_at'])
st.dataframe(activity_df)

# Correctif 5: Liste des équipes (admin)
teams = db.get_all_teams()
teams_df = to_dataframe(teams, default_columns=['id', 'name', 'active'])
st.dataframe(teams_df)

# Correctif 6: Liste des rues (admin)
streets = db.list_streets()
streets_df = to_dataframe(streets, default_columns=['name', 'sector', 'team', 'status'])
st.dataframe(streets_df)
```

### scripts/migrate_sqlite_to_postgres.py (extrait - fonction main)
```python
def main():
    """Migration complète SQLite → PostgreSQL"""
    print("🔄 Début migration SQLite → PostgreSQL...")
    
    # Connexions
    sqlite_conn = get_sqlite_connection()
    if not sqlite_conn:
        return False
    
    try:
        # Créer les tables PostgreSQL
        if not create_postgres_tables():
            return False
        
        # Session PostgreSQL
        engine = get_engine()
        Session = sessionmaker(bind=engine)
        postgres_session = Session()
        
        # Migration par table
        total_migrated = 0
        total_migrated += copy_teams(sqlite_conn, postgres_session)
        total_migrated += copy_streets(sqlite_conn, postgres_session)
        total_migrated += copy_notes(sqlite_conn, postgres_session)
        total_migrated += copy_activity_logs(sqlite_conn, postgres_session)
        total_migrated += copy_addresses(sqlite_conn, postgres_session)
        
        postgres_session.close()
        sqlite_conn.close()
        
        print(f"🎉 Migration terminée ! {total_migrated} enregistrements migrés")
        return True
        
    except Exception as e:
        print(f"❌ Erreur générale migration: {e}")
        if 'postgres_session' in locals():
            postgres_session.close()
        sqlite_conn.close()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
```

### scripts/migrate_password_hashes.py (extrait - fonction analyse)
```python
def analyze_password_hashes():
    """
    Analyse des hashes de mots de passe dans la base
    Identifie les équipes avec des hashes bcrypt qui nécessitent une migration
    """
    conn = get_sqlite_connection()
    if not conn:
        return
    
    try:
        print("🔍 Analyse des hashes de mots de passe...")
        print("=" * 50)
        
        # Récupérer toutes les équipes
        cursor = conn.execute("SELECT id, name, password_hash, created_at FROM teams ORDER BY id")
        teams = cursor.fetchall()
        
        if not teams:
            print("ℹ️ Aucune équipe trouvée dans la base")
            return
        
        bcrypt_count = 0
        argon2_count = 0
        unknown_count = 0
        
        print(f"{'Équipe':<15} {'Algorithme':<10} {'Statut':<20} {'Créé le'}")
        print("-" * 65)
        
        for team in teams:
            # [... logique d'analyse des hashes ...]
            hash_info = get_password_hash_info(hash_value)
            algorithm = hash_info['algorithm']
            
            if algorithm == 'bcrypt':
                bcrypt_count += 1
                status = "🔄 À migrer"
            elif algorithm == 'argon2':
                argon2_count += 1
                status = "✅ Moderne"
            else:
                unknown_count += 1
                status = "❓ Inconnu"
        
        print(f"\n📊 Résumé: {bcrypt_count} bcrypt, {argon2_count} Argon2, {unknown_count} inconnus")
        
    except Exception as e:
        print(f"❌ Erreur lors de l'analyse: {e}")
    finally:
        conn.close()
```

## FICHIERS DE CONFIGURATION

### alembic.ini
```ini
# Configuration Alembic pour migrations PostgreSQL

[alembic]
script_location = src/database/migrations
prepend_sys_path = .
version_path_separator = os
sqlalchemy.url = postgresql://user:pass@localhost/dbname

[post_write_hooks]

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
```

### requirements.txt (référence)
```txt
streamlit>=1.36.0
pandas>=2.2.0
requests>=2.31.0
folium==0.20.0
streamlit-folium>=0.21.0
sqlalchemy==2.0.23
alembic==1.13.1
psycopg2-binary>=2.9.7
passlib[argon2]==1.7.4
boto3==1.34.144
bcrypt>=4.0.0
```

## COMMITS PRÉPARÉS (PHASE 1)

### Commit 1: Infrastructure base SQLAlchemy + PostgreSQL
```
feat: infrastructure SQLAlchemy + PostgreSQL v5.0

- Connexion PostgreSQL avec QueuePool + retry logic
- Modèles SQLAlchemy (Street, Team, Note, ActivityLog, Address)
- Configuration centralisée avec secrets Streamlit
- Alembic pour migrations de schéma
- Support fallback SQLite pour dev local

Files:
+ src/config.py
+ src/database/connection.py  
+ src/database/models.py
+ src/database/migrations/env.py
+ alembic.ini
```

### Commit 2: Stockage S3/local + authentification Argon2
```
feat: stockage S3/local + auth Argon2 avec compat bcrypt

- Client S3 pour backup cloud avec fallback local
- Migration paresseuse bcrypt → Argon2 à la connexion
- API stockage unifiée (cloud.py / local.py)
- Scripts de migration SQLite → PostgreSQL
- Scripts d'analyse des hashes de mot de passe

Files:
+ src/storage/cloud.py
+ src/storage/local.py
+ src/auth/passwords.py
+ scripts/migrate_sqlite_to_postgres.py
+ scripts/migrate_password_hashes.py
```

### Commit 3: Correctifs DataFrame + adapters UI (CRITIQUE)
```
fix: correctifs DataFrame + adapters UI robustes

CORRECTIFS PHASE 1 AUDIT:
- create_map(): coercion DataFrame + itération sécurisée + valeurs par défaut
- Wrapping 6× st.dataframe() avec to_dataframe() adapter
- Adapter List[Dict] → DataFrame pour cohérence UI
- Gestion erreurs robuste (rue manquante, coordonnées invalides)

Files:
~ guignomap/app.py (create_map + 6 st.dataframe fixes)
+ src/utils/adapters.py
```

## VALIDATION & TESTS RECOMMANDÉS

### Scripts PowerShell de validation (déjà fournis)
```powershell
# Validation DataFrame (à exécuter après correctifs)
python -c "
import pandas as pd
from src.utils.adapters import to_dataframe

# Test 1: List[Dict] → DataFrame
data = [{'name': 'Rue A', 'status': 'fait'}, {'name': 'Rue B', 'status': 'a_faire'}]
df = to_dataframe(data)
assert isinstance(df, pd.DataFrame)
assert len(df) == 2
print('✅ Test 1 passed: List[Dict] → DataFrame')

# Test 2: DataFrame → DataFrame (passthrough)
df2 = to_dataframe(df)
assert df.equals(df2)
print('✅ Test 2 passed: DataFrame passthrough')

# Test 3: Données vides → DataFrame vide
empty_df = to_dataframe([], default_columns=['name', 'status'])
assert isinstance(empty_df, pd.DataFrame)
assert list(empty_df.columns) == ['name', 'status']
print('✅ Test 3 passed: Empty → DataFrame with defaults')

print('🎉 Tous les tests adapters passed')
"
```

### Tests de connexion base PostgreSQL
```powershell
python -c "
from src.database.connection import test_connection, get_engine
from src.config import get_database_url

print(f'Database URL: {get_database_url()[:20]}...')  # Masquer credentials
engine = get_engine()
print(f'Engine pool size: {engine.pool.size()}')

if test_connection():
    print('✅ Connexion PostgreSQL OK')
else:
    print('❌ Connexion PostgreSQL échouée')
"
```

## PROCÉDURES DE DÉPLOIEMENT

### 1. Environnement local (SQLite)
```powershell
# Setup venv
py -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt

# Test local
streamlit run guignomap/app.py
```

### 2. Déploiement Streamlit Cloud (PostgreSQL)
```yaml
# Secrets Streamlit Cloud (.streamlit/secrets.toml)
[database]
url = "postgresql://user:***@***:5432/guignomap"
pool_size = 5
max_overflow = 10

[storage]
s3_bucket = "guignomap-prod"
s3_region = "us-east-1"
s3_access_key = "AKIA***"
s3_secret_key = "***"
cdn_base_url = "https://cdn.example.com"  # optionnel
```

### 3. Migration des données (une fois en prod)
```powershell
# Exécuter depuis l'environnement local avec accès PostgreSQL prod
python scripts/migrate_sqlite_to_postgres.py
python scripts/migrate_password_hashes.py  # Analyse seulement
```

## FICHIERS MANQUANTS/AMBIGUS DÉTECTÉS

### Fichiers non trouvés lors de l'export:
- `src/ui/pages/admin_migration.py` : référencé mais absent du repo
- Révisions Alembic dans `src/database/migrations/versions/` : dossier vide

### Questions pour l'utilisateur:
1. Le fichier `admin_migration.py` doit-il être créé ou était-ce une référence incorrecte ?
2. Des révisions Alembic doivent-elles être générées (`alembic revision --autogenerate`) ?
3. Y a-t-il d'autres fichiers/configurations spécifiques au déploiement Streamlit Cloud ?

## NOTES IMPORTANTES

- **IPv6 Streamlit Cloud**: Les migrations PostgreSQL doivent être exécutées côté Cloud car l'environnement local peut avoir des problèmes IPv6
- **Politique MDP v4.1 conservée**: Minimum 4 caractères + confirmation pour maintenir l'UX existante
- **Migration paresseuse**: Les hashes bcrypt sont automatiquement migrés vers Argon2 lors de la prochaine connexion réussie
- **Fallbacks robustes**: Tous les composants ont des fallbacks SQLite/local en cas de problème PostgreSQL/S3
- **Logs détaillés**: Tous les composants loggent leurs actions pour faciliter le debug

---
**FIN DE L'EXPORT - Version v5.0 PHASE 1 complète**
**Date: 2025-09-15 14:30:00 local**
**Taille: ~15KB de code + config + documentation**
```
```
```
---8<--- exports/export_20250915_175357.txt END ---

---8<--- guignomap/__init__.py BEGIN ---
```py

```
---8<--- guignomap/__init__.py END ---

---8<--- guignomap/app.py BEGIN ---
```py
"""
Guigno-Map - Application de gestion de collecte de denrées
Le Relais de Mascouche
Version 3.0 - Production
"""

from pathlib import Path
import time
from datetime import datetime
import pandas as pd
import streamlit as st
import folium
from streamlit_folium import st_folium

# Import des modules locaux
import db_v5 as db
from validators import validate_and_clean_input
from osm import build_geometry_cache, load_geometry_cache, build_addresses_cache, load_addresses_cache, CACHE_FILE
from src.utils.adapters import to_dataframe

# Configuration des chemins - Legacy pour backup seulement
DB_PATH = Path(__file__).parent / "guigno_map.db"

# --- Utilitaire de compatibilité pandas Styler ---
from typing import Callable, Any

def style_map_compat(df: pd.DataFrame, fn: Callable[[Any], str], subset: Any = None):
    """Applique un style cellule-à-cellule en utilisant Styler.map si disponible,
    sinon fallback dynamique vers applymap sans exposer l'attribut (OK pour Pylance).
    
    Args:
        df: DataFrame à styliser
        fn: Fonction qui prend une valeur cellule et retourne une string CSS
        subset: Colonnes à cibler (ex: ['status'] ou None pour toutes)
    """
    styler = df.style
    if hasattr(styler, "map"):
        # Pandas 2.4+ : utilise la nouvelle API map()
        return styler.map(fn, subset=subset)
    # Pandas < 2.4 : fallback vers applymap (sans référence statique)
    return getattr(styler, "applymap")(fn, subset=subset)

# --- Mapping des statuts pour l'affichage ---
STATUS_TO_LABEL = {"a_faire": "À faire", "en_cours": "En cours", "terminee": "Terminée"}
LABEL_TO_STATUS = {v: k for k, v in STATUS_TO_LABEL.items()}

ASSETS = Path(__file__).parent / "assets"

# Configuration Streamlit
st.set_page_config(
    page_title="Guigno-Map | Relais de Mascouche",
    page_icon="🎁",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialisation session
if "auth" not in st.session_state:
    st.session_state.auth = None

# ============================================
# COMPOSANTS UI
# ============================================

def inject_css():
    """Charge le CSS depuis le fichier externe"""
    css_file = ASSETS / "styles.css"
    if css_file.exists():
        css = css_file.read_text(encoding="utf-8")
        st.markdown(f"<style>{css}</style>", unsafe_allow_html=True)

def render_header():
    """Header moderne avec logo Guignolée et design festif"""
    
    # Container principal avec fond festif
    st.markdown("""
    <div style="
        background: linear-gradient(135deg, #c41e3a 0%, #165b33 100%);
        border-radius: 20px;
        padding: 2rem;
        margin-bottom: 2rem;
        position: relative;
        overflow: hidden;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    ">
        <!-- Flocons de neige animés en CSS -->
        <div style="position: absolute; width: 100%; height: 100%; opacity: 0.1;">
            <span style="position: absolute; top: 10%; left: 10%; font-size: 2rem;">❄️</span>
            <span style="position: absolute; top: 20%; left: 80%; font-size: 1.5rem;">❄️</span>
            <span style="position: absolute; top: 60%; left: 30%; font-size: 1.8rem;">❄️</span>
        </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([2, 5, 2])
    
    with col1:
        # Logo Guignolée
        if (ASSETS / "guignolee.png").exists():
            st.image(str(ASSETS / "guignolee.png"), width=150)
    
    with col2:
        st.markdown("""
        <div style="text-align: center;">
            <h1 style="
                color: white;
                font-family: 'Manrope', sans-serif;
                font-size: 2.5rem;
                margin: 0;
                text-shadow: 3px 3px 6px rgba(0,0,0,0.5);
                letter-spacing: 2px;
            ">🎅 GUIGNOLÉE 2025 🎁</h1>
            <p style="
                color: #FFD700;
                font-size: 1.2rem;
                margin: 0.5rem 0 0 0;
                font-weight: 600;
            ">Le Relais de Mascouche - 1er décembre</p>
            <p style="
                color: rgba(255,255,255,0.9);
                font-size: 1rem;
                margin-top: 0.5rem;
            ">Système de gestion de collecte</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        # Stats en temps réel
        stats = db.extended_stats()
        progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
        
        st.markdown(f"""
        <div style="
            background: rgba(255,255,255,0.2);
            border-radius: 15px;
            padding: 1rem;
            text-align: center;
        ">
            <div style="color: #FFD700; font-size: 2rem; font-weight: bold;">
                {progress:.0f}%
            </div>
            <div style="color: white; font-size: 0.9rem;">
                Complété
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

def render_login_card(role="benevole", conn=None):
    """Carte de connexion moderne avec design festif"""
    
    # Container de connexion stylisé
    st.markdown("""
    <div style="
        max-width: 400px;
        margin: 3rem auto;
        background: linear-gradient(135deg, rgba(255,255,255,0.1), rgba(255,255,255,0.05));
        backdrop-filter: blur(10px);
        border: 2px solid rgba(255,215,0,0.3);
        border-radius: 20px;
        padding: 2rem;
        box-shadow: 0 20px 40px rgba(0,0,0,0.3);
    ">
    """, unsafe_allow_html=True)
    
    # Icône et titre
    if role == "superviseur" or role == "gestionnaire":
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <div style="font-size: 3rem;">👔</div>
            <h2 style="color: #FFD700; margin: 1rem 0;">Espace Gestionnaire</h2>
            <p style="color: #cbd5e1;">Gérez la collecte et les équipes</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_gestionnaire", clear_on_submit=False):
            password = st.text_input(
                "🔐 Mot de passe",
                type="password",
                placeholder="Entrez le mot de passe gestionnaire"
            )
            
            col1, col2, col3 = st.columns([1,2,1])
            with col2:
                submit = st.form_submit_button(
                    "🚀 Connexion",
                    width="stretch"
                )
            
            if submit:
                if db.verify_team("ADMIN", password):
                    st.session_state.auth = {"role": "supervisor", "team_id": "ADMIN"}
                    st.success("✅ Bienvenue dans l'espace gestionnaire!")
                    st.snow()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("❌ Mot de passe incorrect")
    
    else:  # Bénévole
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <div style="font-size: 3rem;">🎅</div>
            <h2 style="color: #FFD700; margin: 1rem 0;">Espace Bénévole</h2>
            <p style="color: #cbd5e1;">Accédez à vos rues assignées</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_benevole", clear_on_submit=False):
            col1, col2 = st.columns(2)
            
            with col1:
                team_id = st.text_input(
                    "👥 Identifiant d'équipe",
                    placeholder="Ex: EQ001"
                )
            
            with col2:
                password = st.text_input(
                    "🔐 Mot de passe",
                    type="password",
                    placeholder="Mot de passe équipe"
                )
            
            col1, col2, col3 = st.columns([1,2,1])
            with col2:
                submit = st.form_submit_button(
                    "🎄 Connexion",
                    width="stretch"
                )
            
            if submit:
                if db.verify_team(team_id, password):
                    st.session_state.auth = {"role": "volunteer", "team_id": team_id}
                    st.success(f"✅ Bienvenue équipe {team_id}!")
                    st.snow()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("❌ Identifiants incorrects")
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    # Aide en bas
    st.markdown("""
    <div style="text-align: center; margin-top: 2rem; color: #8b92a4;">
        <small>
        Besoin d'aide? Contactez votre gestionnaire<br>
        📞 450-474-4133
        </small>
    </div>
    """, unsafe_allow_html=True)

def render_metrics(stats):
    """Affiche les métriques principales"""
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Rues", stats['total'])
    
    with col2:
        st.metric("Rues Terminées", stats['done'])
    
    with col3:
        st.metric("En Cours", stats.get('partial', 0))
    
    with col4:
        st.metric("Progression", f"{progress:.1f}%")

def render_dashboard_gestionnaire(conn, geo):
    """Dashboard moderne pour gestionnaires avec KPIs visuels"""
    
    # KPIs principaux en cartes colorées
    stats = db.extended_stats()
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    st.markdown("### 📊 Tableau de bord en temps réel")
    
    # Ligne de KPIs avec icônes festives
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #22c55e, #16a34a);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(34,197,94,0.3);
        ">
            <div style="font-size: 2.5rem;">🏘️</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats['total']}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Total Rues</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(59,130,246,0.3);
        ">
            <div style="font-size: 2.5rem;">✅</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats['done']}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Terminées</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #f59e0b, #d97706);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(245,158,11,0.3);
        ">
            <div style="font-size: 2.5rem;">🚶</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats.get('partial', 0)}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">En cours</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        # Nombre d'équipes actives
        teams_count = len(db.teams())
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #8b5cf6, #7c3aed);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(139,92,246,0.3);
        ">
            <div style="font-size: 2.5rem;">👥</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{teams_count}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Équipes</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col5:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #c41e3a, #165b33);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(196,30,58,0.3);
        ">
            <div style="font-size: 2.5rem;">🎯</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{progress:.0f}%</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Progression</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Barre de progression visuelle
    st.markdown("### 🎄 Progression globale")
    st.progress(progress / 100)
    
    # Graphique par secteur (si disponible)
    st.markdown("### 📈 Performance par équipe")
    try:
        teams_stats = db.stats_by_team()
        if teams_stats:  # Liste non vide
            # Convertir en DataFrame pour plotly
            import pandas as pd
            teams_df = pd.DataFrame(teams_stats)
            
            # Calculer le pourcentage de progression
            teams_df['progress'] = ((teams_df['completed'] / teams_df['total_streets']) * 100).fillna(0)
            
            # Graphique en barres colorées
            import plotly.express as px
            fig = px.bar(
                teams_df, 
                x='id', 
                y='progress',
                color='progress',
                color_continuous_scale=['#ef4444', '#f59e0b', '#22c55e'],
                labels={'team': 'Équipe', 'progress': 'Progression (%)'},
                title="Performance des équipes"
            )
            fig.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig, width="stretch")
        else:
            st.info("Aucune statistique d'équipe disponible")
    except Exception as e:
        st.warning("Graphiques non disponibles (module plotly manquant)")
        # Fallback vers un tableau simple
        try:
            teams_stats = db.stats_by_team()
            if teams_stats:  # Liste non vide
                st.dataframe(to_dataframe(teams_stats), width="stretch")
        except:
            st.info("Aucune statistique d'équipe disponible")

def add_persistent_legend(m):
    """Ajoute une légende persistante pour les 4 états des rues via contrôle HTML"""
    legend_html = """
    <div id='gm-legend' class='leaflet-control-layers leaflet-control' 
         style='position: absolute; bottom: 10px; right: 10px; z-index: 1000;
                background: white; border: 2px solid rgba(0,0,0,0.2); 
                border-radius: 5px; padding: 10px; box-shadow: 0 1px 5px rgba(0,0,0,0.2);
                font-family: "Helvetica Neue", Arial, Helvetica, sans-serif; 
                font-size: 12px; line-height: 18px; color: #333;'>
        <strong style='margin-bottom: 8px; display: block;'>Légende</strong>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #28a745; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Terminée</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #f1c40f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>En cours</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #ff4d4f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Assignée (à faire)</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px dashed #ff4d4f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Non assignée</span>
        </div>
    </div>
    """
    m.get_root().html.add_child(folium.Element(legend_html))

def create_map(df, geo):
    """Crée la carte Folium centrée sur Mascouche avec toutes les rues"""
    # 1) Coercition sûre en DataFrame
    if not isinstance(df, pd.DataFrame):
        try:
            df = pd.DataFrame(df)
        except Exception:
            df = pd.DataFrame([])
    
    # Limites de Mascouche
    bounds = {
        "north": 45.78,
        "south": 45.70,
        "east": -73.55,
        "west": -73.70
    }
    center = [(bounds["north"] + bounds["south"]) / 2, 
              (bounds["east"] + bounds["west"]) / 2]
    
    # Créer la carte
    m = folium.Map(
        location=center,
        zoom_start=13,  # Zoom optimisé pour voir toute la ville
        tiles="https://{s}.tile.openstreetmap.fr/osmfr/{z}/{x}/{y}.png",
        attr='© OpenStreetMap France',
        control_scale=True,
        max_bounds=True,
        min_zoom=11,
        max_zoom=18,
        prefer_canvas=True,
        zoom_control=True,
        scrollWheelZoom=True
    )
    
    # Ajouter plusieurs couches de fond
    folium.TileLayer(
        tiles='https://{s}.tile.openstreetmap.fr/osmfr/{z}/{x}/{y}.png',
        attr='© OpenStreetMap France',
        name='OSM France (Détaillé)',
        overlay=False,
        control=True
    ).add_to(m)

    folium.TileLayer(
        tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager/{z}/{x}/{y}.png',
        attr='© CARTO',
        name='CARTO Voyager',
        overlay=False,
        control=True
    ).add_to(m)

    folium.TileLayer(
        tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Street_Map/MapServer/tile/{z}/{y}/{x}',
        attr='© Esri',
        name='Esri WorldStreetMap',
        overlay=False,
        control=True
    ).add_to(m)

    # Ajouter le contrôle des couches
    folium.LayerControl().add_to(m)
    
    # Définir les limites de la carte sur Mascouche
    m.fit_bounds([[bounds["south"], bounds["west"]], 
                  [bounds["north"], bounds["east"]]])
    
    if not geo:
        st.warning("Aucune donnée géométrique disponible")
        return m
    
    # Construire le lookup des infos DB
    street_info = {}
    if not df.empty:  # DataFrame non vide
        for idx, row in df.iterrows():
            name = str(row.get('name', '')) if pd.notna(row.get('name', '')) else ''
            status = row.get('status', 'a_faire')
            status = status if pd.notna(status) else 'a_faire'
            team = row.get('team', '')
            team = team if pd.notna(team) else ''
            notes = str(row.get('notes', '0')) if pd.notna(row.get('notes', '0')) else '0'
            
            street_info[name] = {
                'status': status,
                'team': str(team).strip() if team else '',
                'notes': notes
            }
    
    # Couleurs par statut
    status_colors = {
        'terminee': '#22c55e',  # Vert
        'en_cours': '#f59e0b',  # Orange
        'a_faire': '#ef4444'    # Rouge
    }
    
    # Compteurs pour stats
    stats = {"total": 0, "assigned": 0, "unassigned": 0}
    
    # Ajouter TOUTES les rues de la géométrie
    for name, paths in geo.items():
        stats["total"] += 1
        
        # Info depuis DB ou défaut (rouge pointillé)
        info = street_info.get(name, {
            'status': 'a_faire',
            'team': '',
            'notes': '0'
        })
        
        status = info['status']
        team = info['team']
        notes = info['notes']
        
        # Style: TOUJOURS pointillé si pas d'équipe
        has_team = bool(team)
        color = status_colors.get(status, '#ef4444')  # Rouge par défaut
        opacity = 0.9 if has_team else 0.7
        dash = None if has_team else '8,12'  # Pointillés si non assigné
        weight = 7 if has_team else 5
        
        if has_team:
            stats["assigned"] += 1
        else:
            stats["unassigned"] += 1
        
        # Tooltip informatif
        tooltip_html = f"""
        <div style='font-family: sans-serif'>
            <strong style='font-size: 14px'>{name}</strong><br>
            <span style='color: {color}'>● Statut: {status.replace('_', ' ').title()}</span><br>
            <span>📋 Équipe: {team if team else '⚠️ NON ASSIGNÉE'}</span><br>
            <span>📝 Notes: {notes}</span>
        </div>
        """
        
        # Ajouter chaque segment de la rue
        for path in paths:
            if path and len(path) >= 2:
                folium.PolyLine(
                    path,
                    color=color,
                    weight=weight,
                    opacity=opacity,
                    dash_array=dash,
                    tooltip=folium.Tooltip(tooltip_html, sticky=True)
                ).add_to(m)
    
    # Ajouter un marqueur au centre-ville
    folium.Marker(
        [45.7475, -73.6005],
        popup="Centre-ville de Mascouche",
        tooltip="Centre-ville",
        icon=folium.Icon(color='red', icon='info-sign')
    ).add_to(m)
    
    # Ajouter la légende persistante
    add_persistent_legend(m)
    
    return m


# ============================================
# UTILITAIRES EXPORT
# ============================================

def export_excel_professionnel(conn):
    """Export Excel avec mise en forme professionnelle"""
    try:
        from reports import ReportGenerator
        generator = ReportGenerator(conn)
        return generator.generate_excel()
    except ImportError:
        # Fallback si les dépendances ne sont pas installées
        return db.export_to_csv()


# ============================================
# FONCTIONNALITÉS AVANCÉES
# ============================================

def detect_mobile():
    """Détecte si l'utilisateur est sur mobile"""
    try:
        # Récupérer les paramètres de l'URL pour forcer le mode mobile
        query_params = st.experimental_get_query_params()
        if 'mobile' in query_params:
            return True
        
        # Mobile-first approach pour l'instant
        return True
    except:
        return False

def show_notification(message, type="success"):
    """Affiche une notification stylisée"""
    icons = {
        "success": "✅",
        "error": "❌",
        "warning": "⚠️",
        "info": "ℹ️"
    }
    colors = {
        "success": "#22c55e",
        "error": "#ef4444", 
        "warning": "#f59e0b",
        "info": "#3b82f6"
    }
    
    st.markdown(f"""
    <div style="
        position: fixed;
        top: 20px;
        right: 20px;
        background: {colors[type]};
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 10px;
        box-shadow: 0 5px 15px rgba(0,0,0,0.3);
        z-index: 9999;
        animation: slideIn 0.3s ease-out;
    ">
        <strong>{icons[type]} {message}</strong>
    </div>
    <style>
    @keyframes slideIn {{
        from {{ transform: translateX(100%); opacity: 0; }}
        to {{ transform: translateX(0); opacity: 1; }}
    }}
    </style>
    """, unsafe_allow_html=True)

def show_team_badges(conn, team_id):
    """Affiche les badges de réussite de l'équipe"""
    try:
        df = db.list_streets(team=team_id)
        done = len(df[df['status'] == 'terminee'])
        total = len(df)
        
        badges = []
        if done >= 1:
            badges.append("🏆 Première rue!")
        if done >= total * 0.25:
            badges.append("🥉 25% complété")
        if done >= total * 0.5:
            badges.append("🥈 50% complété")
        if done >= total * 0.75:
            badges.append("🥇 75% complété")
        if done == total:
            badges.append("🌟 CHAMPION!")
        
        if badges:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #FFD700, #FFA500);
                padding: 1rem;
                border-radius: 10px;
                text-align: center;
                margin: 1rem 0;
            ">
                <strong>Vos badges:</strong><br>
                <div style="font-size: 2rem; margin-top: 0.5rem;">
                    {' '.join(badges)}
                </div>
            </div>
            """, unsafe_allow_html=True)
    except:
        pass

def generate_sms_list(conn):
    """Génère une liste de téléphones pour SMS de groupe"""
    try:
        # Cette fonction nécessiterait une table de téléphones
        # Pour l'instant, retourne un exemple
        return "# Liste des téléphones bénévoles\n# 450-XXX-XXXX\n# 438-XXX-XXXX"
    except:
        return "Liste non disponible"

def page_export_gestionnaire(conn):
    """Section export avec formats multiples"""
    
    st.markdown("### 📊 Centre d'export des données")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>� Rapport PDF</h4>
            <p><small>Format professionnel pour présentation</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            from reports import ReportGenerator
            generator = ReportGenerator(conn)
            pdf_data = generator.generate_pdf()
            st.download_button(
                "📥 Télécharger PDF",
                pdf_data,
                "rapport_guignolee_2025.pdf",
                "application/pdf",
                width="stretch"
            )
        except ImportError:
            st.button("PDF (Installer reportlab)", disabled=True, width="stretch")
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>📊 Excel détaillé</h4>
            <p><small>Avec graphiques et mise en forme</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            excel_data = export_excel_professionnel(conn)
            st.download_button(
                "📥 Télécharger Excel",
                excel_data,
                "guignolee_2025.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width="stretch"
            )
        except:
            st.button("Excel (Non disponible)", disabled=True, width="stretch")
    
    with col3:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>📱 Liste SMS</h4>
            <p><small>Téléphones des bénévoles</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        sms_list = generate_sms_list(conn)
        st.download_button(
            "📥 Liste téléphones",
            sms_list,
            "telephones_benevoles.txt",
            "text/plain",
            width="stretch"
        )


# ============================================
# PAGES
# ============================================

def page_accueil(conn, geo):
    """Page d'accueil"""
    st.markdown("### 🎁 Bienvenue sur Guigno-Map!")
    st.info("Sélectionnez votre mode dans le menu de gauche pour commencer.")
    
    st.markdown("---")
    st.markdown("#### 📊 Aperçu de la collecte")
    
    stats = db.extended_stats()
    render_metrics(stats)
    
    df_all = db.list_streets()
    if df_all:  # Liste non vide
        m = create_map(df_all, geo)
        st_folium(m, height=800, width=None, returned_objects=[])

def page_accueil_v2(conn, geo):
    """Page d'accueil festive avec compte à rebours"""
    
    # Compte à rebours jusqu'au 1er décembre
    from datetime import datetime, timedelta
    target = datetime(2025, 12, 1, 8, 0, 0)
    now = datetime.now()
    diff = target - now
    
    if diff.days > 0:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #c41e3a, #165b33);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h2 style="color: #FFD700; margin: 0;">⏰ Compte à rebours Guignolée</h2>
            <div style="font-size: 3rem; color: white; margin: 1rem 0;">
                {diff.days} jours {diff.seconds//3600} heures
            </div>
            <p style="color: rgba(255,255,255,0.9);">avant le grand jour!</p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #FFD700, #FFA500);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h2 style="color: #c41e3a; margin: 0;">🎉 C'EST AUJOURD'HUI!</h2>
            <div style="font-size: 2rem; color: #165b33; margin: 1rem 0;">
                Bonne Guignolée 2025!
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # Hero section festif
    st.markdown("""
    <div style="
        text-align: center;
        padding: 3rem 1rem;
        background: linear-gradient(135deg, rgba(196,30,58,0.1), rgba(22,91,51,0.1));
        border-radius: 20px;
        margin-bottom: 2rem;
    ">
        <h1 style="font-size: 3rem; margin: 0;">🎄 Bienvenue sur Guigno-Map 🎄</h1>
        <p style="font-size: 1.3rem; color: #666; margin: 1rem 0;">
            Votre plateforme digitale pour la Guignolée 2025
        </p>
        <p style="color: #888;">
            Gérez efficacement votre collecte de denrées avec une interface moderne
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Stats visuelles améliorées
    stats = db.extended_stats()
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    st.markdown("### 📊 État de la collecte en temps réel")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #22c55e, #16a34a);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(34,197,94,0.3);
        ">
            <div style="font-size: 3rem;">🏘️</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats['total']}</div>
            <div>Total Rues</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(59,130,246,0.3);
        ">
            <div style="font-size: 3rem;">✅</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats['done']}</div>
            <div>Complétées</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #f59e0b, #d97706);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(245,158,11,0.3);
        ">
            <div style="font-size: 3rem;">🚶</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats.get('partial', 0)}</div>
            <div>En Cours</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #c41e3a, #165b33);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(196,30,58,0.3);
        ">
            <div style="font-size: 3rem;">🎯</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{progress:.0f}%</div>
            <div>Progression</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Barre de progression globale
    st.markdown("### 🎄 Progression globale de la collecte")
    st.progress(progress / 100)
    
    # Carte festive
    st.markdown("### 🗺️ Vue d'ensemble de Mascouche")
    df_all = db.list_streets()
    if df_all:  # Liste non vide
        m = create_map(df_all, geo)
        st_folium(m, height=750, width=None, returned_objects=[])
    
    # CSS pour réduire l'espace après la carte
    st.markdown("""
    <style>
    div[data-testid="stVerticalBlock"] > div:has(iframe) {
        margin-bottom: 0 !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Call to action
    st.markdown("""
    <div style="
        text-align: center;
        padding: 2rem;
        background: linear-gradient(135deg, rgba(255,215,0,0.1), rgba(255,215,0,0.05));
        border: 2px solid rgba(255,215,0,0.3);
        border-radius: 15px;
        margin-top: 1rem;
    ">
        <h3>🎅 Prêt à participer ?</h3>
        <p>Choisissez votre rôle dans le menu de gauche pour commencer</p>
        <p style="font-size: 0.9rem; color: #666;">
            Bénévoles : Accédez à vos rues assignées<br>
            Gestionnaires : Supervisez toute la collecte
        </p>
    </div>
    """, unsafe_allow_html=True)

def page_benevole(conn, geo):
    """Interface bénévole moderne avec vue limitée"""
    
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        render_login_card("benevole", conn)
        return
    
    team_id = st.session_state.auth["team_id"]
    
    # Header d'équipe personnalisé
    st.markdown(f"""
    <div style="
        background: linear-gradient(135deg, #165b33, #c41e3a);
        padding: 1.5rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
    ">
        <h2 style="color: white; margin: 0;">🎅 Équipe {team_id}</h2>
        <p style="color: #FFD700; margin: 0.5rem 0 0 0;">Bonne collecte!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Stats de l'équipe
    df_team = db.list_streets(team=team_id)
    if not df_team:  # Liste vide
        st.warning("Aucune rue assignée. Contactez votre superviseur.")
        return
    
    done = len(df_team[df_team['status'] == 'terminee'])
    total = len(df_team)
    progress = (done / total * 100) if total > 0 else 0
    
    # Mini dashboard équipe
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("📍 Vos rues", total)
    with col2:
        st.metric("✅ Complétées", done)
    with col3:
        st.metric("🎯 Progression", f"{progress:.0f}%")
    
    # Système de badges
    show_team_badges(conn, team_id)
    
    # Barre de progression
    st.progress(progress / 100)
    
    # Tabs modernisés
    tab1, tab2, tab3 = st.tabs(["🗺️ Ma carte", "📝 Collecte", "📊 Historique"])
    
    with tab1:
        # CARTE LIMITÉE AUX RUES DE L'ÉQUIPE
        st.markdown("### Vos rues assignées")
        
        # Créer une carte avec SEULEMENT les rues de l'équipe
        m = folium.Map(
            location=[45.7475, -73.6005],
            zoom_start=14,
            tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager/{z}/{x}/{y}.png',
            attr='© CARTO'
        )
        
        # Filtrer geo pour n'afficher QUE les rues de l'équipe
        team_streets = df_team['name'].tolist()
        
        for street_name in team_streets:
            if street_name in geo:
                status = df_team[df_team['name'] == street_name]['status'].iloc[0]
                
                # Couleurs selon statut
                colors = {
                    'terminee': '#22c55e',
                    'en_cours': '#f59e0b',
                    'a_faire': '#ef4444'
                }
                color = colors.get(status, '#ef4444')
                
                # Ajouter les segments de cette rue
                for path in geo[street_name]:
                    if path and len(path) >= 2:
                        folium.PolyLine(
                            path,
                            color=color,
                            weight=8,  # Plus épais pour mobile
                            opacity=0.9,
                            tooltip=f"{street_name} - {status.replace('_', ' ').title()}"
                        ).add_to(m)
        
        # Centrer sur les rues de l'équipe
        if team_streets and team_streets[0] in geo:
            first_street = geo[team_streets[0]][0]
            if first_street:
                m.location = first_street[0]
        
        st_folium(m, height=650, width=None, returned_objects=[])
    
    with tab2:
        st.markdown("### 📋 Checklist de collecte")
        
        # Liste interactive des rues
        for row in df_team:
            street = row['name']
            status = row['status']
            notes_count = row.get('notes', 0)
            
            # Carte de rue stylisée
            status_emoji = {'terminee': '✅', 'en_cours': '🚶', 'a_faire': '⭕'}
            status_color = {'terminee': '#22c55e', 'en_cours': '#f59e0b', 'a_faire': '#ef4444'}
            
            with st.expander(f"{status_emoji.get(status, '⭕')} **{street}** ({notes_count} notes)"):
                
                # Changement rapide de statut
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("⭕ À faire", key=f"todo_{street}", width="stretch"):
                        db.set_status(street, 'a_faire')
                        st.rerun()
                with col2:
                    if st.button("🚶 En cours", key=f"progress_{street}", width="stretch"):
                        db.set_status(street, 'en_cours')
                        st.rerun()
                with col3:
                    if st.button("✅ Terminée", key=f"done_{street}", width="stretch"):
                        db.set_status(street, 'terminee')
                        st.rerun()
                
                st.markdown("---")
                
                # Ajout de note rapide
                st.markdown("**Ajouter une note:**")
                with st.form(f"note_{street}", clear_on_submit=True):
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        num = st.text_input("N°", placeholder="123")
                    with col2:
                        note = st.text_input("Note", placeholder="Personne absente")
                    
                    if st.form_submit_button("➕ Ajouter"):
                        if num and note:
                            db.add_note_for_address(street, team_id, num, note)
                            st.success("Note ajoutée!")
                            st.rerun()
                
                # Notes existantes
                notes = db.get_street_addresses_with_notes(street)
                if notes:  # Liste non vide
                    st.markdown("**Notes existantes:**")
                    for n in notes:
                        st.markdown(f"• **{n['address_number']}** : {n['comment']}")
    
    with tab3:
        st.markdown("### 📊 Votre historique")
        try:
            notes = db.get_team_notes(team_id)
            if notes:  # Liste non vide
                st.dataframe(to_dataframe(notes), width="stretch")
            else:
                st.info("Aucune note encore")
        except:
            st.info("Historique non disponible")

def page_benevole_v2(conn, geo):
    """Interface bénévole moderne v4.1 avec vue 'Mes rues'"""
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        # Afficher la page de connexion bénévole
        return page_benevole(conn, geo)
    
    # Interface bénévole connecté avec tabs
    st.header("🎅 Espace Bénévole")
    team_id = st.session_state.auth.get("team", "Équipe inconnue")
    st.markdown(f"**Équipe:** {team_id}")
    
    # Tabs pour bénévoles
    tabs = st.tabs([
        "🏘️ Mes rues",
        "🗺️ Carte de terrain", 
        "📝 Journal d'activité"
    ])
    
    with tabs[0]:
        # Nouvelle vue "Mes rues" v4.1
        page_benevole_mes_rues(conn)
    
    with tabs[1]:
        # Carte traditionnelle (réutilise l'ancienne interface)
        page_benevole(conn, geo)
    
    with tabs[2]:
        # Journal d'activité de l'équipe
        st.markdown("### 📝 Journal d'activité de votre équipe")
        try:
            # Afficher les activités récentes de l'équipe
            cursor = conn.execute("""
                SELECT action, details, created_at
                FROM activity_log
                WHERE team_id = ?
                ORDER BY created_at DESC
                LIMIT 20
            """, (team_id,))
            
            activities = cursor.fetchall()
            if activities:
                for activity in activities:
                    action, details, created_at = activity
                    st.markdown(f"**{created_at}** - {action}: {details}")
            else:
                st.info("Aucune activité enregistrée pour votre équipe")
                
        except Exception as e:
            st.info("Journal d'activité temporairement indisponible")
            st.caption(f"Erreur: {e}")

def page_gestionnaire_v2(conn, geo):
    """Interface gestionnaire moderne (ancien superviseur)"""
    st.header("👔 Tableau de Bord Gestionnaire")
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        render_login_card("gestionnaire", conn)
        return
    
    # Dashboard moderne
    render_dashboard_gestionnaire(conn, geo)
    
    # Tabs
    tabs = st.tabs([
        "📊 Vue d'ensemble",
        "👥 Équipes",
        "🗺️ Assignation",
        "📥 Export",
        "🛠 Tech"
    ])
    
    with tabs[0]:
        # Carte générale
        st.markdown("### Carte générale")
        df_all = db.list_streets()
        if df_all:  # Liste non vide
            m = create_map(df_all, geo)
            st_folium(m, height=800, width=None, returned_objects=[])
        
        # Activité récente
        st.markdown("### Activité récente")
        try:
            recent = db.recent_activity(limit=10)
            if recent:  # Liste non vide
                st.dataframe(to_dataframe(recent), width="stretch")
            else:
                st.info("Aucune activité récente")
        except:
            st.info("Historique d'activité non disponible")
    
    with tabs[1]:
        # Gestion des équipes
        st.subheader("👥 Gestion des équipes", anchor=False)
        
        # === Formulaire de création d'équipe (robuste) ===
        with st.expander("➕ Créer une nouvelle équipe", expanded=False):
            with st.form("create_team_form", clear_on_submit=True):
                team_id_in = st.text_input(
                    "Identifiant d'équipe", 
                    key="new_team_id", 
                    placeholder="Ex: EQUIPE1",
                    help="Lettres et chiffres uniquement, max 20 caractères"
                )
                team_name_in = st.text_input(
                    "Nom d'équipe", 
                    key="new_team_name", 
                    placeholder="Ex: Équipe Centre",
                    help="Nom descriptif de l'équipe"
                )
                
                # Toggle pour afficher/masquer les mots de passe
                show_pw = st.checkbox("Afficher les mots de passe", value=False)
                pw_type = "default" if show_pw else "password"
                
                pwd_in = st.text_input(
                    "Mot de passe", 
                    type=pw_type, 
                    key="new_team_pwd", 
                    placeholder="Minimum 4 caractères",
                    help="Tout caractère accepté, min 4 / max 128"
                )
                pwd_conf = st.text_input(
                    "Confirmer le mot de passe", 
                    type=pw_type, 
                    key="new_team_pwd_conf", 
                    placeholder="Retapez le mot de passe",
                    help="Doit correspondre au mot de passe ci-dessus"
                )
                
                submitted = st.form_submit_button("✅ Créer l'équipe", width="stretch")

            if submitted:
                # Validation avec validators.py
                ok_id, team_id = validate_and_clean_input("team_id", team_id_in)
                ok_name, team_name = validate_and_clean_input("text", team_name_in)
                ok_pw, password = validate_and_clean_input("password", pwd_in)
                
                if not ok_id:
                    st.error("❌ Identifiant d'équipe invalide (lettres/chiffres, max 20)")
                elif not ok_name:
                    st.error("❌ Nom d'équipe invalide ou vide")
                elif not ok_pw:
                    st.error("❌ Mot de passe invalide (minimum 4 caractères)")
                elif pwd_in != pwd_conf:
                    st.error("❌ Les mots de passe ne correspondent pas")
                else:
                    # Tentative de création avec db.create_team
                    try:
                        created = db.create_team(team_id, team_name, password)
                        if created:
                            st.toast(f"✅ Équipe {team_id} créée avec succès", icon="✅")
                            st.rerun()
                        else:
                            st.error("❌ Échec de création (ID déjà existant ?)")
                    except Exception as e:
                        st.error(f"❌ Erreur lors de la création: {e}")
        
        # === Liste des équipes (sans doublon de titre) ===
        try:
            teams_df = db.get_all_teams()
            if teams_df:  # Liste non vide
                st.dataframe(to_dataframe(teams_df), width="stretch")
            else:
                st.info("Aucune équipe créée")
        except Exception as e:
            st.info("Liste des équipes non disponible")
    
    with tabs[2]:
        # Assignation v4.1
        page_assignations_v41(conn)
    
    with tabs[3]:
        # Export amélioré v4.1
        page_export_gestionnaire_v41(conn)

    with tabs[4]:
        st.markdown("### 🛠 Opérations techniques (protégées)")

        # -- PIN stocké dans secrets (config.toml -> [secrets] TECH_PIN="xxxx")
        try:
            TECH_PIN = st.secrets.get("TECH_PIN", "")
        except:
            TECH_PIN = ""  # Pas de fichier secrets.toml

        if "tech_ok" not in st.session_state:
            st.session_state.tech_ok = False

        if not st.session_state.tech_ok:
            pin = st.text_input("Entrer le PIN technique", type="password")
            if st.button("Déverrouiller"):
                if TECH_PIN and pin == TECH_PIN:
                    st.session_state.tech_ok = True
                    st.success("Accès technique déverrouillé.")
                    st.rerun()
                else:
                    st.error("PIN invalide.")
            st.stop()

        st.info("⚠️ Ces actions sont lourdes et n'affectent pas les statuts/notes. Elles régénèrent les caches OSM.")

        # --- Reconstruire le cache géométrique (lourd)
        with st.expander("🔄 Reconstruire cache OSM (géométries)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirm = st.checkbox("Je comprends les implications")
            with col2:
                safety = st.text_input('Écrire "REBUILD" pour confirmer')

            if st.button("Lancer la reconstruction"):
                if confirm and safety.strip().upper() == "REBUILD":
                    with st.spinner("Construction du cache…"):
                        build_geometry_cache()       # reconstruit le fichier osm_cache.json
                        st.cache_data.clear()        # purge cache Streamlit
                    st.success("✅ Cache OSM mis à jour (géométries).")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Reconstruire/Importer le cache des adresses
        with st.expander("📍 Mettre à jour les adresses (OSM)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirmA = st.checkbox("Je confirme")
            with col2:
                safetyA = st.text_input('Écrire "IMPORT" pour confirmer')

            if st.button("Lancer la mise à jour des adresses"):
                if confirmA and safetyA.strip().upper() == "IMPORT":
                    with st.spinner("Téléchargement des adresses OSM…"):
                        build_addresses_cache()
                        addr_cache = load_addresses_cache()
                        count = db.import_addresses_from_cache(addr_cache)
                    st.success(f"✅ {count} adresses importées depuis OSM.")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Gestion des backups
        with st.expander("💾 Gestion des backups", expanded=False):
            backup_mgr = db.get_backup_manager(DB_PATH)
            
            col1, col2 = st.columns([2, 1])
            with col1:
                if st.button("🔄 Créer un backup manuel", width="stretch"):
                    backup_file = backup_mgr.create_backup("manual")
                    if backup_file:
                        st.success(f"Backup créé : {Path(backup_file).name}")
            
            with col2:
                if st.button("📋 Voir les backups", width="stretch"):
                    backups = backup_mgr.list_backups()
                    if backups:
                        for backup in backups[:5]:  # Montrer les 5 derniers
                            st.text(f"• {backup['name']} ({backup['size']})")
                    else:
                        st.info("Aucun backup disponible")

def page_superviseur(conn, geo):
    """Interface superviseur"""
    st.header("🎯 Tableau de Bord Superviseur")
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        render_login_card("superviseur", conn)
        return
    
    # Dashboard moderne
    render_dashboard_gestionnaire(conn, geo)
    
    # Tabs
    tabs = st.tabs([
        "📊 Vue d'ensemble",
        "👥 Équipes",
        "🗺️ Assignation",
        "📥 Export",
        "🛠 Tech"
    ])
    
    with tabs[0]:
        # Carte générale
        st.markdown("### Carte générale")
        df_all = db.list_streets()
        if df_all:  # Liste non vide
            m = create_map(df_all, geo)
            st_folium(m, height=800, width=None, returned_objects=[])
        
        # Activité récente
        st.markdown("### Activité récente")
        recent = db.recent_activity(limit=10)
        if recent:  # Liste non vide
            st.dataframe(to_dataframe(recent), width="stretch")
    
    with tabs[1]:
        # Gestion des équipes
        st.markdown("### Gestion des équipes")
        
        with st.expander("Créer une équipe"):
            with st.form("new_team", clear_on_submit=True):
                new_id = st.text_input("Identifiant")
                new_name = st.text_input("Équipe")
                new_pass = st.text_input("Mot de passe", type="password")
                
                if st.form_submit_button("Créer"):
                    if all([new_id, new_name, new_pass]):
                        if db.create_team(new_id, new_name, new_pass):
                            st.success(f"Équipe {new_id} créée")
                            st.rerun()
        
        # Liste des équipes
        teams_df = db.get_all_teams()
        if teams_df:  # Liste non vide
            st.dataframe(to_dataframe(teams_df), width="stretch")
    
    with tabs[2]:
        # Assignation
        st.markdown("### Assignation des rues")
        
        unassigned = db.get_unassigned_streets()
        
        if unassigned:  # Liste non vide
            with st.form("assign"):
                team = st.selectbox("Équipe", db.teams())
                streets = st.multiselect("Rues", unassigned)
                
                if st.form_submit_button("Assigner"):
                    if team and streets:
                        db.assign_streets_to_team(streets, team)
                        st.success("Rues assignées!")
                        st.rerun()
        else:
            st.success("Toutes les rues sont assignées!")
        
        # Tableau des assignations
        df_all = db.list_streets()
        if df_all:  # Liste non vide
            st.dataframe(
                df_all[['name', 'sector', 'team', 'status']],
                width="stretch"
            )
    
    with tabs[3]:
        # Export
        st.markdown("### Export des données")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                "📥 Export rues (CSV)",
                db.export_to_csv(),
                "rapport_rues.csv",
                "text/csv",
                width="stretch"
            )
        
        with col2:
            st.download_button(
                "📥 Export notes (CSV)",
                db.export_notes_csv(),
                "rapport_notes.csv",
                "text/csv",
                width="stretch"
            )

    with tabs[4]:
        st.markdown("### 🛠 Opérations techniques (protégées)")

        # -- PIN stocké dans secrets (config.toml -> [secrets] TECH_PIN="xxxx")  
        try:
            TECH_PIN = st.secrets.get("TECH_PIN", "")
        except:
            TECH_PIN = ""  # Pas de fichier secrets.toml

        if "tech_ok" not in st.session_state:
            st.session_state.tech_ok = False

        if not st.session_state.tech_ok:
            pin = st.text_input("Entrer le PIN technique", type="password")
            if st.button("Déverrouiller"):
                if TECH_PIN and pin == TECH_PIN:
                    st.session_state.tech_ok = True
                    st.success("Accès technique déverrouillé.")
                    st.rerun()
                else:
                    st.error("PIN invalide.")
            st.stop()

        st.info("⚠️ Ces actions sont lourdes et n'affectent pas les statuts/notes. Elles régénèrent les caches OSM.")

        # --- Reconstruire le cache géométrique (lourd)
        with st.expander("🔄 Reconstruire cache OSM (géométries)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirm = st.checkbox("Je comprends les implications")
            with col2:
                safety = st.text_input('Écrire "REBUILD" pour confirmer')

            if st.button("Lancer la reconstruction"):
                if confirm and safety.strip().upper() == "REBUILD":
                    with st.spinner("Construction du cache…"):
                        build_geometry_cache()       # reconstruit le fichier osm_cache.json
                        st.cache_data.clear()        # purge cache Streamlit
                    st.success("✅ Cache OSM mis à jour (géométries).")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Reconstruire/Importer le cache des adresses
        with st.expander("📍 Mettre à jour les adresses (OSM)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirmA = st.checkbox("Je confirme")
            with col2:
                safetyA = st.text_input('Écrire "IMPORT" pour confirmer')

            if st.button("Lancer la mise à jour des adresses"):
                if confirmA and safetyA.strip().upper() == "IMPORT":
                    with st.spinner("Téléchargement des adresses OSM…"):
                        build_addresses_cache()
                        addr_cache = load_addresses_cache()
                        count = db.import_addresses_from_cache(addr_cache)
                    st.success(f"✅ {count} adresses importées depuis OSM.")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

# ============================================
# MAIN
# ============================================

# ================================================================================
# NOUVELLES FONCTIONS v4.1 - SUPERVISEUR ET BÉNÉVOLE
# ================================================================================

def page_assignations_v41(conn):
    """Panneau d'assignations v4.1 pour superviseurs"""
    
    try:
        # ===== Bloc Assignations (refactor propre) =====
        st.subheader("🗺️ Assignations par secteur", anchor=False)
        
        # Compteur de rues non assignées (bannière info)
        unassigned_count = db.get_unassigned_streets_count()
        if unassigned_count > 0:
            st.info(f"⚠️ {unassigned_count} rue(s) non assignée(s)")
        
        with st.container():
            c1, c2, c3 = st.columns([1, 1.2, 0.7], vertical_alignment="bottom")
            
            with c1:
                # Récupérer la liste des secteurs
                liste_secteurs = db.get_sectors_list()
                secteur = st.selectbox(
                    "SECTEUR À ASSIGNER",
                    options=[""] + (liste_secteurs if liste_secteurs else []),
                    index=0,
                    key="assign_sector",
                    help="Choisissez le secteur à assigner",
                    label_visibility="visible",
                )
            
            with c2:
                # Récupérer la liste des équipes
                teams = db.get_teams_list()
                liste_equipes = [f"{team[1]} ({team[0]})" for team in teams] if teams else []
                
                if liste_equipes:
                    team_display = st.selectbox(
                        "ÉQUIPE", 
                        options=[""] + liste_equipes, 
                        index=0, 
                        key="assign_team"
                    )
                    # Extraire l'ID de l'équipe
                    team = ""
                    if team_display and team_display != "":
                        team = team_display.split("(")[-1].rstrip(")")
                else:
                    st.info("Aucune équipe disponible")
                    team = None
            
            with c3:
                disabled = not (secteur and team)
                if st.button("🎯 Assigner tout le secteur", width="stretch", disabled=disabled):
                    # Appel métier : assigner toutes les rues non assignées du secteur à l'équipe
                    if secteur and team:
                        try:
                            nb = db.bulk_assign_sector(secteur, team)
                            if nb > 0:
                                st.toast(f"✅ {nb} rue(s) assignée(s) à l'équipe {team}", icon="✅")
                                st.rerun()
                            else:
                                st.toast("ℹ️ Aucune rue non assignée dans ce secteur", icon="ℹ️")
                        except Exception as e:
                            st.error(f"Erreur lors de l'assignation: {e}")
        
        # ===== Tableau d'état (uniforme, sans style spécial) =====
        st.markdown("### 📋 État des assignations")
        
        df = db.list_streets()
        if df:  # Liste non vide
            df_disp = df.assign(
                Statut=df["status"].map(STATUS_TO_LABEL).fillna("À faire")
            ).rename(columns={
                "name": "Rue", 
                "sector": "Secteur", 
                "team": "Équipe"
            })[["Rue", "Secteur", "Équipe", "Statut"]]
            
            st.dataframe(df_disp, width="stretch")  # aucun Styler, aucun CSS cellule
        else:
            st.info("Aucune rue trouvée")
            
    except Exception as e:
        st.error(f"Erreur dans le panneau d'assignations: {e}")
        st.info("Fonctionnalité temporairement indisponible")

def page_export_gestionnaire_v41(conn):
    """Page d'export v4.1 avec nouvelles fonctionnalités"""
    st.markdown("### 📥 Export des données")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Export CSV standard
        try:
            st.download_button(
                "📥 Export CSV Standard",
                db.export_to_csv(),
                "rapport_rues.csv",
                "text/csv",
                width="stretch"
            )
        except Exception as e:
            st.button("📥 CSV (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    with col2:
        # Export Excel professionnel
        try:
            from reports import ReportGenerator
            generator = ReportGenerator(conn)
            excel_data = generator.generate_excel()
            st.download_button(
                "📊 Export Excel Pro",
                excel_data,
                "guignolee_2025_rapport.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width="stretch"
            )
        except ImportError:
            st.button("📊 Excel (Installer xlsxwriter)", disabled=True, width="stretch")
        except Exception as e:
            st.button("📊 Excel (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    with col3:
        # Export PDF professionnel
        try:
            from reports import ReportGenerator
            generator = ReportGenerator(conn)
            pdf_data = generator.generate_pdf()
            st.download_button(
                "📄 Export PDF Pro",
                pdf_data,
                "guignolee_2025_rapport.pdf",
                "application/pdf",
                width="stretch"
            )
        except ImportError:
            st.button("📄 PDF (Installer reportlab)", disabled=True, width="stretch")
        except Exception as e:
            st.button("📄 PDF (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    # Export CSV assignations (nouveau v4.1)
    st.markdown("---")
    st.markdown("### 📋 Export spécialisés v4.1")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Export CSV assignations
        try:
            assignations_data = db.get_assignations_export_data()
            if assignations_data:  # Liste non vide
                csv_data = pd.DataFrame(assignations_data).to_csv(index=False, encoding='utf-8')
                st.download_button(
                    "📋 Export CSV Assignations",
                    csv_data,
                    "assignations_secteurs.csv",
                    "text/csv",
                    width="stretch",
                    help="Colonnes: secteur, rue, équipe, statut"
                )
            else:
                st.button("📋 Assignations (Aucune donnée)", disabled=True, width="stretch")
        except Exception as e:
            st.button("📋 Assignations (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    with col2:
        # Export notes
        try:
            st.download_button(
                "📝 Export Notes",
                db.export_notes_csv(),
                "rapport_notes.csv",
                "text/csv",
                width="stretch"
            )
        except Exception as e:
            st.button("📝 Notes (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")

def page_benevole_mes_rues(conn):
    """Vue 'Mes rues' pour bénévoles v4.1"""
    
    # Récupérer l'équipe du bénévole connecté
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        st.warning("Accès réservé aux bénévoles connectés")
        return
    
    team_id = st.session_state.auth.get("team")
    if not team_id:
        st.error("Équipe non identifiée")
        return
    
    st.markdown(f"### 🏘️ Mes rues assignées - Équipe {team_id}")
    
    try:
        # Récupérer les rues de l'équipe
        team_streets = db.get_team_streets(team_id)
        
        if not team_streets:  # Liste vide
            st.info("Aucune rue assignée à votre équipe pour le moment.")
            return
        
        # Afficher les statistiques de l'équipe
        total_streets = len(team_streets)
        done_streets = len([s for s in team_streets if hasattr(s, 'status') and s.status == 'terminee'])
        in_progress = len([s for s in team_streets if hasattr(s, 'status') and s.status == 'en_cours'])
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total rues", total_streets)
        with col2:
            st.metric("Terminées", done_streets)
        with col3:
            st.metric("En cours", in_progress)
        with col4:
            progress = (done_streets / total_streets * 100) if total_streets > 0 else 0
            st.metric("Progression", f"{progress:.1f}%")
        
        st.markdown("---")
        
        # Affichage par rue avec actions
        for street in team_streets:
            if isinstance(street, str):
                street_name = street
            else:
                street_name = street.get("name", street)
            street_name = street['street_name']
            current_status = street['status']
            notes_count = street['notes_count']
            
            with st.expander(f"🏘️ {street_name} ({street['sector']}) - {current_status.replace('_', ' ').title()}", 
                           expanded=current_status == 'en_cours'):
                
                col1, col2, col3 = st.columns([2, 1, 1])
                
                with col1:
                    st.markdown(f"**Secteur:** {street['sector']}")
                    st.markdown(f"**Statut actuel:** {current_status.replace('_', ' ').title()}")
                    if notes_count > 0:
                        st.markdown(f"**Notes existantes:** {notes_count}")
                
                with col2:
                    # Bouton "En cours"
                    if st.button(
                        "🚀 En cours", 
                        key=f"progress_{street_name}",
                        disabled=current_status == 'en_cours',
                        width="stretch"
                    ):
                        if db.update_street_status(street_name, 'en_cours', team_id):
                            st.toast(f"✅ {street_name} marquée en cours", icon="🚀")
                            st.rerun()
                        else:
                            st.error("Erreur lors de la mise à jour")
                
                with col3:
                    # Bouton "Terminée"
                    if st.button(
                        "✅ Terminée", 
                        key=f"done_{street_name}",
                        disabled=current_status == 'terminee',
                        width="stretch"
                    ):
                        if db.update_street_status(street_name, 'terminee', team_id):
                            st.toast(f"🎉 {street_name} terminée!", icon="🎉")
                            st.rerun()
                        else:
                            st.error("Erreur lors de la mise à jour")
                
                # Section notes
                st.markdown("**Gestion des notes:**")
                
                # Afficher les notes existantes
                existing_notes = db.get_street_notes_for_team(street_name, team_id)
                if existing_notes:
                    st.markdown("*Notes existantes:*")
                    for note in existing_notes:
                        st.markdown(f"• **#{list(note.values())[0] if isinstance(note, dict) else note[0]}** : {list(note.values())[1] if isinstance(note, dict) else note[1]} _{list(note.values())[2] if isinstance(note, dict) else note[2]}_")
                
                # Ajouter une nouvelle note
                with st.form(f"note_form_{street_name}"):
                    col_addr, col_note = st.columns([1, 3])
                    with col_addr:
                        address_number = st.text_input(
                            "N° civique", 
                            key=f"addr_{street_name}",
                            placeholder="123A"
                        )
                    with col_note:
                        comment = st.text_area(
                            "Commentaire", 
                            key=f"comment_{street_name}",
                            placeholder="Ex: Absent, refus, don reçu...",
                            max_chars=500,
                            height=80
                        )
                    
                    if st.form_submit_button("💾 Enregistrer note"):
                        if address_number and comment:
                            if db.add_street_note(street_name, team_id, address_number, comment):
                                st.toast(f"📝 Note ajoutée pour {street_name} #{address_number}", icon="📝")
                                st.rerun()
                            else:
                                st.error("Erreur lors de l'enregistrement de la note")
                        else:
                            st.warning("Veuillez remplir le numéro et le commentaire")
                            
    except Exception as e:
        st.error(f"Erreur lors du chargement de vos rues: {e}")
        st.info("Fonctionnalité temporairement indisponible")

def main():
    """Point d'entrée principal - Version 2.0 Guignolée"""
    
    # CSS moderne
    inject_css()
    
    # Connexion DB
    # Initialisation de la base de données
    db.init_db()
    
    # Compatibilité legacy pour les backups
    if 'conn' not in st.session_state:
        import sqlite3
        conn = sqlite3.connect(DB_PATH, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        st.session_state['conn'] = conn
    st.session_state['conn'] = conn
    
    # Cache géométrique
    @st.cache_data(ttl=None)
    def get_geo(_sig):
        data = load_geometry_cache()
        return data if data else {}
    
    sig = int(CACHE_FILE.stat().st_mtime_ns) if CACHE_FILE.exists() else 0
    geo = get_geo(sig)
    
    # Header festif
    render_header()
    
    # Navigation modernisée dans la sidebar
    with st.sidebar:
        # CSS pour la sidebar sans position absolue
        st.markdown("""
        <style>
        .css-1d391kg { padding-top: 1rem !important; }
        .stSidebar > div:first-child { padding-top: 1rem !important; }
        </style>
        """, unsafe_allow_html=True)
        
        # Logo en haut de la sidebar (position normale)
        logo_path = ASSETS / "logo.png"
        if logo_path.exists():
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.image(str(logo_path), width=150)
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
        else:
            # Placeholder centré
            st.markdown("""
            <div style="
                background: linear-gradient(135deg, #c41e3a, #165b33);
                border-radius: 15px;
                padding: 2rem;
                color: white;
                text-align: center;
                margin: 1rem 0;
                box-shadow: 0 4px 15px rgba(0,0,0,0.3);
            ">
                <div style="font-size: 2.5rem;">🎁</div>
                <div style="font-weight: bold; font-size: 1.2rem;">LOGO</div>
                <small>Espace réservé</small>
            </div>
            """, unsafe_allow_html=True)
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
        
        # Navigation
        st.markdown("### 🎄 Navigation")
        
        # Boutons de navigation stylisés
        if st.button("🏠 Accueil", width="stretch"):
            st.session_state.page = "accueil"
            st.rerun()
        
        if st.button("🎅 Bénévole", width="stretch"):
            st.session_state.page = "benevole"
            st.rerun()
            
        if st.button("👔 Gestionnaire", width="stretch"):
            st.session_state.page = "gestionnaire"  
            st.rerun()
        
        # Déconnexion si connecté
        if st.session_state.auth:
            st.markdown("---")
            if st.button("🚪 Déconnexion", width="stretch"):
                st.session_state.auth = None
                st.rerun()
        
        # Compteur temps réel
        st.markdown("---")
        stats = db.extended_stats()
        st.markdown(f"""
        <div style="text-align: center;">
            <h4>État de la collecte</h4>
            <div style="font-size: 2rem; color: #FFD700;">
                {stats['done']}/{stats['total']}
            </div>
            <small>Rues complétées</small>
        </div>
        """, unsafe_allow_html=True)
    
    # Routing pages
    page = st.session_state.get('page', 'accueil')
    
    if page == "accueil":
        page_accueil_v2(conn, geo)
    elif page == "benevole":
        page_benevole_v2(conn, geo)
    elif page == "gestionnaire":
        page_gestionnaire_v2(conn, geo)
    
    # Footer festif
    st.markdown("""
    <div style="
        text-align: center;
        padding: 2rem;
        margin-top: 3rem;
        border-top: 2px solid rgba(255,215,0,0.3);
        color: #8b92a4;
    ">
        <p>
            🎄 Guignolée 2025 - Le Relais de Mascouche 🎄<br>
            <small>Ensemble, redonnons espoir | 📞 450-474-4133</small>
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Bannière en bas de page
    if (ASSETS / "banner.png").exists():
        st.image(str(ASSETS / "banner.png"), width="stretch")

if __name__ == "__main__":
    main()

```
---8<--- guignomap/app.py END ---

---8<--- guignomap/backup.py BEGIN ---
```py
"""
Système de backup automatique pour GuignoMap
Sauvegarde la base de données et les caches
"""

import shutil
import sqlite3
from pathlib import Path
from datetime import datetime
import json
import zipfile

class BackupManager:
    def __init__(self, db_path):
        self.db_path = Path(db_path)
        self.backup_dir = self.db_path.parent / "backups"
        self.backup_dir.mkdir(exist_ok=True)
        self.max_backups = 7  # Garder 7 jours de backups
        
    def create_backup(self, reason="manual"):
        """Crée un backup complet avec timestamp"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_{timestamp}_{reason}"
        backup_path = self.backup_dir / backup_name
        backup_path.mkdir(exist_ok=True)
        
        try:
            # Backup de la base de données
            db_backup = backup_path / "guigno_map.db"
            shutil.copy2(self.db_path, db_backup)
            
            # Backup des caches OSM
            for cache_file in ["osm_cache.json", "osm_addresses.json"]:
                cache_path = self.db_path.parent / cache_file
                if cache_path.exists():
                    shutil.copy2(cache_path, backup_path / cache_file)
            
            # Créer un ZIP
            zip_path = self.backup_dir / f"{backup_name}.zip"
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file in backup_path.iterdir():
                    zipf.write(file, file.name)
            
            # Nettoyer le dossier temporaire
            shutil.rmtree(backup_path)
            
            # Nettoyer les vieux backups
            self._cleanup_old_backups()
            
            # Log le backup
            self._log_backup(timestamp, reason)
            
            print(f"✅ Backup créé : {zip_path.name}")
            return str(zip_path)
            
        except Exception as e:
            print(f"❌ Erreur backup : {e}")
            if backup_path.exists():
                shutil.rmtree(backup_path)
            return None
    
    def restore_backup(self, backup_file):
        """Restaure un backup spécifique"""
        backup_path = self.backup_dir / backup_file
        if not backup_path.exists():
            print(f"❌ Backup introuvable : {backup_file}")
            return False
            
        try:
            # Créer un backup de sécurité avant restauration
            self.create_backup("pre_restore")
            
            # Extraire le ZIP
            temp_dir = self.backup_dir / "temp_restore"
            with zipfile.ZipFile(backup_path, 'r') as zipf:
                zipf.extractall(temp_dir)
            
            # Restaurer les fichiers
            for file in temp_dir.iterdir():
                target = self.db_path.parent / file.name
                shutil.copy2(file, target)
            
            # Nettoyer
            shutil.rmtree(temp_dir)
            
            print(f"✅ Backup restauré : {backup_file}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur restauration : {e}")
            return False
    
    def list_backups(self):
        """Liste tous les backups disponibles"""
        backups = []
        for file in self.backup_dir.glob("backup_*.zip"):
            stat = file.stat()
            backups.append({
                "name": file.name,
                "size": f"{stat.st_size / 1024 / 1024:.2f} MB",
                "date": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S")
            })
        return sorted(backups, key=lambda x: x["date"], reverse=True)
    
    def _cleanup_old_backups(self):
        """Supprime les backups de plus de 7 jours"""
        backups = sorted(self.backup_dir.glob("backup_*.zip"), key=lambda x: x.stat().st_mtime)
        while len(backups) > self.max_backups:
            oldest = backups.pop(0)
            oldest.unlink()
            print(f"🗑️ Ancien backup supprimé : {oldest.name}")
    
    def _log_backup(self, timestamp, reason):
        """Log les backups dans un fichier"""
        log_file = self.backup_dir / "backup_log.json"
        log = []
        if log_file.exists():
            with open(log_file, 'r') as f:
                log = json.load(f)
        
        log.append({
            "timestamp": timestamp,
            "reason": reason,
            "date": datetime.now().isoformat()
        })
        
        # Garder seulement les 100 derniers logs
        log = log[-100:]
        
        with open(log_file, 'w') as f:
            json.dump(log, f, indent=2)

def auto_backup_before_critical(func):
    """Décorateur pour backup automatique avant opérations critiques"""
    def wrapper(*args, **kwargs):
        # Trouver la connexion DB dans les arguments
        conn = None
        for arg in args:
            if hasattr(arg, 'execute'):  # C'est une connexion SQLite
                conn = arg
                break
        
        if conn:
            try:
                # Créer un backup avant l'opération
                db_path = Path(__file__).parent / "guigno_map.db"
                backup_mgr = BackupManager(db_path)
                backup_mgr.create_backup(f"auto_{func.__name__}")
            except:
                pass  # Ne pas bloquer l'opération si le backup échoue
        
        return func(*args, **kwargs)
    return wrapper
```
---8<--- guignomap/backup.py END ---

---8<--- guignomap/backups/backup_log.json BEGIN ---
```json
[
  {
    "timestamp": "20250914_194955",
    "reason": "auto_bulk_assign_sector",
    "date": "2025-09-14T19:49:55.266670"
  }
]
```
---8<--- guignomap/backups/backup_log.json END ---

---8<--- guignomap/db.py BEGIN ---
```py
import sqlite3
import pandas as pd
import hashlib
import bcrypt
from backup import auto_backup_before_critical, BackupManager
from validators import validate_and_clean_input, InputValidator
from datetime import datetime
import json
from pathlib import Path
import os
import secrets
import string

# Schéma amélioré de la base de données
SCHEMA = """
-- Table des rues
CREATE TABLE IF NOT EXISTS streets (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    sector TEXT,
    team TEXT,
    status TEXT NOT NULL DEFAULT 'a_faire' 
        CHECK (status IN ('a_faire', 'en_cours', 'terminee'))
);

-- Table des équipes
CREATE TABLE IF NOT EXISTS teams (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    password_hash TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    active BOOLEAN DEFAULT 1
);

-- Table des notes/commentaires PAR ADRESSE
CREATE TABLE IF NOT EXISTS notes (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    street_name TEXT NOT NULL,
    team_id TEXT NOT NULL,
    address_number TEXT,
    comment TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (street_name) REFERENCES streets(name),
    FOREIGN KEY (team_id) REFERENCES teams(id)
);

-- Table d'activité (log)
CREATE TABLE IF NOT EXISTS activity_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    team_id TEXT,
    action TEXT NOT NULL,
    details TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Table des adresses OSM
CREATE TABLE IF NOT EXISTS addresses (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    street_name TEXT NOT NULL,
    house_number TEXT NOT NULL,
    latitude REAL,
    longitude REAL,
    osm_type TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (street_name) REFERENCES streets(name)
);

-- Index pour améliorer les performances
CREATE INDEX IF NOT EXISTS idx_streets_team ON streets(team);
CREATE INDEX IF NOT EXISTS idx_streets_status ON streets(status);
CREATE INDEX IF NOT EXISTS idx_notes_street ON notes(street_name);
CREATE INDEX IF NOT EXISTS idx_activity_created ON activity_log(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_addresses_street ON addresses(street_name);
CREATE INDEX IF NOT EXISTS idx_addresses_number ON addresses(house_number);
"""

def get_conn(db_path):
    """Crée une connexion à la base de données"""
    conn = sqlite3.connect(db_path, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    return conn

def init_db(conn):
    """Initialise la base de données avec le schéma et les données initiales"""
    try:
        # Créer les tables si elles n'existent pas
        conn.executescript(SCHEMA)
        conn.commit()
        
        # Créer un compte admin par défaut s'il n'existe pas
        cursor = conn.execute("SELECT COUNT(*) FROM teams WHERE id = 'ADMIN'")
        if cursor.fetchone()[0] == 0:
            pwd = os.getenv("GM_ADMIN_PWD", "RELAIS2025")  # Par défaut RELAIS2025
            create_team(conn, 'ADMIN', 'Superviseur', pwd)
        
        # AUTO-IMPORT : Si aucune rue n'existe, importer automatiquement depuis OSM
        cursor = conn.execute("SELECT COUNT(*) FROM streets")
        if cursor.fetchone()[0] == 0:
            print("🔄 Aucune rue trouvée. Import automatique depuis OpenStreetMap...")
            auto_import_streets(conn)
            
    except Exception as e:
        print(f"Erreur lors de l'initialisation de la DB: {e}")
        raise

@auto_backup_before_critical
def auto_import_streets(conn):
    """Import automatique des rues de Mascouche"""
    try:
        # Essayer d'abord avec OSM
        from osm import generate_streets_csv
        csv_data = generate_streets_csv("Mascouche")
        
        if csv_data:
            import io
            df = pd.read_csv(io.StringIO(csv_data.decode('utf-8')))
            
            if not df.empty:
                for _, row in df.iterrows():
                    conn.execute(
                        "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, ?, ?, 'a_faire')",
                        (row.get("name", ""), row.get("sector", ""), row.get("team", ""))
                    )
                conn.commit()
                print(f"✅ {len(df)} rues importées automatiquement")
                log_activity(conn, None, "AUTO_IMPORT", f"Import automatique de {len(df)} rues")
                return
    except Exception as e:
        print(f"⚠️ Erreur lors de l'import OSM: {e}")
    
    # Fallback : Données de test si OSM échoue
    print("📦 Import de données de test...")
    test_streets = [
        ("Montée Masson", "Centre", ""),
        ("Chemin Sainte-Marie", "Centre", ""),
        ("Boulevard de Mascouche", "Centre", ""),
        ("Rue Dupras", "Centre", ""),
        ("Rue Saint-Pierre", "Centre", ""),
        ("Rue de l'Église", "Centre", ""),
        ("Avenue des Érables", "Nord", ""),
        ("Rue des Pins", "Nord", ""),
        ("Rue Gravel", "Sud", ""),
        ("Rue Forget", "Sud", ""),
    ]
    
    for name, sector, team in test_streets:
        conn.execute(
            "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, ?, ?, 'a_faire')",
            (name, sector, team)
        )
    conn.commit()
    print(f"✅ {len(test_streets)} rues de test importées")

# ---------- Fonctions pour les équipes ----------
def hash_password(password):
    """Hash un mot de passe avec bcrypt et salt automatique"""
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
    return hashed.decode('utf-8')

def create_team(conn, team_id, name, password):
    """Crée une nouvelle équipe avec validation"""
    try:
        # Valider les entrées
        valid_id, clean_id = validate_and_clean_input("team_id", team_id)
        valid_name, clean_name = validate_and_clean_input("text", name)
        valid_pwd, _ = validate_and_clean_input("password", password)
        
        if not valid_id or not valid_name or not valid_pwd:
            return False
        
        conn.execute(
            "INSERT INTO teams (id, name, password_hash) VALUES (?, ?, ?)",
            (clean_id, clean_name, hash_password(password))
        )
        conn.commit()
        log_activity(conn, clean_id, "TEAM_CREATED", f"Équipe {clean_name} créée")
        return True
    except sqlite3.IntegrityError:
        return False

def verify_team(conn, team_id, password):
    """Vérifie les identifiants d'une équipe avec bcrypt"""
    cursor = conn.execute(
        "SELECT password_hash FROM teams WHERE id = ? AND active = 1",
        (team_id,)
    )
    row = cursor.fetchone()
    if row:
        try:
            # Support ancien SHA256 pour migration
            stored_hash = row[0]
            if stored_hash.startswith('$2b$') or stored_hash.startswith('$2a$'):
                # Hash bcrypt
                return bcrypt.checkpw(password.encode('utf-8'), stored_hash.encode('utf-8'))
            else:
                # Ancien SHA256, vérifier et migrer
                if stored_hash == hashlib.sha256(password.encode()).hexdigest():
                    # Migrer vers bcrypt
                    new_hash = hash_password(password)
                    conn.execute("UPDATE teams SET password_hash = ? WHERE id = ?", (new_hash, team_id))
                    conn.commit()
                    return True
                return False
        except Exception as e:
            print(f"Erreur vérification mot de passe: {e}")
            return False
    return False

def migrate_all_passwords_to_bcrypt(conn):
    """Migration manuelle des mots de passe SHA256 vers bcrypt"""
    print("⚠️ Migration des mots de passe requise")
    print("Entrez les mots de passe actuels pour migration:")
    
    cursor = conn.execute("SELECT id, name FROM teams WHERE active = 1")
    teams = cursor.fetchall()
    
    for team_id, team_name in teams:
        if team_id == 'ADMIN':
            pwd = input(f"Mot de passe actuel pour {team_name} (ADMIN): ")
            if pwd:
                new_hash = hash_password(pwd)
                conn.execute("UPDATE teams SET password_hash = ? WHERE id = ?", (new_hash, team_id))
        
    conn.commit()
    print("✅ Migration terminée")

def get_all_teams(conn):
    """Récupère toutes les équipes avec leurs statistiques"""
    query = """
    SELECT 
        t.id,
        t.name,
        t.created_at,
        COUNT(DISTINCT s.name) as streets_count,
        SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done_count,
        CASE 
            WHEN COUNT(s.name) > 0 
            THEN (SUM(CASE WHEN s.status = 'terminee' THEN 1.0 ELSE 0 END) / COUNT(s.name)) * 100
            ELSE 0 
        END as progress
    FROM teams t
    LEFT JOIN streets s ON t.id = s.team
    WHERE t.active = 1 AND t.id != 'ADMIN'
    GROUP BY t.id, t.name, t.created_at
    ORDER BY t.id
    """
    return pd.read_sql_query(query, conn)

@auto_backup_before_critical
def delete_team(conn, team_id):
    """Désactive une équipe"""
    conn.execute("UPDATE teams SET active = 0 WHERE id = ?", (team_id,))
    conn.execute("UPDATE streets SET team = NULL WHERE team = ?", (team_id,))
    conn.commit()
    log_activity(conn, None, "TEAM_DELETED", f"Équipe {team_id} supprimée")

def teams(conn):
    """Liste des IDs d'équipes actives"""
    cursor = conn.execute(
        "SELECT id FROM teams WHERE active = 1 AND id != 'ADMIN' ORDER BY id"
    )
    return [row[0] for row in cursor.fetchall()]

# ---------- Fonctions pour les rues ----------
def list_streets(conn, team=None):
    """Liste les rues, optionnellement filtrées par équipe"""
    try:
        if team:
            query = """
                SELECT 
                    s.name, 
                    COALESCE(s.sector, '') as sector, 
                    COALESCE(s.team, '') as team, 
                    COALESCE(s.status, 'a_faire') as status,
                    COUNT(n.id) as notes,
                    COUNT(DISTINCT n.address_number) as addresses_with_notes
                FROM streets s
                LEFT JOIN notes n ON s.name = n.street_name
                WHERE s.team = ?
                GROUP BY s.name, s.sector, s.team, s.status
                ORDER BY 
                    CASE s.status 
                        WHEN 'a_faire' THEN 1 
                        WHEN 'en_cours' THEN 2 
                        WHEN 'terminee' THEN 3 
                    END, 
                    s.name
            """
            df = pd.read_sql_query(query, conn, params=(team,))
        else:
            query = """
                SELECT 
                    s.name, 
                    COALESCE(s.sector, '') as sector, 
                    COALESCE(s.team, '') as team, 
                    COALESCE(s.status, 'a_faire') as status,
                    COUNT(n.id) as notes,
                    COUNT(DISTINCT n.address_number) as addresses_with_notes
                FROM streets s
                LEFT JOIN notes n ON s.name = n.street_name
                GROUP BY s.name, s.sector, s.team, s.status
                ORDER BY 
                    s.team, 
                    CASE s.status 
                        WHEN 'a_faire' THEN 1 
                        WHEN 'en_cours' THEN 2 
                        WHEN 'terminee' THEN 3 
                    END, 
                    s.name
            """
            df = pd.read_sql_query(query, conn)
        
        # S'assurer que toutes les colonnes existent
        for col in ['name', 'sector', 'team', 'status', 'notes', 'addresses_with_notes']:
            if col not in df.columns:
                df[col] = '' if col in ['sector', 'team'] else ('a_faire' if col == 'status' else 0)
        
        return df
        
    except Exception as e:
        print(f"Erreur list_streets: {e}")
        # Retourner un DataFrame vide avec la structure attendue
        return pd.DataFrame(columns=['name', 'sector', 'team', 'status', 'notes', 'addresses_with_notes'])

def get_unassigned_streets(conn):
    """Récupère les rues non assignées"""
    query = """
        SELECT name, sector 
        FROM streets 
        WHERE team IS NULL OR team = ''
        ORDER BY sector, name
    """
    return pd.read_sql_query(query, conn)

def assign_streets_to_team(conn, street_names, team_id):
    """Assigne plusieurs rues à une équipe en une transaction"""
    try:
        for street_name in street_names:
            conn.execute(
                "UPDATE streets SET team = ? WHERE name = ?",
                (team_id, street_name)
            )
        conn.commit()
        log_activity(conn, team_id, "STREETS_ASSIGNED", f"{len(street_names)} rues assignées")
        return True
    except Exception as e:
        conn.rollback()
        print(f"Erreur lors de l'assignation: {e}")
        return False

def set_status(conn, name, status):
    """Met à jour le statut d'une rue avec validation"""
    valid_name, clean_name = validate_and_clean_input("street_name", name)
    clean_status = InputValidator.validate_status(status)
    
    if not valid_name:
        print("❌ Nom de rue invalide")
        return False
    
    conn.execute(
        "UPDATE streets SET status = ? WHERE name = ?",
        (clean_status, clean_name)
    )
    conn.commit()
    
    cursor = conn.execute("SELECT team FROM streets WHERE name = ?", (clean_name,))
    row = cursor.fetchone()
    if row:
        log_activity(conn, row[0], f"STATUS_{clean_status.upper()}", f"Rue {clean_name}")
    return True

# ---------- Fonctions pour les notes PAR ADRESSE ----------
def add_note_for_address(conn, street_name, team_id, address_number, comment):
    """Ajoute une note pour une adresse spécifique avec validation"""
    # Valider toutes les entrées
    valid_street, clean_street = validate_and_clean_input("street_name", street_name)
    valid_team, clean_team = validate_and_clean_input("team_id", team_id)
    valid_addr, clean_addr = validate_and_clean_input("address", address_number)
    valid_note, clean_note = validate_and_clean_input("note", comment)
    
    if not all([valid_street, valid_team, valid_addr, valid_note]):
        print("❌ Données invalides pour la note")
        return False
    
    conn.execute(
        """INSERT INTO notes (street_name, team_id, address_number, comment) 
           VALUES (?, ?, ?, ?)""",
        (clean_street, clean_team, clean_addr, clean_note)
    )
    
    # Met automatiquement le statut à "en_cours" si c'était "a_faire"
    conn.execute(
        """UPDATE streets 
           SET status = CASE 
               WHEN status = 'a_faire' THEN 'en_cours' 
               ELSE status 
           END
           WHERE name = ?""",
        (clean_street,)
    )
    
    conn.commit()
    log_activity(conn, clean_team, "NOTE_ADDED", f"Note ajoutée pour {clean_addr} {clean_street}")
    return True

def get_street_addresses_with_notes(conn, street_name):
    """Récupère toutes les adresses avec notes pour une rue"""
    query = """
        SELECT 
            n.address_number,
            n.comment,
            n.created_at,
            t.name as team_name
        FROM notes n
        JOIN teams t ON n.team_id = t.id
        WHERE n.street_name = ?
        ORDER BY 
            CAST(n.address_number AS INTEGER),
            n.created_at DESC
    """
    return pd.read_sql_query(query, conn, params=(street_name,))

def get_team_notes(conn, team_id):
    """Récupère toutes les notes d'une équipe"""
    query = """
        SELECT 
            street_name, 
            address_number, 
            comment, 
            created_at
        FROM notes
        WHERE team_id = ?
        ORDER BY created_at DESC
        LIMIT 50
    """
    return pd.read_sql_query(query, conn, params=(team_id,))

# ---------- Fonctions de statistiques ----------
def extended_stats(conn):
    """Statistiques étendues avec détails par adresse"""
    cursor = conn.execute("""
        SELECT 
            COUNT(DISTINCT s.name) as total,
            SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done,
            SUM(CASE WHEN s.status = 'en_cours' THEN 1 ELSE 0 END) as partial,
            SUM(CASE WHEN s.status = 'a_faire' THEN 1 ELSE 0 END) as todo,
            COUNT(DISTINCT n.id) as total_notes,
            COUNT(DISTINCT n.address_number || n.street_name) as addresses_with_notes
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name
    """)
    row = cursor.fetchone()
    return {
        "total": row[0] or 0,
        "done": row[1] or 0,
        "partial": row[2] or 0,
        "todo": row[3] or 0,
        "total_notes": row[4] or 0,
        "addresses_with_notes": row[5] or 0
    }

def stats_by_team(conn):
    """Statistiques par équipe"""
    query = """
        SELECT 
            s.team,
            COUNT(DISTINCT s.name) as total,
            SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done,
            SUM(CASE WHEN s.status = 'en_cours' THEN 1 ELSE 0 END) as partial,
            COUNT(DISTINCT n.id) as notes,
            ROUND(
                (SUM(CASE WHEN s.status = 'terminee' THEN 1.0 ELSE 0 END) / COUNT(*)) * 100, 
                1
            ) as progress
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name AND n.team_id = s.team
        WHERE s.team IS NOT NULL AND s.team != ''
        GROUP BY s.team
        ORDER BY progress DESC
    """
    return pd.read_sql_query(query, conn)

# ---------- Fonctions d'activité ----------
def recent_activity(conn, limit=10):
    """Récupère l'activité récente"""
    query = """
        SELECT 
            datetime(created_at, 'localtime') as timestamp,
            COALESCE(team_id, 'SYSTEM') as team,
            action,
            details
        FROM activity_log
        ORDER BY created_at DESC
        LIMIT ?
    """
    return pd.read_sql_query(query, conn, params=(limit,))

# ---------- Fonctions d'export ----------
def export_to_csv(conn):
    """Exporte toutes les données en CSV"""
    query = """
        SELECT 
            s.name as rue,
            s.sector as secteur,
            s.team as equipe,
            s.status as statut,
            COUNT(DISTINCT n.id) as nombre_notes,
            COUNT(DISTINCT n.address_number) as adresses_avec_notes
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name
        GROUP BY s.name, s.sector, s.team, s.status
        ORDER BY s.team, s.name
    """
    df = pd.read_sql_query(query, conn)
    return df.to_csv(index=False).encode('utf-8')

def export_notes_csv(conn):
    """Exporte toutes les notes en CSV avec adresses"""
    query = """
        SELECT 
            n.street_name as rue,
            n.address_number as numero,
            n.team_id as equipe,
            n.comment as commentaire,
            n.created_at as date_creation
        FROM notes n
        ORDER BY n.street_name, CAST(n.address_number AS INTEGER), n.created_at DESC
    """
    df = pd.read_sql_query(query, conn)
    return df.to_csv(index=False).encode('utf-8')

# ========================================
# NOUVELLES FONCTIONS POUR LES ADRESSES
# ========================================

@auto_backup_before_critical
def import_addresses_from_cache(conn, cache):
    """
    Importe les adresses depuis le cache OSM vers la base de données
    """
    try:
        # Vider la table existante
        conn.execute("DELETE FROM addresses")
        
        imported_count = 0
        skipped_count = 0
        
        for street_name, addresses in cache.items():
            # Vérifier que la rue existe dans la DB
            cursor = conn.execute("SELECT COUNT(*) FROM streets WHERE name = ?", (street_name,))
            if cursor.fetchone()[0] == 0:
                # Si la rue n'existe pas, la créer
                conn.execute(
                    "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, '', '', 'a_faire')",
                    (street_name,)
                )
                print(f"➕ Rue ajoutée: {street_name}")
            
            for addr in addresses:
                try:
                    # Validation des données
                    number = str(addr.get("number", "")).strip()
                    lat = addr.get("lat")
                    lon = addr.get("lon")
                    osm_type = addr.get("type", "unknown")
                    
                    if not number or lat is None or lon is None:
                        skipped_count += 1
                        continue
                    
                    conn.execute(
                        """INSERT INTO addresses (street_name, house_number, latitude, longitude, osm_type) 
                           VALUES (?, ?, ?, ?, ?)""",
                        (street_name, number, float(lat), float(lon), osm_type)
                    )
                    imported_count += 1
                except Exception as e:
                    print(f"⚠️ Erreur import adresse {addr}: {e}")
                    skipped_count += 1
        
        conn.commit()
        log_activity(conn, None, "ADDRESSES_IMPORTED", f"{imported_count} adresses importées, {skipped_count} ignorées")
        print(f"✅ {imported_count} adresses importées en base de données ({skipped_count} ignorées)")
        return imported_count
        
    except Exception as e:
        conn.rollback()
        print(f"❌ Erreur import adresses: {e}")
        return 0

def get_addresses_for_street(conn, street_name):
    """
    Récupère toutes les adresses d'une rue depuis la base de données
    """
    query = """
        SELECT 
            house_number,
            latitude,
            longitude,
            osm_type,
            created_at
        FROM addresses
        WHERE street_name = ?
        ORDER BY CAST(house_number AS INTEGER)
    """
    return pd.read_sql_query(query, conn, params=(street_name,))

def get_addresses_stats(conn):
    """
    Récupère les statistiques des adresses
    """
    cursor = conn.execute("""
        SELECT 
            COUNT(DISTINCT street_name) as streets_with_addresses,
            COUNT(*) as total_addresses,
            COUNT(DISTINCT CASE WHEN osm_type = 'node' THEN id END) as node_addresses,
            COUNT(DISTINCT CASE WHEN osm_type = 'way' THEN id END) as way_addresses
        FROM addresses
    """)
    row = cursor.fetchone()
    return {
        "streets_with_addresses": row[0] or 0,
        "total_addresses": row[1] or 0,
        "node_addresses": row[2] or 0,
        "way_addresses": row[3] or 0
    }

def get_backup_manager(db_path):
    """Retourne une instance du gestionnaire de backup"""
    return BackupManager(db_path)

# ================================================================================
# NOUVELLES FONCTIONS v4.1 - SUPERVISEUR ET BÉNÉVOLE
# ================================================================================

def get_unassigned_streets_count(conn):
    """Compte les rues non assignées à une équipe"""
    try:
        cursor = conn.execute("""
            SELECT COUNT(*) FROM streets 
            WHERE team IS NULL OR team = ''
        """)
        return cursor.fetchone()[0] or 0
    except Exception as e:
        print(f"Erreur get_unassigned_streets_count: {e}")
        return 0

def get_sectors_list(conn):
    """Récupère la liste des secteurs disponibles"""
    try:
        cursor = conn.execute("""
            SELECT DISTINCT sector FROM streets 
            WHERE sector IS NOT NULL AND sector != ''
            ORDER BY sector
        """)
        return [row[0] for row in cursor.fetchall()]
    except Exception as e:
        print(f"Erreur get_sectors_list: {e}")
        return []

def get_teams_list(conn):
    """Récupère la liste des équipes actives"""
    try:
        cursor = conn.execute("""
            SELECT id, name FROM teams 
            WHERE active = 1 AND id != 'ADMIN'
            ORDER BY name
        """)
        return [(row[0], row[1]) for row in cursor.fetchall()]
    except Exception as e:
        print(f"Erreur get_teams_list: {e}")
        return []

@auto_backup_before_critical
def bulk_assign_sector(conn, sector, team_id):
    """Assigne toutes les rues d'un secteur à une équipe"""
    try:
        # Valider les entrées
        valid_sector, clean_sector = validate_and_clean_input("sector", sector)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        
        if not valid_sector or not valid_team:
            raise ValueError("Secteur ou équipe invalide")
        
        # Vérifier que l'équipe existe
        cursor = conn.execute("SELECT COUNT(*) FROM teams WHERE id = ?", (clean_team,))
        if cursor.fetchone()[0] == 0:
            raise ValueError(f"Équipe {clean_team} inexistante")
        
        # Effectuer l'assignation
        cursor = conn.execute("""
            UPDATE streets 
            SET team = ? 
            WHERE sector = ? AND (team IS NULL OR team = '')
        """, (clean_team, clean_sector))
        
        affected_rows = cursor.rowcount
        conn.commit()
        
        # Log de l'activité
        log_activity(conn, clean_team, "bulk_assign", 
                    f"Assignation secteur {clean_sector}: {affected_rows} rues")
        
        return affected_rows
        
    except Exception as e:
        print(f"Erreur bulk_assign_sector: {e}")
        return 0

def get_team_streets(conn, team_id):
    """Récupère les rues assignées à une équipe"""
    try:
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        if not valid_team:
            return pd.DataFrame()
        
        query = """
            SELECT 
                s.name as street_name,
                s.sector,
                s.status,
                COUNT(n.id) as notes_count
            FROM streets s
            LEFT JOIN notes n ON s.name = n.street_name AND n.team_id = ?
            WHERE s.team = ?
            GROUP BY s.name, s.sector, s.status
            ORDER BY s.sector, s.name
        """
        return pd.read_sql_query(query, conn, params=(clean_team, clean_team))
        
    except Exception as e:
        print(f"Erreur get_team_streets: {e}")
        return pd.DataFrame()

@auto_backup_before_critical
def update_street_status(conn, street_name, new_status, team_id):
    """Met à jour le statut d'une rue"""
    try:
        # Valider les entrées
        valid_street, clean_street = validate_and_clean_input("street_name", street_name)
        valid_status, clean_status = validate_and_clean_input("status", new_status)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        
        if not all([valid_street, valid_status, valid_team]):
            raise ValueError("Paramètres invalides")
        
        # Vérifier que la rue est assignée à cette équipe
        cursor = conn.execute("""
            SELECT COUNT(*) FROM streets 
            WHERE name = ? AND team = ?
        """, (clean_street, clean_team))
        
        if cursor.fetchone()[0] == 0:
            raise ValueError(f"Rue {clean_street} non assignée à l'équipe {clean_team}")
        
        # Mettre à jour le statut
        conn.execute("""
            UPDATE streets 
            SET status = ? 
            WHERE name = ? AND team = ?
        """, (clean_status, clean_street, clean_team))
        
        conn.commit()
        
        # Log de l'activité
        log_activity(conn, clean_team, "status_update", 
                    f"Rue {clean_street}: {clean_status}")
        
        return True
        
    except Exception as e:
        print(f"Erreur update_street_status: {e}")
        return False

def get_assignations_export_data(conn):
    """Récupère les données d'assignation pour export CSV"""
    try:
        query = """
            SELECT 
                COALESCE(sector, 'Non défini') as secteur,
                name as rue,
                COALESCE(team, 'Non assignée') as equipe,
                CASE status 
                    WHEN 'a_faire' THEN 'À faire'
                    WHEN 'en_cours' THEN 'En cours'
                    WHEN 'terminee' THEN 'Terminée'
                    ELSE status 
                END as statut
            FROM streets
            ORDER BY secteur, rue
        """
        return pd.read_sql_query(query, conn)
        
    except Exception as e:
        print(f"Erreur get_assignations_export_data: {e}")
        return pd.DataFrame()

def log_activity(conn, team_id, action, details):
    """Enregistre une activité dans le log"""
    try:
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        valid_action, clean_action = validate_and_clean_input("text", action)
        valid_details, clean_details = validate_and_clean_input("note", details)
        
        if not all([valid_team, valid_action, valid_details]):
            print("Paramètres de log invalides")
            return
        
        conn.execute("""
            INSERT INTO activity_log (team_id, action, details)
            VALUES (?, ?, ?)
        """, (clean_team, clean_action, clean_details))
        
        conn.commit()
        
        # Log aussi dans un fichier texte pour backup
        log_dir = Path(__file__).parent / "logs"
        log_dir.mkdir(exist_ok=True)
        
        log_file = log_dir / "activity.log"
        with open(log_file, "a", encoding="utf-8") as f:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            f.write(f"{timestamp} | {clean_team} | {clean_action} | {clean_details}\n")
            
    except Exception as e:
        print(f"Erreur log_activity: {e}")

def get_street_notes_for_team(conn, street_name, team_id):
    """Récupère les notes d'une rue pour une équipe"""
    try:
        valid_street, clean_street = validate_and_clean_input("street_name", street_name)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        
        if not all([valid_street, valid_team]):
            return []
        
        cursor = conn.execute("""
            SELECT address_number, comment, created_at
            FROM notes
            WHERE street_name = ? AND team_id = ?
            ORDER BY created_at DESC
        """, (clean_street, clean_team))
        
        return cursor.fetchall()
        
    except Exception as e:
        print(f"Erreur get_street_notes_for_team: {e}")
        return []

@auto_backup_before_critical
def add_street_note(conn, street_name, team_id, address_number, comment):
    """Ajoute une note pour une adresse spécifique"""
    try:
        # Valider les entrées
        valid_street, clean_street = validate_and_clean_input("street_name", street_name)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        valid_address, clean_address = validate_and_clean_input("address", address_number)
        valid_comment, clean_comment = validate_and_clean_input("note", comment)
        
        if not all([valid_street, valid_team, valid_address, valid_comment]):
            raise ValueError("Paramètres invalides")
        
        # Vérifier que la rue est assignée à cette équipe
        cursor = conn.execute("""
            SELECT COUNT(*) FROM streets 
            WHERE name = ? AND team = ?
        """, (clean_street, clean_team))
        
        if cursor.fetchone()[0] == 0:
            raise ValueError(f"Rue {clean_street} non assignée à l'équipe {clean_team}")
        
        # Ajouter la note
        conn.execute("""
            INSERT INTO notes (street_name, team_id, address_number, comment)
            VALUES (?, ?, ?, ?)
        """, (clean_street, clean_team, clean_address, clean_comment))
        
        conn.commit()
        
        # Log de l'activité
        log_activity(conn, clean_team, "note_added", 
                    f"Note ajoutée - {clean_street} #{clean_address}")
        
        return True
        
    except Exception as e:
        print(f"Erreur add_street_note: {e}")
        return False
```
---8<--- guignomap/db.py END ---

---8<--- guignomap/osm.py BEGIN ---
```py
"""
Module OSM pour Guigno-Map
Gère l'import et le cache des données OpenStreetMap pour Mascouche
"""

import io
import json
from pathlib import Path
import pandas as pd
import overpy

# Configuration
CACHE_FILE = Path(__file__).parent / "osm_cache.json"
ADDR_CACHE_FILE = Path(__file__).parent / "osm_addresses.json"

# Toutes les voies routières nommées de Mascouche
QUERY_STREETS_ALL = """
[out:json][timeout:300];
area["name"="Mascouche"]["boundary"="administrative"]->.a;
(
  way["highway"~"^(primary|secondary|tertiary|residential|service|unclassified|living_street|pedestrian|track|road|busway|footway|path)$"](area.a);
);
(._;>;);
out body;
"""
# Note: Récupère TOUS les types de voies incluant petites rues, allées, chemins piétonniers

# Requête pour les adresses
QUERY_ADDR_NODES = """
[out:json][timeout:180];
area["name"="Mascouche"]["boundary"="administrative"]->.a;
(
  node["addr:housenumber"]["addr:street"](area.a);
  way["addr:housenumber"]["addr:street"](area.a);
);
out tags center;
"""

def generate_streets_csv(city="Mascouche"):
    """
    Génère un CSV avec les noms des rues principales de la ville
    Filtre automatiquement les rues privées et les petites ruelles
    """
    try:
        api = overpy.Overpass()
        result = api.query(QUERY_STREETS_ALL)
        
        streets = []
        for way in result.ways:
            name = way.tags.get("name")
            if not name:
                continue
            g = getattr(way, "geometry", None)
            # garder si on a une vraie géométrie (>= 2 points)
            if isinstance(g, list) and len(g) >= 2:
                streets.append(name)

        streets = sorted(set(streets))
        
        # Assigner automatiquement des secteurs basés sur les patterns de noms
        sectors = []
        for street in streets:
            if any(word in street.lower() for word in ["montée", "chemin", "boulevard"]):
                sectors.append("Principal")
            elif any(word in street.lower() for word in ["avenue", "place", "croissant"]):
                sectors.append("Résidentiel")
            elif "rue" in street.lower():
                sectors.append("Centre")
            else:
                sectors.append("")
        
        df = pd.DataFrame({
            "name": streets,
            "sector": sectors,
            "team": [""] * len(streets)
        })
        
        buf = io.StringIO()
        df.to_csv(buf, index=False)
        print(f"✅ CSV généré avec {len(streets)} rues principales")
        return buf.getvalue().encode("utf-8")
        
    except Exception as e:
        print(f"❌ Erreur OSM: {e}")
        # Retourner des données de test en cas d'erreur
        return create_fallback_csv()

def build_geometry_cache():
    """
    Construit le cache des géométries pour TOUTES les voies de Mascouche
    Force la résolution complète des nodes
    """
    try:
        print("🔄 Récupération complète de toutes les voies de Mascouche...")
        
        # IMPORTANT: Configurer l'API pour résoudre automatiquement les nodes manquants
        api = overpy.Overpass()
        
        # Requête améliorée qui force le retour des coordonnées
        query = """
        [out:json][timeout:300];
        area["name"="Mascouche"]["boundary"="administrative"]->.a;
        (
          way["highway"]["name"](area.a);
          way["highway"]["ref"](area.a);
        );
        (._;>;);
        out body;
        """
        
        print("📡 Connexion à OpenStreetMap (cela peut prendre 30-60 secondes)...")
        result = api.query(query)
        
        geo = {}
        stats = {"total": 0, "avec_geo": 0, "sans_geo": 0}
        
        # Construire un dictionnaire des nodes pour accès rapide
        nodes_dict = {}
        if hasattr(result, 'nodes'):
            for node in result.nodes:
                if hasattr(node, 'id') and hasattr(node, 'lat') and hasattr(node, 'lon'):
                    nodes_dict[node.id] = (float(node.lat), float(node.lon))
        
        print(f"📍 {len(nodes_dict)} nodes récupérés")
        
        ways = result.ways if hasattr(result, 'ways') else []
        print(f"📊 {len(ways)} voies trouvées dans OpenStreetMap")
        
        for way in ways:
            try:
                # Récupérer le nom ou ref
                if not hasattr(way, 'tags'):
                    continue
                    
                name = way.tags.get("name")
                if not name:
                    ref = way.tags.get("ref")
                    if ref:
                        name = f"Autoroute {ref}"
                    else:
                        continue
                
                stats["total"] += 1
                coords = []
                
                # Récupérer les IDs des nodes
                if hasattr(way, 'nd_ids'):
                    # Si on a les IDs des nodes, les résoudre
                    for node_id in way.nd_ids:
                        if node_id in nodes_dict:
                            lat, lon = nodes_dict[node_id]
                            coords.append([lat, lon])
                elif hasattr(way, 'nodes'):
                    # Si on a directement les nodes
                    for node in way.nodes:
                        if hasattr(node, 'lat') and hasattr(node, 'lon'):
                            coords.append([float(node.lat), float(node.lon)])
                        elif hasattr(node, 'id') and node.id in nodes_dict:
                            lat, lon = nodes_dict[node.id]
                            coords.append([lat, lon])
                
                if len(coords) >= 2:
                    if name not in geo:
                        geo[name] = []
                    geo[name].append(coords)
                    stats["avec_geo"] += 1
                else:
                    stats["sans_geo"] += 1
                    
            except Exception as e:
                continue
        
        print(f"✅ Résultat: {stats['avec_geo']} voies avec géométrie sur {stats['total']} trouvées")
        
        # Si on a récupéré des données, sauvegarder
        if geo:
            CACHE_FILE.write_text(json.dumps(geo, indent=2), encoding="utf-8")
            print(f"💾 Cache créé: {len(geo)} voies sauvegardées dans osm_cache.json")
            
            # Importer aussi automatiquement dans la DB
            try:
                from pathlib import Path
                import sys
                sys.path.append(str(Path(__file__).parent))
                import db
                
                db_path = Path(__file__).parent / "guigno_map.db"
                conn = db.get_conn(db_path)
                
                # Ajouter les rues manquantes à la DB
                for street_name in geo.keys():
                    cursor = conn.execute("SELECT COUNT(*) FROM streets WHERE name = ?", (street_name,))
                    if cursor.fetchone()[0] == 0:
                        conn.execute(
                            "INSERT INTO streets(name, sector, team, status) VALUES (?, '', '', 'a_faire')",
                            (street_name,)
                        )
                conn.commit()
                print(f"✅ Rues importées dans la base de données")
            except Exception as e:
                print(f"⚠️ Import DB: {e}")
            
            return geo
        
        # Si aucune donnée, utiliser un fallback étendu
        print("⚠️ Aucune donnée OSM, utilisation du fallback local")
        return get_extended_fallback()
            
    except Exception as e:
        print(f"❌ Erreur: {e}")
        return get_extended_fallback()

def get_fallback_geometry():
    """Fallback avec les principales voies de Mascouche"""
    return {
        "Autoroute 25": [[[45.70, -73.65], [45.78, -73.58]]],
        "Autoroute 640": [[[45.76, -73.70], [45.76, -73.55]]],
        "Montée Masson": [[[45.730, -73.620], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.752, -73.590]]],
        "Chemin des Anglais": [[[45.74, -73.65], [45.75, -73.64]]],
        "Chemin Gascon": [[[45.75, -73.62], [45.76, -73.60]]],
        "Chemin Pincourt": [[[45.72, -73.64], [45.73, -73.63]]],
        "Chemin Newton": [[[45.73, -73.58], [45.74, -73.57]]],
        "Chemin Saint-Henri": [[[45.71, -73.61], [45.72, -73.60]]],
        "Chemin Saint-Pierre": [[[45.74, -73.59], [45.75, -73.58]]],
        "Avenue de la Gare": [[[45.745, -73.601], [45.748, -73.598]]],
        "Rue Dupras": [[[45.745, -73.602], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.749, -73.600]]],
        "Rue de l'Église": [[[45.747, -73.601], [45.750, -73.599]]],
        "Avenue des Érables": [[[45.755, -73.605], [45.758, -73.600]]],
        "Rue des Pins": [[[45.756, -73.603], [45.759, -73.598]]],
        "Rue Brien": [[[45.738, -73.605], [45.741, -73.600]]],
        "Rue Bohémier": [[[45.742, -73.607], [45.745, -73.604]]]
    }

def get_extended_fallback():
    """Fallback étendu avec les principales voies de Mascouche"""
    fallback = {
        # Autoroutes
        "Autoroute 25": [[[45.70, -73.65], [45.72, -73.63], [45.74, -73.61], [45.76, -73.59], [45.78, -73.58]]],
        "Autoroute 640": [[[45.76, -73.70], [45.76, -73.65], [45.76, -73.60], [45.76, -73.55]]],
        
        # Chemins principaux
        "Montée Masson": [[[45.730, -73.620], [45.740, -73.610], [45.750, -73.600], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.745, -73.605], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.747, -73.600], [45.752, -73.590]]],
        "Chemin des Anglais": [[[45.74, -73.65], [45.745, -73.645], [45.75, -73.64]]],
        "Chemin Gascon": [[[45.75, -73.62], [45.755, -73.615], [45.76, -73.60]]],
        "Chemin Pincourt": [[[45.72, -73.64], [45.725, -73.635], [45.73, -73.63]]],
        "Chemin Newton": [[[45.73, -73.58], [45.735, -73.575], [45.74, -73.57]]],
        "Chemin Saint-Henri": [[[45.71, -73.61], [45.715, -73.605], [45.72, -73.60]]],
        "Chemin Saint-Pierre": [[[45.74, -73.59], [45.745, -73.585], [45.75, -73.58]]],
        
        # Avenues
        "Avenue de la Gare": [[[45.745, -73.601], [45.747, -73.599], [45.748, -73.598]]],
        "Avenue Bourque": [[[45.742, -73.603], [45.744, -73.601], [45.746, -73.599]]],
        "Avenue Crépeau": [[[45.743, -73.602], [45.745, -73.600], [45.747, -73.598]]],
        "Avenue Garden": [[[45.751, -73.606], [45.753, -73.604], [45.755, -73.602]]],
        "Avenue de l'Esplanade": [[[45.748, -73.605], [45.750, -73.603], [45.752, -73.601]]],
        
        # Rues du centre
        "Rue Dupras": [[[45.745, -73.602], [45.747, -73.600], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.748, -73.602], [45.749, -73.600]]],
        "Rue de l'Église": [[[45.747, -73.601], [45.749, -73.599], [45.750, -73.598]]],
        "Rue Brien": [[[45.738, -73.605], [45.740, -73.603], [45.741, -73.600]]],
        "Rue Bohémier": [[[45.742, -73.607], [45.744, -73.605], [45.745, -73.604]]],
        
        # Rues résidentielles
        "Rue des Pins": [[[45.756, -73.603], [45.758, -73.601], [45.759, -73.598]]],
        "Avenue des Érables": [[[45.755, -73.605], [45.757, -73.603], [45.758, -73.600]]],
        "Rue Gravel": [[[45.738, -73.605], [45.740, -73.603], [45.741, -73.600]]]
    }
    
    # Sauvegarder le fallback
    CACHE_FILE.write_text(json.dumps(fallback, indent=2), encoding="utf-8")
    print(f"💾 Fallback sauvegardé avec {len(fallback)} voies principales")
    
    return fallback

def load_geometry_cache():
    """
    Charge le cache de géométries depuis le fichier JSON
    Crée un cache de base si le fichier n'existe pas
    """
    if not CACHE_FILE.exists():
        print("⚠️ Cache non trouvé, construction en cours...")
        return build_geometry_cache()  # build_geometry_cache() gère déjà le fallback en mémoire
    
    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
            print(f"✅ Cache chargé: {len(cache)} rues")
            return cache
    except Exception as e:
        print(f"❌ Erreur chargement cache: {e}")
        # Ne pas écrire de fallback sur disque ! Utiliser build_geometry_cache() qui gère le fallback en mémoire
        return build_geometry_cache()

def create_fallback_csv():
    """
    Crée un CSV de fallback avec quelques rues principales de Mascouche
    Utilisé si l'API OSM est indisponible
    """
    fallback_streets = [
        ("Montée Masson", "Principal"),
        ("Chemin Sainte-Marie", "Principal"),
        ("Boulevard de Mascouche", "Principal"),
        ("Chemin des Anglais", "Principal"),
        ("Rue Dupras", "Centre"),
        ("Rue Saint-Pierre", "Centre"),
        ("Rue de l'Église", "Centre"),
        ("Avenue des Érables", "Résidentiel"),
        ("Rue des Pins", "Résidentiel"),
        ("Avenue Garden", "Résidentiel"),
    ]
    
    df = pd.DataFrame(fallback_streets, columns=["name", "sector"])
    df["team"] = ""
    
    buf = io.StringIO()
    df.to_csv(buf, index=False)
    print("⚠️ Mode fallback: 10 rues de test")
    return buf.getvalue().encode("utf-8")

def create_fallback_cache():
    """
    Crée un cache minimal pour tests
    """
    fallback_geo = {
        "Montée Masson": [[[45.730, -73.620], [45.750, -73.600], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.748, -73.602], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.747, -73.600], [45.752, -73.590]]],
        "Rue Dupras": [[[45.745, -73.602], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.749, -73.600]]],
        "Rue de l'Église": [[[45.747, -73.601], [45.750, -73.599]]],
        "Avenue des Érables": [[[45.755, -73.605], [45.758, -73.600]]],
        "Rue des Pins": [[[45.756, -73.603], [45.759, -73.598]]],
        "Avenue Garden": [[[45.753, -73.606], [45.756, -73.601]]],
        "Rue Gravel": [[[45.738, -73.605], [45.741, -73.600]]]
    }
    
    CACHE_FILE.write_text(json.dumps(fallback_geo, indent=2), encoding="utf-8")
    print("⚠️ Cache fallback créé avec 10 rues")

# Fonction utilitaire pour tests
def test_osm_connection():
    """
    Teste la connexion à l'API Overpass
    """
    try:
        api = overpy.Overpass()
        # Requête minimale pour tester
        result = api.query('[out:json];node(45.7475,-73.6005,45.7476,-73.6004);out;')
        print("✅ Connexion OSM OK")
        return True
    except:
        print("❌ Connexion OSM échouée")
        return False

# ========================================
# NOUVELLES FONCTIONS POUR LES ADRESSES
# ========================================

def build_addresses_cache():
    """
    Construit le cache des adresses OSM pour Mascouche
    Récupère addr:housenumber + addr:street depuis OSM
    """
    try:
        api = overpy.Overpass()
        result = api.query(QUERY_ADDR_NODES)
        
        addresses = {}
        
        # Traiter les nodes avec adresses
        for node in result.nodes:
            house_number = node.tags.get("addr:housenumber")
            street_name = node.tags.get("addr:street")
            
            if house_number and street_name:
                if street_name not in addresses:
                    addresses[street_name] = []
                addresses[street_name].append({
                    "number": str(house_number),  # Forcer en string
                    "lat": float(node.lat),
                    "lon": float(node.lon),
                    "type": "node"
                })
        
        # Traiter les ways avec adresses
        for way in result.ways:
            num = way.tags.get("addr:housenumber")
            street = way.tags.get("addr:street")
            if not num or not street:
                continue
            
            # Récupérer le centre du way
            lat = getattr(way, "center_lat", None)
            lon = getattr(way, "center_lon", None)
            
            # Fallback si center_lat/lon non disponibles
            if lat is None or lon is None:
                nodes = getattr(way, "nodes", []) or []
                if nodes:
                    try:
                        valid_lats = []
                        valid_lons = []
                        for n in nodes:
                            if hasattr(n, 'lat') and hasattr(n, 'lon'):
                                if n.lat is not None and n.lon is not None:
                                    valid_lats.append(float(n.lat))
                                    valid_lons.append(float(n.lon))
                        if valid_lats and valid_lons:
                            lat = sum(valid_lats) / len(valid_lats)
                            lon = sum(valid_lons) / len(valid_lons)
                    except Exception as e:
                        print(f"Erreur calcul centre pour way: {e}")
                        continue
            
            if lat is not None and lon is not None:
                addresses.setdefault(street, []).append({
                    "number": str(num),
                    "lat": float(lat),
                    "lon": float(lon),
                    "type": "way"
                })
        
        # Trier les adresses par numéro pour chaque rue
        for street_name in addresses:
            try:
                # Tri numérique intelligent
                addresses[street_name].sort(
                    key=lambda x: (
                        int(''.join(filter(str.isdigit, x["number"]))) 
                        if any(c.isdigit() for c in x["number"]) 
                        else float('inf')
                    )
                )
            except:
                # Si le tri échoue, garder l'ordre original
                pass
        
        # Sauvegarder le cache
        ADDR_CACHE_FILE.write_text(json.dumps(addresses, indent=2), encoding="utf-8")
        total_addresses = sum(len(addrs) for addrs in addresses.values())
        print(f"✅ Cache adresses créé: {len(addresses)} rues, {total_addresses} adresses")
        return addresses
        
    except Exception as e:
        print(f"❌ Erreur construction cache adresses: {e}")
        # Créer un cache vide en cas d'erreur
        ADDR_CACHE_FILE.write_text(json.dumps({}), encoding="utf-8")
        return {}

def load_addresses_cache():
    """
    Charge le cache d'adresses depuis le fichier JSON
    """
    if not ADDR_CACHE_FILE.exists():
        print("⚠️ Cache adresses non trouvé")
        return {}
    
    try:
        with open(ADDR_CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
            total_addresses = sum(len(addrs) for addrs in cache.values())
            print(f"✅ Cache adresses chargé: {len(cache)} rues, {total_addresses} adresses")
            return cache
    except Exception as e:
        print(f"❌ Erreur chargement cache adresses: {e}")
        return {}
```
---8<--- guignomap/osm.py END ---

---8<--- guignomap/reports.py BEGIN ---
```py
"""
Générateur de rapports Excel et PDF pour GuignoMap
"""

from pathlib import Path
from datetime import datetime
import pandas as pd
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, PageBreak, Image
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib.enums import TA_CENTER, TA_RIGHT
import xlsxwriter
from io import BytesIO

# Mapping des statuts pour l'affichage (évite imports circulaires)
STATUS_TO_LABEL = {"a_faire": "À faire", "en_cours": "En cours", "terminee": "Terminée"}

class ReportGenerator:
    def __init__(self, conn):
        self.conn = conn
        self.styles = getSampleStyleSheet()
        self._setup_custom_styles()
    
    def _setup_custom_styles(self):
        """Définit les styles personnalisés pour PDF"""
        self.styles.add(ParagraphStyle(
            name='CustomTitle',
            parent=self.styles['Heading1'],
            fontSize=24,
            textColor=colors.HexColor('#8B0000'),
            spaceAfter=30,
            alignment=TA_CENTER
        ))
        
        self.styles.add(ParagraphStyle(
            name='SectionTitle',
            parent=self.styles['Heading2'],
            fontSize=16,
            textColor=colors.HexColor('#8B0000'),
            spaceAfter=12,
            spaceBefore=12
        ))
    
    def generate_excel(self):
        """Génère un rapport Excel professionnel"""
        output = BytesIO()
        workbook = xlsxwriter.Workbook(output, {'remove_timezone': True})
        
        # Styles Excel
        header_format = workbook.add_format({
            'bold': True,
            'bg_color': '#8B0000',
            'font_color': 'white',
            'align': 'center',
            'valign': 'vcenter',
            'border': 1
        })
        
        cell_format = workbook.add_format({
            'align': 'center',
            'valign': 'vcenter',
            'border': 1
        })
        
        status_formats = {
            'terminee': workbook.add_format({'bg_color': '#90EE90', 'border': 1}),
            'en_cours': workbook.add_format({'bg_color': '#FFE4B5', 'border': 1}),
            'a_faire': workbook.add_format({'bg_color': '#FFB6C1', 'border': 1})
        }
        
        # Feuille 1 : Résumé
        summary_sheet = workbook.add_worksheet('Résumé Guignolée 2025')
        summary_sheet.set_column(0, 4, 20)  # A:E
        
        # Titre
        title_format = workbook.add_format({
            'bold': True,
            'font_size': 20,
            'font_color': '#8B0000',
            'align': 'center'
        })
        summary_sheet.merge_range(0, 0, 0, 4, 'GUIGNOLÉE 2025 - RELAIS DE MASCOUCHE', title_format)  # A1:E1
        summary_sheet.merge_range(1, 0, 1, 4, f'Rapport généré le {datetime.now().strftime("%d/%m/%Y à %H:%M")}', cell_format)  # A2:E2
        
        # Stats globales
        from db import extended_stats
        stats = extended_stats(self.conn)
        
        row = 4
        summary_sheet.write(row, 0, 'STATISTIQUES GLOBALES', header_format)
        summary_sheet.merge_range(row, 1, row, 4, '', header_format)  # B{row+1}:E{row+1}
        
        row += 2
        summary_data = [
            ['Total des rues', stats['total']],
            ['Rues terminées', stats['done']],
            ['Rues en cours', stats.get('partial', 0)],
            ['Rues à faire', stats.get('todo', 0)],
            ['Progression globale', f"{(stats['done']/stats['total']*100) if stats['total'] > 0 else 0:.1f}%"],
            ['Total des notes', stats.get('total_notes', 0)],
            ['Adresses avec notes', stats.get('addresses_with_notes', 0)]
        ]
        
        for label, value in summary_data:
            summary_sheet.write(row, 0, label, cell_format)
            summary_sheet.write(row, 1, value, cell_format)
            row += 1
        
        # Feuille 2 : Détail des rues
        streets_sheet = workbook.add_worksheet('Détail des rues')
        streets_sheet.set_column(0, 0, 30)
        streets_sheet.set_column(1, 4, 15)
        
        # Headers
        headers = ['Rue', 'Secteur', 'Équipe', 'Statut', 'Notes']
        for col, header in enumerate(headers):
            streets_sheet.write(0, col, header, header_format)
        
        # Données
        from db import list_streets
        df = list_streets(self.conn)
        
        for idx, row_data in enumerate(df.iterrows(), 1):
            _, row = row_data
            streets_sheet.write(idx, 0, row.get('name', ''), cell_format)
            streets_sheet.write(idx, 1, row.get('sector', ''), cell_format)
            streets_sheet.write(idx, 2, row.get('team', ''), cell_format)
            
            status = row.get('status', 'a_faire')
            format_to_use = status_formats.get(status, cell_format)
            status_label = STATUS_TO_LABEL.get(status, "À faire")
            streets_sheet.write(idx, 3, status_label, format_to_use)
            
            streets_sheet.write(idx, 4, row.get('notes', 0), cell_format)
        
        # Feuille 3 : Performance des équipes
        teams_sheet = workbook.add_worksheet('Performance équipes')
        teams_sheet.set_column(0, 5, 15)
        
        from db import stats_by_team
        teams_df = stats_by_team(self.conn)
        
        if not teams_df.empty:
            headers = ['Équipe', 'Total rues', 'Terminées', 'En cours', 'Notes', 'Progression %']
            for col, header in enumerate(headers):
                teams_sheet.write(0, col, header, header_format)
            
            for idx, row_data in enumerate(teams_df.iterrows(), 1):
                _, row = row_data
                teams_sheet.write(idx, 0, row.get('team', ''), cell_format)
                teams_sheet.write(idx, 1, row.get('total', 0), cell_format)
                teams_sheet.write(idx, 2, row.get('done', 0), cell_format)
                teams_sheet.write(idx, 3, row.get('partial', 0), cell_format)
                teams_sheet.write(idx, 4, row.get('notes', 0), cell_format)
                teams_sheet.write(idx, 5, f"{row.get('progress', 0):.1f}%", cell_format)
        
        workbook.close()
        output.seek(0)
        return output.getvalue()
    
    def generate_pdf(self):
        """Génère un rapport PDF professionnel"""
        output = BytesIO()
        doc = SimpleDocTemplate(output, pagesize=A4)
        story = []
        
        # Page de titre
        story.append(Paragraph("GUIGNOLÉE 2025", self.styles['CustomTitle']))
        story.append(Paragraph("Le Relais de Mascouche", self.styles['Title']))
        story.append(Spacer(1, 0.2*inch))
        story.append(Paragraph(f"Rapport généré le {datetime.now().strftime('%d/%m/%Y à %H:%M')}", self.styles['Normal']))
        story.append(PageBreak())
        
        # Résumé
        story.append(Paragraph("Résumé de la collecte", self.styles['SectionTitle']))
        
        from db import extended_stats
        stats = extended_stats(self.conn)
        
        summary_data = [
            ['Statistique', 'Valeur'],
            ['Total des rues', str(stats['total'])],
            ['Rues terminées', str(stats['done'])],
            ['Rues en cours', str(stats.get('partial', 0))],
            ['Rues à faire', str(stats.get('todo', 0))],
            ['Progression', f"{(stats['done']/stats['total']*100) if stats['total'] > 0 else 0:.1f}%"],
            ['Total notes', str(stats.get('total_notes', 0))]
        ]
        
        summary_table = Table(summary_data, colWidths=[3*inch, 2*inch])
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#8B0000')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 14),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(summary_table)
        story.append(PageBreak())
        
        # Performance des équipes
        story.append(Paragraph("Performance des équipes", self.styles['SectionTitle']))
        
        from db import stats_by_team
        teams_df = stats_by_team(self.conn)
        
        if not teams_df.empty:
            teams_data = [['Équipe', 'Total', 'Terminées', 'En cours', 'Progression']]
            for _, row in teams_df.iterrows():
                teams_data.append([
                    row.get('team', ''),
                    str(row.get('total', 0)),
                    str(row.get('done', 0)),
                    str(row.get('partial', 0)),
                    f"{row.get('progress', 0):.1f}%"
                ])
            
            teams_table = Table(teams_data, colWidths=[2*inch, 1*inch, 1*inch, 1*inch, 1.5*inch])
            teams_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#8B0000')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            story.append(teams_table)
        
        doc.build(story)
        output.seek(0)
        return output.getvalue()
```
---8<--- guignomap/reports.py END ---

---8<--- guignomap/validators.py BEGIN ---
```py
"""
Validateurs et sanitizers pour GuignoMap
Protection contre injections et validation des formats
"""

import re
import html
from typing import Optional, Tuple

class InputValidator:
    """Classe de validation et sanitization des entrées"""
    
    @staticmethod
    def sanitize_text(text: str, max_length: int = 255) -> str:
        """Nettoie et limite un texte"""
        if not text:
            return ""
        # Supprimer les caractères de contrôle
        text = "".join(char for char in text if ord(char) >= 32 or char == '\n')
        # Échapper le HTML
        text = html.escape(text)
        # Limiter la longueur
        return text[:max_length].strip()
    
    @staticmethod
    def sanitize_street_name(name: str) -> str:
        """Valide et nettoie un nom de rue"""
        if not name:
            return ""
        # Garder seulement lettres, chiffres, espaces, tirets, apostrophes, accents
        name = re.sub(r'[^a-zA-ZÀ-ÿ0-9\s\-\'\.]', '', name)
        return name[:100].strip()
    
    @staticmethod
    def sanitize_team_id(team_id: str) -> str:
        """Valide un ID d'équipe"""
        if not team_id:
            return ""
        # Format: LETTRES + CHIFFRES seulement, max 20 caractères
        team_id = re.sub(r'[^A-Z0-9]', '', team_id.upper())
        return team_id[:20]
    
    @staticmethod
    def sanitize_address_number(number: str) -> str:
        """Valide un numéro civique"""
        if not number:
            return ""
        # Garder chiffres et lettres (ex: 123A)
        number = re.sub(r'[^0-9A-Za-z\-]', '', number)
        return number[:10]
    
    @staticmethod
    def validate_password(password: str) -> Tuple[bool, str]:
        """Valide la force d'un mot de passe - minimum 4 caractères"""
        if password is None:
            return False, "Mot de passe requis"
        if len(password) < 4:
            return False, "Minimum 4 caractères"
        if len(password) > 128:
            return False, "Maximum 128 caractères"
        return True, "OK"
    
    @staticmethod
    def validate_sector(sector: str) -> str:
        """Valide un secteur"""
        valid_sectors = ['Principal', 'Centre', 'Nord', 'Sud', 'Est', 'Ouest', 'Résidentiel', '']
        if sector not in valid_sectors:
            return ''
        return sector
    
    @staticmethod
    def validate_status(status: str) -> str:
        """Valide un statut de rue"""
        valid_statuses = ['a_faire', 'en_cours', 'terminee']
        if status not in valid_statuses:
            return 'a_faire'
        return status
    
    @staticmethod
    def sanitize_note(note: str) -> str:
        """Nettoie une note/commentaire"""
        if not note:
            return ""
        # Supprimer caractères dangereux mais garder ponctuation basique
        note = re.sub(r'[<>\"\'`;]', '', note)
        return note[:500].strip()
    
    @staticmethod
    def is_sql_safe(text: str) -> bool:
        """Vérifie qu'un texte ne contient pas de patterns SQL dangereux"""
        if not text:
            return True
        dangerous_patterns = [
            r'\bDROP\b', r'\bDELETE\b', r'\bINSERT\b', r'\bUPDATE\b',
            r'\bEXEC\b', r'\bEXECUTE\b', r'--', r'/\*', r'\*/', r';'
        ]
        text_upper = text.upper()
        for pattern in dangerous_patterns:
            if re.search(pattern, text_upper):
                return False
        return True

def validate_and_clean_input(input_type: str, value: str) -> Tuple[bool, str]:
    """Fonction principale de validation"""
    validator = InputValidator()
    
    if input_type == "team_id":
        clean = validator.sanitize_team_id(value)
        return bool(clean), clean
    
    elif input_type == "street_name":
        clean = validator.sanitize_street_name(value)
        if not validator.is_sql_safe(clean):
            return False, ""
        return bool(clean), clean
    
    elif input_type == "address":
        clean = validator.sanitize_address_number(value)
        return bool(clean), clean
    
    elif input_type == "note":
        clean = validator.sanitize_note(value)
        if not validator.is_sql_safe(clean):
            return False, ""
        return bool(clean), clean
    
    elif input_type == "sector":
        clean = validator.validate_sector(value)
        return True, clean
    
    elif input_type == "status":
        clean = validator.validate_status(value)
        return True, clean
    
    elif input_type == "password":
        valid, msg = validator.validate_password(value)
        return valid, value if valid else ""
    
    else:
        clean = validator.sanitize_text(value)
        return bool(clean), clean
```
---8<--- guignomap/validators.py END ---

---8<--- GuignoMap_code_export_20250914_audit.txt BEGIN ---
```txt
================================================================================
                    GUIGNO-MAP - EXPORT CODE COMPLET POUR AUDIT
                           Le Relais de Mascouche - v4.0 Windows  
                     Export généré le: 2025-09-14 15:32:38 (COMPLET)
================================================================================

🖥️ ENVIRONNEMENT DE DÉVELOPPEMENT:
- OS: Windows 11
- Architecture: AMD64
- Python: 3.13.6
- Environnement virtuel: .venv activé

📦 DÉPENDANCES INSTALLÉES:
streamlit>=1.36.0, pandas>=2.2.0, folium==0.20.0, streamlit-folium>=0.21.0, 
overpy==0.7, bcrypt>=4.0.0, plotly>=5.18.0, xlsxwriter>=3.1.0, reportlab>=4.0.0

🔧 NOUVELLES FONCTIONNALITÉS v4.0:
- 🔒 Sécurité bcrypt avec migration automatique SHA256
- 💾 Système de backup automatique (ZIP avec rotation 7 jours)
- ✅ Validation et sanitisation complète des entrées
- 📊 Exports Excel et PDF professionnels
- 🖥️ Scripts de lancement Windows optimisés

================================================================================
SECTION 1: CONFIGURATION ET DOCUMENTATION
================================================================================

================================================================================
FICHIER: README.md
DESCRIPTION: Documentation principale du projet
LIGNES: 370
================================================================================
# GuignoMap - Système de gestion pour la Guignolée 2025 🎄

Une application web moderne conçue spécialement pour optimiser la collecte de dons lors de la Guignolée 2025 à Mascouche.

## ✨ Nouvelles fonctionnalités v3.0

### 🎄 Interface festive
- **Page d'accueil moderne** avec compte à rebours vers Noël
- **En-tête festif** aux couleurs de la Guignolée 2025
- **Carte de Noël thématique** avec icônes festives

### 📱 Optimisations mobiles
- **Interface responsive** optimisée pour tous les appareils
- **Navigation tactile** adaptée aux smartphones
- **Contrôles de carte** optimisés pour mobile

### 🏆 Système de motivation
- **Badges d'équipe** : Débutants, Actifs, Champions, Légendes
- **Notifications temps réel** pour les accomplissements
- **Tableaux de bord interactifs** avec graphiques Plotly

### 📊 Centre d'export avancé
- **Export Excel professionnel** avec formatage automatique
- **Génération de listes SMS** pour la communication d'équipe
- **Export PDF** (préparation)
- **Rapports détaillés** par équipe et secteur

### 🗺️ Améliorations cartographiques
- **Choix de fonds de carte** : OpenStreetMap France, CARTO Voyager, Esri
- **Zoom optimisé** centré sur Mascouche
- **Zone d'affichage agrandie** : 90% de l'écran sur PC
- **Gestion d'erreur robuste** : secrets.toml optionnel
- **Visibilité améliorée** des rues avec lignes plus épaisses
- **Récupération complète** de toutes les rues via OSM

### 👥 Gestion moderne
- **Terminologie unifiée** : "gestionnaire" au lieu de "superviseur"
- **Navigation sidebar** moderne et intuitive
- **Interface bénévole restreinte** aux rues assignées seulement
- **Authentification simplifiée** avec cartes de connexion

## 🚀 Installation et utilisation

### Prérequis
- Python 3.8+
- Accès internet pour OSM et les tuiles de carte

### Installation
```bash
git clone https://github.com/votre-repo/GuignoMap.git
cd GuignoMap
pip install -r requirements.txt
```

### Lancement
```bash
cd guignomap
streamlit run app.py
```

## 📦 Dépendances principales

- **streamlit** : Interface web moderne
- **folium** : Cartes interactives
- **pandas** : Manipulation des données
- **overpy** : API OpenStreetMap
- **plotly** : Graphiques interactifs
- **xlsxwriter** : Export Excel professionnel

## 🎯 Fonctionnalités principales

### Pour les bénévoles
- 🗺️ **Carte interactive** avec leurs rues assignées uniquement
- ✅ **Système de validation** rue par rue avec notes
- 🏆 **Badges de progression** et encouragements
- � **Interface mobile** optimisée

### Pour les gestionnaires
- 📊 **Tableau de bord complet** avec KPIs temps réel
- �️ **Vue d'ensemble** de toutes les équipes
- 📈 **Graphiques de progression** par Plotly
- � **Centre d'export** avec formats multiples
- 👥 **Gestion des équipes** et assignation
- � **Notifications** d'activité

### Données et exports
- 📝 **Base de données SQLite** intégrée
- 📊 **Export Excel** avec formatage professionnel
- 📱 **Listes SMS** pour communication
- 📄 **Rapports PDF** (en développement)
source .venv/bin/activate

## 🗃️ Structure du projet

```
GuignoMap/
├── guignomap/
│   ├── app.py              # Application principale Streamlit
│   ├── db.py               # Gestion base de données
│   ├── osm.py              # Interface OpenStreetMap
│   ├── guigno_map.db       # Base de données SQLite
│   ├── osm_cache.json      # Cache des données OSM
│   ├── streets_mascouche.csv # Données des rues
│   └── assets/
│       ├── banner.png      # Bannière Guignolée
│       ├── logo.png        # Logo officiel
│       └── styles.css      # Styles personnalisés
├── requirements.txt        # Dépendances Python
└── README.md              # Documentation
```

## 🎄 Thème Guignolée 2025

L'application adopte une identité visuelle festive pour l'édition 2025 :
- **Couleurs** : Rouge festif (#dc3545), vert sapin, or
- **Typographie** : Poppins pour une lecture moderne
- **Icônes** : Thème de Noël et solidarité
- **Animations** : Compte à rebours dynamique vers Noël

## � Statistiques temps réel

Le système suit automatiquement :
- Progression globale de la collecte
- Performance par équipe et bénévole
- Couverture géographique
- Tendances et objectifs

## 🔐 Sécurité et accès

- **Authentification** par nom d'équipe
- **Restriction d'accès** : bénévoles limités à leurs rues
- **Données locales** : pas de transmission externe
- **Sauvegarde automatique** des progressions

## 🤝 Contribution

GuignoMap est développé pour la Guignolée de Mascouche. Pour toute suggestion ou amélioration, contactez l'équipe organisatrice.

---

**Joyeuses Fêtes et bonne Guignolée 2025 ! 🎄🎁**
2. **Consultez votre liste** de rues assignées
3. **Commencez une rue** :
   - Sélectionnez la rue dans la liste
   - Changez le statut de "À faire" à "En cours"
4. **Pendant la collecte** :
   - Ajoutez des notes pour les adresses spéciales
   - Ex: "145 - Famille absente, denrées déposées"
5. **Terminez la rue** :
   - Une fois la rue complète, changez le statut à "Terminée"
6. **Passez à la rue suivante**

### 🆘 Que faire si...

#### ❓ **Je ne vois pas mes rues**
- Vérifiez que vous êtes connecté comme bénévole
- Demandez au superviseur si des rues vous ont été assignées

#### ❓ **Je ne peux pas me connecter**
- Vérifiez votre code d'équipe et mot de passe
- Contactez le superviseur pour confirmation

#### ❓ **La carte ne s'affiche pas**
- Actualisez la page (F5)
- Le superviseur peut reconstruire les données dans l'onglet Tech

#### ❓ **Je veux voir toute la ville**
- Seuls les superviseurs voient toute la carte
- Les bénévoles ne voient que leurs rues assignées

### 💡 Conseils pratiques

#### Pour les **superviseurs** :
- Créez les équipes AVANT d'assigner des rues
- Assignez des secteurs logiques (ex: même quartier)
- Consultez régulièrement l'onglet "Vue d'ensemble" pour le suivi
- Exportez les données à la fin pour les rapports

#### Pour les **bénévoles** :
- Changez le statut dès que vous commencez une rue
- Ajoutez des notes pour les situations particulières
- N'oubliez pas de marquer "Terminée" quand c'est fini
- Utilisez l'auto-refresh pour voir les mises à jour des autres équipes

### 🎨 Interface rapide
- **Menu gauche** : Navigation principale
- **Carte centrale** : Vue géographique avec couleurs
- **Légende en bas à droite** : Explication des couleurs et statistiques
- **Auto-refresh** : Active le rafraîchissement automatique toutes les 15 secondes

## 🔐 Connexion

### Superviseur
- **Portail** : 🎯 Superviseur
- **Mot de passe** : `admin123`
- **Fonctions** : Gestion complète + opérations techniques

### Bénévoles
- **Portail** : 👥 Bénévole
- **Identifiants** : Créés par le superviseur

## 📁 Structure du projet

```
GuignoMap/
├── guignomap/
│   ├── app.py              # Application principale
│   ├── db.py               # Gestion base de données robuste
│   ├── osm.py              # Intégration OpenStreetMap + adresses
│   ├── guigno_map.db       # Base SQLite
│   ├── osm_cache.json      # Cache géométries
│   ├── osm_addresses.json  # Cache adresses OSM
│   └── assets/
│       ├── styles.css      # Styles personnalisés
│       ├── logo.png        # Logo du Relais
│       └── banner.png      # Bannière (optionnel)
├── .streamlit/
│   └── config.toml         # Configuration Streamlit
├── requirements.txt        # Dépendances Python
└── README.md              # Documentation
```

## 🛠️ Technologies

- **Frontend** : Streamlit + CSS personnalisé
- **Backend** : Python + SQLite avec gestion d'erreurs
- **Cartes** : Folium + OpenStreetMap + API Overpass
- **Données** : Pandas + Overpy avec validation robuste

## 📊 Fonctionnalités détaillées

### Pour les Superviseurs
- Vue d'ensemble avec carte complète de Mascouche
- Gestion des équipes avec création/suppression
- Assignation intelligente des rues
- Export des rapports (rues + notes)
- **Onglet Tech** protégé par PIN pour :
  - Reconstruction du cache géométrique OSM
  - Import/mise à jour des adresses depuis OSM
  - Gestion d'erreurs avancée avec fallback
- Visualisation complète : autoroutes, rues principales, voies privées
- Statistiques en temps réel avec compteurs dynamiques

### Pour les Bénévoles
- Interface dédiée à leur tournée assignée
- Ajout de notes par adresse civique
- Mise à jour du statut des rues (à faire → en cours → terminée)
- Consultation des notes existantes
- Carte centrée sur leur zone de travail
- Ajout de notes par adresse
- Mise à jour du statut des rues
- Suivi en temps réel
- Carte centrée automatiquement sur la zone de travail
- Interface fluide avec rechargement intelligent des données
- **Visibilité totale** des voies de collecte (y compris voies privées)

## 🎨 Thème visuel

Interface moderne aux couleurs du **Relais de Mascouche** :
- Rouge bordeaux (#8B0000)
- Or (#FFD700)
- Design responsive
- Animations fluides

### Légende de la carte améliorée
- 🟢 **Vert** : Rues terminées
- � **Orange** : Rues en cours
- 🔴 **Rouge** : Rues à faire
- **Lignes pleines** : Rues assignées à une équipe
- **Lignes pointillées** : Rues non assignées
- **Compteurs dynamiques** : Total, assignées, non assignées
- **Marqueur centre-ville** : Point de référence Mascouche

## 🚧 Développement

### Base de données renforcée
- Tables : `streets`, `teams`, `notes`, `activity_log`, `addresses`
- Import automatique depuis OpenStreetMap avec validation
- Gestion d'erreurs et création automatique des rues manquantes
- Données de test intégrées et fallback robuste

### Système OSM révolutionnaire v3.1
- **Couverture maximale** : TOUTES les voies nommées + autoroutes (ref)
- **Requête optimisée** : `highway+name OU highway+ref`
- **Cache multi-niveaux** : géométries + adresses OSM
- **Fallback étendu** : 19 voies principales de Mascouche
- **Gestion d'erreurs** : validation, retry, récupération automatique
- **Import adresses** : numéros civiques avec tri intelligent
- **Performance** : cache Streamlit sensible aux modifications

### Couverture des voies complète
- 🛣️ **Autoroutes** : A-25, A-640 (via ref)
- 🏘️ **Voies principales** : Montée Masson, Chemin Sainte-Marie
- 🚗 **Voies résidentielles** : toutes les rues nommées
- 🏠 **Voies d'accès** : service, private roads
- 🔚 **Impasses et allées** : couverture totale
- ✅ **Inclusions** : TOUT sauf limitation technique OSM

### Améliorations critiques v3.1
- **🐛 Fix create_map()** : Gestion robuste des colonnes DataFrame
- **🔧 Fix build_addresses_cache()** : Validation types et tri intelligent  
- **🛡️ Fix import_addresses_from_cache()** : Création automatique des rues
- **⚡ Fix list_streets()** : COALESCE pour éviter les NULL
- **🎯 UI améliorée** : Limites géographiques et zoom adaptatif
- **📊 Statistiques** : Compteurs en temps réel dans la légende

### Architecture technique
- **Frontend** : Streamlit avec gestion d'erreur globale
- **Géolocalisation** : API Overpass OSM avec requête universelle
- **Données** : SQLite + cache JSON double (géo + adresses)
- **Couverture** : Système d'inclusion universelle (name + ref)
- **Robustesse** : Fallback à tous les niveaux avec validation

## 📝 Changelog v3.3

### 🎄 Thème Guignolée festif
- **Header moderne** : Design spécial Guignolée 2025 avec dégradé rouge/vert
- **Animations** : Flocons de neige CSS pour ambiance festive
- **Branding** : "🎅 GUIGNOLÉE 2025 🎁" avec police Manrope
- **Stats temps réel** : Progression visible directement dans le header
- **Support logo** : Détection automatique du logo Guignolée

### 🖼️ Sidebar avec logo intégré
- **Logo professionnel** : Espace dédié 200px en haut de sidebar
- **Positionnement optimal** : Collé au bord supérieur sans espace vide
- **Fallback élégant** : Placeholder festif avec dégradé Guignolée si logo absent
- **Navigation moderne** : Boutons stylisés Accueil/Bénévole/Gestionnaire
- **Branding complet** : Cohérence visuelle avec header festif

### 🎨 Effets de connexion festifs
- **Connexion bénévole** : Effet neige (`st.snow()`) pour ambiance hivernale
- **Connexion gestionnaire** : Effet neige unifié pour cohérence thématique
- **Messages personnalisés** : Accueil par équipe avec design festif

## 📝 Changelog v3.2

### 🗺️ Améliorations cartographiques majeures
- **Fonds multiples** : OSM France (détaillé), CARTO Voyager (moderne), Esri WorldStreetMap (professionnel)
- **Sélecteur de couches** : Contrôle dynamique pour changer de fond à la volée
- **Zoom optimisé** : zoom_start=13 pour meilleur cadrage de Mascouche
- **Performances** : prefer_canvas=True pour rendu fluide + contrôles complets
- **Visibilité** : weight 7/5 et opacity 0.9/0.7 pour meilleure lisibilité
- **Navigation** : zoom_control et scrollWheelZoom activés

### 🎯 Interface utilisateur
- **Terminologie** : "Code" → "Identifiant", "Nom" → "Équipe" pour clarté
- **UX** : Amélioration compréhension des champs par les utilisateurs

## 📝 Changelog v3.1

### 🔧 Corrections critiques
- **create_map()** : Gestion robuste colonnes pandas + limites géographiques
- **build_addresses_cache()** : Tri numérique intelligent + gestion d'erreurs
- **import_addresses_from_cache()** : Validation + création automatique rues
- **list_streets()** : COALESCE pour colonnes NULL + structure garantie
- **Requête OSM** : Inclusion autoroutes via ref + couverture maximale

### ✨ Nouvelles fonctionnalités  
- **Carte centrée Mascouche** : Bounds géographiques + zoom adaptatif
- **Légende avancée** : Statistiques temps réel + compteurs dynamiques
- **Marqueur centre-ville** : Point de référence visuel
- **Fallback étendu** : 19 voies principales + autoroutes
- **Gestion d'erreurs** : Messages informatifs + récupération automatique

## 📝 Support

Développé pour **Le Relais de Mascouche** - Collecte de denrées 2025

---
*Version 3.4 - Interface sidebar complète avec logo intégré et effets festifs*


================================================================================
FICHIER: README_VENV.md
DESCRIPTION: Documentation environnement virtuel
LIGNES: 65
================================================================================
# 🐍 GuignoMap - Instructions d'environnement virtuel

## 🎯 Avantages de l'environnement virtuel

✅ **Isolation des dépendances** : Évite les conflits entre projets  
✅ **Versions spécifiques** : Garantit la reproductibilité  
✅ **Facilité de déploiement** : Package complet et maîtrisé  

## 🚀 Utilisation

### Option 1 - Scripts automatiques (Recommandé)
```cmd
# Double-cliquez sur un de ces fichiers :
lancer_guignomap.bat          # Script Batch
lancer_guignomap.ps1          # Script PowerShell
```

### Option 2 - Activation manuelle
```cmd
# 1. Activer l'environnement virtuel
.venv\Scripts\activate

# 2. Lancer l'application
python -m streamlit run guignomap/app.py

# 3. Désactiver (optionnel)
deactivate
```

### Option 3 - PowerShell
```powershell
# 1. Activer l'environnement virtuel
.\.venv\Scripts\Activate.ps1

# 2. Lancer l'application
python -m streamlit run guignomap/app.py
```

## 🔧 Gestion des dépendances

### Installer de nouveaux packages
```cmd
# Avec l'environnement activé :
pip install nom_du_package

# Mettre à jour requirements.txt :
pip freeze > requirements.txt
```

### Recréer l'environnement
```cmd
# Supprimer l'ancien environnement
rmdir /s .venv

# Recréer
py -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

## 📊 Status actuel
- ✅ Environnement virtuel créé : `.venv/`
- ✅ Dépendances installées et testées
- ✅ Scripts de lancement mis à jour
- ✅ `.gitignore` configuré

================================================================================
FICHIER: requirements.txt
DESCRIPTION: Dépendances Python
LIGNES: 9
================================================================================
streamlit>=1.36.0
pandas>=2.2.0
folium==0.20.0
streamlit-folium>=0.21.0
overpy==0.7
bcrypt>=4.0.0
plotly>=5.18.0
xlsxwriter>=3.1.0
reportlab>=4.0.0


================================================================================
SECTION 2: SCRIPTS DE LANCEMENT WINDOWS
================================================================================

================================================================================
FICHIER: lancer_guignomap.bat
DESCRIPTION: Script de lancement Batch Windows
LIGNES: 21
================================================================================
@echo off
echo ========================================
echo       GuignoMap - Relais de Mascouche
echo ========================================
echo.
echo Activation de l'environnement virtuel...
echo.

REM Change vers le répertoire de l'application
cd /d "%~dp0"

REM Active l'environnement virtuel
call .venv\Scripts\activate

echo Lancement de l'application...
echo.

REM Lance Streamlit avec l'application
python -m streamlit run guignomap/app.py --server.port 8501 --server.headless true

pause

================================================================================
FICHIER: lancer_guignomap.ps1
DESCRIPTION: Script de lancement PowerShell Windows
LIGNES: 23
================================================================================
# GuignoMap - Script de lancement PowerShell
# Relais de Mascouche

Write-Host "========================================" -ForegroundColor Green
Write-Host "       GuignoMap - Relais de Mascouche" -ForegroundColor Green  
Write-Host "========================================" -ForegroundColor Green
Write-Host ""
Write-Host "Activation de l'environnement virtuel..." -ForegroundColor Yellow
Write-Host ""

# Change vers le répertoire de l'application
Set-Location $PSScriptRoot

# Active l'environnement virtuel
& .\.venv\Scripts\Activate.ps1

Write-Host "Lancement de l'application..." -ForegroundColor Yellow
Write-Host ""

# Lance Streamlit avec l'application
& python -m streamlit run guignomap/app.py --server.port 8501 --server.headless true

Read-Host "Appuyez sur Entrée pour fermer..."


================================================================================
SECTION 3: CODE SOURCE PRINCIPAL
================================================================================

================================================================================
FICHIER: guignomap/app.py
DESCRIPTION: Application Streamlit principale
LIGNES: 1690
================================================================================
"""
Guigno-Map - Application de gestion de collecte de denrées
Le Relais de Mascouche
Version 3.0 - Production
"""

from pathlib import Path
import time
from datetime import datetime
import pandas as pd
import streamlit as st
import folium
from streamlit_folium import st_folium

# Import des modules locaux
import db
from osm import build_geometry_cache, load_geometry_cache, build_addresses_cache, load_addresses_cache, CACHE_FILE

# Configuration des chemins
DB_PATH = Path(__file__).parent / "guigno_map.db"
ASSETS = Path(__file__).parent / "assets"

# Configuration Streamlit
st.set_page_config(
    page_title="Guigno-Map | Relais de Mascouche",
    page_icon="🎁",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialisation session
if "auth" not in st.session_state:
    st.session_state.auth = None

# ============================================
# COMPOSANTS UI
# ============================================

def inject_css():
    """Charge le CSS depuis le fichier externe"""
    css_file = ASSETS / "styles.css"
    if css_file.exists():
        css = css_file.read_text(encoding="utf-8")
        st.markdown(f"<style>{css}</style>", unsafe_allow_html=True)

def render_header():
    """Header moderne avec logo Guignolée et design festif"""
    
    # Container principal avec fond festif
    st.markdown("""
    <div style="
        background: linear-gradient(135deg, #c41e3a 0%, #165b33 100%);
        border-radius: 20px;
        padding: 2rem;
        margin-bottom: 2rem;
        position: relative;
        overflow: hidden;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    ">
        <!-- Flocons de neige animés en CSS -->
        <div style="position: absolute; width: 100%; height: 100%; opacity: 0.1;">
            <span style="position: absolute; top: 10%; left: 10%; font-size: 2rem;">❄️</span>
            <span style="position: absolute; top: 20%; left: 80%; font-size: 1.5rem;">❄️</span>
            <span style="position: absolute; top: 60%; left: 30%; font-size: 1.8rem;">❄️</span>
        </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([2, 5, 2])
    
    with col1:
        # Logo Guignolée
        if (ASSETS / "guignolee.png").exists():
            st.image(str(ASSETS / "guignolee.png"), width=150)
    
    with col2:
        st.markdown("""
        <div style="text-align: center;">
            <h1 style="
                color: white;
                font-family: 'Manrope', sans-serif;
                font-size: 2.5rem;
                margin: 0;
                text-shadow: 3px 3px 6px rgba(0,0,0,0.5);
                letter-spacing: 2px;
            ">🎅 GUIGNOLÉE 2025 🎁</h1>
            <p style="
                color: #FFD700;
                font-size: 1.2rem;
                margin: 0.5rem 0 0 0;
                font-weight: 600;
            ">Le Relais de Mascouche - 1er décembre</p>
            <p style="
                color: rgba(255,255,255,0.9);
                font-size: 1rem;
                margin-top: 0.5rem;
            ">Système de gestion de collecte</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        # Stats en temps réel
        stats = db.extended_stats(st.session_state.get('conn'))
        progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
        
        st.markdown(f"""
        <div style="
            background: rgba(255,255,255,0.2);
            border-radius: 15px;
            padding: 1rem;
            text-align: center;
        ">
            <div style="color: #FFD700; font-size: 2rem; font-weight: bold;">
                {progress:.0f}%
            </div>
            <div style="color: white; font-size: 0.9rem;">
                Complété
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

def render_login_card(role="benevole", conn=None):
    """Carte de connexion moderne avec design festif"""
    
    # Container de connexion stylisé
    st.markdown("""
    <div style="
        max-width: 400px;
        margin: 3rem auto;
        background: linear-gradient(135deg, rgba(255,255,255,0.1), rgba(255,255,255,0.05));
        backdrop-filter: blur(10px);
        border: 2px solid rgba(255,215,0,0.3);
        border-radius: 20px;
        padding: 2rem;
        box-shadow: 0 20px 40px rgba(0,0,0,0.3);
    ">
    """, unsafe_allow_html=True)
    
    # Icône et titre
    if role == "superviseur" or role == "gestionnaire":
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <div style="font-size: 3rem;">👔</div>
            <h2 style="color: #FFD700; margin: 1rem 0;">Espace Gestionnaire</h2>
            <p style="color: #cbd5e1;">Gérez la collecte et les équipes</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_gestionnaire", clear_on_submit=False):
            password = st.text_input(
                "🔐 Mot de passe",
                type="password",
                placeholder="Entrez le mot de passe gestionnaire"
            )
            
            col1, col2, col3 = st.columns([1,2,1])
            with col2:
                submit = st.form_submit_button(
                    "🚀 Connexion",
                    use_container_width=True
                )
            
            if submit:
                if db.verify_team(conn, "ADMIN", password):
                    st.session_state.auth = {"role": "supervisor", "team_id": "ADMIN"}
                    st.success("✅ Bienvenue dans l'espace gestionnaire!")
                    st.snow()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("❌ Mot de passe incorrect")
    
    else:  # Bénévole
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <div style="font-size: 3rem;">🎅</div>
            <h2 style="color: #FFD700; margin: 1rem 0;">Espace Bénévole</h2>
            <p style="color: #cbd5e1;">Accédez à vos rues assignées</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_benevole", clear_on_submit=False):
            col1, col2 = st.columns(2)
            
            with col1:
                team_id = st.text_input(
                    "👥 Identifiant d'équipe",
                    placeholder="Ex: EQ001"
                )
            
            with col2:
                password = st.text_input(
                    "🔐 Mot de passe",
                    type="password",
                    placeholder="Mot de passe équipe"
                )
            
            col1, col2, col3 = st.columns([1,2,1])
            with col2:
                submit = st.form_submit_button(
                    "🎄 Connexion",
                    use_container_width=True
                )
            
            if submit:
                if db.verify_team(conn, team_id, password):
                    st.session_state.auth = {"role": "volunteer", "team_id": team_id}
                    st.success(f"✅ Bienvenue équipe {team_id}!")
                    st.snow()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("❌ Identifiants incorrects")
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    # Aide en bas
    st.markdown("""
    <div style="text-align: center; margin-top: 2rem; color: #8b92a4;">
        <small>
        Besoin d'aide? Contactez votre gestionnaire<br>
        📞 450-474-4133
        </small>
    </div>
    """, unsafe_allow_html=True)

def render_metrics(stats):
    """Affiche les métriques principales"""
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Rues", stats['total'])
    
    with col2:
        st.metric("Rues Terminées", stats['done'])
    
    with col3:
        st.metric("En Cours", stats.get('partial', 0))
    
    with col4:
        st.metric("Progression", f"{progress:.1f}%")

def render_dashboard_gestionnaire(conn, geo):
    """Dashboard moderne pour gestionnaires avec KPIs visuels"""
    
    # KPIs principaux en cartes colorées
    stats = db.extended_stats(conn)
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    st.markdown("### 📊 Tableau de bord en temps réel")
    
    # Ligne de KPIs avec icônes festives
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #22c55e, #16a34a);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(34,197,94,0.3);
        ">
            <div style="font-size: 2.5rem;">🏘️</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats['total']}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Total Rues</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(59,130,246,0.3);
        ">
            <div style="font-size: 2.5rem;">✅</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats['done']}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Terminées</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #f59e0b, #d97706);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(245,158,11,0.3);
        ">
            <div style="font-size: 2.5rem;">🚶</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats.get('partial', 0)}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">En cours</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        # Nombre d'équipes actives
        teams_count = len(db.teams(conn))
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #8b5cf6, #7c3aed);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(139,92,246,0.3);
        ">
            <div style="font-size: 2.5rem;">👥</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{teams_count}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Équipes</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col5:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #c41e3a, #165b33);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(196,30,58,0.3);
        ">
            <div style="font-size: 2.5rem;">🎯</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{progress:.0f}%</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Progression</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Barre de progression visuelle
    st.markdown("### 🎄 Progression globale")
    st.progress(progress / 100)
    
    # Graphique par secteur (si disponible)
    st.markdown("### 📈 Performance par équipe")
    try:
        teams_stats = db.stats_by_team(conn)
        if not teams_stats.empty:
            # Graphique en barres colorées
            import plotly.express as px
            fig = px.bar(
                teams_stats, 
                x='team', 
                y='progress',
                color='progress',
                color_continuous_scale=['#ef4444', '#f59e0b', '#22c55e'],
                labels={'team': 'Équipe', 'progress': 'Progression (%)'},
                title="Performance des équipes"
            )
            fig.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Aucune statistique d'équipe disponible")
    except Exception as e:
        st.warning("Graphiques non disponibles (module plotly manquant)")
        # Fallback vers un tableau simple
        try:
            teams_stats = db.stats_by_team(conn)
            if not teams_stats.empty:
                st.dataframe(teams_stats, use_container_width=True)
        except:
            st.info("Aucune statistique d'équipe disponible")

def create_map(df, geo):
    """Crée la carte Folium centrée sur Mascouche avec toutes les rues"""
    # Limites de Mascouche
    bounds = {
        "north": 45.78,
        "south": 45.70,
        "east": -73.55,
        "west": -73.70
    }
    center = [(bounds["north"] + bounds["south"]) / 2, 
              (bounds["east"] + bounds["west"]) / 2]
    
    # Créer la carte
    m = folium.Map(
        location=center,
        zoom_start=13,  # Zoom optimisé pour voir toute la ville
        tiles="https://{s}.tile.openstreetmap.fr/osmfr/{z}/{x}/{y}.png",
        attr='© OpenStreetMap France',
        control_scale=True,
        max_bounds=True,
        min_zoom=11,
        max_zoom=18,
        prefer_canvas=True,
        zoom_control=True,
        scrollWheelZoom=True
    )
    
    # Ajouter plusieurs couches de fond
    folium.TileLayer(
        tiles='https://{s}.tile.openstreetmap.fr/osmfr/{z}/{x}/{y}.png',
        attr='© OpenStreetMap France',
        name='OSM France (Détaillé)',
        overlay=False,
        control=True
    ).add_to(m)

    folium.TileLayer(
        tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager/{z}/{x}/{y}.png',
        attr='© CARTO',
        name='CARTO Voyager',
        overlay=False,
        control=True
    ).add_to(m)

    folium.TileLayer(
        tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Street_Map/MapServer/tile/{z}/{y}/{x}',
        attr='© Esri',
        name='Esri WorldStreetMap',
        overlay=False,
        control=True
    ).add_to(m)

    # Ajouter le contrôle des couches
    folium.LayerControl().add_to(m)
    
    # Définir les limites de la carte sur Mascouche
    m.fit_bounds([[bounds["south"], bounds["west"]], 
                  [bounds["north"], bounds["east"]]])
    
    if not geo:
        st.warning("Aucune donnée géométrique disponible")
        return m
    
    # Construire le lookup des infos DB
    street_info = {}
    if not df.empty:
        for idx, row in df.iterrows():
            name = str(row['name']) if 'name' in df.columns else ''
            status = row['status'] if 'status' in df.columns and pd.notna(row['status']) else 'a_faire'
            team = row['team'] if 'team' in df.columns and pd.notna(row['team']) else ''
            notes = str(row['notes']) if 'notes' in df.columns and pd.notna(row['notes']) else '0'
            
            street_info[name] = {
                'status': status,
                'team': str(team).strip() if team else '',
                'notes': notes
            }
    
    # Couleurs par statut
    status_colors = {
        'terminee': '#22c55e',  # Vert
        'en_cours': '#f59e0b',  # Orange
        'a_faire': '#ef4444'    # Rouge
    }
    
    # Compteurs pour stats
    stats = {"total": 0, "assigned": 0, "unassigned": 0}
    
    # Ajouter TOUTES les rues de la géométrie
    for name, paths in geo.items():
        stats["total"] += 1
        
        # Info depuis DB ou défaut (rouge pointillé)
        info = street_info.get(name, {
            'status': 'a_faire',
            'team': '',
            'notes': '0'
        })
        
        status = info['status']
        team = info['team']
        notes = info['notes']
        
        # Style: TOUJOURS pointillé si pas d'équipe
        has_team = bool(team)
        color = status_colors.get(status, '#ef4444')  # Rouge par défaut
        opacity = 0.9 if has_team else 0.7
        dash = None if has_team else '8,12'  # Pointillés si non assigné
        weight = 7 if has_team else 5
        
        if has_team:
            stats["assigned"] += 1
        else:
            stats["unassigned"] += 1
        
        # Tooltip informatif
        tooltip_html = f"""
        <div style='font-family: sans-serif'>
            <strong style='font-size: 14px'>{name}</strong><br>
            <span style='color: {color}'>● Statut: {status.replace('_', ' ').title()}</span><br>
            <span>📋 Équipe: {team if team else '⚠️ NON ASSIGNÉE'}</span><br>
            <span>📝 Notes: {notes}</span>
        </div>
        """
        
        # Ajouter chaque segment de la rue
        for path in paths:
            if path and len(path) >= 2:
                folium.PolyLine(
                    path,
                    color=color,
                    weight=weight,
                    opacity=opacity,
                    dash_array=dash,
                    tooltip=folium.Tooltip(tooltip_html, sticky=True)
                ).add_to(m)
    
    # Ajouter un marqueur au centre-ville
    folium.Marker(
        [45.7475, -73.6005],
        popup="Centre-ville de Mascouche",
        tooltip="Centre-ville",
        icon=folium.Icon(color='red', icon='info-sign')
    ).add_to(m)
    
    # Légende améliorée
    legend_html = f'''
    <div style="position: fixed; bottom: 50px; right: 50px; width: 220px;
                background: white; z-index:9999; font-size:14px;
                border: 2px solid #8B0000; border-radius: 10px; padding: 15px;
                box-shadow: 0 0 15px rgba(0,0,0,0.2)">
        <h4 style="margin: 0 0 10px 0; color: #8B0000;">Légende</h4>
        <div><span style="background:#22c55e; width:30px; height:3px; display:inline-block;"></span> Terminée</div>
        <div><span style="background:#f59e0b; width:30px; height:3px; display:inline-block;"></span> En cours</div>
        <div><span style="background:#ef4444; width:30px; height:3px; display:inline-block;"></span> À faire</div>
        <hr style="margin: 8px 0;">
        <div><span style="border-bottom: 3px dashed #666; width:30px; display:inline-block;"></span> Non assignée</div>
        <div><span style="border-bottom: 3px solid #666; width:30px; display:inline-block;"></span> Assignée</div>
        <hr style="margin: 8px 0;">
        <small>
            <strong>Total:</strong> {stats["total"]} voies<br>
            <strong>Assignées:</strong> {stats["assigned"]}<br>
            <strong>Non assignées:</strong> {stats["unassigned"]}
        </small>
    </div>
    '''
    m.get_root().html.add_child(folium.Element(legend_html))
    
    return m


# ============================================
# UTILITAIRES EXPORT
# ============================================

def export_excel_professionnel(conn):
    """Export Excel avec mise en forme professionnelle"""
    try:
        from reports import ReportGenerator
        generator = ReportGenerator(conn)
        return generator.generate_excel()
    except ImportError:
        # Fallback si les dépendances ne sont pas installées
        return db.export_to_csv(conn)


# ============================================
# FONCTIONNALITÉS AVANCÉES
# ============================================

def detect_mobile():
    """Détecte si l'utilisateur est sur mobile"""
    try:
        # Récupérer les paramètres de l'URL pour forcer le mode mobile
        query_params = st.experimental_get_query_params()
        if 'mobile' in query_params:
            return True
        
        # Mobile-first approach pour l'instant
        return True
    except:
        return False

def show_notification(message, type="success"):
    """Affiche une notification stylisée"""
    icons = {
        "success": "✅",
        "error": "❌",
        "warning": "⚠️",
        "info": "ℹ️"
    }
    colors = {
        "success": "#22c55e",
        "error": "#ef4444", 
        "warning": "#f59e0b",
        "info": "#3b82f6"
    }
    
    st.markdown(f"""
    <div style="
        position: fixed;
        top: 20px;
        right: 20px;
        background: {colors[type]};
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 10px;
        box-shadow: 0 5px 15px rgba(0,0,0,0.3);
        z-index: 9999;
        animation: slideIn 0.3s ease-out;
    ">
        <strong>{icons[type]} {message}</strong>
    </div>
    <style>
    @keyframes slideIn {{
        from {{ transform: translateX(100%); opacity: 0; }}
        to {{ transform: translateX(0); opacity: 1; }}
    }}
    </style>
    """, unsafe_allow_html=True)

def show_team_badges(conn, team_id):
    """Affiche les badges de réussite de l'équipe"""
    try:
        df = db.list_streets(conn, team=team_id)
        done = len(df[df['status'] == 'terminee'])
        total = len(df)
        
        badges = []
        if done >= 1:
            badges.append("🏆 Première rue!")
        if done >= total * 0.25:
            badges.append("🥉 25% complété")
        if done >= total * 0.5:
            badges.append("🥈 50% complété")
        if done >= total * 0.75:
            badges.append("🥇 75% complété")
        if done == total:
            badges.append("🌟 CHAMPION!")
        
        if badges:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #FFD700, #FFA500);
                padding: 1rem;
                border-radius: 10px;
                text-align: center;
                margin: 1rem 0;
            ">
                <strong>Vos badges:</strong><br>
                <div style="font-size: 2rem; margin-top: 0.5rem;">
                    {' '.join(badges)}
                </div>
            </div>
            """, unsafe_allow_html=True)
    except:
        pass

def generate_sms_list(conn):
    """Génère une liste de téléphones pour SMS de groupe"""
    try:
        # Cette fonction nécessiterait une table de téléphones
        # Pour l'instant, retourne un exemple
        return "# Liste des téléphones bénévoles\n# 450-XXX-XXXX\n# 438-XXX-XXXX"
    except:
        return "Liste non disponible"

def create_festive_map(df, geo):
    """Carte avec thème festif de Noël"""
    center = [45.7475, -73.6005]
    
    m = folium.Map(
        location=center,
        zoom_start=13,
        tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Street_Map/MapServer/tile/{z}/{y}/{x}',
        attr='© Esri',
        control_scale=True
    )
    
    # Marqueur spécial pour le Relais
    folium.Marker(
        [45.7475, -73.6005],
        popup="🎁 Le Relais de Mascouche",
        tooltip="Point de départ de la Guignolée",
        icon=folium.Icon(color='red', icon='gift', prefix='fa')
    ).add_to(m)
    
    # Construction du lookup
    street_info = {}
    if not df.empty:
        for _, row in df.iterrows():
            name = str(row['name']) if 'name' in df.columns else ''
            street_info[name] = {
                'status': row.get('status', 'a_faire'),
                'team': row.get('team', ''),
                'notes': str(row.get('notes', 0))
            }
    
    # Couleurs festives
    status_colors = {
        'terminee': '#165b33',  # Vert sapin
        'en_cours': '#FFD700',   # Or
        'a_faire': '#c41e3a'     # Rouge Noël
    }
    
    for name, paths in geo.items():
        info = street_info.get(name, {'status': 'a_faire', 'team': '', 'notes': '0'})
        
        color = status_colors.get(info['status'], '#c41e3a')
        team = info['team']
        opacity = 0.9 if team else 0.5
        dash = None if team else '10,10'
        weight = 8 if team else 5
        
        tooltip_html = f"""
        <div style='font-family: sans-serif; font-size: 14px;'>
            <strong>{name}</strong><br>
            <span style='color: {color};'>● {info['status'].replace('_', ' ').title()}</span><br>
            👥 {team if team else 'Non assignée'}<br>
            📝 {info['notes']} notes
        </div>
        """
        
        for path in paths:
            if path and len(path) >= 2:
                folium.PolyLine(
                    path,
                    color=color,
                    weight=weight,
                    opacity=opacity,
                    dash_array=dash,
                    tooltip=folium.Tooltip(tooltip_html, sticky=True)
                ).add_to(m)
    
    # Légende festive
    legend_html = '''
    <div style="position: fixed; bottom: 50px; right: 50px; width: 220px;
                background: linear-gradient(135deg, white, #f0f0f0);
                border: 3px solid #c41e3a; border-radius: 15px; padding: 15px;
                box-shadow: 0 5px 20px rgba(0,0,0,0.3);">
        <h4 style="margin: 0 0 10px 0; color: #c41e3a; text-align: center;">
            🎄 Légende 🎄
        </h4>
        <div><span style="background:#165b33; width:30px; height:4px; display:inline-block;"></span> Collecte terminée</div>
        <div><span style="background:#FFD700; width:30px; height:4px; display:inline-block;"></span> En cours</div>
        <div><span style="background:#c41e3a; width:30px; height:4px; display:inline-block;"></span> À faire</div>
        <hr style="margin: 8px 0; border-color: #c41e3a;">
        <div><span style="border-bottom: 4px dashed #999; width:30px; display:inline-block;"></span> Non assignée</div>
    </div>
    '''
    m.get_root().html.add_child(folium.Element(legend_html))
    
    return m

def page_export_gestionnaire(conn):
    """Section export avec formats multiples"""
    
    st.markdown("### 📊 Centre d'export des données")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>� Rapport PDF</h4>
            <p><small>Format professionnel pour présentation</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            from reports import ReportGenerator
            generator = ReportGenerator(conn)
            pdf_data = generator.generate_pdf()
            st.download_button(
                "📥 Télécharger PDF",
                pdf_data,
                "rapport_guignolee_2025.pdf",
                "application/pdf",
                use_container_width=True
            )
        except ImportError:
            st.button("PDF (Installer reportlab)", disabled=True, use_container_width=True)
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>📊 Excel détaillé</h4>
            <p><small>Avec graphiques et mise en forme</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            excel_data = export_excel_professionnel(conn)
            st.download_button(
                "📥 Télécharger Excel",
                excel_data,
                "guignolee_2025.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        except:
            st.button("Excel (Non disponible)", disabled=True, use_container_width=True)
    
    with col3:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>📱 Liste SMS</h4>
            <p><small>Téléphones des bénévoles</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        sms_list = generate_sms_list(conn)
        st.download_button(
            "📥 Liste téléphones",
            sms_list,
            "telephones_benevoles.txt",
            "text/plain",
            use_container_width=True
        )


# ============================================
# PAGES
# ============================================

def page_accueil(conn, geo):
    """Page d'accueil"""
    st.markdown("### 🎁 Bienvenue sur Guigno-Map!")
    st.info("Sélectionnez votre mode dans le menu de gauche pour commencer.")
    
    st.markdown("---")
    st.markdown("#### 📊 Aperçu de la collecte")
    
    stats = db.extended_stats(conn)
    render_metrics(stats)
    
    df_all = db.list_streets(conn)
    if not df_all.empty:
        m = create_map(df_all, geo)
        st_folium(m, height=800, width=None, returned_objects=[])

def page_accueil_v2(conn, geo):
    """Page d'accueil festive avec compte à rebours"""
    
    # Compte à rebours jusqu'au 1er décembre
    from datetime import datetime, timedelta
    target = datetime(2025, 12, 1, 8, 0, 0)
    now = datetime.now()
    diff = target - now
    
    if diff.days > 0:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #c41e3a, #165b33);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h2 style="color: #FFD700; margin: 0;">⏰ Compte à rebours Guignolée</h2>
            <div style="font-size: 3rem; color: white; margin: 1rem 0;">
                {diff.days} jours {diff.seconds//3600} heures
            </div>
            <p style="color: rgba(255,255,255,0.9);">avant le grand jour!</p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #FFD700, #FFA500);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h2 style="color: #c41e3a; margin: 0;">🎉 C'EST AUJOURD'HUI!</h2>
            <div style="font-size: 2rem; color: #165b33; margin: 1rem 0;">
                Bonne Guignolée 2025!
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # Hero section festif
    st.markdown("""
    <div style="
        text-align: center;
        padding: 3rem 1rem;
        background: linear-gradient(135deg, rgba(196,30,58,0.1), rgba(22,91,51,0.1));
        border-radius: 20px;
        margin-bottom: 2rem;
    ">
        <h1 style="font-size: 3rem; margin: 0;">🎄 Bienvenue sur Guigno-Map 🎄</h1>
        <p style="font-size: 1.3rem; color: #666; margin: 1rem 0;">
            Votre plateforme digitale pour la Guignolée 2025
        </p>
        <p style="color: #888;">
            Gérez efficacement votre collecte de denrées avec une interface moderne
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Stats visuelles améliorées
    stats = db.extended_stats(conn)
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    st.markdown("### 📊 État de la collecte en temps réel")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #22c55e, #16a34a);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(34,197,94,0.3);
        ">
            <div style="font-size: 3rem;">🏘️</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats['total']}</div>
            <div>Total Rues</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(59,130,246,0.3);
        ">
            <div style="font-size: 3rem;">✅</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats['done']}</div>
            <div>Complétées</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #f59e0b, #d97706);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(245,158,11,0.3);
        ">
            <div style="font-size: 3rem;">🚶</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats.get('partial', 0)}</div>
            <div>En Cours</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #c41e3a, #165b33);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(196,30,58,0.3);
        ">
            <div style="font-size: 3rem;">🎯</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{progress:.0f}%</div>
            <div>Progression</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Barre de progression globale
    st.markdown("### 🎄 Progression globale de la collecte")
    st.progress(progress / 100)
    
    # Carte festive
    st.markdown("### 🗺️ Vue d'ensemble de Mascouche")
    df_all = db.list_streets(conn)
    if not df_all.empty:
        m = create_festive_map(df_all, geo)
        st_folium(m, height=750, width=None, returned_objects=[])
    
    # CSS pour réduire l'espace après la carte
    st.markdown("""
    <style>
    div[data-testid="stVerticalBlock"] > div:has(iframe) {
        margin-bottom: 0 !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Call to action
    st.markdown("""
    <div style="
        text-align: center;
        padding: 2rem;
        background: linear-gradient(135deg, rgba(255,215,0,0.1), rgba(255,215,0,0.05));
        border: 2px solid rgba(255,215,0,0.3);
        border-radius: 15px;
        margin-top: 1rem;
    ">
        <h3>🎅 Prêt à participer ?</h3>
        <p>Choisissez votre rôle dans le menu de gauche pour commencer</p>
        <p style="font-size: 0.9rem; color: #666;">
            Bénévoles : Accédez à vos rues assignées<br>
            Gestionnaires : Supervisez toute la collecte
        </p>
    </div>
    """, unsafe_allow_html=True)

def page_benevole(conn, geo):
    """Interface bénévole moderne avec vue limitée"""
    
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        render_login_card("benevole", conn)
        return
    
    team_id = st.session_state.auth["team_id"]
    
    # Header d'équipe personnalisé
    st.markdown(f"""
    <div style="
        background: linear-gradient(135deg, #165b33, #c41e3a);
        padding: 1.5rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
    ">
        <h2 style="color: white; margin: 0;">🎅 Équipe {team_id}</h2>
        <p style="color: #FFD700; margin: 0.5rem 0 0 0;">Bonne collecte!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Stats de l'équipe
    df_team = db.list_streets(conn, team=team_id)
    if df_team.empty:
        st.warning("Aucune rue assignée. Contactez votre superviseur.")
        return
    
    done = len(df_team[df_team['status'] == 'terminee'])
    total = len(df_team)
    progress = (done / total * 100) if total > 0 else 0
    
    # Mini dashboard équipe
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("📍 Vos rues", total)
    with col2:
        st.metric("✅ Complétées", done)
    with col3:
        st.metric("🎯 Progression", f"{progress:.0f}%")
    
    # Système de badges
    show_team_badges(conn, team_id)
    
    # Barre de progression
    st.progress(progress / 100)
    
    # Tabs modernisés
    tab1, tab2, tab3 = st.tabs(["🗺️ Ma carte", "📝 Collecte", "📊 Historique"])
    
    with tab1:
        # CARTE LIMITÉE AUX RUES DE L'ÉQUIPE
        st.markdown("### Vos rues assignées")
        
        # Créer une carte avec SEULEMENT les rues de l'équipe
        m = folium.Map(
            location=[45.7475, -73.6005],
            zoom_start=14,
            tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager/{z}/{x}/{y}.png',
            attr='© CARTO'
        )
        
        # Filtrer geo pour n'afficher QUE les rues de l'équipe
        team_streets = df_team['name'].tolist()
        
        for street_name in team_streets:
            if street_name in geo:
                status = df_team[df_team['name'] == street_name]['status'].iloc[0]
                
                # Couleurs selon statut
                colors = {
                    'terminee': '#22c55e',
                    'en_cours': '#f59e0b',
                    'a_faire': '#ef4444'
                }
                color = colors.get(status, '#ef4444')
                
                # Ajouter les segments de cette rue
                for path in geo[street_name]:
                    if path and len(path) >= 2:
                        folium.PolyLine(
                            path,
                            color=color,
                            weight=8,  # Plus épais pour mobile
                            opacity=0.9,
                            tooltip=f"{street_name} - {status.replace('_', ' ').title()}"
                        ).add_to(m)
        
        # Centrer sur les rues de l'équipe
        if team_streets and team_streets[0] in geo:
            first_street = geo[team_streets[0]][0]
            if first_street:
                m.location = first_street[0]
        
        st_folium(m, height=650, width=None, returned_objects=[])
    
    with tab2:
        st.markdown("### 📋 Checklist de collecte")
        
        # Liste interactive des rues
        for _, row in df_team.iterrows():
            street = row['name']
            status = row['status']
            notes_count = row.get('notes', 0)
            
            # Carte de rue stylisée
            status_emoji = {'terminee': '✅', 'en_cours': '🚶', 'a_faire': '⭕'}
            status_color = {'terminee': '#22c55e', 'en_cours': '#f59e0b', 'a_faire': '#ef4444'}
            
            with st.expander(f"{status_emoji.get(status, '⭕')} **{street}** ({notes_count} notes)"):
                
                # Changement rapide de statut
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("⭕ À faire", key=f"todo_{street}", use_container_width=True):
                        db.set_status(conn, street, 'a_faire')
                        st.rerun()
                with col2:
                    if st.button("🚶 En cours", key=f"progress_{street}", use_container_width=True):
                        db.set_status(conn, street, 'en_cours')
                        st.rerun()
                with col3:
                    if st.button("✅ Terminée", key=f"done_{street}", use_container_width=True):
                        db.set_status(conn, street, 'terminee')
                        st.rerun()
                
                st.markdown("---")
                
                # Ajout de note rapide
                st.markdown("**Ajouter une note:**")
                with st.form(f"note_{street}", clear_on_submit=True):
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        num = st.text_input("N°", placeholder="123")
                    with col2:
                        note = st.text_input("Note", placeholder="Personne absente")
                    
                    if st.form_submit_button("➕ Ajouter"):
                        if num and note:
                            db.add_note_for_address(conn, street, team_id, num, note)
                            st.success("Note ajoutée!")
                            st.rerun()
                
                # Notes existantes
                notes = db.get_street_addresses_with_notes(conn, street)
                if not notes.empty:
                    st.markdown("**Notes existantes:**")
                    for _, n in notes.iterrows():
                        st.markdown(f"• **{n['address_number']}** : {n['comment']}")
    
    with tab3:
        st.markdown("### 📊 Votre historique")
        try:
            notes = db.get_team_notes(conn, team_id)
            if not notes.empty:
                st.dataframe(notes, use_container_width=True)
            else:
                st.info("Aucune note encore")
        except:
            st.info("Historique non disponible")

def page_benevole_v2(conn, geo):
    """Interface bénévole moderne v2 - Alias pour compatibilité"""
    return page_benevole(conn, geo)

def page_gestionnaire_v2(conn, geo):
    """Interface gestionnaire moderne (ancien superviseur)"""
    st.header("👔 Tableau de Bord Gestionnaire")
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        render_login_card("gestionnaire", conn)
        return
    
    # Dashboard moderne
    render_dashboard_gestionnaire(conn, geo)
    
    # Tabs
    tabs = st.tabs([
        "📊 Vue d'ensemble",
        "👥 Équipes",
        "🗺️ Assignation",
        "📥 Export",
        "🛠 Tech"
    ])
    
    with tabs[0]:
        # Carte générale
        st.markdown("### Carte générale")
        df_all = db.list_streets(conn)
        if not df_all.empty:
            m = create_map(df_all, geo)
            st_folium(m, height=800, width=None, returned_objects=[])
        
        # Activité récente
        st.markdown("### Activité récente")
        try:
            recent = db.recent_activity(conn, limit=10)
            if not recent.empty:
                st.dataframe(recent, use_container_width=True)
            else:
                st.info("Aucune activité récente")
        except:
            st.info("Historique d'activité non disponible")
    
    with tabs[1]:
        # Gestion des équipes
        st.markdown("### Gestion des équipes")
        
        with st.expander("Créer une équipe"):
            with st.form("new_team", clear_on_submit=True):
                new_id = st.text_input("Identifiant")
                new_name = st.text_input("Équipe")
                new_pass = st.text_input("Mot de passe", type="password")
                
                if st.form_submit_button("Créer"):
                    if all([new_id, new_name, new_pass]):
                        if db.create_team(conn, new_id, new_name, new_pass):
                            st.success(f"Équipe {new_id} créée")
                            st.rerun()
        
        # Liste des équipes
        try:
            teams_df = db.get_all_teams(conn)
            if not teams_df.empty:
                st.dataframe(teams_df, use_container_width=True)
            else:
                st.info("Aucune équipe créée")
        except:
            st.info("Liste des équipes non disponible")
    
    with tabs[2]:
        # Assignation
        st.markdown("### Assignation des rues")
        
        try:
            unassigned = db.get_unassigned_streets(conn)
            
            if not unassigned.empty:
                with st.form("assign"):
                    team = st.selectbox("Équipe", db.teams(conn))
                    streets = st.multiselect("Rues", unassigned['name'].tolist())
                    
                    if st.form_submit_button("Assigner"):
                        if team and streets:
                            db.assign_streets_to_team(conn, streets, team)
                            st.success("Rues assignées!")
                            st.rerun()
            else:
                st.success("Toutes les rues sont assignées!")
        except:
            st.warning("Fonction d'assignation non disponible")
        
        # Tableau des assignations
        df_all = db.list_streets(conn)
        if not df_all.empty:
            st.dataframe(
                df_all[['name', 'sector', 'team', 'status']],
                use_container_width=True
            )
    
    with tabs[3]:
        # Export amélioré
        st.markdown("### Export des données")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.download_button(
                "📥 Export CSV Standard",
                db.export_to_csv(conn),
                "rapport_rues.csv",
                "text/csv",
                use_container_width=True
            )
        
        with col2:
            try:
                excel_data = export_excel_professionnel(conn)
                st.download_button(
                    "📊 Export Excel Pro",
                    excel_data,
                    "guignolee_2025_rapport.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            except:
                st.button("📊 Excel (Non disponible)", disabled=True, use_container_width=True)
        
        with col3:
            try:
                st.download_button(
                    "📝 Export Notes",
                    db.export_notes_csv(conn),
                    "rapport_notes.csv",
                    "text/csv",
                    use_container_width=True
                )
            except:
                st.button("📝 Notes (Non disponible)", disabled=True, use_container_width=True)

    with tabs[4]:
        st.markdown("### 🛠 Opérations techniques (protégées)")

        # -- PIN stocké dans secrets (config.toml -> [secrets] TECH_PIN="xxxx")
        try:
            TECH_PIN = st.secrets.get("TECH_PIN", "")
        except:
            TECH_PIN = ""  # Pas de fichier secrets.toml

        if "tech_ok" not in st.session_state:
            st.session_state.tech_ok = False

        if not st.session_state.tech_ok:
            pin = st.text_input("Entrer le PIN technique", type="password")
            if st.button("Déverrouiller"):
                if TECH_PIN and pin == TECH_PIN:
                    st.session_state.tech_ok = True
                    st.success("Accès technique déverrouillé.")
                    st.rerun()
                else:
                    st.error("PIN invalide.")
            st.stop()

        st.info("⚠️ Ces actions sont lourdes et n'affectent pas les statuts/notes. Elles régénèrent les caches OSM.")

        # --- Reconstruire le cache géométrique (lourd)
        with st.expander("🔄 Reconstruire cache OSM (géométries)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirm = st.checkbox("Je comprends les implications")
            with col2:
                safety = st.text_input('Écrire "REBUILD" pour confirmer')

            if st.button("Lancer la reconstruction"):
                if confirm and safety.strip().upper() == "REBUILD":
                    with st.spinner("Construction du cache…"):
                        build_geometry_cache()       # reconstruit le fichier osm_cache.json
                        st.cache_data.clear()        # purge cache Streamlit
                    st.success("✅ Cache OSM mis à jour (géométries).")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Reconstruire/Importer le cache des adresses
        with st.expander("📍 Mettre à jour les adresses (OSM)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirmA = st.checkbox("Je confirme")
            with col2:
                safetyA = st.text_input('Écrire "IMPORT" pour confirmer')

            if st.button("Lancer la mise à jour des adresses"):
                if confirmA and safetyA.strip().upper() == "IMPORT":
                    with st.spinner("Téléchargement des adresses OSM…"):
                        build_addresses_cache()
                        addr_cache = load_addresses_cache()
                        count = db.import_addresses_from_cache(conn, addr_cache)
                    st.success(f"✅ {count} adresses importées depuis OSM.")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Gestion des backups
        with st.expander("💾 Gestion des backups", expanded=False):
            backup_mgr = db.get_backup_manager(DB_PATH)
            
            col1, col2 = st.columns([2, 1])
            with col1:
                if st.button("🔄 Créer un backup manuel", use_container_width=True):
                    backup_file = backup_mgr.create_backup("manual")
                    if backup_file:
                        st.success(f"Backup créé : {Path(backup_file).name}")
            
            with col2:
                if st.button("📋 Voir les backups", use_container_width=True):
                    backups = backup_mgr.list_backups()
                    if backups:
                        for backup in backups[:5]:  # Montrer les 5 derniers
                            st.text(f"• {backup['name']} ({backup['size']})")
                    else:
                        st.info("Aucun backup disponible")

def page_superviseur(conn, geo):
    """Interface superviseur"""
    st.header("🎯 Tableau de Bord Superviseur")
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        render_login_card("superviseur", conn)
        return
    
    # Dashboard moderne
    render_dashboard_gestionnaire(conn, geo)
    
    # Tabs
    tabs = st.tabs([
        "📊 Vue d'ensemble",
        "👥 Équipes",
        "🗺️ Assignation",
        "📥 Export",
        "🛠 Tech"
    ])
    
    with tabs[0]:
        # Carte générale
        st.markdown("### Carte générale")
        df_all = db.list_streets(conn)
        if not df_all.empty:
            m = create_map(df_all, geo)
            st_folium(m, height=800, width=None, returned_objects=[])
        
        # Activité récente
        st.markdown("### Activité récente")
        recent = db.recent_activity(conn, limit=10)
        if not recent.empty:
            st.dataframe(recent, use_container_width=True)
    
    with tabs[1]:
        # Gestion des équipes
        st.markdown("### Gestion des équipes")
        
        with st.expander("Créer une équipe"):
            with st.form("new_team", clear_on_submit=True):
                new_id = st.text_input("Identifiant")
                new_name = st.text_input("Équipe")
                new_pass = st.text_input("Mot de passe", type="password")
                
                if st.form_submit_button("Créer"):
                    if all([new_id, new_name, new_pass]):
                        if db.create_team(conn, new_id, new_name, new_pass):
                            st.success(f"Équipe {new_id} créée")
                            st.rerun()
        
        # Liste des équipes
        teams_df = db.get_all_teams(conn)
        if not teams_df.empty:
            st.dataframe(teams_df, use_container_width=True)
    
    with tabs[2]:
        # Assignation
        st.markdown("### Assignation des rues")
        
        unassigned = db.get_unassigned_streets(conn)
        
        if not unassigned.empty:
            with st.form("assign"):
                team = st.selectbox("Équipe", db.teams(conn))
                streets = st.multiselect("Rues", unassigned['name'].tolist())
                
                if st.form_submit_button("Assigner"):
                    if team and streets:
                        db.assign_streets_to_team(conn, streets, team)
                        st.success("Rues assignées!")
                        st.rerun()
        else:
            st.success("Toutes les rues sont assignées!")
        
        # Tableau des assignations
        df_all = db.list_streets(conn)
        if not df_all.empty:
            st.dataframe(
                df_all[['name', 'sector', 'team', 'status']],
                use_container_width=True
            )
    
    with tabs[3]:
        # Export
        st.markdown("### Export des données")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                "📥 Export rues (CSV)",
                db.export_to_csv(conn),
                "rapport_rues.csv",
                "text/csv",
                use_container_width=True
            )
        
        with col2:
            st.download_button(
                "📥 Export notes (CSV)",
                db.export_notes_csv(conn),
                "rapport_notes.csv",
                "text/csv",
                use_container_width=True
            )

    with tabs[4]:
        st.markdown("### 🛠 Opérations techniques (protégées)")

        # -- PIN stocké dans secrets (config.toml -> [secrets] TECH_PIN="xxxx")  
        try:
            TECH_PIN = st.secrets.get("TECH_PIN", "")
        except:
            TECH_PIN = ""  # Pas de fichier secrets.toml

        if "tech_ok" not in st.session_state:
            st.session_state.tech_ok = False

        if not st.session_state.tech_ok:
            pin = st.text_input("Entrer le PIN technique", type="password")
            if st.button("Déverrouiller"):
                if TECH_PIN and pin == TECH_PIN:
                    st.session_state.tech_ok = True
                    st.success("Accès technique déverrouillé.")
                    st.rerun()
                else:
                    st.error("PIN invalide.")
            st.stop()

        st.info("⚠️ Ces actions sont lourdes et n'affectent pas les statuts/notes. Elles régénèrent les caches OSM.")

        # --- Reconstruire le cache géométrique (lourd)
        with st.expander("🔄 Reconstruire cache OSM (géométries)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirm = st.checkbox("Je comprends les implications")
            with col2:
                safety = st.text_input('Écrire "REBUILD" pour confirmer')

            if st.button("Lancer la reconstruction"):
                if confirm and safety.strip().upper() == "REBUILD":
                    with st.spinner("Construction du cache…"):
                        build_geometry_cache()       # reconstruit le fichier osm_cache.json
                        st.cache_data.clear()        # purge cache Streamlit
                    st.success("✅ Cache OSM mis à jour (géométries).")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Reconstruire/Importer le cache des adresses
        with st.expander("📍 Mettre à jour les adresses (OSM)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirmA = st.checkbox("Je confirme")
            with col2:
                safetyA = st.text_input('Écrire "IMPORT" pour confirmer')

            if st.button("Lancer la mise à jour des adresses"):
                if confirmA and safetyA.strip().upper() == "IMPORT":
                    with st.spinner("Téléchargement des adresses OSM…"):
                        build_addresses_cache()
                        addr_cache = load_addresses_cache()
                        count = db.import_addresses_from_cache(conn, addr_cache)
                    st.success(f"✅ {count} adresses importées depuis OSM.")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

# ============================================
# MAIN
# ============================================

def main():
    """Point d'entrée principal - Version 2.0 Guignolée"""
    
    # CSS moderne
    inject_css()
    
    # Connexion DB
    conn = db.get_conn(DB_PATH)
    db.init_db(conn)
    st.session_state['conn'] = conn
    
    # Cache géométrique
    @st.cache_data(ttl=None)
    def get_geo(_sig):
        data = load_geometry_cache()
        return data if data else {}
    
    sig = int(CACHE_FILE.stat().st_mtime_ns) if CACHE_FILE.exists() else 0
    geo = get_geo(sig)
    
    # Header festif
    render_header()
    
    # Navigation modernisée dans la sidebar
    with st.sidebar:
        # CSS pour la sidebar sans position absolue
        st.markdown("""
        <style>
        .css-1d391kg { padding-top: 1rem !important; }
        .stSidebar > div:first-child { padding-top: 1rem !important; }
        </style>
        """, unsafe_allow_html=True)
        
        # Logo en haut de la sidebar (position normale)
        logo_path = ASSETS / "logo.png"
        if logo_path.exists():
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.image(str(logo_path), width=150)
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
        else:
            # Placeholder centré
            st.markdown("""
            <div style="
                background: linear-gradient(135deg, #c41e3a, #165b33);
                border-radius: 15px;
                padding: 2rem;
                color: white;
                text-align: center;
                margin: 1rem 0;
                box-shadow: 0 4px 15px rgba(0,0,0,0.3);
            ">
                <div style="font-size: 2.5rem;">🎁</div>
                <div style="font-weight: bold; font-size: 1.2rem;">LOGO</div>
                <small>Espace réservé</small>
            </div>
            """, unsafe_allow_html=True)
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
        
        # Navigation
        st.markdown("### 🎄 Navigation")
        
        # Boutons de navigation stylisés
        if st.button("🏠 Accueil", use_container_width=True):
            st.session_state.page = "accueil"
            st.rerun()
        
        if st.button("🎅 Bénévole", use_container_width=True):
            st.session_state.page = "benevole"
            st.rerun()
            
        if st.button("👔 Gestionnaire", use_container_width=True):
            st.session_state.page = "gestionnaire"  
            st.rerun()
        
        # Déconnexion si connecté
        if st.session_state.auth:
            st.markdown("---")
            if st.button("🚪 Déconnexion", use_container_width=True):
                st.session_state.auth = None
                st.rerun()
        
        # Compteur temps réel
        st.markdown("---")
        stats = db.extended_stats(conn)
        st.markdown(f"""
        <div style="text-align: center;">
            <h4>État de la collecte</h4>
            <div style="font-size: 2rem; color: #FFD700;">
                {stats['done']}/{stats['total']}
            </div>
            <small>Rues complétées</small>
        </div>
        """, unsafe_allow_html=True)
    
    # Routing pages
    page = st.session_state.get('page', 'accueil')
    
    if page == "accueil":
        page_accueil_v2(conn, geo)
    elif page == "benevole":
        page_benevole_v2(conn, geo)
    elif page == "gestionnaire":
        page_gestionnaire_v2(conn, geo)
    
    # Footer festif
    st.markdown("""
    <div style="
        text-align: center;
        padding: 2rem;
        margin-top: 3rem;
        border-top: 2px solid rgba(255,215,0,0.3);
        color: #8b92a4;
    ">
        <p>
            🎄 Guignolée 2025 - Le Relais de Mascouche 🎄<br>
            <small>Ensemble, redonnons espoir | 📞 450-474-4133</small>
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Bannière en bas de page
    if (ASSETS / "banner.png").exists():
        st.image(str(ASSETS / "banner.png"), use_column_width=True)

if __name__ == "__main__":
    main()


================================================================================
FICHIER: guignomap/db.py
DESCRIPTION: Base de données et logique métier
LIGNES: 647
================================================================================
import sqlite3
import pandas as pd
import hashlib
import bcrypt
from backup import auto_backup_before_critical, BackupManager
from validators import validate_and_clean_input, InputValidator
from datetime import datetime
import json
from pathlib import Path
import os
import secrets
import string

# Schéma amélioré de la base de données
SCHEMA = """
-- Table des rues
CREATE TABLE IF NOT EXISTS streets (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    sector TEXT,
    team TEXT,
    status TEXT NOT NULL DEFAULT 'a_faire' 
        CHECK (status IN ('a_faire', 'en_cours', 'terminee'))
);

-- Table des équipes
CREATE TABLE IF NOT EXISTS teams (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    password_hash TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    active BOOLEAN DEFAULT 1
);

-- Table des notes/commentaires PAR ADRESSE
CREATE TABLE IF NOT EXISTS notes (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    street_name TEXT NOT NULL,
    team_id TEXT NOT NULL,
    address_number TEXT,
    comment TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (street_name) REFERENCES streets(name),
    FOREIGN KEY (team_id) REFERENCES teams(id)
);

-- Table d'activité (log)
CREATE TABLE IF NOT EXISTS activity_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    team_id TEXT,
    action TEXT NOT NULL,
    details TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Table des adresses OSM
CREATE TABLE IF NOT EXISTS addresses (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    street_name TEXT NOT NULL,
    house_number TEXT NOT NULL,
    latitude REAL,
    longitude REAL,
    osm_type TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (street_name) REFERENCES streets(name)
);

-- Index pour améliorer les performances
CREATE INDEX IF NOT EXISTS idx_streets_team ON streets(team);
CREATE INDEX IF NOT EXISTS idx_streets_status ON streets(status);
CREATE INDEX IF NOT EXISTS idx_notes_street ON notes(street_name);
CREATE INDEX IF NOT EXISTS idx_activity_created ON activity_log(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_addresses_street ON addresses(street_name);
CREATE INDEX IF NOT EXISTS idx_addresses_number ON addresses(house_number);
"""

def get_conn(db_path):
    """Crée une connexion à la base de données"""
    conn = sqlite3.connect(db_path, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    return conn

def init_db(conn):
    """Initialise la base de données avec le schéma et les données initiales"""
    try:
        # Créer les tables si elles n'existent pas
        conn.executescript(SCHEMA)
        conn.commit()
        
        # Créer un compte admin par défaut s'il n'existe pas
        cursor = conn.execute("SELECT COUNT(*) FROM teams WHERE id = 'ADMIN'")
        if cursor.fetchone()[0] == 0:
            pwd = os.getenv("GM_ADMIN_PWD", "RELAIS2025")  # Par défaut RELAIS2025
            create_team(conn, 'ADMIN', 'Superviseur', pwd)
        
        # AUTO-IMPORT : Si aucune rue n'existe, importer automatiquement depuis OSM
        cursor = conn.execute("SELECT COUNT(*) FROM streets")
        if cursor.fetchone()[0] == 0:
            print("🔄 Aucune rue trouvée. Import automatique depuis OpenStreetMap...")
            auto_import_streets(conn)
            
    except Exception as e:
        print(f"Erreur lors de l'initialisation de la DB: {e}")
        raise

@auto_backup_before_critical
def auto_import_streets(conn):
    """Import automatique des rues de Mascouche"""
    try:
        # Essayer d'abord avec OSM
        from osm import generate_streets_csv
        csv_data = generate_streets_csv("Mascouche")
        
        if csv_data:
            import io
            df = pd.read_csv(io.StringIO(csv_data.decode('utf-8')))
            
            if not df.empty:
                for _, row in df.iterrows():
                    conn.execute(
                        "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, ?, ?, 'a_faire')",
                        (row.get("name", ""), row.get("sector", ""), row.get("team", ""))
                    )
                conn.commit()
                print(f"✅ {len(df)} rues importées automatiquement")
                log_activity(conn, None, "AUTO_IMPORT", f"Import automatique de {len(df)} rues")
                return
    except Exception as e:
        print(f"⚠️ Erreur lors de l'import OSM: {e}")
    
    # Fallback : Données de test si OSM échoue
    print("📦 Import de données de test...")
    test_streets = [
        ("Montée Masson", "Centre", ""),
        ("Chemin Sainte-Marie", "Centre", ""),
        ("Boulevard de Mascouche", "Centre", ""),
        ("Rue Dupras", "Centre", ""),
        ("Rue Saint-Pierre", "Centre", ""),
        ("Rue de l'Église", "Centre", ""),
        ("Avenue des Érables", "Nord", ""),
        ("Rue des Pins", "Nord", ""),
        ("Rue Gravel", "Sud", ""),
        ("Rue Forget", "Sud", ""),
    ]
    
    for name, sector, team in test_streets:
        conn.execute(
            "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, ?, ?, 'a_faire')",
            (name, sector, team)
        )
    conn.commit()
    print(f"✅ {len(test_streets)} rues de test importées")

# ---------- Fonctions pour les équipes ----------
def hash_password(password):
    """Hash un mot de passe avec bcrypt et salt automatique"""
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
    return hashed.decode('utf-8')

def create_team(conn, team_id, name, password):
    """Crée une nouvelle équipe avec validation"""
    try:
        # Valider les entrées
        valid_id, clean_id = validate_and_clean_input("team_id", team_id)
        valid_name, clean_name = validate_and_clean_input("text", name)
        valid_pwd, _ = validate_and_clean_input("password", password)
        
        if not valid_id or not valid_name:
            print("❌ ID ou nom d'équipe invalide")
            return False
        
        if not valid_pwd:
            print("❌ Mot de passe trop faible (min 8 car, maj+min+chiffre)")
            return False
        
        conn.execute(
            "INSERT INTO teams (id, name, password_hash) VALUES (?, ?, ?)",
            (clean_id, clean_name, hash_password(password))
        )
        conn.commit()
        log_activity(conn, clean_id, "TEAM_CREATED", f"Équipe {clean_name} créée")
        return True
    except sqlite3.IntegrityError:
        return False

def verify_team(conn, team_id, password):
    """Vérifie les identifiants d'une équipe avec bcrypt"""
    cursor = conn.execute(
        "SELECT password_hash FROM teams WHERE id = ? AND active = 1",
        (team_id,)
    )
    row = cursor.fetchone()
    if row:
        try:
            # Support ancien SHA256 pour migration
            stored_hash = row[0]
            if stored_hash.startswith('$2b$') or stored_hash.startswith('$2a$'):
                # Hash bcrypt
                return bcrypt.checkpw(password.encode('utf-8'), stored_hash.encode('utf-8'))
            else:
                # Ancien SHA256, vérifier et migrer
                if stored_hash == hashlib.sha256(password.encode()).hexdigest():
                    # Migrer vers bcrypt
                    new_hash = hash_password(password)
                    conn.execute("UPDATE teams SET password_hash = ? WHERE id = ?", (new_hash, team_id))
                    conn.commit()
                    return True
                return False
        except Exception as e:
            print(f"Erreur vérification mot de passe: {e}")
            return False
    return False

def migrate_all_passwords_to_bcrypt(conn):
    """Migration manuelle des mots de passe SHA256 vers bcrypt"""
    print("⚠️ Migration des mots de passe requise")
    print("Entrez les mots de passe actuels pour migration:")
    
    cursor = conn.execute("SELECT id, name FROM teams WHERE active = 1")
    teams = cursor.fetchall()
    
    for team_id, team_name in teams:
        if team_id == 'ADMIN':
            pwd = input(f"Mot de passe actuel pour {team_name} (ADMIN): ")
            if pwd:
                new_hash = hash_password(pwd)
                conn.execute("UPDATE teams SET password_hash = ? WHERE id = ?", (new_hash, team_id))
        
    conn.commit()
    print("✅ Migration terminée")

def get_all_teams(conn):
    """Récupère toutes les équipes avec leurs statistiques"""
    query = """
    SELECT 
        t.id,
        t.name,
        t.created_at,
        COUNT(DISTINCT s.name) as streets_count,
        SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done_count,
        CASE 
            WHEN COUNT(s.name) > 0 
            THEN (SUM(CASE WHEN s.status = 'terminee' THEN 1.0 ELSE 0 END) / COUNT(s.name)) * 100
            ELSE 0 
        END as progress
    FROM teams t
    LEFT JOIN streets s ON t.id = s.team
    WHERE t.active = 1 AND t.id != 'ADMIN'
    GROUP BY t.id, t.name, t.created_at
    ORDER BY t.id
    """
    return pd.read_sql_query(query, conn)

@auto_backup_before_critical
def delete_team(conn, team_id):
    """Désactive une équipe"""
    conn.execute("UPDATE teams SET active = 0 WHERE id = ?", (team_id,))
    conn.execute("UPDATE streets SET team = NULL WHERE team = ?", (team_id,))
    conn.commit()
    log_activity(conn, None, "TEAM_DELETED", f"Équipe {team_id} supprimée")

def teams(conn):
    """Liste des IDs d'équipes actives"""
    cursor = conn.execute(
        "SELECT id FROM teams WHERE active = 1 AND id != 'ADMIN' ORDER BY id"
    )
    return [row[0] for row in cursor.fetchall()]

# ---------- Fonctions pour les rues ----------
def list_streets(conn, team=None):
    """Liste les rues, optionnellement filtrées par équipe"""
    try:
        if team:
            query = """
                SELECT 
                    s.name, 
                    COALESCE(s.sector, '') as sector, 
                    COALESCE(s.team, '') as team, 
                    COALESCE(s.status, 'a_faire') as status,
                    COUNT(n.id) as notes,
                    COUNT(DISTINCT n.address_number) as addresses_with_notes
                FROM streets s
                LEFT JOIN notes n ON s.name = n.street_name
                WHERE s.team = ?
                GROUP BY s.name, s.sector, s.team, s.status
                ORDER BY 
                    CASE s.status 
                        WHEN 'a_faire' THEN 1 
                        WHEN 'en_cours' THEN 2 
                        WHEN 'terminee' THEN 3 
                    END, 
                    s.name
            """
            df = pd.read_sql_query(query, conn, params=(team,))
        else:
            query = """
                SELECT 
                    s.name, 
                    COALESCE(s.sector, '') as sector, 
                    COALESCE(s.team, '') as team, 
                    COALESCE(s.status, 'a_faire') as status,
                    COUNT(n.id) as notes,
                    COUNT(DISTINCT n.address_number) as addresses_with_notes
                FROM streets s
                LEFT JOIN notes n ON s.name = n.street_name
                GROUP BY s.name, s.sector, s.team, s.status
                ORDER BY 
                    s.team, 
                    CASE s.status 
                        WHEN 'a_faire' THEN 1 
                        WHEN 'en_cours' THEN 2 
                        WHEN 'terminee' THEN 3 
                    END, 
                    s.name
            """
            df = pd.read_sql_query(query, conn)
        
        # S'assurer que toutes les colonnes existent
        for col in ['name', 'sector', 'team', 'status', 'notes', 'addresses_with_notes']:
            if col not in df.columns:
                df[col] = '' if col in ['sector', 'team'] else ('a_faire' if col == 'status' else 0)
        
        return df
        
    except Exception as e:
        print(f"Erreur list_streets: {e}")
        # Retourner un DataFrame vide avec la structure attendue
        return pd.DataFrame(columns=['name', 'sector', 'team', 'status', 'notes', 'addresses_with_notes'])

def get_unassigned_streets(conn):
    """Récupère les rues non assignées"""
    query = """
        SELECT name, sector 
        FROM streets 
        WHERE team IS NULL OR team = ''
        ORDER BY sector, name
    """
    return pd.read_sql_query(query, conn)

def assign_streets_to_team(conn, street_names, team_id):
    """Assigne plusieurs rues à une équipe en une transaction"""
    try:
        for street_name in street_names:
            conn.execute(
                "UPDATE streets SET team = ? WHERE name = ?",
                (team_id, street_name)
            )
        conn.commit()
        log_activity(conn, team_id, "STREETS_ASSIGNED", f"{len(street_names)} rues assignées")
        return True
    except Exception as e:
        conn.rollback()
        print(f"Erreur lors de l'assignation: {e}")
        return False

def set_status(conn, name, status):
    """Met à jour le statut d'une rue avec validation"""
    valid_name, clean_name = validate_and_clean_input("street_name", name)
    clean_status = InputValidator.validate_status(status)
    
    if not valid_name:
        print("❌ Nom de rue invalide")
        return False
    
    conn.execute(
        "UPDATE streets SET status = ? WHERE name = ?",
        (clean_status, clean_name)
    )
    conn.commit()
    
    cursor = conn.execute("SELECT team FROM streets WHERE name = ?", (clean_name,))
    row = cursor.fetchone()
    if row:
        log_activity(conn, row[0], f"STATUS_{clean_status.upper()}", f"Rue {clean_name}")
    return True

# ---------- Fonctions pour les notes PAR ADRESSE ----------
def add_note_for_address(conn, street_name, team_id, address_number, comment):
    """Ajoute une note pour une adresse spécifique avec validation"""
    # Valider toutes les entrées
    valid_street, clean_street = validate_and_clean_input("street_name", street_name)
    valid_team, clean_team = validate_and_clean_input("team_id", team_id)
    valid_addr, clean_addr = validate_and_clean_input("address", address_number)
    valid_note, clean_note = validate_and_clean_input("note", comment)
    
    if not all([valid_street, valid_team, valid_addr, valid_note]):
        print("❌ Données invalides pour la note")
        return False
    
    conn.execute(
        """INSERT INTO notes (street_name, team_id, address_number, comment) 
           VALUES (?, ?, ?, ?)""",
        (clean_street, clean_team, clean_addr, clean_note)
    )
    
    # Met automatiquement le statut à "en_cours" si c'était "a_faire"
    conn.execute(
        """UPDATE streets 
           SET status = CASE 
               WHEN status = 'a_faire' THEN 'en_cours' 
               ELSE status 
           END
           WHERE name = ?""",
        (clean_street,)
    )
    
    conn.commit()
    log_activity(conn, clean_team, "NOTE_ADDED", f"Note ajoutée pour {clean_addr} {clean_street}")
    return True

def get_street_addresses_with_notes(conn, street_name):
    """Récupère toutes les adresses avec notes pour une rue"""
    query = """
        SELECT 
            n.address_number,
            n.comment,
            n.created_at,
            t.name as team_name
        FROM notes n
        JOIN teams t ON n.team_id = t.id
        WHERE n.street_name = ?
        ORDER BY 
            CAST(n.address_number AS INTEGER),
            n.created_at DESC
    """
    return pd.read_sql_query(query, conn, params=(street_name,))

def get_team_notes(conn, team_id):
    """Récupère toutes les notes d'une équipe"""
    query = """
        SELECT 
            street_name, 
            address_number, 
            comment, 
            created_at
        FROM notes
        WHERE team_id = ?
        ORDER BY created_at DESC
        LIMIT 50
    """
    return pd.read_sql_query(query, conn, params=(team_id,))

# ---------- Fonctions de statistiques ----------
def extended_stats(conn):
    """Statistiques étendues avec détails par adresse"""
    cursor = conn.execute("""
        SELECT 
            COUNT(DISTINCT s.name) as total,
            SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done,
            SUM(CASE WHEN s.status = 'en_cours' THEN 1 ELSE 0 END) as partial,
            SUM(CASE WHEN s.status = 'a_faire' THEN 1 ELSE 0 END) as todo,
            COUNT(DISTINCT n.id) as total_notes,
            COUNT(DISTINCT n.address_number || n.street_name) as addresses_with_notes
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name
    """)
    row = cursor.fetchone()
    return {
        "total": row[0] or 0,
        "done": row[1] or 0,
        "partial": row[2] or 0,
        "todo": row[3] or 0,
        "total_notes": row[4] or 0,
        "addresses_with_notes": row[5] or 0
    }

def stats_by_team(conn):
    """Statistiques par équipe"""
    query = """
        SELECT 
            s.team,
            COUNT(DISTINCT s.name) as total,
            SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done,
            SUM(CASE WHEN s.status = 'en_cours' THEN 1 ELSE 0 END) as partial,
            COUNT(DISTINCT n.id) as notes,
            ROUND(
                (SUM(CASE WHEN s.status = 'terminee' THEN 1.0 ELSE 0 END) / COUNT(*)) * 100, 
                1
            ) as progress
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name AND n.team_id = s.team
        WHERE s.team IS NOT NULL AND s.team != ''
        GROUP BY s.team
        ORDER BY progress DESC
    """
    return pd.read_sql_query(query, conn)

# ---------- Fonctions d'activité ----------
def log_activity(conn, team_id, action, details=None):
    """Enregistre une activité dans le log"""
    try:
        conn.execute(
            "INSERT INTO activity_log (team_id, action, details) VALUES (?, ?, ?)",
            (team_id, action, details)
        )
        conn.commit()
    except:
        pass

def recent_activity(conn, limit=10):
    """Récupère l'activité récente"""
    query = """
        SELECT 
            datetime(created_at, 'localtime') as timestamp,
            COALESCE(team_id, 'SYSTEM') as team,
            action,
            details
        FROM activity_log
        ORDER BY created_at DESC
        LIMIT ?
    """
    return pd.read_sql_query(query, conn, params=(limit,))

# ---------- Fonctions d'export ----------
def export_to_csv(conn):
    """Exporte toutes les données en CSV"""
    query = """
        SELECT 
            s.name as rue,
            s.sector as secteur,
            s.team as equipe,
            s.status as statut,
            COUNT(DISTINCT n.id) as nombre_notes,
            COUNT(DISTINCT n.address_number) as adresses_avec_notes
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name
        GROUP BY s.name, s.sector, s.team, s.status
        ORDER BY s.team, s.name
    """
    df = pd.read_sql_query(query, conn)
    return df.to_csv(index=False).encode('utf-8')

def export_notes_csv(conn):
    """Exporte toutes les notes en CSV avec adresses"""
    query = """
        SELECT 
            n.street_name as rue,
            n.address_number as numero,
            n.team_id as equipe,
            n.comment as commentaire,
            n.created_at as date_creation
        FROM notes n
        ORDER BY n.street_name, CAST(n.address_number AS INTEGER), n.created_at DESC
    """
    df = pd.read_sql_query(query, conn)
    return df.to_csv(index=False).encode('utf-8')

# ========================================
# NOUVELLES FONCTIONS POUR LES ADRESSES
# ========================================

@auto_backup_before_critical
def import_addresses_from_cache(conn, cache):
    """
    Importe les adresses depuis le cache OSM vers la base de données
    """
    try:
        # Vider la table existante
        conn.execute("DELETE FROM addresses")
        
        imported_count = 0
        skipped_count = 0
        
        for street_name, addresses in cache.items():
            # Vérifier que la rue existe dans la DB
            cursor = conn.execute("SELECT COUNT(*) FROM streets WHERE name = ?", (street_name,))
            if cursor.fetchone()[0] == 0:
                # Si la rue n'existe pas, la créer
                conn.execute(
                    "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, '', '', 'a_faire')",
                    (street_name,)
                )
                print(f"➕ Rue ajoutée: {street_name}")
            
            for addr in addresses:
                try:
                    # Validation des données
                    number = str(addr.get("number", "")).strip()
                    lat = addr.get("lat")
                    lon = addr.get("lon")
                    osm_type = addr.get("type", "unknown")
                    
                    if not number or lat is None or lon is None:
                        skipped_count += 1
                        continue
                    
                    conn.execute(
                        """INSERT INTO addresses (street_name, house_number, latitude, longitude, osm_type) 
                           VALUES (?, ?, ?, ?, ?)""",
                        (street_name, number, float(lat), float(lon), osm_type)
                    )
                    imported_count += 1
                except Exception as e:
                    print(f"⚠️ Erreur import adresse {addr}: {e}")
                    skipped_count += 1
        
        conn.commit()
        log_activity(conn, None, "ADDRESSES_IMPORTED", f"{imported_count} adresses importées, {skipped_count} ignorées")
        print(f"✅ {imported_count} adresses importées en base de données ({skipped_count} ignorées)")
        return imported_count
        
    except Exception as e:
        conn.rollback()
        print(f"❌ Erreur import adresses: {e}")
        return 0

def get_addresses_for_street(conn, street_name):
    """
    Récupère toutes les adresses d'une rue depuis la base de données
    """
    query = """
        SELECT 
            house_number,
            latitude,
            longitude,
            osm_type,
            created_at
        FROM addresses
        WHERE street_name = ?
        ORDER BY CAST(house_number AS INTEGER)
    """
    return pd.read_sql_query(query, conn, params=(street_name,))

def get_addresses_stats(conn):
    """
    Récupère les statistiques des adresses
    """
    cursor = conn.execute("""
        SELECT 
            COUNT(DISTINCT street_name) as streets_with_addresses,
            COUNT(*) as total_addresses,
            COUNT(DISTINCT CASE WHEN osm_type = 'node' THEN id END) as node_addresses,
            COUNT(DISTINCT CASE WHEN osm_type = 'way' THEN id END) as way_addresses
        FROM addresses
    """)
    row = cursor.fetchone()
    return {
        "streets_with_addresses": row[0] or 0,
        "total_addresses": row[1] or 0,
        "node_addresses": row[2] or 0,
        "way_addresses": row[3] or 0
    }

def get_backup_manager(db_path):
    """Retourne une instance du gestionnaire de backup"""
    return BackupManager(db_path)

================================================================================
FICHIER: guignomap/osm.py
DESCRIPTION: Interface OpenStreetMap
LIGNES: 472
================================================================================
"""
Module OSM pour Guigno-Map
Gère l'import et le cache des données OpenStreetMap pour Mascouche
"""

import io
import json
from pathlib import Path
import pandas as pd
import overpy

# Configuration
CACHE_FILE = Path(__file__).parent / "osm_cache.json"
ADDR_CACHE_FILE = Path(__file__).parent / "osm_addresses.json"

# Toutes les voies routières nommées de Mascouche
QUERY_STREETS_ALL = """
[out:json][timeout:300];
area["name"="Mascouche"]["boundary"="administrative"]->.a;
(
  way["highway"~"^(primary|secondary|tertiary|residential|service|unclassified|living_street|pedestrian|track|road|busway|footway|path)$"](area.a);
);
(._;>;);
out body;
"""
# Note: Récupère TOUS les types de voies incluant petites rues, allées, chemins piétonniers

# Requête pour les adresses
QUERY_ADDR_NODES = """
[out:json][timeout:180];
area["name"="Mascouche"]["boundary"="administrative"]->.a;
(
  node["addr:housenumber"]["addr:street"](area.a);
  way["addr:housenumber"]["addr:street"](area.a);
);
out tags center;
"""

def generate_streets_csv(city="Mascouche"):
    """
    Génère un CSV avec les noms des rues principales de la ville
    Filtre automatiquement les rues privées et les petites ruelles
    """
    try:
        api = overpy.Overpass()
        result = api.query(QUERY_STREETS_ALL)
        
        streets = []
        for way in result.ways:
            name = way.tags.get("name")
            if not name:
                continue
            g = getattr(way, "geometry", None)
            # garder si on a une vraie géométrie (>= 2 points)
            if isinstance(g, list) and len(g) >= 2:
                streets.append(name)

        streets = sorted(set(streets))
        
        # Assigner automatiquement des secteurs basés sur les patterns de noms
        sectors = []
        for street in streets:
            if any(word in street.lower() for word in ["montée", "chemin", "boulevard"]):
                sectors.append("Principal")
            elif any(word in street.lower() for word in ["avenue", "place", "croissant"]):
                sectors.append("Résidentiel")
            elif "rue" in street.lower():
                sectors.append("Centre")
            else:
                sectors.append("")
        
        df = pd.DataFrame({
            "name": streets,
            "sector": sectors,
            "team": [""] * len(streets)
        })
        
        buf = io.StringIO()
        df.to_csv(buf, index=False)
        print(f"✅ CSV généré avec {len(streets)} rues principales")
        return buf.getvalue().encode("utf-8")
        
    except Exception as e:
        print(f"❌ Erreur OSM: {e}")
        # Retourner des données de test en cas d'erreur
        return create_fallback_csv()

def build_geometry_cache():
    """
    Construit le cache des géométries pour TOUTES les voies de Mascouche
    Force la résolution complète des nodes
    """
    try:
        print("🔄 Récupération complète de toutes les voies de Mascouche...")
        
        # IMPORTANT: Configurer l'API pour résoudre automatiquement les nodes manquants
        api = overpy.Overpass()
        
        # Requête améliorée qui force le retour des coordonnées
        query = """
        [out:json][timeout:300];
        area["name"="Mascouche"]["boundary"="administrative"]->.a;
        (
          way["highway"]["name"](area.a);
          way["highway"]["ref"](area.a);
        );
        (._;>;);
        out body;
        """
        
        print("📡 Connexion à OpenStreetMap (cela peut prendre 30-60 secondes)...")
        result = api.query(query)
        
        geo = {}
        stats = {"total": 0, "avec_geo": 0, "sans_geo": 0}
        
        # Construire un dictionnaire des nodes pour accès rapide
        nodes_dict = {}
        if hasattr(result, 'nodes'):
            for node in result.nodes:
                if hasattr(node, 'id') and hasattr(node, 'lat') and hasattr(node, 'lon'):
                    nodes_dict[node.id] = (float(node.lat), float(node.lon))
        
        print(f"📍 {len(nodes_dict)} nodes récupérés")
        
        ways = result.ways if hasattr(result, 'ways') else []
        print(f"📊 {len(ways)} voies trouvées dans OpenStreetMap")
        
        for way in ways:
            try:
                # Récupérer le nom ou ref
                if not hasattr(way, 'tags'):
                    continue
                    
                name = way.tags.get("name")
                if not name:
                    ref = way.tags.get("ref")
                    if ref:
                        name = f"Autoroute {ref}"
                    else:
                        continue
                
                stats["total"] += 1
                coords = []
                
                # Récupérer les IDs des nodes
                if hasattr(way, 'nd_ids'):
                    # Si on a les IDs des nodes, les résoudre
                    for node_id in way.nd_ids:
                        if node_id in nodes_dict:
                            lat, lon = nodes_dict[node_id]
                            coords.append([lat, lon])
                elif hasattr(way, 'nodes'):
                    # Si on a directement les nodes
                    for node in way.nodes:
                        if hasattr(node, 'lat') and hasattr(node, 'lon'):
                            coords.append([float(node.lat), float(node.lon)])
                        elif hasattr(node, 'id') and node.id in nodes_dict:
                            lat, lon = nodes_dict[node.id]
                            coords.append([lat, lon])
                
                if len(coords) >= 2:
                    if name not in geo:
                        geo[name] = []
                    geo[name].append(coords)
                    stats["avec_geo"] += 1
                else:
                    stats["sans_geo"] += 1
                    
            except Exception as e:
                continue
        
        print(f"✅ Résultat: {stats['avec_geo']} voies avec géométrie sur {stats['total']} trouvées")
        
        # Si on a récupéré des données, sauvegarder
        if geo:
            CACHE_FILE.write_text(json.dumps(geo, indent=2), encoding="utf-8")
            print(f"💾 Cache créé: {len(geo)} voies sauvegardées dans osm_cache.json")
            
            # Importer aussi automatiquement dans la DB
            try:
                from pathlib import Path
                import sys
                sys.path.append(str(Path(__file__).parent))
                import db
                
                db_path = Path(__file__).parent / "guigno_map.db"
                conn = db.get_conn(db_path)
                
                # Ajouter les rues manquantes à la DB
                for street_name in geo.keys():
                    cursor = conn.execute("SELECT COUNT(*) FROM streets WHERE name = ?", (street_name,))
                    if cursor.fetchone()[0] == 0:
                        conn.execute(
                            "INSERT INTO streets(name, sector, team, status) VALUES (?, '', '', 'a_faire')",
                            (street_name,)
                        )
                conn.commit()
                print(f"✅ Rues importées dans la base de données")
            except Exception as e:
                print(f"⚠️ Import DB: {e}")
            
            return geo
        
        # Si aucune donnée, utiliser un fallback étendu
        print("⚠️ Aucune donnée OSM, utilisation du fallback local")
        return get_extended_fallback()
            
    except Exception as e:
        print(f"❌ Erreur: {e}")
        return get_extended_fallback()

def get_fallback_geometry():
    """Fallback avec les principales voies de Mascouche"""
    return {
        "Autoroute 25": [[[45.70, -73.65], [45.78, -73.58]]],
        "Autoroute 640": [[[45.76, -73.70], [45.76, -73.55]]],
        "Montée Masson": [[[45.730, -73.620], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.752, -73.590]]],
        "Chemin des Anglais": [[[45.74, -73.65], [45.75, -73.64]]],
        "Chemin Gascon": [[[45.75, -73.62], [45.76, -73.60]]],
        "Chemin Pincourt": [[[45.72, -73.64], [45.73, -73.63]]],
        "Chemin Newton": [[[45.73, -73.58], [45.74, -73.57]]],
        "Chemin Saint-Henri": [[[45.71, -73.61], [45.72, -73.60]]],
        "Chemin Saint-Pierre": [[[45.74, -73.59], [45.75, -73.58]]],
        "Avenue de la Gare": [[[45.745, -73.601], [45.748, -73.598]]],
        "Rue Dupras": [[[45.745, -73.602], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.749, -73.600]]],
        "Rue de l'Église": [[[45.747, -73.601], [45.750, -73.599]]],
        "Avenue des Érables": [[[45.755, -73.605], [45.758, -73.600]]],
        "Rue des Pins": [[[45.756, -73.603], [45.759, -73.598]]],
        "Rue Brien": [[[45.738, -73.605], [45.741, -73.600]]],
        "Rue Bohémier": [[[45.742, -73.607], [45.745, -73.604]]]
    }

def get_extended_fallback():
    """Fallback étendu avec les principales voies de Mascouche"""
    fallback = {
        # Autoroutes
        "Autoroute 25": [[[45.70, -73.65], [45.72, -73.63], [45.74, -73.61], [45.76, -73.59], [45.78, -73.58]]],
        "Autoroute 640": [[[45.76, -73.70], [45.76, -73.65], [45.76, -73.60], [45.76, -73.55]]],
        
        # Chemins principaux
        "Montée Masson": [[[45.730, -73.620], [45.740, -73.610], [45.750, -73.600], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.745, -73.605], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.747, -73.600], [45.752, -73.590]]],
        "Chemin des Anglais": [[[45.74, -73.65], [45.745, -73.645], [45.75, -73.64]]],
        "Chemin Gascon": [[[45.75, -73.62], [45.755, -73.615], [45.76, -73.60]]],
        "Chemin Pincourt": [[[45.72, -73.64], [45.725, -73.635], [45.73, -73.63]]],
        "Chemin Newton": [[[45.73, -73.58], [45.735, -73.575], [45.74, -73.57]]],
        "Chemin Saint-Henri": [[[45.71, -73.61], [45.715, -73.605], [45.72, -73.60]]],
        "Chemin Saint-Pierre": [[[45.74, -73.59], [45.745, -73.585], [45.75, -73.58]]],
        
        # Avenues
        "Avenue de la Gare": [[[45.745, -73.601], [45.747, -73.599], [45.748, -73.598]]],
        "Avenue Bourque": [[[45.742, -73.603], [45.744, -73.601], [45.746, -73.599]]],
        "Avenue Crépeau": [[[45.743, -73.602], [45.745, -73.600], [45.747, -73.598]]],
        "Avenue Garden": [[[45.751, -73.606], [45.753, -73.604], [45.755, -73.602]]],
        "Avenue de l'Esplanade": [[[45.748, -73.605], [45.750, -73.603], [45.752, -73.601]]],
        
        # Rues du centre
        "Rue Dupras": [[[45.745, -73.602], [45.747, -73.600], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.748, -73.602], [45.749, -73.600]]],
        "Rue de l'Église": [[[45.747, -73.601], [45.749, -73.599], [45.750, -73.598]]],
        "Rue Brien": [[[45.738, -73.605], [45.740, -73.603], [45.741, -73.600]]],
        "Rue Bohémier": [[[45.742, -73.607], [45.744, -73.605], [45.745, -73.604]]],
        
        # Rues résidentielles
        "Rue des Pins": [[[45.756, -73.603], [45.758, -73.601], [45.759, -73.598]]],
        "Avenue des Érables": [[[45.755, -73.605], [45.757, -73.603], [45.758, -73.600]]],
        "Rue Gravel": [[[45.738, -73.605], [45.740, -73.603], [45.741, -73.600]]]
    }
    
    # Sauvegarder le fallback
    CACHE_FILE.write_text(json.dumps(fallback, indent=2), encoding="utf-8")
    print(f"💾 Fallback sauvegardé avec {len(fallback)} voies principales")
    
    return fallback

def load_geometry_cache():
    """
    Charge le cache de géométries depuis le fichier JSON
    Crée un cache de base si le fichier n'existe pas
    """
    if not CACHE_FILE.exists():
        print("⚠️ Cache non trouvé, construction en cours...")
        return build_geometry_cache()  # build_geometry_cache() gère déjà le fallback en mémoire
    
    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
            print(f"✅ Cache chargé: {len(cache)} rues")
            return cache
    except Exception as e:
        print(f"❌ Erreur chargement cache: {e}")
        # Ne pas écrire de fallback sur disque ! Utiliser build_geometry_cache() qui gère le fallback en mémoire
        return build_geometry_cache()

def create_fallback_csv():
    """
    Crée un CSV de fallback avec quelques rues principales de Mascouche
    Utilisé si l'API OSM est indisponible
    """
    fallback_streets = [
        ("Montée Masson", "Principal"),
        ("Chemin Sainte-Marie", "Principal"),
        ("Boulevard de Mascouche", "Principal"),
        ("Chemin des Anglais", "Principal"),
        ("Rue Dupras", "Centre"),
        ("Rue Saint-Pierre", "Centre"),
        ("Rue de l'Église", "Centre"),
        ("Avenue des Érables", "Résidentiel"),
        ("Rue des Pins", "Résidentiel"),
        ("Avenue Garden", "Résidentiel"),
    ]
    
    df = pd.DataFrame(fallback_streets, columns=["name", "sector"])
    df["team"] = ""
    
    buf = io.StringIO()
    df.to_csv(buf, index=False)
    print("⚠️ Mode fallback: 10 rues de test")
    return buf.getvalue().encode("utf-8")

def create_fallback_cache():
    """
    Crée un cache minimal pour tests
    """
    fallback_geo = {
        "Montée Masson": [[[45.730, -73.620], [45.750, -73.600], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.748, -73.602], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.747, -73.600], [45.752, -73.590]]],
        "Rue Dupras": [[[45.745, -73.602], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.749, -73.600]]],
        "Rue de l'Église": [[[45.747, -73.601], [45.750, -73.599]]],
        "Avenue des Érables": [[[45.755, -73.605], [45.758, -73.600]]],
        "Rue des Pins": [[[45.756, -73.603], [45.759, -73.598]]],
        "Avenue Garden": [[[45.753, -73.606], [45.756, -73.601]]],
        "Rue Gravel": [[[45.738, -73.605], [45.741, -73.600]]]
    }
    
    CACHE_FILE.write_text(json.dumps(fallback_geo, indent=2), encoding="utf-8")
    print("⚠️ Cache fallback créé avec 10 rues")

# Fonction utilitaire pour tests
def test_osm_connection():
    """
    Teste la connexion à l'API Overpass
    """
    try:
        api = overpy.Overpass()
        # Requête minimale pour tester
        result = api.query('[out:json];node(45.7475,-73.6005,45.7476,-73.6004);out;')
        print("✅ Connexion OSM OK")
        return True
    except:
        print("❌ Connexion OSM échouée")
        return False

# ========================================
# NOUVELLES FONCTIONS POUR LES ADRESSES
# ========================================

def build_addresses_cache():
    """
    Construit le cache des adresses OSM pour Mascouche
    Récupère addr:housenumber + addr:street depuis OSM
    """
    try:
        api = overpy.Overpass()
        result = api.query(QUERY_ADDR_NODES)
        
        addresses = {}
        
        # Traiter les nodes avec adresses
        for node in result.nodes:
            house_number = node.tags.get("addr:housenumber")
            street_name = node.tags.get("addr:street")
            
            if house_number and street_name:
                if street_name not in addresses:
                    addresses[street_name] = []
                addresses[street_name].append({
                    "number": str(house_number),  # Forcer en string
                    "lat": float(node.lat),
                    "lon": float(node.lon),
                    "type": "node"
                })
        
        # Traiter les ways avec adresses
        for way in result.ways:
            num = way.tags.get("addr:housenumber")
            street = way.tags.get("addr:street")
            if not num or not street:
                continue
            
            # Récupérer le centre du way
            lat = getattr(way, "center_lat", None)
            lon = getattr(way, "center_lon", None)
            
            # Fallback si center_lat/lon non disponibles
            if lat is None or lon is None:
                nodes = getattr(way, "nodes", []) or []
                if nodes:
                    try:
                        valid_lats = []
                        valid_lons = []
                        for n in nodes:
                            if hasattr(n, 'lat') and hasattr(n, 'lon'):
                                if n.lat is not None and n.lon is not None:
                                    valid_lats.append(float(n.lat))
                                    valid_lons.append(float(n.lon))
                        if valid_lats and valid_lons:
                            lat = sum(valid_lats) / len(valid_lats)
                            lon = sum(valid_lons) / len(valid_lons)
                    except Exception as e:
                        print(f"Erreur calcul centre pour way: {e}")
                        continue
            
            if lat is not None and lon is not None:
                addresses.setdefault(street, []).append({
                    "number": str(num),
                    "lat": float(lat),
                    "lon": float(lon),
                    "type": "way"
                })
        
        # Trier les adresses par numéro pour chaque rue
        for street_name in addresses:
            try:
                # Tri numérique intelligent
                addresses[street_name].sort(
                    key=lambda x: (
                        int(''.join(filter(str.isdigit, x["number"]))) 
                        if any(c.isdigit() for c in x["number"]) 
                        else float('inf')
                    )
                )
            except:
                # Si le tri échoue, garder l'ordre original
                pass
        
        # Sauvegarder le cache
        ADDR_CACHE_FILE.write_text(json.dumps(addresses, indent=2), encoding="utf-8")
        total_addresses = sum(len(addrs) for addrs in addresses.values())
        print(f"✅ Cache adresses créé: {len(addresses)} rues, {total_addresses} adresses")
        return addresses
        
    except Exception as e:
        print(f"❌ Erreur construction cache adresses: {e}")
        # Créer un cache vide en cas d'erreur
        ADDR_CACHE_FILE.write_text(json.dumps({}), encoding="utf-8")
        return {}

def load_addresses_cache():
    """
    Charge le cache d'adresses depuis le fichier JSON
    """
    if not ADDR_CACHE_FILE.exists():
        print("⚠️ Cache adresses non trouvé")
        return {}
    
    try:
        with open(ADDR_CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
            total_addresses = sum(len(addrs) for addrs in cache.values())
            print(f"✅ Cache adresses chargé: {len(cache)} rues, {total_addresses} adresses")
            return cache
    except Exception as e:
        print(f"❌ Erreur chargement cache adresses: {e}")
        return {}

================================================================================
FICHIER: guignomap/backup.py
DESCRIPTION: NOUVEAU v4.0: Système de backup automatique
LIGNES: 153
================================================================================
"""
Système de backup automatique pour GuignoMap
Sauvegarde la base de données et les caches
"""

import shutil
import sqlite3
from pathlib import Path
from datetime import datetime
import json
import zipfile

class BackupManager:
    def __init__(self, db_path):
        self.db_path = Path(db_path)
        self.backup_dir = self.db_path.parent / "backups"
        self.backup_dir.mkdir(exist_ok=True)
        self.max_backups = 7  # Garder 7 jours de backups
        
    def create_backup(self, reason="manual"):
        """Crée un backup complet avec timestamp"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_{timestamp}_{reason}"
        backup_path = self.backup_dir / backup_name
        backup_path.mkdir(exist_ok=True)
        
        try:
            # Backup de la base de données
            db_backup = backup_path / "guigno_map.db"
            shutil.copy2(self.db_path, db_backup)
            
            # Backup des caches OSM
            for cache_file in ["osm_cache.json", "osm_addresses.json"]:
                cache_path = self.db_path.parent / cache_file
                if cache_path.exists():
                    shutil.copy2(cache_path, backup_path / cache_file)
            
            # Créer un ZIP
            zip_path = self.backup_dir / f"{backup_name}.zip"
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file in backup_path.iterdir():
                    zipf.write(file, file.name)
            
            # Nettoyer le dossier temporaire
            shutil.rmtree(backup_path)
            
            # Nettoyer les vieux backups
            self._cleanup_old_backups()
            
            # Log le backup
            self._log_backup(timestamp, reason)
            
            print(f"✅ Backup créé : {zip_path.name}")
            return str(zip_path)
            
        except Exception as e:
            print(f"❌ Erreur backup : {e}")
            if backup_path.exists():
                shutil.rmtree(backup_path)
            return None
    
    def restore_backup(self, backup_file):
        """Restaure un backup spécifique"""
        backup_path = self.backup_dir / backup_file
        if not backup_path.exists():
            print(f"❌ Backup introuvable : {backup_file}")
            return False
            
        try:
            # Créer un backup de sécurité avant restauration
            self.create_backup("pre_restore")
            
            # Extraire le ZIP
            temp_dir = self.backup_dir / "temp_restore"
            with zipfile.ZipFile(backup_path, 'r') as zipf:
                zipf.extractall(temp_dir)
            
            # Restaurer les fichiers
            for file in temp_dir.iterdir():
                target = self.db_path.parent / file.name
                shutil.copy2(file, target)
            
            # Nettoyer
            shutil.rmtree(temp_dir)
            
            print(f"✅ Backup restauré : {backup_file}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur restauration : {e}")
            return False
    
    def list_backups(self):
        """Liste tous les backups disponibles"""
        backups = []
        for file in self.backup_dir.glob("backup_*.zip"):
            stat = file.stat()
            backups.append({
                "name": file.name,
                "size": f"{stat.st_size / 1024 / 1024:.2f} MB",
                "date": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S")
            })
        return sorted(backups, key=lambda x: x["date"], reverse=True)
    
    def _cleanup_old_backups(self):
        """Supprime les backups de plus de 7 jours"""
        backups = sorted(self.backup_dir.glob("backup_*.zip"), key=lambda x: x.stat().st_mtime)
        while len(backups) > self.max_backups:
            oldest = backups.pop(0)
            oldest.unlink()
            print(f"🗑️ Ancien backup supprimé : {oldest.name}")
    
    def _log_backup(self, timestamp, reason):
        """Log les backups dans un fichier"""
        log_file = self.backup_dir / "backup_log.json"
        log = []
        if log_file.exists():
            with open(log_file, 'r') as f:
                log = json.load(f)
        
        log.append({
            "timestamp": timestamp,
            "reason": reason,
            "date": datetime.now().isoformat()
        })
        
        # Garder seulement les 100 derniers logs
        log = log[-100:]
        
        with open(log_file, 'w') as f:
            json.dump(log, f, indent=2)

def auto_backup_before_critical(func):
    """Décorateur pour backup automatique avant opérations critiques"""
    def wrapper(*args, **kwargs):
        # Trouver la connexion DB dans les arguments
        conn = None
        for arg in args:
            if hasattr(arg, 'execute'):  # C'est une connexion SQLite
                conn = arg
                break
        
        if conn:
            try:
                # Créer un backup avant l'opération
                db_path = Path(__file__).parent / "guigno_map.db"
                backup_mgr = BackupManager(db_path)
                backup_mgr.create_backup(f"auto_{func.__name__}")
            except:
                pass  # Ne pas bloquer l'opération si le backup échoue
        
        return func(*args, **kwargs)
    return wrapper

================================================================================
FICHIER: guignomap/validators.py
DESCRIPTION: NOUVEAU v4.0: Validation et sanitisation
LIGNES: 147
================================================================================
"""
Validateurs et sanitizers pour GuignoMap
Protection contre injections et validation des formats
"""

import re
import html
from typing import Optional, Tuple

class InputValidator:
    """Classe de validation et sanitization des entrées"""
    
    @staticmethod
    def sanitize_text(text: str, max_length: int = 255) -> str:
        """Nettoie et limite un texte"""
        if not text:
            return ""
        # Supprimer les caractères de contrôle
        text = "".join(char for char in text if ord(char) >= 32 or char == '\n')
        # Échapper le HTML
        text = html.escape(text)
        # Limiter la longueur
        return text[:max_length].strip()
    
    @staticmethod
    def sanitize_street_name(name: str) -> str:
        """Valide et nettoie un nom de rue"""
        if not name:
            return ""
        # Garder seulement lettres, chiffres, espaces, tirets, apostrophes, accents
        name = re.sub(r'[^a-zA-ZÀ-ÿ0-9\s\-\'\.]', '', name)
        return name[:100].strip()
    
    @staticmethod
    def sanitize_team_id(team_id: str) -> str:
        """Valide un ID d'équipe"""
        if not team_id:
            return ""
        # Format: LETTRES + CHIFFRES seulement, max 20 caractères
        team_id = re.sub(r'[^A-Z0-9]', '', team_id.upper())
        return team_id[:20]
    
    @staticmethod
    def sanitize_address_number(number: str) -> str:
        """Valide un numéro civique"""
        if not number:
            return ""
        # Garder chiffres et lettres (ex: 123A)
        number = re.sub(r'[^0-9A-Za-z\-]', '', number)
        return number[:10]
    
    @staticmethod
    def validate_password(password: str) -> Tuple[bool, str]:
        """Valide la force d'un mot de passe"""
        if not password:
            return False, "Mot de passe requis"
        if len(password) < 8:
            return False, "Minimum 8 caractères"
        if len(password) > 128:
            return False, "Maximum 128 caractères"
        if not re.search(r'[A-Z]', password):
            return False, "Au moins une majuscule requise"
        if not re.search(r'[a-z]', password):
            return False, "Au moins une minuscule requise"
        if not re.search(r'[0-9]', password):
            return False, "Au moins un chiffre requis"
        return True, "OK"
    
    @staticmethod
    def validate_sector(sector: str) -> str:
        """Valide un secteur"""
        valid_sectors = ['Principal', 'Centre', 'Nord', 'Sud', 'Est', 'Ouest', 'Résidentiel', '']
        if sector not in valid_sectors:
            return ''
        return sector
    
    @staticmethod
    def validate_status(status: str) -> str:
        """Valide un statut de rue"""
        valid_statuses = ['a_faire', 'en_cours', 'terminee']
        if status not in valid_statuses:
            return 'a_faire'
        return status
    
    @staticmethod
    def sanitize_note(note: str) -> str:
        """Nettoie une note/commentaire"""
        if not note:
            return ""
        # Supprimer caractères dangereux mais garder ponctuation basique
        note = re.sub(r'[<>\"\'`;]', '', note)
        return note[:500].strip()
    
    @staticmethod
    def is_sql_safe(text: str) -> bool:
        """Vérifie qu'un texte ne contient pas de patterns SQL dangereux"""
        if not text:
            return True
        dangerous_patterns = [
            r'\bDROP\b', r'\bDELETE\b', r'\bINSERT\b', r'\bUPDATE\b',
            r'\bEXEC\b', r'\bEXECUTE\b', r'--', r'/\*', r'\*/', r';'
        ]
        text_upper = text.upper()
        for pattern in dangerous_patterns:
            if re.search(pattern, text_upper):
                return False
        return True

def validate_and_clean_input(input_type: str, value: str) -> Tuple[bool, str]:
    """Fonction principale de validation"""
    validator = InputValidator()
    
    if input_type == "team_id":
        clean = validator.sanitize_team_id(value)
        return bool(clean), clean
    
    elif input_type == "street_name":
        clean = validator.sanitize_street_name(value)
        if not validator.is_sql_safe(clean):
            return False, ""
        return bool(clean), clean
    
    elif input_type == "address":
        clean = validator.sanitize_address_number(value)
        return bool(clean), clean
    
    elif input_type == "note":
        clean = validator.sanitize_note(value)
        if not validator.is_sql_safe(clean):
            return False, ""
        return bool(clean), clean
    
    elif input_type == "sector":
        clean = validator.validate_sector(value)
        return True, clean
    
    elif input_type == "status":
        clean = validator.validate_status(value)
        return True, clean
    
    elif input_type == "password":
        valid, msg = validator.validate_password(value)
        return valid, value if valid else ""
    
    else:
        clean = validator.sanitize_text(value)
        return bool(clean), clean

================================================================================
FICHIER: guignomap/reports.py
DESCRIPTION: NOUVEAU v4.0: Génération rapports Excel/PDF
LIGNES: 232
================================================================================
"""
Générateur de rapports Excel et PDF pour GuignoMap
"""

from pathlib import Path
from datetime import datetime
import pandas as pd
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, PageBreak, Image
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib.enums import TA_CENTER, TA_RIGHT
import xlsxwriter
from io import BytesIO

class ReportGenerator:
    def __init__(self, conn):
        self.conn = conn
        self.styles = getSampleStyleSheet()
        self._setup_custom_styles()
    
    def _setup_custom_styles(self):
        """Définit les styles personnalisés pour PDF"""
        self.styles.add(ParagraphStyle(
            name='CustomTitle',
            parent=self.styles['Heading1'],
            fontSize=24,
            textColor=colors.HexColor('#8B0000'),
            spaceAfter=30,
            alignment=TA_CENTER
        ))
        
        self.styles.add(ParagraphStyle(
            name='SectionTitle',
            parent=self.styles['Heading2'],
            fontSize=16,
            textColor=colors.HexColor('#8B0000'),
            spaceAfter=12,
            spaceBefore=12
        ))
    
    def generate_excel(self):
        """Génère un rapport Excel professionnel"""
        output = BytesIO()
        workbook = xlsxwriter.Workbook(output, {'remove_timezone': True})
        
        # Styles Excel
        header_format = workbook.add_format({
            'bold': True,
            'bg_color': '#8B0000',
            'font_color': 'white',
            'align': 'center',
            'valign': 'vcenter',
            'border': 1
        })
        
        cell_format = workbook.add_format({
            'align': 'center',
            'valign': 'vcenter',
            'border': 1
        })
        
        status_formats = {
            'terminee': workbook.add_format({'bg_color': '#90EE90', 'border': 1}),
            'en_cours': workbook.add_format({'bg_color': '#FFE4B5', 'border': 1}),
            'a_faire': workbook.add_format({'bg_color': '#FFB6C1', 'border': 1})
        }
        
        # Feuille 1 : Résumé
        summary_sheet = workbook.add_worksheet('Résumé Guignolée 2025')
        summary_sheet.set_column('A:E', 20)
        
        # Titre
        title_format = workbook.add_format({
            'bold': True,
            'font_size': 20,
            'font_color': '#8B0000',
            'align': 'center'
        })
        summary_sheet.merge_range('A1:E1', 'GUIGNOLÉE 2025 - RELAIS DE MASCOUCHE', title_format)
        summary_sheet.merge_range('A2:E2', f'Rapport généré le {datetime.now().strftime("%d/%m/%Y à %H:%M")}', cell_format)
        
        # Stats globales
        from db import extended_stats
        stats = extended_stats(self.conn)
        
        row = 4
        summary_sheet.write(row, 0, 'STATISTIQUES GLOBALES', header_format)
        summary_sheet.merge_range(f'B{row+1}:E{row+1}', '', header_format)
        
        row += 2
        summary_data = [
            ['Total des rues', stats['total']],
            ['Rues terminées', stats['done']],
            ['Rues en cours', stats.get('partial', 0)],
            ['Rues à faire', stats.get('todo', 0)],
            ['Progression globale', f"{(stats['done']/stats['total']*100) if stats['total'] > 0 else 0:.1f}%"],
            ['Total des notes', stats.get('total_notes', 0)],
            ['Adresses avec notes', stats.get('addresses_with_notes', 0)]
        ]
        
        for label, value in summary_data:
            summary_sheet.write(row, 0, label, cell_format)
            summary_sheet.write(row, 1, value, cell_format)
            row += 1
        
        # Feuille 2 : Détail des rues
        streets_sheet = workbook.add_worksheet('Détail des rues')
        streets_sheet.set_column('A:A', 30)
        streets_sheet.set_column('B:E', 15)
        
        # Headers
        headers = ['Rue', 'Secteur', 'Équipe', 'Statut', 'Notes']
        for col, header in enumerate(headers):
            streets_sheet.write(0, col, header, header_format)
        
        # Données
        from db import list_streets
        df = list_streets(self.conn)
        
        for idx, row_data in enumerate(df.iterrows(), 1):
            _, row = row_data
            streets_sheet.write(idx, 0, row.get('name', ''), cell_format)
            streets_sheet.write(idx, 1, row.get('sector', ''), cell_format)
            streets_sheet.write(idx, 2, row.get('team', ''), cell_format)
            
            status = row.get('status', 'a_faire')
            format_to_use = status_formats.get(status, cell_format)
            streets_sheet.write(idx, 3, status.replace('_', ' ').title(), format_to_use)
            
            streets_sheet.write(idx, 4, row.get('notes', 0), cell_format)
        
        # Feuille 3 : Performance des équipes
        teams_sheet = workbook.add_worksheet('Performance équipes')
        teams_sheet.set_column('A:F', 15)
        
        from db import stats_by_team
        teams_df = stats_by_team(self.conn)
        
        if not teams_df.empty:
            headers = ['Équipe', 'Total rues', 'Terminées', 'En cours', 'Notes', 'Progression %']
            for col, header in enumerate(headers):
                teams_sheet.write(0, col, header, header_format)
            
            for idx, row_data in enumerate(teams_df.iterrows(), 1):
                _, row = row_data
                teams_sheet.write(idx, 0, row.get('team', ''), cell_format)
                teams_sheet.write(idx, 1, row.get('total', 0), cell_format)
                teams_sheet.write(idx, 2, row.get('done', 0), cell_format)
                teams_sheet.write(idx, 3, row.get('partial', 0), cell_format)
                teams_sheet.write(idx, 4, row.get('notes', 0), cell_format)
                teams_sheet.write(idx, 5, f"{row.get('progress', 0):.1f}%", cell_format)
        
        workbook.close()
        output.seek(0)
        return output.getvalue()
    
    def generate_pdf(self):
        """Génère un rapport PDF professionnel"""
        output = BytesIO()
        doc = SimpleDocTemplate(output, pagesize=A4)
        story = []
        
        # Page de titre
        story.append(Paragraph("GUIGNOLÉE 2025", self.styles['CustomTitle']))
        story.append(Paragraph("Le Relais de Mascouche", self.styles['Title']))
        story.append(Spacer(1, 0.2*inch))
        story.append(Paragraph(f"Rapport généré le {datetime.now().strftime('%d/%m/%Y à %H:%M')}", self.styles['Normal']))
        story.append(PageBreak())
        
        # Résumé
        story.append(Paragraph("Résumé de la collecte", self.styles['SectionTitle']))
        
        from db import extended_stats
        stats = extended_stats(self.conn)
        
        summary_data = [
            ['Statistique', 'Valeur'],
            ['Total des rues', str(stats['total'])],
            ['Rues terminées', str(stats['done'])],
            ['Rues en cours', str(stats.get('partial', 0))],
            ['Rues à faire', str(stats.get('todo', 0))],
            ['Progression', f"{(stats['done']/stats['total']*100) if stats['total'] > 0 else 0:.1f}%"],
            ['Total notes', str(stats.get('total_notes', 0))]
        ]
        
        summary_table = Table(summary_data, colWidths=[3*inch, 2*inch])
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#8B0000')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 14),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(summary_table)
        story.append(PageBreak())
        
        # Performance des équipes
        story.append(Paragraph("Performance des équipes", self.styles['SectionTitle']))
        
        from db import stats_by_team
        teams_df = stats_by_team(self.conn)
        
        if not teams_df.empty:
            teams_data = [['Équipe', 'Total', 'Terminées', 'En cours', 'Progression']]
            for _, row in teams_df.iterrows():
                teams_data.append([
                    row.get('team', ''),
                    str(row.get('total', 0)),
                    str(row.get('done', 0)),
                    str(row.get('partial', 0)),
                    f"{row.get('progress', 0):.1f}%"
                ])
            
            teams_table = Table(teams_data, colWidths=[2*inch, 1*inch, 1*inch, 1*inch, 1.5*inch])
            teams_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#8B0000')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            story.append(teams_table)
        
        doc.build(story)
        output.seek(0)
        return output.getvalue()


================================================================================
SECTION 4: INTERFACE ET CONFIGURATION
================================================================================

================================================================================
FICHIER: guignomap/assets/styles.css
DESCRIPTION: Styles CSS personnalisés
LIGNES: 633
================================================================================
/* ========================================
   GUIGNO-MAP - STYLES PERSONNALISÉS
   Le Relais de Mascouche
   ======================================== */

/* Import Google Fonts */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=Manrope:wght@700;800&display=swap');

/* ========================================
   VARIABLES CSS & THÈME
   ======================================== */
:root {
    /* Couleurs principales du Relais */
    --relais-rouge: #8B0000;
    --relais-rouge-light: #a52a2a;
    --relais-or: #FFD700;
    --relais-or-light: #FFE44D;
    
    /* Couleurs de statut */
    --status-green: #22c55e;
    --status-orange: #f59e0b;
    --status-red: #ef4444;
    --status-gray: #9ca3af;
    
    /* Couleurs de base */
    --bg-dark: #0e1117;
    --bg-secondary: #151b22;
    --bg-card: #1a1f2e;
    --border-color: #222a33;
    --text-primary: #fafafa;
    --text-secondary: #cbd5e1;
    --text-muted: #8b92a4;
    
    /* Espacements */
    --spacing-xs: 0.25rem;
    --spacing-sm: 0.5rem;
    --spacing-md: 1rem;
    --spacing-lg: 1.5rem;
    --spacing-xl: 2rem;
    
    /* Border radius */
    --radius-sm: 8px;
    --radius-md: 12px;
    --radius-lg: 16px;
    --radius-xl: 20px;
}

/* ========================================
   RESET & BASE STREAMLIT
   ======================================== */

/* Cache les éléments Streamlit non désirés */
header[data-testid="stHeader"] { 
    visibility: hidden; 
    height: 0; 
}

#MainMenu {visibility: hidden;}
footer {visibility: hidden;}

.block-container { 
    padding-top: 1rem;
    max-width: 100%;
}

/* Police globale */
* {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif !important;
}

/* ========================================
   HEADER PRINCIPAL AMÉLIORÉ
   ======================================== */
.brand-header {
    border-radius: var(--radius-lg);
    padding: 1.5rem 2rem;
    margin: 0 0 2rem 0;
    background: linear-gradient(135deg, 
        var(--relais-rouge) 0%, 
        var(--relais-rouge-light) 100%);
    border: 1px solid rgba(255, 255, 255, 0.1);
    position: relative;
    overflow: hidden;
    box-shadow: 0 10px 40px rgba(139, 0, 0, 0.3);
}

.brand-header::before {
    content: '';
    position: absolute;
    top: -50%;
    right: -10%;
    width: 60%;
    height: 200%;
    background: linear-gradient(90deg, 
        transparent, 
        rgba(255, 215, 0, 0.1));
    transform: rotate(35deg);
    pointer-events: none;
}

.brand-header::after {
    content: '🎁';
    position: absolute;
    right: 2rem;
    top: 50%;
    transform: translateY(-50%);
    font-size: 3rem;
    opacity: 0.2;
}

.brand-title {
    font-family: 'Manrope', sans-serif !important;
    font-size: 2rem;
    font-weight: 800;
    margin: 0 0 0.25rem;
    color: white;
    text-shadow: 2px 2px 8px rgba(0, 0, 0, 0.3);
    letter-spacing: -0.5px;
}

.brand-sub {
    color: rgba(255, 255, 255, 0.9);
    margin: 0;
    font-size: 1rem;
    font-weight: 400;
}

/* ========================================
   CARTES & CONTENEURS
   ======================================== */
.modern-card {
    background: var(--bg-card);
    border-radius: var(--radius-md);
    padding: var(--spacing-lg);
    margin-bottom: var(--spacing-md);
    border: 1px solid var(--border-color);
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
    transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
}

.modern-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 8px 16px rgba(0, 0, 0, 0.4);
    border-color: var(--relais-rouge);
}

.stat-card {
    background: linear-gradient(135deg, var(--bg-card) 0%, var(--bg-secondary) 100%);
    border-radius: var(--radius-md);
    padding: var(--spacing-md) var(--spacing-lg);
    border-left: 4px solid var(--relais-rouge);
    position: relative;
    overflow: hidden;
}

.stat-card::after {
    content: '';
    position: absolute;
    top: 0;
    right: 0;
    width: 100px;
    height: 100%;
    background: linear-gradient(90deg, transparent, rgba(139, 0, 0, 0.1));
    transform: skewX(-20deg);
}

/* ========================================
   MÉTRIQUES STREAMLIT
   ======================================== */
[data-testid="stMetric"] {
    background: linear-gradient(135deg, var(--bg-card) 0%, var(--bg-secondary) 100%);
    border-radius: var(--radius-md);
    padding: var(--spacing-md) var(--spacing-lg);
    border: 1px solid var(--border-color);
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.2);
    transition: all 0.3s ease;
}

[data-testid="stMetric"]:hover {
    transform: scale(1.02);
    border-color: var(--relais-rouge);
}

[data-testid="metric-container"] > div:first-child {
    color: var(--text-secondary);
    font-size: 0.875rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

[data-testid="metric-container"] > div:nth-child(2) {
    font-size: 2rem;
    font-weight: 700;
    color: var(--relais-rouge);
    margin-top: 0.25rem;
}

/* ========================================
   BOUTONS
   ======================================== */
.stButton > button,
.stDownloadButton > button {
    background: linear-gradient(135deg, var(--relais-rouge) 0%, var(--relais-rouge-light) 100%);
    color: white;
    border: none;
    border-radius: var(--radius-sm);
    padding: 0.625rem 1.25rem;
    font-weight: 600;
    font-size: 0.95rem;
    letter-spacing: 0.3px;
    box-shadow: 0 4px 12px rgba(139, 0, 0, 0.3);
    transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
    position: relative;
    overflow: hidden;
}

.stButton > button::before {
    content: '';
    position: absolute;
    top: 0;
    left: -100%;
    width: 100%;
    height: 100%;
    background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent);
    transition: left 0.5s;
}

.stButton > button:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(139, 0, 0, 0.4);
}

.stButton > button:hover::before {
    left: 100%;
}

.stButton > button:active {
    transform: translateY(0);
}

/* Bouton secondaire */
.secondary-btn > button {
    background: transparent !important;
    color: var(--relais-rouge) !important;
    border: 2px solid var(--relais-rouge) !important;
}

.secondary-btn > button:hover {
    background: var(--relais-rouge) !important;
    color: white !important;
}

/* ========================================
   INPUTS & FORMULAIRES
   ======================================== */
.stTextInput > div > div > input,
.stSelectbox > div > div > select,
.stTextArea > div > div > textarea {
    background: var(--bg-secondary);
    border: 2px solid var(--border-color);
    border-radius: var(--radius-sm);
    color: var(--text-primary);
    padding: 0.75rem 1rem;
    font-size: 0.95rem;
    transition: all 0.3s ease;
}

.stTextInput > div > div > input:focus,
.stSelectbox > div > div > select:focus,
.stTextArea > div > div > textarea:focus {
    border-color: var(--relais-rouge);
    box-shadow: 0 0 0 3px rgba(139, 0, 0, 0.1);
    outline: none;
}

/* Labels */
.stTextInput > label,
.stSelectbox > label,
.stTextArea > label {
    color: var(--text-secondary);
    font-weight: 600;
    font-size: 0.875rem;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-bottom: 0.5rem;
}

/* ========================================
   TABLEAUX
   ======================================== */
.stDataFrame {
    border-radius: var(--radius-md);
    overflow: hidden;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
    border: 1px solid var(--border-color);
}

.dataframe {
    background: var(--bg-card) !important;
}

.dataframe thead tr th {
    background: linear-gradient(135deg, var(--relais-rouge) 0%, var(--relais-rouge-light) 100%) !important;
    color: white !important;
    font-weight: 600;
    text-transform: uppercase;
    font-size: 0.8rem;
    letter-spacing: 0.5px;
    padding: 0.75rem !important;
    border: none !important;
}

.dataframe tbody tr {
    border-bottom: 1px solid var(--border-color);
    transition: background 0.2s ease;
}

.dataframe tbody tr:hover {
    background: rgba(139, 0, 0, 0.1) !important;
}

.dataframe tbody tr td {
    color: var(--text-primary) !important;
    padding: 0.75rem !important;
    border: none !important;
}

/* ========================================
   TABS
   ======================================== */
.stTabs [data-baseweb="tab-list"] {
    background: var(--bg-secondary);
    border-radius: var(--radius-md);
    padding: 0.5rem;
    gap: 0.5rem;
    border: 1px solid var(--border-color);
}

.stTabs [data-baseweb="tab"] {
    background: transparent;
    color: var(--text-secondary);
    border-radius: var(--radius-sm);
    padding: 0.625rem 1.25rem;
    font-weight: 600;
    transition: all 0.3s ease;
}

.stTabs [data-baseweb="tab"]:hover {
    background: rgba(139, 0, 0, 0.1);
    color: var(--text-primary);
}

.stTabs [aria-selected="true"] {
    background: linear-gradient(135deg, var(--relais-rouge) 0%, var(--relais-rouge-light) 100%) !important;
    color: white !important;
    box-shadow: 0 2px 8px rgba(139, 0, 0, 0.3);
}

/* ========================================
   EXPANDEURS
   ======================================== */
.streamlit-expanderHeader {
    background: var(--bg-card);
    border-radius: var(--radius-sm);
    border: 1px solid var(--border-color);
    font-weight: 600;
    color: var(--text-primary);
    transition: all 0.3s ease;
}

.streamlit-expanderHeader:hover {
    background: var(--bg-secondary);
    border-color: var(--relais-rouge);
}

/* ========================================
   SIDEBAR
   ======================================== */
section[data-testid="stSidebar"] {
    background: var(--bg-secondary);
    border-right: 1px solid var(--border-color);
}

section[data-testid="stSidebar"] .block-container {
    padding: var(--spacing-lg);
}

/* ========================================
   BADGES DE STATUT
   ======================================== */
.status-badge {
    display: inline-block;
    padding: 0.25rem 0.75rem;
    border-radius: var(--radius-xl);
    font-size: 0.75rem;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.status-terminee {
    background: rgba(34, 197, 94, 0.2);
    color: var(--status-green);
    border: 1px solid var(--status-green);
}

.status-en-cours {
    background: rgba(245, 158, 11, 0.2);
    color: var(--status-orange);
    border: 1px solid var(--status-orange);
}

.status-a-faire {
    background: rgba(239, 68, 68, 0.2);
    color: var(--status-red);
    border: 1px solid var(--status-red);
}

/* ========================================
   ALERTES & MESSAGES
   ======================================== */
.stAlert {
    border-radius: var(--radius-md);
    border-left-width: 4px;
    padding: var(--spacing-md) var(--spacing-lg);
}

.stSuccess {
    background: rgba(34, 197, 94, 0.1);
    border-left-color: var(--status-green);
    color: var(--status-green);
}

.stError {
    background: rgba(239, 68, 68, 0.1);
    border-left-color: var(--status-red);
    color: var(--status-red);
}

.stWarning {
    background: rgba(245, 158, 11, 0.1);
    border-left-color: var(--status-orange);
    color: var(--status-orange);
}

.stInfo {
    background: rgba(139, 0, 0, 0.1);
    border-left-color: var(--relais-rouge);
    color: var(--text-primary);
}

/* ========================================
   PROGRESS BAR
   ======================================== */
.custom-progress {
    background: var(--bg-card);
    border-radius: var(--radius-md);
    padding: var(--spacing-lg);
    border: 1px solid var(--border-color);
    margin: var(--spacing-md) 0;
}

.progress-bar {
    background: var(--bg-secondary);
    height: 12px;
    border-radius: 6px;
    overflow: hidden;
    position: relative;
}

.progress-fill {
    height: 100%;
    background: linear-gradient(90deg, 
        var(--status-green) 0%, 
        var(--status-orange) 50%, 
        var(--status-red) 100%);
    border-radius: 6px;
    transition: width 0.5s cubic-bezier(0.4, 0, 0.2, 1);
    position: relative;
}

.progress-fill::after {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: linear-gradient(90deg, 
        transparent 0%, 
        rgba(255, 255, 255, 0.3) 50%, 
        transparent 100%);
    animation: shimmer 2s infinite;
}

/* ========================================
   ANIMATIONS
   ======================================== */
@keyframes shimmer {
    0% { transform: translateX(-100%); }
    100% { transform: translateX(100%); }
}

@keyframes pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.7; }
}

@keyframes slideIn {
    from {
        opacity: 0;
        transform: translateY(-10px);
    }
    to {
        opacity: 1;
        transform: translateY(0);
    }
}

.loading {
    animation: pulse 2s infinite;
}

.slide-in {
    animation: slideIn 0.3s ease-out;
}

/* ========================================
   CARTE FOLIUM
   ======================================== */
iframe {
    border-radius: var(--radius-md);
    border: 1px solid var(--border-color);
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
}

/* ========================================
   FOOTER
   ======================================== */
.footer {
    text-align: center;
    padding: var(--spacing-xl);
    color: var(--text-secondary);
    border-top: 1px solid var(--border-color);
    margin-top: 3rem;
    font-size: 0.875rem;
}

.footer a {
    color: var(--relais-rouge);
    text-decoration: none;
    font-weight: 600;
    transition: color 0.3s ease;
}

.footer a:hover {
    color: var(--relais-or);
}

/* ========================================
   RESPONSIVE
   ======================================== */
@media (max-width: 768px) {
    .brand-title {
        font-size: 1.5rem;
    }
    
    .brand-sub {
        font-size: 0.875rem;
    }
    
    .modern-card {
        padding: var(--spacing-md);
    }
    
    .stButton > button {
        width: 100%;
    }
    
    [data-testid="metric-container"] > div:nth-child(2) {
        font-size: 1.5rem;
    }
}

@media (max-width: 480px) {
    .brand-header {
        padding: var(--spacing-md);
    }
    
    .brand-title {
        font-size: 1.25rem;
    }
    
    .brand-header::after {
        display: none;
    }
}

/* ========================================
   UTILITIES
   ======================================== */
.text-center { text-align: center; }
.text-right { text-align: right; }
.mt-1 { margin-top: var(--spacing-sm); }
.mt-2 { margin-top: var(--spacing-md); }
.mt-3 { margin-top: var(--spacing-lg); }
.mb-1 { margin-bottom: var(--spacing-sm); }
.mb-2 { margin-bottom: var(--spacing-md); }
.mb-3 { margin-bottom: var(--spacing-lg); }
.p-1 { padding: var(--spacing-sm); }
.p-2 { padding: var(--spacing-md); }
.p-3 { padding: var(--spacing-lg); }

/* ========================================
   DARK MODE OPTIMIZATIONS
   ======================================== */
@media (prefers-color-scheme: light) {
    :root {
        --bg-dark: #ffffff;
        --bg-secondary: #f8f9fa;
        --bg-card: #ffffff;
        --border-color: #e5e7eb;
        --text-primary: #111827;
        --text-secondary: #6b7280;
        --text-muted: #9ca3af;
    }
    
    .modern-card,
    [data-testid="stMetric"] {
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
    }
}

================================================================================
FICHIER: .streamlit/config.toml
DESCRIPTION: Configuration Streamlit
LIGNES: 36
================================================================================
[theme]
# Thème sombre avec les couleurs du Relais
base = "dark"
primaryColor = "#A9CF3B"              # Vert du Relais
backgroundColor = "#0F1318"           # Fond très sombre
secondaryBackgroundColor = "#1A1F26"  # Fond secondaire
textColor = "#F2F3F5"                 # Texte clair
font = "sans serif"

[client]
# Configuration minimale de la toolbar
toolbarMode = "minimal"
showErrorDetails = false

[runner]
# Optimisations de performance
magicEnabled = true
installTracer = false
fixMatplotlib = true

[server]
# Configuration serveur
headless = true
runOnSave = true
maxUploadSize = 10
enableCORS = false
enableXsrfProtection = true

[browser]
# Collecte des stats d'usage (désactivé pour confidentialité)
gatherUsageStats = false

[deprecation]
# Désactiver les avertissements de dépréciation
showImageFormat = false
showPyplotGlobalUse = false


================================================================================
FIN DE L'EXPORT COMPLET - GUIGNO-MAP v4.0
================================================================================

📊 STATISTIQUES DE L'EXPORT:
- Date de génération: 2025-09-14 15:32:38
- Nombre total de lignes: 4620
- Taille: 161945 bytes

🔧 FICHIERS INCLUS:
✅ Documentation complète (README.md, README_VENV.md)
✅ Configuration (requirements.txt, config.toml)
✅ Scripts Windows (lancer_guignomap.bat/.ps1)
✅ Code source principal (app.py, db.py, osm.py)
✅ Nouveaux modules v4.0 (backup.py, validators.py, reports.py)
✅ Interface et styles (CSS, assets)

Le système GuignoMap v4.0 est maintenant prêt pour un déploiement
sécurisé et professionnel pour la Guignolée 2025 de Mascouche.

================================================================================

```
---8<--- GuignoMap_code_export_20250914_audit.txt END ---

---8<--- GuignoMap_code_export_20250915_final_UTF8.txt BEGIN ---
```txt
# GuignoMap - Export de code complet
# Date : 15 septembre 2025 - 13:30:00
# Version : 4.1 finale avec améliorations UI/UX
# Auteur : GitHub Copilot & développeur
# Projet : Système de gestion pour la Guignolée 2025
# Encodage : UTF-8 (sans BOM)

## RÉSUMÉ DES AMÉLIORATIONS RÉCENTES

### Corrections UI/UX finalisées :
1. **Assignations** : Suppression overlay texte au-dessus sélecteur secteur, layout propre container/colonnes
2. **Équipes** : Suppression doublon markdown causant superposition, formulaire robuste avec confirmation mot de passe
3. **Validation** : Politique mot de passe assouplie (min 4 chars, aucune autre contrainte)
4. **Interface** : Toggle "Afficher mots de passe", rendu uniforme sans styles spéciaux
5. **Exports** : Correction API XlsxWriter (indices entiers), plus d'erreurs Pylance
6. **Base données** : Déduplication log_activity, fonction create_team robuste

### Architecture technique :
- Python 3.13.6, Streamlit, pandas, folium, xlsxwriter, bcrypt
- Base SQLite avec validation complète
- Système de backup automatique
- Exports professionnels (Excel, PDF, CSV)
- Authentification bcrypt sécurisée

### Commits récents :
- 46b2213: equipes: remove summary/markdown duplication (no overlay); relax password policy to min 4 chars; docs
- 1ee36fe: equipes: add password confirmation; policy = min 4 chars; show/hide toggle; docs
- 6a2c728: ui(assignations): remove stray overlay above sector select; clean layout; uniform table rendering
- 23959b2: UI/UX finalisé : suppression overlay + colonne Statut uniforme + corrections Pylance

================================================================================

## FICHIER 1: guignomap/app.py (Application principale Streamlit)

```python"""
Guigno-Map - Application de gestion de collecte de denrées
Le Relais de Mascouche
Version 3.0 - Production
"""

from pathlib import Path
import time
from datetime import datetime
import pandas as pd
import streamlit as st
import folium
from streamlit_folium import st_folium

# Import des modules locaux
import db
from validators import validate_and_clean_input
from osm import build_geometry_cache, load_geometry_cache, build_addresses_cache, load_addresses_cache, CACHE_FILE

# Configuration des chemins
DB_PATH = Path(__file__).parent / "guigno_map.db"

# --- Utilitaire de compatibilité pandas Styler ---
from typing import Callable, Any

def style_map_compat(df: pd.DataFrame, fn: Callable[[Any], str], subset: Any = None):
    """Applique un style cellule-à-cellule en utilisant Styler.map si disponible,
    sinon fallback dynamique vers applymap sans exposer l'attribut (OK pour Pylance).
    
    Args:
        df: DataFrame à styliser
        fn: Fonction qui prend une valeur cellule et retourne une string CSS
        subset: Colonnes à cibler (ex: ['status'] ou None pour toutes)
    """
    styler = df.style
    if hasattr(styler, "map"):
        # Pandas 2.4+ : utilise la nouvelle API map()
        return styler.map(fn, subset=subset)
    # Pandas < 2.4 : fallback vers applymap (sans référence statique)
    return getattr(styler, "applymap")(fn, subset=subset)

# --- Mapping des statuts pour l'affichage ---
STATUS_TO_LABEL = {"a_faire": "À faire", "en_cours": "En cours", "terminee": "Terminée"}
LABEL_TO_STATUS = {v: k for k, v in STATUS_TO_LABEL.items()}

ASSETS = Path(__file__).parent / "assets"

# Configuration Streamlit
st.set_page_config(
    page_title="Guigno-Map | Relais de Mascouche",
    page_icon="🎁",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialisation session
if "auth" not in st.session_state:
    st.session_state.auth = None

# ============================================
# COMPOSANTS UI
# ============================================

def inject_css():
    """Charge le CSS depuis le fichier externe"""
    css_file = ASSETS / "styles.css"
    if css_file.exists():
        css = css_file.read_text(encoding="utf-8")
        st.markdown(f"<style>{css}</style>", unsafe_allow_html=True)

def render_header():
    """Header moderne avec logo Guignolée et design festif"""
    
    # Container principal avec fond festif
    st.markdown("""
    <div style="
        background: linear-gradient(135deg, #c41e3a 0%, #165b33 100%);
        border-radius: 20px;
        padding: 2rem;
        margin-bottom: 2rem;
        position: relative;
        overflow: hidden;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    ">
        <!-- Flocons de neige animés en CSS -->
        <div style="position: absolute; width: 100%; height: 100%; opacity: 0.1;">
            <span style="position: absolute; top: 10%; left: 10%; font-size: 2rem;">❄️</span>
            <span style="position: absolute; top: 20%; left: 80%; font-size: 1.5rem;">❄️</span>
            <span style="position: absolute; top: 60%; left: 30%; font-size: 1.8rem;">❄️</span>
        </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([2, 5, 2])
    
    with col1:
        # Logo Guignolée
        if (ASSETS / "guignolee.png").exists():
            st.image(str(ASSETS / "guignolee.png"), width=150)
    
    with col2:
        st.markdown("""
        <div style="text-align: center;">
            <h1 style="
                color: white;
                font-family: 'Manrope', sans-serif;
                font-size: 2.5rem;
                margin: 0;
                text-shadow: 3px 3px 6px rgba(0,0,0,0.5);
                letter-spacing: 2px;
            ">🎅 GUIGNOLÉE 2025 🎁</h1>
            <p style="
                color: #FFD700;
                font-size: 1.2rem;
                margin: 0.5rem 0 0 0;
                font-weight: 600;
            ">Le Relais de Mascouche - 1er décembre</p>
            <p style="
                color: rgba(255,255,255,0.9);
                font-size: 1rem;
                margin-top: 0.5rem;
            ">Système de gestion de collecte</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        # Stats en temps réel
        stats = db.extended_stats(st.session_state.get('conn'))
        progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
        
        st.markdown(f"""
        <div style="
            background: rgba(255,255,255,0.2);
            border-radius: 15px;
            padding: 1rem;
            text-align: center;
        ">
            <div style="color: #FFD700; font-size: 2rem; font-weight: bold;">
                {progress:.0f}%
            </div>
            <div style="color: white; font-size: 0.9rem;">
                Complété
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

def render_login_card(role="benevole", conn=None):
    """Carte de connexion moderne avec design festif"""
    
    # Container de connexion stylisé
    st.markdown("""
    <div style="
        max-width: 400px;
        margin: 3rem auto;
        background: linear-gradient(135deg, rgba(255,255,255,0.1), rgba(255,255,255,0.05));
        backdrop-filter: blur(10px);
        border: 2px solid rgba(255,215,0,0.3);
        border-radius: 20px;
        padding: 2rem;
        box-shadow: 0 20px 40px rgba(0,0,0,0.3);
    ">
    """, unsafe_allow_html=True)
    
    # Icône et titre
    if role == "superviseur" or role == "gestionnaire":
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <div style="font-size: 3rem;">👔</div>
            <h2 style="color: #FFD700; margin: 1rem 0;">Espace Gestionnaire</h2>
            <p style="color: #cbd5e1;">Gérez la collecte et les équipes</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_gestionnaire", clear_on_submit=False):
            password = st.text_input(
                "🔐 Mot de passe",
                type="password",
                placeholder="Entrez le mot de passe gestionnaire"
            )
            
            col1, col2, col3 = st.columns([1,2,1])
            with col2:
                submit = st.form_submit_button(
                    "🚀 Connexion",
                    width="stretch"
                )
            
            if submit:
                if db.verify_team(conn, "ADMIN", password):
                    st.session_state.auth = {"role": "supervisor", "team_id": "ADMIN"}
                    st.success("✅ Bienvenue dans l'espace gestionnaire!")
                    st.snow()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("❌ Mot de passe incorrect")
    
    else:  # Bénévole
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <div style="font-size: 3rem;">🎅</div>
            <h2 style="color: #FFD700; margin: 1rem 0;">Espace Bénévole</h2>
            <p style="color: #cbd5e1;">Accédez à vos rues assignées</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_benevole", clear_on_submit=False):
            col1, col2 = st.columns(2)
            
            with col1:
                team_id = st.text_input(
                    "👥 Identifiant d'équipe",
                    placeholder="Ex: EQ001"
                )
            
            with col2:
                password = st.text_input(
                    "🔐 Mot de passe",
                    type="password",
                    placeholder="Mot de passe équipe"
                )
            
            col1, col2, col3 = st.columns([1,2,1])
            with col2:
                submit = st.form_submit_button(
                    "🎄 Connexion",
                    width="stretch"
                )
            
            if submit:
                if db.verify_team(conn, team_id, password):
                    st.session_state.auth = {"role": "volunteer", "team_id": team_id}
                    st.success(f"✅ Bienvenue équipe {team_id}!")
                    st.snow()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("❌ Identifiants incorrects")
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    # Aide en bas
    st.markdown("""
    <div style="text-align: center; margin-top: 2rem; color: #8b92a4;">
        <small>
        Besoin d'aide? Contactez votre gestionnaire<br>
        📞 450-474-4133
        </small>
    </div>
    """, unsafe_allow_html=True)

def render_metrics(stats):
    """Affiche les métriques principales"""
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Rues", stats['total'])
    
    with col2:
        st.metric("Rues Terminées", stats['done'])
    
    with col3:
        st.metric("En Cours", stats.get('partial', 0))
    
    with col4:
        st.metric("Progression", f"{progress:.1f}%")

def render_dashboard_gestionnaire(conn, geo):
    """Dashboard moderne pour gestionnaires avec KPIs visuels"""
    
    # KPIs principaux en cartes colorées
    stats = db.extended_stats(conn)
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    st.markdown("### 📊 Tableau de bord en temps réel")
    
    # Ligne de KPIs avec icônes festives
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #22c55e, #16a34a);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(34,197,94,0.3);
        ">
            <div style="font-size: 2.5rem;">🏘️</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats['total']}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Total Rues</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(59,130,246,0.3);
        ">
            <div style="font-size: 2.5rem;">✅</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats['done']}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Terminées</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #f59e0b, #d97706);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(245,158,11,0.3);
        ">
            <div style="font-size: 2.5rem;">🚶</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats.get('partial', 0)}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">En cours</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        # Nombre d'équipes actives
        teams_count = len(db.teams(conn))
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #8b5cf6, #7c3aed);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(139,92,246,0.3);
        ">
            <div style="font-size: 2.5rem;">👥</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{teams_count}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Équipes</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col5:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #c41e3a, #165b33);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(196,30,58,0.3);
        ">
            <div style="font-size: 2.5rem;">🎯</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{progress:.0f}%</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Progression</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Barre de progression visuelle
    st.markdown("### 🎄 Progression globale")
    st.progress(progress / 100)
    
    # Graphique par secteur (si disponible)
    st.markdown("### 📈 Performance par équipe")
    try:
        teams_stats = db.stats_by_team(conn)
        if not teams_stats.empty:
            # Graphique en barres colorées
            import plotly.express as px
            fig = px.bar(
                teams_stats, 
                x='team', 
                y='progress',
                color='progress',
                color_continuous_scale=['#ef4444', '#f59e0b', '#22c55e'],
                labels={'team': 'Équipe', 'progress': 'Progression (%)'},
                title="Performance des équipes"
            )
            fig.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig, width="stretch")
        else:
            st.info("Aucune statistique d'équipe disponible")
    except Exception as e:
        st.warning("Graphiques non disponibles (module plotly manquant)")
        # Fallback vers un tableau simple
        try:
            teams_stats = db.stats_by_team(conn)
            if not teams_stats.empty:
                st.dataframe(teams_stats, width="stretch")
        except:
            st.info("Aucune statistique d'équipe disponible")

def add_persistent_legend(m):
    """Ajoute une légende persistante pour les 4 états des rues via contrôle HTML"""
    legend_html = """
    <div id='gm-legend' class='leaflet-control-layers leaflet-control' 
         style='position: absolute; bottom: 10px; right: 10px; z-index: 1000;
                background: white; border: 2px solid rgba(0,0,0,0.2); 
                border-radius: 5px; padding: 10px; box-shadow: 0 1px 5px rgba(0,0,0,0.2);
                font-family: "Helvetica Neue", Arial, Helvetica, sans-serif; 
                font-size: 12px; line-height: 18px; color: #333;'>
        <strong style='margin-bottom: 8px; display: block;'>Légende</strong>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #28a745; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Terminée</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #f1c40f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>En cours</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #ff4d4f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Assignée (à faire)</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px dashed #ff4d4f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Non assignée</span>
        </div>
    </div>
    """
    m.get_root().html.add_child(folium.Element(legend_html))

def create_map(df, geo):
    """Crée la carte Folium centrée sur Mascouche avec toutes les rues"""
    # Limites de Mascouche
    bounds = {
        "north": 45.78,
        "south": 45.70,
        "east": -73.55,
        "west": -73.70
    }
    center = [(bounds["north"] + bounds["south"]) / 2, 
              (bounds["east"] + bounds["west"]) / 2]
    
    # Créer la carte
    m = folium.Map(
        location=center,
        zoom_start=13,  # Zoom optimisé pour voir toute la ville
        tiles="https://{s}.tile.openstreetmap.fr/osmfr/{z}/{x}/{y}.png",
        attr='© OpenStreetMap France',
        control_scale=True,
        max_bounds=True,
        min_zoom=11,
        max_zoom=18,
        prefer_canvas=True,
        zoom_control=True,
        scrollWheelZoom=True
    )
    
    # Ajouter plusieurs couches de fond
    folium.TileLayer(
        tiles='https://{s}.tile.openstreetmap.fr/osmfr/{z}/{x}/{y}.png',
        attr='© OpenStreetMap France',
        name='OSM France (Détaillé)',
        overlay=False,
        control=True
    ).add_to(m)

    folium.TileLayer(
        tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager/{z}/{x}/{y}.png',
        attr='© CARTO',
        name='CARTO Voyager',
        overlay=False,
        control=True
    ).add_to(m)

    folium.TileLayer(
        tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Street_Map/MapServer/tile/{z}/{y}/{x}',
        attr='© Esri',
        name='Esri WorldStreetMap',
        overlay=False,
        control=True
    ).add_to(m)

    # Ajouter le contrôle des couches
    folium.LayerControl().add_to(m)
    
    # Définir les limites de la carte sur Mascouche
    m.fit_bounds([[bounds["south"], bounds["west"]], 
                  [bounds["north"], bounds["east"]]])
    
    if not geo:
        st.warning("Aucune donnée géométrique disponible")
        return m
    
    # Construire le lookup des infos DB
    street_info = {}
    if not df.empty:
        for idx, row in df.iterrows():
            name = str(row['name']) if 'name' in df.columns else ''
            status = row['status'] if 'status' in df.columns and pd.notna(row['status']) else 'a_faire'
            team = row['team'] if 'team' in df.columns and pd.notna(row['team']) else ''
            notes = str(row['notes']) if 'notes' in df.columns and pd.notna(row['notes']) else '0'
            
            street_info[name] = {
                'status': status,
                'team': str(team).strip() if team else '',
                'notes': notes
            }
    
    # Couleurs par statut
    status_colors = {
        'terminee': '#22c55e',  # Vert
        'en_cours': '#f59e0b',  # Orange
        'a_faire': '#ef4444'    # Rouge
    }
    
    # Compteurs pour stats
    stats = {"total": 0, "assigned": 0, "unassigned": 0}
    
    # Ajouter TOUTES les rues de la géométrie
    for name, paths in geo.items():
        stats["total"] += 1
        
        # Info depuis DB ou défaut (rouge pointillé)
        info = street_info.get(name, {
            'status': 'a_faire',
            'team': '',
            'notes': '0'
        })
        
        status = info['status']
        team = info['team']
        notes = info['notes']
        
        # Style: TOUJOURS pointillé si pas d'équipe
        has_team = bool(team)
        color = status_colors.get(status, '#ef4444')  # Rouge par défaut
        opacity = 0.9 if has_team else 0.7
        dash = None if has_team else '8,12'  # Pointillés si non assigné
        weight = 7 if has_team else 5
        
        if has_team:
            stats["assigned"] += 1
        else:
            stats["unassigned"] += 1
        
        # Tooltip informatif
        tooltip_html = f"""
        <div style='font-family: sans-serif'>
            <strong style='font-size: 14px'>{name}</strong><br>
            <span style='color: {color}'>● Statut: {status.replace('_', ' ').title()}</span><br>
            <span>📋 Équipe: {team if team else '⚠️ NON ASSIGNÉE'}</span><br>
            <span>📝 Notes: {notes}</span>
        </div>
        """
        
        # Ajouter chaque segment de la rue
        for path in paths:
            if path and len(path) >= 2:
                folium.PolyLine(
                    path,
                    color=color,
                    weight=weight,
                    opacity=opacity,
                    dash_array=dash,
                    tooltip=folium.Tooltip(tooltip_html, sticky=True)
                ).add_to(m)
    
    # Ajouter un marqueur au centre-ville
    folium.Marker(
        [45.7475, -73.6005],
        popup="Centre-ville de Mascouche",
        tooltip="Centre-ville",
        icon=folium.Icon(color='red', icon='info-sign')
    ).add_to(m)
    
    # Ajouter la légende persistante
    add_persistent_legend(m)
    
    return m


# ============================================
# UTILITAIRES EXPORT
# ============================================

def export_excel_professionnel(conn):
    """Export Excel avec mise en forme professionnelle"""
    try:
        from reports import ReportGenerator
        generator = ReportGenerator(conn)
        return generator.generate_excel()
    except ImportError:
        # Fallback si les dépendances ne sont pas installées
        return db.export_to_csv(conn)


# ============================================
# FONCTIONNALITÉS AVANCÉES
# ============================================

def detect_mobile():
    """Détecte si l'utilisateur est sur mobile"""
    try:
        # Récupérer les paramètres de l'URL pour forcer le mode mobile
        query_params = st.experimental_get_query_params()
        if 'mobile' in query_params:
            return True
        
        # Mobile-first approach pour l'instant
        return True
    except:
        return False

def show_notification(message, type="success"):
    """Affiche une notification stylisée"""
    icons = {
        "success": "✅",
        "error": "❌",
        "warning": "⚠️",
        "info": "ℹ️"
    }
    colors = {
        "success": "#22c55e",
        "error": "#ef4444", 
        "warning": "#f59e0b",
        "info": "#3b82f6"
    }
    
    st.markdown(f"""
    <div style="
        position: fixed;
        top: 20px;
        right: 20px;
        background: {colors[type]};
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 10px;
        box-shadow: 0 5px 15px rgba(0,0,0,0.3);
        z-index: 9999;
        animation: slideIn 0.3s ease-out;
    ">
        <strong>{icons[type]} {message}</strong>
    </div>
    <style>
    @keyframes slideIn {{
        from {{ transform: translateX(100%); opacity: 0; }}
        to {{ transform: translateX(0); opacity: 1; }}
    }}
    </style>
    """, unsafe_allow_html=True)

def show_team_badges(conn, team_id):
    """Affiche les badges de réussite de l'équipe"""
    try:
        df = db.list_streets(conn, team=team_id)
        done = len(df[df['status'] == 'terminee'])
        total = len(df)
        
        badges = []
        if done >= 1:
            badges.append("🏆 Première rue!")
        if done >= total * 0.25:
            badges.append("🥉 25% complété")
        if done >= total * 0.5:
            badges.append("🥈 50% complété")
        if done >= total * 0.75:
            badges.append("🥇 75% complété")
        if done == total:
            badges.append("🌟 CHAMPION!")
        
        if badges:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #FFD700, #FFA500);
                padding: 1rem;
                border-radius: 10px;
                text-align: center;
                margin: 1rem 0;
            ">
                <strong>Vos badges:</strong><br>
                <div style="font-size: 2rem; margin-top: 0.5rem;">
                    {' '.join(badges)}
                </div>
            </div>
            """, unsafe_allow_html=True)
    except:
        pass

def generate_sms_list(conn):
    """Génère une liste de téléphones pour SMS de groupe"""
    try:
        # Cette fonction nécessiterait une table de téléphones
        # Pour l'instant, retourne un exemple
        return "# Liste des téléphones bénévoles\n# 450-XXX-XXXX\n# 438-XXX-XXXX"
    except:
        return "Liste non disponible"

def page_export_gestionnaire(conn):
    """Section export avec formats multiples"""
    
    st.markdown("### 📊 Centre d'export des données")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>� Rapport PDF</h4>
            <p><small>Format professionnel pour présentation</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            from reports import ReportGenerator
            generator = ReportGenerator(conn)
            pdf_data = generator.generate_pdf()
            st.download_button(
                "📥 Télécharger PDF",
                pdf_data,
                "rapport_guignolee_2025.pdf",
                "application/pdf",
                width="stretch"
            )
        except ImportError:
            st.button("PDF (Installer reportlab)", disabled=True, width="stretch")
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>📊 Excel détaillé</h4>
            <p><small>Avec graphiques et mise en forme</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            excel_data = export_excel_professionnel(conn)
            st.download_button(
                "📥 Télécharger Excel",
                excel_data,
                "guignolee_2025.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width="stretch"
            )
        except:
            st.button("Excel (Non disponible)", disabled=True, width="stretch")
    
    with col3:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>📱 Liste SMS</h4>
            <p><small>Téléphones des bénévoles</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        sms_list = generate_sms_list(conn)
        st.download_button(
            "📥 Liste téléphones",
            sms_list,
            "telephones_benevoles.txt",
            "text/plain",
            width="stretch"
        )


# ============================================
# PAGES
# ============================================

def page_accueil(conn, geo):
    """Page d'accueil"""
    st.markdown("### 🎁 Bienvenue sur Guigno-Map!")
    st.info("Sélectionnez votre mode dans le menu de gauche pour commencer.")
    
    st.markdown("---")
    st.markdown("#### 📊 Aperçu de la collecte")
    
    stats = db.extended_stats(conn)
    render_metrics(stats)
    
    df_all = db.list_streets(conn)
    if not df_all.empty:
        m = create_map(df_all, geo)
        st_folium(m, height=800, width=None, returned_objects=[])

def page_accueil_v2(conn, geo):
    """Page d'accueil festive avec compte à rebours"""
    
    # Compte à rebours jusqu'au 1er décembre
    from datetime import datetime, timedelta
    target = datetime(2025, 12, 1, 8, 0, 0)
    now = datetime.now()
    diff = target - now
    
    if diff.days > 0:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #c41e3a, #165b33);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h2 style="color: #FFD700; margin: 0;">⏰ Compte à rebours Guignolée</h2>
            <div style="font-size: 3rem; color: white; margin: 1rem 0;">
                {diff.days} jours {diff.seconds//3600} heures
            </div>
            <p style="color: rgba(255,255,255,0.9);">avant le grand jour!</p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #FFD700, #FFA500);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h2 style="color: #c41e3a; margin: 0;">🎉 C'EST AUJOURD'HUI!</h2>
            <div style="font-size: 2rem; color: #165b33; margin: 1rem 0;">
                Bonne Guignolée 2025!
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # Hero section festif
    st.markdown("""
    <div style="
        text-align: center;
        padding: 3rem 1rem;
        background: linear-gradient(135deg, rgba(196,30,58,0.1), rgba(22,91,51,0.1));
        border-radius: 20px;
        margin-bottom: 2rem;
    ">
        <h1 style="font-size: 3rem; margin: 0;">🎄 Bienvenue sur Guigno-Map 🎄</h1>
        <p style="font-size: 1.3rem; color: #666; margin: 1rem 0;">
            Votre plateforme digitale pour la Guignolée 2025
        </p>
        <p style="color: #888;">
            Gérez efficacement votre collecte de denrées avec une interface moderne
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Stats visuelles améliorées
    stats = db.extended_stats(conn)
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    st.markdown("### 📊 État de la collecte en temps réel")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #22c55e, #16a34a);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(34,197,94,0.3);
        ">
            <div style="font-size: 3rem;">🏘️</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats['total']}</div>
            <div>Total Rues</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(59,130,246,0.3);
        ">
            <div style="font-size: 3rem;">✅</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats['done']}</div>
            <div>Complétées</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #f59e0b, #d97706);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(245,158,11,0.3);
        ">
            <div style="font-size: 3rem;">🚶</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats.get('partial', 0)}</div>
            <div>En Cours</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #c41e3a, #165b33);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(196,30,58,0.3);
        ">
            <div style="font-size: 3rem;">🎯</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{progress:.0f}%</div>
            <div>Progression</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Barre de progression globale
    st.markdown("### 🎄 Progression globale de la collecte")
    st.progress(progress / 100)
    
    # Carte festive
    st.markdown("### 🗺️ Vue d'ensemble de Mascouche")
    df_all = db.list_streets(conn)
    if not df_all.empty:
        m = create_map(df_all, geo)
        st_folium(m, height=750, width=None, returned_objects=[])
    
    # CSS pour réduire l'espace après la carte
    st.markdown("""
    <style>
    div[data-testid="stVerticalBlock"] > div:has(iframe) {
        margin-bottom: 0 !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Call to action
    st.markdown("""
    <div style="
        text-align: center;
        padding: 2rem;
        background: linear-gradient(135deg, rgba(255,215,0,0.1), rgba(255,215,0,0.05));
        border: 2px solid rgba(255,215,0,0.3);
        border-radius: 15px;
        margin-top: 1rem;
    ">
        <h3>🎅 Prêt à participer ?</h3>
        <p>Choisissez votre rôle dans le menu de gauche pour commencer</p>
        <p style="font-size: 0.9rem; color: #666;">
            Bénévoles : Accédez à vos rues assignées<br>
            Gestionnaires : Supervisez toute la collecte
        </p>
    </div>
    """, unsafe_allow_html=True)

def page_benevole(conn, geo):
    """Interface bénévole moderne avec vue limitée"""
    
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        render_login_card("benevole", conn)
        return
    
    team_id = st.session_state.auth["team_id"]
    
    # Header d'équipe personnalisé
    st.markdown(f"""
    <div style="
        background: linear-gradient(135deg, #165b33, #c41e3a);
        padding: 1.5rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
    ">
        <h2 style="color: white; margin: 0;">🎅 Équipe {team_id}</h2>
        <p style="color: #FFD700; margin: 0.5rem 0 0 0;">Bonne collecte!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Stats de l'équipe
    df_team = db.list_streets(conn, team=team_id)
    if df_team.empty:
        st.warning("Aucune rue assignée. Contactez votre superviseur.")
        return
    
    done = len(df_team[df_team['status'] == 'terminee'])
    total = len(df_team)
    progress = (done / total * 100) if total > 0 else 0
    
    # Mini dashboard équipe
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("📍 Vos rues", total)
    with col2:
        st.metric("✅ Complétées", done)
    with col3:
        st.metric("🎯 Progression", f"{progress:.0f}%")
    
    # Système de badges
    show_team_badges(conn, team_id)
    
    # Barre de progression
    st.progress(progress / 100)
    
    # Tabs modernisés
    tab1, tab2, tab3 = st.tabs(["🗺️ Ma carte", "📝 Collecte", "📊 Historique"])
    
    with tab1:
        # CARTE LIMITÉE AUX RUES DE L'ÉQUIPE
        st.markdown("### Vos rues assignées")
        
        # Créer une carte avec SEULEMENT les rues de l'équipe
        m = folium.Map(
            location=[45.7475, -73.6005],
            zoom_start=14,
            tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager/{z}/{x}/{y}.png',
            attr='© CARTO'
        )
        
        # Filtrer geo pour n'afficher QUE les rues de l'équipe
        team_streets = df_team['name'].tolist()
        
        for street_name in team_streets:
            if street_name in geo:
                status = df_team[df_team['name'] == street_name]['status'].iloc[0]
                
                # Couleurs selon statut
                colors = {
                    'terminee': '#22c55e',
                    'en_cours': '#f59e0b',
                    'a_faire': '#ef4444'
                }
                color = colors.get(status, '#ef4444')
                
                # Ajouter les segments de cette rue
                for path in geo[street_name]:
                    if path and len(path) >= 2:
                        folium.PolyLine(
                            path,
                            color=color,
                            weight=8,  # Plus épais pour mobile
                            opacity=0.9,
                            tooltip=f"{street_name} - {status.replace('_', ' ').title()}"
                        ).add_to(m)
        
        # Centrer sur les rues de l'équipe
        if team_streets and team_streets[0] in geo:
            first_street = geo[team_streets[0]][0]
            if first_street:
                m.location = first_street[0]
        
        st_folium(m, height=650, width=None, returned_objects=[])
    
    with tab2:
        st.markdown("### 📋 Checklist de collecte")
        
        # Liste interactive des rues
        for _, row in df_team.iterrows():
            street = row['name']
            status = row['status']
            notes_count = row.get('notes', 0)
            
            # Carte de rue stylisée
            status_emoji = {'terminee': '✅', 'en_cours': '🚶', 'a_faire': '⭕'}
            status_color = {'terminee': '#22c55e', 'en_cours': '#f59e0b', 'a_faire': '#ef4444'}
            
            with st.expander(f"{status_emoji.get(status, '⭕')} **{street}** ({notes_count} notes)"):
                
                # Changement rapide de statut
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("⭕ À faire", key=f"todo_{street}", width="stretch"):
                        db.set_status(conn, street, 'a_faire')
                        st.rerun()
                with col2:
                    if st.button("🚶 En cours", key=f"progress_{street}", width="stretch"):
                        db.set_status(conn, street, 'en_cours')
                        st.rerun()
                with col3:
                    if st.button("✅ Terminée", key=f"done_{street}", width="stretch"):
                        db.set_status(conn, street, 'terminee')
                        st.rerun()
                
                st.markdown("---")
                
                # Ajout de note rapide
                st.markdown("**Ajouter une note:**")
                with st.form(f"note_{street}", clear_on_submit=True):
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        num = st.text_input("N°", placeholder="123")
                    with col2:
                        note = st.text_input("Note", placeholder="Personne absente")
                    
                    if st.form_submit_button("➕ Ajouter"):
                        if num and note:
                            db.add_note_for_address(conn, street, team_id, num, note)
                            st.success("Note ajoutée!")
                            st.rerun()
                
                # Notes existantes
                notes = db.get_street_addresses_with_notes(conn, street)
                if not notes.empty:
                    st.markdown("**Notes existantes:**")
                    for _, n in notes.iterrows():
                        st.markdown(f"• **{n['address_number']}** : {n['comment']}")
    
    with tab3:
        st.markdown("### 📊 Votre historique")
        try:
            notes = db.get_team_notes(conn, team_id)
            if not notes.empty:
                st.dataframe(notes, width="stretch")
            else:
                st.info("Aucune note encore")
        except:
            st.info("Historique non disponible")

def page_benevole_v2(conn, geo):
    """Interface bénévole moderne v4.1 avec vue 'Mes rues'"""
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        # Afficher la page de connexion bénévole
        return page_benevole(conn, geo)
    
    # Interface bénévole connecté avec tabs
    st.header("🎅 Espace Bénévole")
    team_id = st.session_state.auth.get("team", "Équipe inconnue")
    st.markdown(f"**Équipe:** {team_id}")
    
    # Tabs pour bénévoles
    tabs = st.tabs([
        "🏘️ Mes rues",
        "🗺️ Carte de terrain", 
        "📝 Journal d'activité"
    ])
    
    with tabs[0]:
        # Nouvelle vue "Mes rues" v4.1
        page_benevole_mes_rues(conn)
    
    with tabs[1]:
        # Carte traditionnelle (réutilise l'ancienne interface)
        page_benevole(conn, geo)
    
    with tabs[2]:
        # Journal d'activité de l'équipe
        st.markdown("### 📝 Journal d'activité de votre équipe")
        try:
            # Afficher les activités récentes de l'équipe
            cursor = conn.execute("""
                SELECT action, details, created_at
                FROM activity_log
                WHERE team_id = ?
                ORDER BY created_at DESC
                LIMIT 20
            """, (team_id,))
            
            activities = cursor.fetchall()
            if activities:
                for activity in activities:
                    action, details, created_at = activity
                    st.markdown(f"**{created_at}** - {action}: {details}")
            else:
                st.info("Aucune activité enregistrée pour votre équipe")
                
        except Exception as e:
            st.info("Journal d'activité temporairement indisponible")
            st.caption(f"Erreur: {e}")

def page_gestionnaire_v2(conn, geo):
    """Interface gestionnaire moderne (ancien superviseur)"""
    st.header("👔 Tableau de Bord Gestionnaire")
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        render_login_card("gestionnaire", conn)
        return
    
    # Dashboard moderne
    render_dashboard_gestionnaire(conn, geo)
    
    # Tabs
    tabs = st.tabs([
        "📊 Vue d'ensemble",
        "👥 Équipes",
        "🗺️ Assignation",
        "📥 Export",
        "🛠 Tech"
    ])
    
    with tabs[0]:
        # Carte générale
        st.markdown("### Carte générale")
        df_all = db.list_streets(conn)
        if not df_all.empty:
            m = create_map(df_all, geo)
            st_folium(m, height=800, width=None, returned_objects=[])
        
        # Activité récente
        st.markdown("### Activité récente")
        try:
            recent = db.recent_activity(conn, limit=10)
            if not recent.empty:
                st.dataframe(recent, width="stretch")
            else:
                st.info("Aucune activité récente")
        except:
            st.info("Historique d'activité non disponible")
    
    with tabs[1]:
        # Gestion des équipes
        st.subheader("👥 Gestion des équipes", anchor=False)
        
        # === Formulaire de création d'équipe (robuste) ===
        with st.expander("➕ Créer une nouvelle équipe", expanded=False):
            with st.form("create_team_form", clear_on_submit=True):
                team_id_in = st.text_input(
                    "Identifiant d'équipe", 
                    key="new_team_id", 
                    placeholder="Ex: EQUIPE1",
                    help="Lettres et chiffres uniquement, max 20 caractères"
                )
                team_name_in = st.text_input(
                    "Nom d'équipe", 
                    key="new_team_name", 
                    placeholder="Ex: Équipe Centre",
                    help="Nom descriptif de l'équipe"
                )
                
                # Toggle pour afficher/masquer les mots de passe
                show_pw = st.checkbox("Afficher les mots de passe", value=False)
                pw_type = "default" if show_pw else "password"
                
                pwd_in = st.text_input(
                    "Mot de passe", 
                    type=pw_type, 
                    key="new_team_pwd", 
                    placeholder="Minimum 4 caractères",
                    help="Tout caractère accepté, min 4 / max 128"
                )
                pwd_conf = st.text_input(
                    "Confirmer le mot de passe", 
                    type=pw_type, 
                    key="new_team_pwd_conf", 
                    placeholder="Retapez le mot de passe",
                    help="Doit correspondre au mot de passe ci-dessus"
                )
                
                submitted = st.form_submit_button("✅ Créer l'équipe", width="stretch")

            if submitted:
                # Validation avec validators.py
                ok_id, team_id = validate_and_clean_input("team_id", team_id_in)
                ok_name, team_name = validate_and_clean_input("text", team_name_in)
                ok_pw, password = validate_and_clean_input("password", pwd_in)
                
                if not ok_id:
                    st.error("❌ Identifiant d'équipe invalide (lettres/chiffres, max 20)")
                elif not ok_name:
                    st.error("❌ Nom d'équipe invalide ou vide")
                elif not ok_pw:
                    st.error("❌ Mot de passe invalide (minimum 4 caractères)")
                elif pwd_in != pwd_conf:
                    st.error("❌ Les mots de passe ne correspondent pas")
                else:
                    # Tentative de création avec db.create_team
                    try:
                        created = db.create_team(conn, team_id, team_name, password)
                        if created:
                            st.toast(f"✅ Équipe {team_id} créée avec succès", icon="✅")
                            st.rerun()
                        else:
                            st.error("❌ Échec de création (ID déjà existant ?)")
                    except Exception as e:
                        st.error(f"❌ Erreur lors de la création: {e}")
        
        # === Liste des équipes (sans doublon de titre) ===
        try:
            teams_df = db.get_all_teams(conn)
            if not teams_df.empty:
                st.dataframe(teams_df, width="stretch")
            else:
                st.info("Aucune équipe créée")
        except Exception as e:
            st.info("Liste des équipes non disponible")
    
    with tabs[2]:
        # Assignation v4.1
        page_assignations_v41(conn)
    
    with tabs[3]:
        # Export amélioré v4.1
        page_export_gestionnaire_v41(conn)

    with tabs[4]:
        st.markdown("### 🛠 Opérations techniques (protégées)")

        # -- PIN stocké dans secrets (config.toml -> [secrets] TECH_PIN="xxxx")
        try:
            TECH_PIN = st.secrets.get("TECH_PIN", "")
        except:
            TECH_PIN = ""  # Pas de fichier secrets.toml

        if "tech_ok" not in st.session_state:
            st.session_state.tech_ok = False

        if not st.session_state.tech_ok:
            pin = st.text_input("Entrer le PIN technique", type="password")
            if st.button("Déverrouiller"):
                if TECH_PIN and pin == TECH_PIN:
                    st.session_state.tech_ok = True
                    st.success("Accès technique déverrouillé.")
                    st.rerun()
                else:
                    st.error("PIN invalide.")
            st.stop()

        st.info("⚠️ Ces actions sont lourdes et n'affectent pas les statuts/notes. Elles régénèrent les caches OSM.")

        # --- Reconstruire le cache géométrique (lourd)
        with st.expander("🔄 Reconstruire cache OSM (géométries)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirm = st.checkbox("Je comprends les implications")
            with col2:
                safety = st.text_input('Écrire "REBUILD" pour confirmer')

            if st.button("Lancer la reconstruction"):
                if confirm and safety.strip().upper() == "REBUILD":
                    with st.spinner("Construction du cache…"):
                        build_geometry_cache()       # reconstruit le fichier osm_cache.json
                        st.cache_data.clear()        # purge cache Streamlit
                    st.success("✅ Cache OSM mis à jour (géométries).")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Reconstruire/Importer le cache des adresses
        with st.expander("📍 Mettre à jour les adresses (OSM)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirmA = st.checkbox("Je confirme")
            with col2:
                safetyA = st.text_input('Écrire "IMPORT" pour confirmer')

            if st.button("Lancer la mise à jour des adresses"):
                if confirmA and safetyA.strip().upper() == "IMPORT":
                    with st.spinner("Téléchargement des adresses OSM…"):
                        build_addresses_cache()
                        addr_cache = load_addresses_cache()
                        count = db.import_addresses_from_cache(conn, addr_cache)
                    st.success(f"✅ {count} adresses importées depuis OSM.")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Gestion des backups
        with st.expander("💾 Gestion des backups", expanded=False):
            backup_mgr = db.get_backup_manager(DB_PATH)
            
            col1, col2 = st.columns([2, 1])
            with col1:
                if st.button("🔄 Créer un backup manuel", width="stretch"):
                    backup_file = backup_mgr.create_backup("manual")
                    if backup_file:
                        st.success(f"Backup créé : {Path(backup_file).name}")
            
            with col2:
                if st.button("📋 Voir les backups", width="stretch"):
                    backups = backup_mgr.list_backups()
                    if backups:
                        for backup in backups[:5]:  # Montrer les 5 derniers
                            st.text(f"• {backup['name']} ({backup['size']})")
                    else:
                        st.info("Aucun backup disponible")

def page_superviseur(conn, geo):
    """Interface superviseur"""
    st.header("🎯 Tableau de Bord Superviseur")
    
    # Vérifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        render_login_card("superviseur", conn)
        return
    
    # Dashboard moderne
    render_dashboard_gestionnaire(conn, geo)
    
    # Tabs
    tabs = st.tabs([
        "📊 Vue d'ensemble",
        "👥 Équipes",
        "🗺️ Assignation",
        "📥 Export",
        "🛠 Tech"
    ])
    
    with tabs[0]:
        # Carte générale
        st.markdown("### Carte générale")
        df_all = db.list_streets(conn)
        if not df_all.empty:
            m = create_map(df_all, geo)
            st_folium(m, height=800, width=None, returned_objects=[])
        
        # Activité récente
        st.markdown("### Activité récente")
        recent = db.recent_activity(conn, limit=10)
        if not recent.empty:
            st.dataframe(recent, width="stretch")
    
    with tabs[1]:
        # Gestion des équipes
        st.markdown("### Gestion des équipes")
        
        with st.expander("Créer une équipe"):
            with st.form("new_team", clear_on_submit=True):
                new_id = st.text_input("Identifiant")
                new_name = st.text_input("Équipe")
                new_pass = st.text_input("Mot de passe", type="password")
                
                if st.form_submit_button("Créer"):
                    if all([new_id, new_name, new_pass]):
                        if db.create_team(conn, new_id, new_name, new_pass):
                            st.success(f"Équipe {new_id} créée")
                            st.rerun()
        
        # Liste des équipes
        teams_df = db.get_all_teams(conn)
        if not teams_df.empty:
            st.dataframe(teams_df, width="stretch")
    
    with tabs[2]:
        # Assignation
        st.markdown("### Assignation des rues")
        
        unassigned = db.get_unassigned_streets(conn)
        
        if not unassigned.empty:
            with st.form("assign"):
                team = st.selectbox("Équipe", db.teams(conn))
                streets = st.multiselect("Rues", unassigned['name'].tolist())
                
                if st.form_submit_button("Assigner"):
                    if team and streets:
                        db.assign_streets_to_team(conn, streets, team)
                        st.success("Rues assignées!")
                        st.rerun()
        else:
            st.success("Toutes les rues sont assignées!")
        
        # Tableau des assignations
        df_all = db.list_streets(conn)
        if not df_all.empty:
            st.dataframe(
                df_all[['name', 'sector', 'team', 'status']],
                width="stretch"
            )
    
    with tabs[3]:
        # Export
        st.markdown("### Export des données")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                "📥 Export rues (CSV)",
                db.export_to_csv(conn),
                "rapport_rues.csv",
                "text/csv",
                width="stretch"
            )
        
        with col2:
            st.download_button(
                "📥 Export notes (CSV)",
                db.export_notes_csv(conn),
                "rapport_notes.csv",
                "text/csv",
                width="stretch"
            )

    with tabs[4]:
        st.markdown("### 🛠 Opérations techniques (protégées)")

        # -- PIN stocké dans secrets (config.toml -> [secrets] TECH_PIN="xxxx")  
        try:
            TECH_PIN = st.secrets.get("TECH_PIN", "")
        except:
            TECH_PIN = ""  # Pas de fichier secrets.toml

        if "tech_ok" not in st.session_state:
            st.session_state.tech_ok = False

        if not st.session_state.tech_ok:
            pin = st.text_input("Entrer le PIN technique", type="password")
            if st.button("Déverrouiller"):
                if TECH_PIN and pin == TECH_PIN:
                    st.session_state.tech_ok = True
                    st.success("Accès technique déverrouillé.")
                    st.rerun()
                else:
                    st.error("PIN invalide.")
            st.stop()

        st.info("⚠️ Ces actions sont lourdes et n'affectent pas les statuts/notes. Elles régénèrent les caches OSM.")

        # --- Reconstruire le cache géométrique (lourd)
        with st.expander("🔄 Reconstruire cache OSM (géométries)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirm = st.checkbox("Je comprends les implications")
            with col2:
                safety = st.text_input('Écrire "REBUILD" pour confirmer')

            if st.button("Lancer la reconstruction"):
                if confirm and safety.strip().upper() == "REBUILD":
                    with st.spinner("Construction du cache…"):
                        build_geometry_cache()       # reconstruit le fichier osm_cache.json
                        st.cache_data.clear()        # purge cache Streamlit
                    st.success("✅ Cache OSM mis à jour (géométries).")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

        # --- Reconstruire/Importer le cache des adresses
        with st.expander("📍 Mettre à jour les adresses (OSM)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirmA = st.checkbox("Je confirme")
            with col2:
                safetyA = st.text_input('Écrire "IMPORT" pour confirmer')

            if st.button("Lancer la mise à jour des adresses"):
                if confirmA and safetyA.strip().upper() == "IMPORT":
                    with st.spinner("Téléchargement des adresses OSM…"):
                        build_addresses_cache()
                        addr_cache = load_addresses_cache()
                        count = db.import_addresses_from_cache(conn, addr_cache)
                    st.success(f"✅ {count} adresses importées depuis OSM.")
                    st.rerun()
                else:
                    st.warning("Confirmation incomplète.")

# ============================================
# MAIN
# ============================================

# ================================================================================
# NOUVELLES FONCTIONS v4.1 - SUPERVISEUR ET BÉNÉVOLE
# ================================================================================

def page_assignations_v41(conn):
    """Panneau d'assignations v4.1 pour superviseurs"""
    
    try:
        # ===== Bloc Assignations (refactor propre) =====
        st.subheader("🗺️ Assignations par secteur", anchor=False)
        
        # Compteur de rues non assignées (bannière info)
        unassigned_count = db.get_unassigned_streets_count(conn)
        if unassigned_count > 0:
            st.info(f"⚠️ {unassigned_count} rue(s) non assignée(s)")
        
        with st.container():
            c1, c2, c3 = st.columns([1, 1.2, 0.7], vertical_alignment="bottom")
            
            with c1:
                # Récupérer la liste des secteurs
                liste_secteurs = db.get_sectors_list(conn)
                secteur = st.selectbox(
                    "SECTEUR À ASSIGNER",
                    options=[""] + (liste_secteurs if liste_secteurs else []),
                    index=0,
                    key="assign_sector",
                    help="Choisissez le secteur à assigner",
                    label_visibility="visible",
                )
            
            with c2:
                # Récupérer la liste des équipes
                teams = db.get_teams_list(conn)
                liste_equipes = [f"{team[1]} ({team[0]})" for team in teams] if teams else []
                
                if liste_equipes:
                    team_display = st.selectbox(
                        "ÉQUIPE", 
                        options=[""] + liste_equipes, 
                        index=0, 
                        key="assign_team"
                    )
                    # Extraire l'ID de l'équipe
                    team = ""
                    if team_display and team_display != "":
                        team = team_display.split("(")[-1].rstrip(")")
                else:
                    st.info("Aucune équipe disponible")
                    team = None
            
            with c3:
                disabled = not (secteur and team)
                if st.button("🎯 Assigner tout le secteur", width="stretch", disabled=disabled):
                    # Appel métier : assigner toutes les rues non assignées du secteur à l'équipe
                    if secteur and team:
                        try:
                            nb = db.bulk_assign_sector(conn, secteur, team)
                            if nb > 0:
                                st.toast(f"✅ {nb} rue(s) assignée(s) à l'équipe {team}", icon="✅")
                                st.rerun()
                            else:
                                st.toast("ℹ️ Aucune rue non assignée dans ce secteur", icon="ℹ️")
                        except Exception as e:
                            st.error(f"Erreur lors de l'assignation: {e}")
        
        # ===== Tableau d'état (uniforme, sans style spécial) =====
        st.markdown("### 📋 État des assignations")
        
        df = db.list_streets(conn)
        if not df.empty:
            df_disp = df.assign(
                Statut=df["status"].map(STATUS_TO_LABEL).fillna("À faire")
            ).rename(columns={
                "name": "Rue", 
                "sector": "Secteur", 
                "team": "Équipe"
            })[["Rue", "Secteur", "Équipe", "Statut"]]
            
            st.dataframe(df_disp, width="stretch")  # aucun Styler, aucun CSS cellule
        else:
            st.info("Aucune rue trouvée")
            
    except Exception as e:
        st.error(f"Erreur dans le panneau d'assignations: {e}")
        st.info("Fonctionnalité temporairement indisponible")

def page_export_gestionnaire_v41(conn):
    """Page d'export v4.1 avec nouvelles fonctionnalités"""
    st.markdown("### 📥 Export des données")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Export CSV standard
        try:
            st.download_button(
                "📥 Export CSV Standard",
                db.export_to_csv(conn),
                "rapport_rues.csv",
                "text/csv",
                width="stretch"
            )
        except Exception as e:
            st.button("📥 CSV (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    with col2:
        # Export Excel professionnel
        try:
            from reports import ReportGenerator
            generator = ReportGenerator(conn)
            excel_data = generator.generate_excel()
            st.download_button(
                "📊 Export Excel Pro",
                excel_data,
                "guignolee_2025_rapport.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width="stretch"
            )
        except ImportError:
            st.button("📊 Excel (Installer xlsxwriter)", disabled=True, width="stretch")
        except Exception as e:
            st.button("📊 Excel (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    with col3:
        # Export PDF professionnel
        try:
            from reports import ReportGenerator
            generator = ReportGenerator(conn)
            pdf_data = generator.generate_pdf()
            st.download_button(
                "📄 Export PDF Pro",
                pdf_data,
                "guignolee_2025_rapport.pdf",
                "application/pdf",
                width="stretch"
            )
        except ImportError:
            st.button("📄 PDF (Installer reportlab)", disabled=True, width="stretch")
        except Exception as e:
            st.button("📄 PDF (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    # Export CSV assignations (nouveau v4.1)
    st.markdown("---")
    st.markdown("### 📋 Export spécialisés v4.1")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Export CSV assignations
        try:
            assignations_data = db.get_assignations_export_data(conn)
            if not assignations_data.empty:
                csv_data = assignations_data.to_csv(index=False, encoding='utf-8')
                st.download_button(
                    "📋 Export CSV Assignations",
                    csv_data,
                    "assignations_secteurs.csv",
                    "text/csv",
                    width="stretch",
                    help="Colonnes: secteur, rue, équipe, statut"
                )
            else:
                st.button("📋 Assignations (Aucune donnée)", disabled=True, width="stretch")
        except Exception as e:
            st.button("📋 Assignations (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    with col2:
        # Export notes
        try:
            st.download_button(
                "📝 Export Notes",
                db.export_notes_csv(conn),
                "rapport_notes.csv",
                "text/csv",
                width="stretch"
            )
        except Exception as e:
            st.button("📝 Notes (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")

def page_benevole_mes_rues(conn):
    """Vue 'Mes rues' pour bénévoles v4.1"""
    
    # Récupérer l'équipe du bénévole connecté
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        st.warning("Accès réservé aux bénévoles connectés")
        return
    
    team_id = st.session_state.auth.get("team")
    if not team_id:
        st.error("Équipe non identifiée")
        return
    
    st.markdown(f"### 🏘️ Mes rues assignées - Équipe {team_id}")
    
    try:
        # Récupérer les rues de l'équipe
        team_streets = db.get_team_streets(conn, team_id)
        
        if team_streets.empty:
            st.info("Aucune rue assignée à votre équipe pour le moment.")
            return
        
        # Afficher les statistiques de l'équipe
        total_streets = len(team_streets)
        done_streets = len(team_streets[team_streets['status'] == 'terminee'])
        in_progress = len(team_streets[team_streets['status'] == 'en_cours'])
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total rues", total_streets)
        with col2:
            st.metric("Terminées", done_streets)
        with col3:
            st.metric("En cours", in_progress)
        with col4:
            progress = (done_streets / total_streets * 100) if total_streets > 0 else 0
            st.metric("Progression", f"{progress:.1f}%")
        
        st.markdown("---")
        
        # Affichage par rue avec actions
        for _, street in team_streets.iterrows():
            street_name = street['street_name']
            current_status = street['status']
            notes_count = street['notes_count']
            
            with st.expander(f"🏘️ {street_name} ({street['sector']}) - {current_status.replace('_', ' ').title()}", 
                           expanded=current_status == 'en_cours'):
                
                col1, col2, col3 = st.columns([2, 1, 1])
                
                with col1:
                    st.markdown(f"**Secteur:** {street['sector']}")
                    st.markdown(f"**Statut actuel:** {current_status.replace('_', ' ').title()}")
                    if notes_count > 0:
                        st.markdown(f"**Notes existantes:** {notes_count}")
                
                with col2:
                    # Bouton "En cours"
                    if st.button(
                        "🚀 En cours", 
                        key=f"progress_{street_name}",
                        disabled=current_status == 'en_cours',
                        width="stretch"
                    ):
                        if db.update_street_status(conn, street_name, 'en_cours', team_id):
                            st.toast(f"✅ {street_name} marquée en cours", icon="🚀")
                            st.rerun()
                        else:
                            st.error("Erreur lors de la mise à jour")
                
                with col3:
                    # Bouton "Terminée"
                    if st.button(
                        "✅ Terminée", 
                        key=f"done_{street_name}",
                        disabled=current_status == 'terminee',
                        width="stretch"
                    ):
                        if db.update_street_status(conn, street_name, 'terminee', team_id):
                            st.toast(f"🎉 {street_name} terminée!", icon="🎉")
                            st.rerun()
                        else:
                            st.error("Erreur lors de la mise à jour")
                
                # Section notes
                st.markdown("**Gestion des notes:**")
                
                # Afficher les notes existantes
                existing_notes = db.get_street_notes_for_team(conn, street_name, team_id)
                if existing_notes:
                    st.markdown("*Notes existantes:*")
                    for note in existing_notes:
                        st.markdown(f"• **#{note[0]}** : {note[1]} _{note[2]}_")
                
                # Ajouter une nouvelle note
                with st.form(f"note_form_{street_name}"):
                    col_addr, col_note = st.columns([1, 3])
                    with col_addr:
                        address_number = st.text_input(
                            "N° civique", 
                            key=f"addr_{street_name}",
                            placeholder="123A"
                        )
                    with col_note:
                        comment = st.text_area(
                            "Commentaire", 
                            key=f"comment_{street_name}",
                            placeholder="Ex: Absent, refus, don reçu...",
                            max_chars=500,
                            height=80
                        )
                    
                    if st.form_submit_button("💾 Enregistrer note"):
                        if address_number and comment:
                            if db.add_street_note(conn, street_name, team_id, address_number, comment):
                                st.toast(f"📝 Note ajoutée pour {street_name} #{address_number}", icon="📝")
                                st.rerun()
                            else:
                                st.error("Erreur lors de l'enregistrement de la note")
                        else:
                            st.warning("Veuillez remplir le numéro et le commentaire")
                            
    except Exception as e:
        st.error(f"Erreur lors du chargement de vos rues: {e}")
        st.info("Fonctionnalité temporairement indisponible")

def main():
    """Point d'entrée principal - Version 2.0 Guignolée"""
    
    # CSS moderne
    inject_css()
    
    # Connexion DB
    conn = db.get_conn(DB_PATH)
    db.init_db(conn)
    st.session_state['conn'] = conn
    
    # Cache géométrique
    @st.cache_data(ttl=None)
    def get_geo(_sig):
        data = load_geometry_cache()
        return data if data else {}
    
    sig = int(CACHE_FILE.stat().st_mtime_ns) if CACHE_FILE.exists() else 0
    geo = get_geo(sig)
    
    # Header festif
    render_header()
    
    # Navigation modernisée dans la sidebar
    with st.sidebar:
        # CSS pour la sidebar sans position absolue
        st.markdown("""
        <style>
        .css-1d391kg { padding-top: 1rem !important; }
        .stSidebar > div:first-child { padding-top: 1rem !important; }
        </style>
        """, unsafe_allow_html=True)
        
        # Logo en haut de la sidebar (position normale)
        logo_path = ASSETS / "logo.png"
        if logo_path.exists():
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.image(str(logo_path), width=150)
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
        else:
            # Placeholder centré
            st.markdown("""
            <div style="
                background: linear-gradient(135deg, #c41e3a, #165b33);
                border-radius: 15px;
                padding: 2rem;
                color: white;
                text-align: center;
                margin: 1rem 0;
                box-shadow: 0 4px 15px rgba(0,0,0,0.3);
            ">
                <div style="font-size: 2.5rem;">🎁</div>
                <div style="font-weight: bold; font-size: 1.2rem;">LOGO</div>
                <small>Espace réservé</small>
            </div>
            """, unsafe_allow_html=True)
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
        
        # Navigation
        st.markdown("### 🎄 Navigation")
        
        # Boutons de navigation stylisés
        if st.button("🏠 Accueil", width="stretch"):
            st.session_state.page = "accueil"
            st.rerun()
        
        if st.button("🎅 Bénévole", width="stretch"):
            st.session_state.page = "benevole"
            st.rerun()
            
        if st.button("👔 Gestionnaire", width="stretch"):
            st.session_state.page = "gestionnaire"  
            st.rerun()
        
        # Déconnexion si connecté
        if st.session_state.auth:
            st.markdown("---")
            if st.button("🚪 Déconnexion", width="stretch"):
                st.session_state.auth = None
                st.rerun()
        
        # Compteur temps réel
        st.markdown("---")
        stats = db.extended_stats(conn)
        st.markdown(f"""
        <div style="text-align: center;">
            <h4>État de la collecte</h4>
            <div style="font-size: 2rem; color: #FFD700;">
                {stats['done']}/{stats['total']}
            </div>
            <small>Rues complétées</small>
        </div>
        """, unsafe_allow_html=True)
    
    # Routing pages
    page = st.session_state.get('page', 'accueil')
    
    if page == "accueil":
        page_accueil_v2(conn, geo)
    elif page == "benevole":
        page_benevole_v2(conn, geo)
    elif page == "gestionnaire":
        page_gestionnaire_v2(conn, geo)
    
    # Footer festif
    st.markdown("""
    <div style="
        text-align: center;
        padding: 2rem;
        margin-top: 3rem;
        border-top: 2px solid rgba(255,215,0,0.3);
        color: #8b92a4;
    ">
        <p>
            🎄 Guignolée 2025 - Le Relais de Mascouche 🎄<br>
            <small>Ensemble, redonnons espoir | 📞 450-474-4133</small>
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Bannière en bas de page
    if (ASSETS / "banner.png").exists():
        st.image(str(ASSETS / "banner.png"), width="stretch")

if __name__ == "__main__":
    main()


```n
================================================================================
## FICHIER 2: guignomap/db.py (Gestion base de données)

```python

import sqlite3
import pandas as pd
import hashlib
import bcrypt
from backup import auto_backup_before_critical, BackupManager
from validators import validate_and_clean_input, InputValidator
from datetime import datetime
import json
from pathlib import Path
import os
import secrets
import string

# Schéma amélioré de la base de données
SCHEMA = """
-- Table des rues
CREATE TABLE IF NOT EXISTS streets (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    sector TEXT,
    team TEXT,
    status TEXT NOT NULL DEFAULT 'a_faire' 
        CHECK (status IN ('a_faire', 'en_cours', 'terminee'))
);

-- Table des équipes
CREATE TABLE IF NOT EXISTS teams (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    password_hash TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    active BOOLEAN DEFAULT 1
);

-- Table des notes/commentaires PAR ADRESSE
CREATE TABLE IF NOT EXISTS notes (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    street_name TEXT NOT NULL,
    team_id TEXT NOT NULL,
    address_number TEXT,
    comment TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (street_name) REFERENCES streets(name),
    FOREIGN KEY (team_id) REFERENCES teams(id)
);

-- Table d'activité (log)
CREATE TABLE IF NOT EXISTS activity_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    team_id TEXT,
    action TEXT NOT NULL,
    details TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Table des adresses OSM
CREATE TABLE IF NOT EXISTS addresses (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    street_name TEXT NOT NULL,
    house_number TEXT NOT NULL,
    latitude REAL,
    longitude REAL,
    osm_type TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (street_name) REFERENCES streets(name)
);

-- Index pour améliorer les performances
CREATE INDEX IF NOT EXISTS idx_streets_team ON streets(team);
CREATE INDEX IF NOT EXISTS idx_streets_status ON streets(status);
CREATE INDEX IF NOT EXISTS idx_notes_street ON notes(street_name);
CREATE INDEX IF NOT EXISTS idx_activity_created ON activity_log(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_addresses_street ON addresses(street_name);
CREATE INDEX IF NOT EXISTS idx_addresses_number ON addresses(house_number);
"""

def get_conn(db_path):
    """Crée une connexion à la base de données"""
    conn = sqlite3.connect(db_path, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    return conn

def init_db(conn):
    """Initialise la base de données avec le schéma et les données initiales"""
    try:
        # Créer les tables si elles n'existent pas
        conn.executescript(SCHEMA)
        conn.commit()
        
        # Créer un compte admin par défaut s'il n'existe pas
        cursor = conn.execute("SELECT COUNT(*) FROM teams WHERE id = 'ADMIN'")
        if cursor.fetchone()[0] == 0:
            pwd = os.getenv("GM_ADMIN_PWD", "RELAIS2025")  # Par défaut RELAIS2025
            create_team(conn, 'ADMIN', 'Superviseur', pwd)
        
        # AUTO-IMPORT : Si aucune rue n'existe, importer automatiquement depuis OSM
        cursor = conn.execute("SELECT COUNT(*) FROM streets")
        if cursor.fetchone()[0] == 0:
            print("🔄 Aucune rue trouvée. Import automatique depuis OpenStreetMap...")
            auto_import_streets(conn)
            
    except Exception as e:
        print(f"Erreur lors de l'initialisation de la DB: {e}")
        raise

@auto_backup_before_critical
def auto_import_streets(conn):
    """Import automatique des rues de Mascouche"""
    try:
        # Essayer d'abord avec OSM
        from osm import generate_streets_csv
        csv_data = generate_streets_csv("Mascouche")
        
        if csv_data:
            import io
            df = pd.read_csv(io.StringIO(csv_data.decode('utf-8')))
            
            if not df.empty:
                for _, row in df.iterrows():
                    conn.execute(
                        "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, ?, ?, 'a_faire')",
                        (row.get("name", ""), row.get("sector", ""), row.get("team", ""))
                    )
                conn.commit()
                print(f"✅ {len(df)} rues importées automatiquement")
                log_activity(conn, None, "AUTO_IMPORT", f"Import automatique de {len(df)} rues")
                return
    except Exception as e:
        print(f"⚠️ Erreur lors de l'import OSM: {e}")
    
    # Fallback : Données de test si OSM échoue
    print("📦 Import de données de test...")
    test_streets = [
        ("Montée Masson", "Centre", ""),
        ("Chemin Sainte-Marie", "Centre", ""),
        ("Boulevard de Mascouche", "Centre", ""),
        ("Rue Dupras", "Centre", ""),
        ("Rue Saint-Pierre", "Centre", ""),
        ("Rue de l'Église", "Centre", ""),
        ("Avenue des Érables", "Nord", ""),
        ("Rue des Pins", "Nord", ""),
        ("Rue Gravel", "Sud", ""),
        ("Rue Forget", "Sud", ""),
    ]
    
    for name, sector, team in test_streets:
        conn.execute(
            "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, ?, ?, 'a_faire')",
            (name, sector, team)
        )
    conn.commit()
    print(f"✅ {len(test_streets)} rues de test importées")

# ---------- Fonctions pour les équipes ----------
def hash_password(password):
    """Hash un mot de passe avec bcrypt et salt automatique"""
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
    return hashed.decode('utf-8')

def create_team(conn, team_id, name, password):
    """Crée une nouvelle équipe avec validation"""
    try:
        # Valider les entrées
        valid_id, clean_id = validate_and_clean_input("team_id", team_id)
        valid_name, clean_name = validate_and_clean_input("text", name)
        valid_pwd, _ = validate_and_clean_input("password", password)
        
        if not valid_id or not valid_name or not valid_pwd:
            return False
        
        conn.execute(
            "INSERT INTO teams (id, name, password_hash) VALUES (?, ?, ?)",
            (clean_id, clean_name, hash_password(password))
        )
        conn.commit()
        log_activity(conn, clean_id, "TEAM_CREATED", f"Équipe {clean_name} créée")
        return True
    except sqlite3.IntegrityError:
        return False

def verify_team(conn, team_id, password):
    """Vérifie les identifiants d'une équipe avec bcrypt"""
    cursor = conn.execute(
        "SELECT password_hash FROM teams WHERE id = ? AND active = 1",
        (team_id,)
    )
    row = cursor.fetchone()
    if row:
        try:
            # Support ancien SHA256 pour migration
            stored_hash = row[0]
            if stored_hash.startswith('$2b$') or stored_hash.startswith('$2a$'):
                # Hash bcrypt
                return bcrypt.checkpw(password.encode('utf-8'), stored_hash.encode('utf-8'))
            else:
                # Ancien SHA256, vérifier et migrer
                if stored_hash == hashlib.sha256(password.encode()).hexdigest():
                    # Migrer vers bcrypt
                    new_hash = hash_password(password)
                    conn.execute("UPDATE teams SET password_hash = ? WHERE id = ?", (new_hash, team_id))
                    conn.commit()
                    return True
                return False
        except Exception as e:
            print(f"Erreur vérification mot de passe: {e}")
            return False
    return False

def migrate_all_passwords_to_bcrypt(conn):
    """Migration manuelle des mots de passe SHA256 vers bcrypt"""
    print("⚠️ Migration des mots de passe requise")
    print("Entrez les mots de passe actuels pour migration:")
    
    cursor = conn.execute("SELECT id, name FROM teams WHERE active = 1")
    teams = cursor.fetchall()
    
    for team_id, team_name in teams:
        if team_id == 'ADMIN':
            pwd = input(f"Mot de passe actuel pour {team_name} (ADMIN): ")
            if pwd:
                new_hash = hash_password(pwd)
                conn.execute("UPDATE teams SET password_hash = ? WHERE id = ?", (new_hash, team_id))
        
    conn.commit()
    print("✅ Migration terminée")

def get_all_teams(conn):
    """Récupère toutes les équipes avec leurs statistiques"""
    query = """
    SELECT 
        t.id,
        t.name,
        t.created_at,
        COUNT(DISTINCT s.name) as streets_count,
        SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done_count,
        CASE 
            WHEN COUNT(s.name) > 0 
            THEN (SUM(CASE WHEN s.status = 'terminee' THEN 1.0 ELSE 0 END) / COUNT(s.name)) * 100
            ELSE 0 
        END as progress
    FROM teams t
    LEFT JOIN streets s ON t.id = s.team
    WHERE t.active = 1 AND t.id != 'ADMIN'
    GROUP BY t.id, t.name, t.created_at
    ORDER BY t.id
    """
    return pd.read_sql_query(query, conn)

@auto_backup_before_critical
def delete_team(conn, team_id):
    """Désactive une équipe"""
    conn.execute("UPDATE teams SET active = 0 WHERE id = ?", (team_id,))
    conn.execute("UPDATE streets SET team = NULL WHERE team = ?", (team_id,))
    conn.commit()
    log_activity(conn, None, "TEAM_DELETED", f"Équipe {team_id} supprimée")

def teams(conn):
    """Liste des IDs d'équipes actives"""
    cursor = conn.execute(
        "SELECT id FROM teams WHERE active = 1 AND id != 'ADMIN' ORDER BY id"
    )
    return [row[0] for row in cursor.fetchall()]

# ---------- Fonctions pour les rues ----------
def list_streets(conn, team=None):
    """Liste les rues, optionnellement filtrées par équipe"""
    try:
        if team:
            query = """
                SELECT 
                    s.name, 
                    COALESCE(s.sector, '') as sector, 
                    COALESCE(s.team, '') as team, 
                    COALESCE(s.status, 'a_faire') as status,
                    COUNT(n.id) as notes,
                    COUNT(DISTINCT n.address_number) as addresses_with_notes
                FROM streets s
                LEFT JOIN notes n ON s.name = n.street_name
                WHERE s.team = ?
                GROUP BY s.name, s.sector, s.team, s.status
                ORDER BY 
                    CASE s.status 
                        WHEN 'a_faire' THEN 1 
                        WHEN 'en_cours' THEN 2 
                        WHEN 'terminee' THEN 3 
                    END, 
                    s.name
            """
            df = pd.read_sql_query(query, conn, params=(team,))
        else:
            query = """
                SELECT 
                    s.name, 
                    COALESCE(s.sector, '') as sector, 
                    COALESCE(s.team, '') as team, 
                    COALESCE(s.status, 'a_faire') as status,
                    COUNT(n.id) as notes,
                    COUNT(DISTINCT n.address_number) as addresses_with_notes
                FROM streets s
                LEFT JOIN notes n ON s.name = n.street_name
                GROUP BY s.name, s.sector, s.team, s.status
                ORDER BY 
                    s.team, 
                    CASE s.status 
                        WHEN 'a_faire' THEN 1 
                        WHEN 'en_cours' THEN 2 
                        WHEN 'terminee' THEN 3 
                    END, 
                    s.name
            """
            df = pd.read_sql_query(query, conn)
        
        # S'assurer que toutes les colonnes existent
        for col in ['name', 'sector', 'team', 'status', 'notes', 'addresses_with_notes']:
            if col not in df.columns:
                df[col] = '' if col in ['sector', 'team'] else ('a_faire' if col == 'status' else 0)
        
        return df
        
    except Exception as e:
        print(f"Erreur list_streets: {e}")
        # Retourner un DataFrame vide avec la structure attendue
        return pd.DataFrame(columns=['name', 'sector', 'team', 'status', 'notes', 'addresses_with_notes'])

def get_unassigned_streets(conn):
    """Récupère les rues non assignées"""
    query = """
        SELECT name, sector 
        FROM streets 
        WHERE team IS NULL OR team = ''
        ORDER BY sector, name
    """
    return pd.read_sql_query(query, conn)

def assign_streets_to_team(conn, street_names, team_id):
    """Assigne plusieurs rues à une équipe en une transaction"""
    try:
        for street_name in street_names:
            conn.execute(
                "UPDATE streets SET team = ? WHERE name = ?",
                (team_id, street_name)
            )
        conn.commit()
        log_activity(conn, team_id, "STREETS_ASSIGNED", f"{len(street_names)} rues assignées")
        return True
    except Exception as e:
        conn.rollback()
        print(f"Erreur lors de l'assignation: {e}")
        return False

def set_status(conn, name, status):
    """Met à jour le statut d'une rue avec validation"""
    valid_name, clean_name = validate_and_clean_input("street_name", name)
    clean_status = InputValidator.validate_status(status)
    
    if not valid_name:
        print("❌ Nom de rue invalide")
        return False
    
    conn.execute(
        "UPDATE streets SET status = ? WHERE name = ?",
        (clean_status, clean_name)
    )
    conn.commit()
    
    cursor = conn.execute("SELECT team FROM streets WHERE name = ?", (clean_name,))
    row = cursor.fetchone()
    if row:
        log_activity(conn, row[0], f"STATUS_{clean_status.upper()}", f"Rue {clean_name}")
    return True

# ---------- Fonctions pour les notes PAR ADRESSE ----------
def add_note_for_address(conn, street_name, team_id, address_number, comment):
    """Ajoute une note pour une adresse spécifique avec validation"""
    # Valider toutes les entrées
    valid_street, clean_street = validate_and_clean_input("street_name", street_name)
    valid_team, clean_team = validate_and_clean_input("team_id", team_id)
    valid_addr, clean_addr = validate_and_clean_input("address", address_number)
    valid_note, clean_note = validate_and_clean_input("note", comment)
    
    if not all([valid_street, valid_team, valid_addr, valid_note]):
        print("❌ Données invalides pour la note")
        return False
    
    conn.execute(
        """INSERT INTO notes (street_name, team_id, address_number, comment) 
           VALUES (?, ?, ?, ?)""",
        (clean_street, clean_team, clean_addr, clean_note)
    )
    
    # Met automatiquement le statut à "en_cours" si c'était "a_faire"
    conn.execute(
        """UPDATE streets 
           SET status = CASE 
               WHEN status = 'a_faire' THEN 'en_cours' 
               ELSE status 
           END
           WHERE name = ?""",
        (clean_street,)
    )
    
    conn.commit()
    log_activity(conn, clean_team, "NOTE_ADDED", f"Note ajoutée pour {clean_addr} {clean_street}")
    return True

def get_street_addresses_with_notes(conn, street_name):
    """Récupère toutes les adresses avec notes pour une rue"""
    query = """
        SELECT 
            n.address_number,
            n.comment,
            n.created_at,
            t.name as team_name
        FROM notes n
        JOIN teams t ON n.team_id = t.id
        WHERE n.street_name = ?
        ORDER BY 
            CAST(n.address_number AS INTEGER),
            n.created_at DESC
    """
    return pd.read_sql_query(query, conn, params=(street_name,))

def get_team_notes(conn, team_id):
    """Récupère toutes les notes d'une équipe"""
    query = """
        SELECT 
            street_name, 
            address_number, 
            comment, 
            created_at
        FROM notes
        WHERE team_id = ?
        ORDER BY created_at DESC
        LIMIT 50
    """
    return pd.read_sql_query(query, conn, params=(team_id,))

# ---------- Fonctions de statistiques ----------
def extended_stats(conn):
    """Statistiques étendues avec détails par adresse"""
    cursor = conn.execute("""
        SELECT 
            COUNT(DISTINCT s.name) as total,
            SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done,
            SUM(CASE WHEN s.status = 'en_cours' THEN 1 ELSE 0 END) as partial,
            SUM(CASE WHEN s.status = 'a_faire' THEN 1 ELSE 0 END) as todo,
            COUNT(DISTINCT n.id) as total_notes,
            COUNT(DISTINCT n.address_number || n.street_name) as addresses_with_notes
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name
    """)
    row = cursor.fetchone()
    return {
        "total": row[0] or 0,
        "done": row[1] or 0,
        "partial": row[2] or 0,
        "todo": row[3] or 0,
        "total_notes": row[4] or 0,
        "addresses_with_notes": row[5] or 0
    }

def stats_by_team(conn):
    """Statistiques par équipe"""
    query = """
        SELECT 
            s.team,
            COUNT(DISTINCT s.name) as total,
            SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done,
            SUM(CASE WHEN s.status = 'en_cours' THEN 1 ELSE 0 END) as partial,
            COUNT(DISTINCT n.id) as notes,
            ROUND(
                (SUM(CASE WHEN s.status = 'terminee' THEN 1.0 ELSE 0 END) / COUNT(*)) * 100, 
                1
            ) as progress
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name AND n.team_id = s.team
        WHERE s.team IS NOT NULL AND s.team != ''
        GROUP BY s.team
        ORDER BY progress DESC
    """
    return pd.read_sql_query(query, conn)

# ---------- Fonctions d'activité ----------
def recent_activity(conn, limit=10):
    """Récupère l'activité récente"""
    query = """
        SELECT 
            datetime(created_at, 'localtime') as timestamp,
            COALESCE(team_id, 'SYSTEM') as team,
            action,
            details
        FROM activity_log
        ORDER BY created_at DESC
        LIMIT ?
    """
    return pd.read_sql_query(query, conn, params=(limit,))

# ---------- Fonctions d'export ----------
def export_to_csv(conn):
    """Exporte toutes les données en CSV"""
    query = """
        SELECT 
            s.name as rue,
            s.sector as secteur,
            s.team as equipe,
            s.status as statut,
            COUNT(DISTINCT n.id) as nombre_notes,
            COUNT(DISTINCT n.address_number) as adresses_avec_notes
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name
        GROUP BY s.name, s.sector, s.team, s.status
        ORDER BY s.team, s.name
    """
    df = pd.read_sql_query(query, conn)
    return df.to_csv(index=False).encode('utf-8')

def export_notes_csv(conn):
    """Exporte toutes les notes en CSV avec adresses"""
    query = """
        SELECT 
            n.street_name as rue,
            n.address_number as numero,
            n.team_id as equipe,
            n.comment as commentaire,
            n.created_at as date_creation
        FROM notes n
        ORDER BY n.street_name, CAST(n.address_number AS INTEGER), n.created_at DESC
    """
    df = pd.read_sql_query(query, conn)
    return df.to_csv(index=False).encode('utf-8')

# ========================================
# NOUVELLES FONCTIONS POUR LES ADRESSES
# ========================================

@auto_backup_before_critical
def import_addresses_from_cache(conn, cache):
    """
    Importe les adresses depuis le cache OSM vers la base de données
    """
    try:
        # Vider la table existante
        conn.execute("DELETE FROM addresses")
        
        imported_count = 0
        skipped_count = 0
        
        for street_name, addresses in cache.items():
            # Vérifier que la rue existe dans la DB
            cursor = conn.execute("SELECT COUNT(*) FROM streets WHERE name = ?", (street_name,))
            if cursor.fetchone()[0] == 0:
                # Si la rue n'existe pas, la créer
                conn.execute(
                    "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, '', '', 'a_faire')",
                    (street_name,)
                )
                print(f"➕ Rue ajoutée: {street_name}")
            
            for addr in addresses:
                try:
                    # Validation des données
                    number = str(addr.get("number", "")).strip()
                    lat = addr.get("lat")
                    lon = addr.get("lon")
                    osm_type = addr.get("type", "unknown")
                    
                    if not number or lat is None or lon is None:
                        skipped_count += 1
                        continue
                    
                    conn.execute(
                        """INSERT INTO addresses (street_name, house_number, latitude, longitude, osm_type) 
                           VALUES (?, ?, ?, ?, ?)""",
                        (street_name, number, float(lat), float(lon), osm_type)
                    )
                    imported_count += 1
                except Exception as e:
                    print(f"⚠️ Erreur import adresse {addr}: {e}")
                    skipped_count += 1
        
        conn.commit()
        log_activity(conn, None, "ADDRESSES_IMPORTED", f"{imported_count} adresses importées, {skipped_count} ignorées")
        print(f"✅ {imported_count} adresses importées en base de données ({skipped_count} ignorées)")
        return imported_count
        
    except Exception as e:
        conn.rollback()
        print(f"❌ Erreur import adresses: {e}")
        return 0

def get_addresses_for_street(conn, street_name):
    """
    Récupère toutes les adresses d'une rue depuis la base de données
    """
    query = """
        SELECT 
            house_number,
            latitude,
            longitude,
            osm_type,
            created_at
        FROM addresses
        WHERE street_name = ?
        ORDER BY CAST(house_number AS INTEGER)
    """
    return pd.read_sql_query(query, conn, params=(street_name,))

def get_addresses_stats(conn):
    """
    Récupère les statistiques des adresses
    """
    cursor = conn.execute("""
        SELECT 
            COUNT(DISTINCT street_name) as streets_with_addresses,
            COUNT(*) as total_addresses,
            COUNT(DISTINCT CASE WHEN osm_type = 'node' THEN id END) as node_addresses,
            COUNT(DISTINCT CASE WHEN osm_type = 'way' THEN id END) as way_addresses
        FROM addresses
    """)
    row = cursor.fetchone()
    return {
        "streets_with_addresses": row[0] or 0,
        "total_addresses": row[1] or 0,
        "node_addresses": row[2] or 0,
        "way_addresses": row[3] or 0
    }

def get_backup_manager(db_path):
    """Retourne une instance du gestionnaire de backup"""
    return BackupManager(db_path)

# ================================================================================
# NOUVELLES FONCTIONS v4.1 - SUPERVISEUR ET BÉNÉVOLE
# ================================================================================

def get_unassigned_streets_count(conn):
    """Compte les rues non assignées à une équipe"""
    try:
        cursor = conn.execute("""
            SELECT COUNT(*) FROM streets 
            WHERE team IS NULL OR team = ''
        """)
        return cursor.fetchone()[0] or 0
    except Exception as e:
        print(f"Erreur get_unassigned_streets_count: {e}")
        return 0

def get_sectors_list(conn):
    """Récupère la liste des secteurs disponibles"""
    try:
        cursor = conn.execute("""
            SELECT DISTINCT sector FROM streets 
            WHERE sector IS NOT NULL AND sector != ''
            ORDER BY sector
        """)
        return [row[0] for row in cursor.fetchall()]
    except Exception as e:
        print(f"Erreur get_sectors_list: {e}")
        return []

def get_teams_list(conn):
    """Récupère la liste des équipes actives"""
    try:
        cursor = conn.execute("""
            SELECT id, name FROM teams 
            WHERE active = 1 AND id != 'ADMIN'
            ORDER BY name
        """)
        return [(row[0], row[1]) for row in cursor.fetchall()]
    except Exception as e:
        print(f"Erreur get_teams_list: {e}")
        return []

@auto_backup_before_critical
def bulk_assign_sector(conn, sector, team_id):
    """Assigne toutes les rues d'un secteur à une équipe"""
    try:
        # Valider les entrées
        valid_sector, clean_sector = validate_and_clean_input("sector", sector)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        
        if not valid_sector or not valid_team:
            raise ValueError("Secteur ou équipe invalide")
        
        # Vérifier que l'équipe existe
        cursor = conn.execute("SELECT COUNT(*) FROM teams WHERE id = ?", (clean_team,))
        if cursor.fetchone()[0] == 0:
            raise ValueError(f"Équipe {clean_team} inexistante")
        
        # Effectuer l'assignation
        cursor = conn.execute("""
            UPDATE streets 
            SET team = ? 
            WHERE sector = ? AND (team IS NULL OR team = '')
        """, (clean_team, clean_sector))
        
        affected_rows = cursor.rowcount
        conn.commit()
        
        # Log de l'activité
        log_activity(conn, clean_team, "bulk_assign", 
                    f"Assignation secteur {clean_sector}: {affected_rows} rues")
        
        return affected_rows
        
    except Exception as e:
        print(f"Erreur bulk_assign_sector: {e}")
        return 0

def get_team_streets(conn, team_id):
    """Récupère les rues assignées à une équipe"""
    try:
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        if not valid_team:
            return pd.DataFrame()
        
        query = """
            SELECT 
                s.name as street_name,
                s.sector,
                s.status,
                COUNT(n.id) as notes_count
            FROM streets s
            LEFT JOIN notes n ON s.name = n.street_name AND n.team_id = ?
            WHERE s.team = ?
            GROUP BY s.name, s.sector, s.status
            ORDER BY s.sector, s.name
        """
        return pd.read_sql_query(query, conn, params=(clean_team, clean_team))
        
    except Exception as e:
        print(f"Erreur get_team_streets: {e}")
        return pd.DataFrame()

@auto_backup_before_critical
def update_street_status(conn, street_name, new_status, team_id):
    """Met à jour le statut d'une rue"""
    try:
        # Valider les entrées
        valid_street, clean_street = validate_and_clean_input("street_name", street_name)
        valid_status, clean_status = validate_and_clean_input("status", new_status)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        
        if not all([valid_street, valid_status, valid_team]):
            raise ValueError("Paramètres invalides")
        
        # Vérifier que la rue est assignée à cette équipe
        cursor = conn.execute("""
            SELECT COUNT(*) FROM streets 
            WHERE name = ? AND team = ?
        """, (clean_street, clean_team))
        
        if cursor.fetchone()[0] == 0:
            raise ValueError(f"Rue {clean_street} non assignée à l'équipe {clean_team}")
        
        # Mettre à jour le statut
        conn.execute("""
            UPDATE streets 
            SET status = ? 
            WHERE name = ? AND team = ?
        """, (clean_status, clean_street, clean_team))
        
        conn.commit()
        
        # Log de l'activité
        log_activity(conn, clean_team, "status_update", 
                    f"Rue {clean_street}: {clean_status}")
        
        return True
        
    except Exception as e:
        print(f"Erreur update_street_status: {e}")
        return False

def get_assignations_export_data(conn):
    """Récupère les données d'assignation pour export CSV"""
    try:
        query = """
            SELECT 
                COALESCE(sector, 'Non défini') as secteur,
                name as rue,
                COALESCE(team, 'Non assignée') as equipe,
                CASE status 
                    WHEN 'a_faire' THEN 'À faire'
                    WHEN 'en_cours' THEN 'En cours'
                    WHEN 'terminee' THEN 'Terminée'
                    ELSE status 
                END as statut
            FROM streets
            ORDER BY secteur, rue
        """
        return pd.read_sql_query(query, conn)
        
    except Exception as e:
        print(f"Erreur get_assignations_export_data: {e}")
        return pd.DataFrame()

def log_activity(conn, team_id, action, details):
    """Enregistre une activité dans le log"""
    try:
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        valid_action, clean_action = validate_and_clean_input("text", action)
        valid_details, clean_details = validate_and_clean_input("note", details)
        
        if not all([valid_team, valid_action, valid_details]):
            print("Paramètres de log invalides")
            return
        
        conn.execute("""
            INSERT INTO activity_log (team_id, action, details)
            VALUES (?, ?, ?)
        """, (clean_team, clean_action, clean_details))
        
        conn.commit()
        
        # Log aussi dans un fichier texte pour backup
        log_dir = Path(__file__).parent / "logs"
        log_dir.mkdir(exist_ok=True)
        
        log_file = log_dir / "activity.log"
        with open(log_file, "a", encoding="utf-8") as f:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            f.write(f"{timestamp} | {clean_team} | {clean_action} | {clean_details}\n")
            
    except Exception as e:
        print(f"Erreur log_activity: {e}")

def get_street_notes_for_team(conn, street_name, team_id):
    """Récupère les notes d'une rue pour une équipe"""
    try:
        valid_street, clean_street = validate_and_clean_input("street_name", street_name)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        
        if not all([valid_street, valid_team]):
            return []
        
        cursor = conn.execute("""
            SELECT address_number, comment, created_at
            FROM notes
            WHERE street_name = ? AND team_id = ?
            ORDER BY created_at DESC
        """, (clean_street, clean_team))
        
        return cursor.fetchall()
        
    except Exception as e:
        print(f"Erreur get_street_notes_for_team: {e}")
        return []

@auto_backup_before_critical
def add_street_note(conn, street_name, team_id, address_number, comment):
    """Ajoute une note pour une adresse spécifique"""
    try:
        # Valider les entrées
        valid_street, clean_street = validate_and_clean_input("street_name", street_name)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        valid_address, clean_address = validate_and_clean_input("address", address_number)
        valid_comment, clean_comment = validate_and_clean_input("note", comment)
        
        if not all([valid_street, valid_team, valid_address, valid_comment]):
            raise ValueError("Paramètres invalides")
        
        # Vérifier que la rue est assignée à cette équipe
        cursor = conn.execute("""
            SELECT COUNT(*) FROM streets 
            WHERE name = ? AND team = ?
        """, (clean_street, clean_team))
        
        if cursor.fetchone()[0] == 0:
            raise ValueError(f"Rue {clean_street} non assignée à l'équipe {clean_team}")
        
        # Ajouter la note
        conn.execute("""
            INSERT INTO notes (street_name, team_id, address_number, comment)
            VALUES (?, ?, ?, ?)
        """, (clean_street, clean_team, clean_address, clean_comment))
        
        conn.commit()
        
        # Log de l'activité
        log_activity(conn, clean_team, "note_added", 
                    f"Note ajoutée - {clean_street} #{clean_address}")
        
        return True
        
    except Exception as e:
        print(f"Erreur add_street_note: {e}")
        return False

```n
================================================================================
## FICHIER 3: guignomap/validators.py (Validation des entrées)

```python

"""
Validateurs et sanitizers pour GuignoMap
Protection contre injections et validation des formats
"""

import re
import html
from typing import Optional, Tuple

class InputValidator:
    """Classe de validation et sanitization des entrées"""
    
    @staticmethod
    def sanitize_text(text: str, max_length: int = 255) -> str:
        """Nettoie et limite un texte"""
        if not text:
            return ""
        # Supprimer les caractères de contrôle
        text = "".join(char for char in text if ord(char) >= 32 or char == '\n')
        # Échapper le HTML
        text = html.escape(text)
        # Limiter la longueur
        return text[:max_length].strip()
    
    @staticmethod
    def sanitize_street_name(name: str) -> str:
        """Valide et nettoie un nom de rue"""
        if not name:
            return ""
        # Garder seulement lettres, chiffres, espaces, tirets, apostrophes, accents
        name = re.sub(r'[^a-zA-ZÀ-ÿ0-9\s\-\'\.]', '', name)
        return name[:100].strip()
    
    @staticmethod
    def sanitize_team_id(team_id: str) -> str:
        """Valide un ID d'équipe"""
        if not team_id:
            return ""
        # Format: LETTRES + CHIFFRES seulement, max 20 caractères
        team_id = re.sub(r'[^A-Z0-9]', '', team_id.upper())
        return team_id[:20]
    
    @staticmethod
    def sanitize_address_number(number: str) -> str:
        """Valide un numéro civique"""
        if not number:
            return ""
        # Garder chiffres et lettres (ex: 123A)
        number = re.sub(r'[^0-9A-Za-z\-]', '', number)
        return number[:10]
    
    @staticmethod
    def validate_password(password: str) -> Tuple[bool, str]:
        """Valide la force d'un mot de passe - minimum 4 caractères"""
        if password is None:
            return False, "Mot de passe requis"
        if len(password) < 4:
            return False, "Minimum 4 caractères"
        if len(password) > 128:
            return False, "Maximum 128 caractères"
        return True, "OK"
    
    @staticmethod
    def validate_sector(sector: str) -> str:
        """Valide un secteur"""
        valid_sectors = ['Principal', 'Centre', 'Nord', 'Sud', 'Est', 'Ouest', 'Résidentiel', '']
        if sector not in valid_sectors:
            return ''
        return sector
    
    @staticmethod
    def validate_status(status: str) -> str:
        """Valide un statut de rue"""
        valid_statuses = ['a_faire', 'en_cours', 'terminee']
        if status not in valid_statuses:
            return 'a_faire'
        return status
    
    @staticmethod
    def sanitize_note(note: str) -> str:
        """Nettoie une note/commentaire"""
        if not note:
            return ""
        # Supprimer caractères dangereux mais garder ponctuation basique
        note = re.sub(r'[<>\"\'`;]', '', note)
        return note[:500].strip()
    
    @staticmethod
    def is_sql_safe(text: str) -> bool:
        """Vérifie qu'un texte ne contient pas de patterns SQL dangereux"""
        if not text:
            return True
        dangerous_patterns = [
            r'\bDROP\b', r'\bDELETE\b', r'\bINSERT\b', r'\bUPDATE\b',
            r'\bEXEC\b', r'\bEXECUTE\b', r'--', r'/\*', r'\*/', r';'
        ]
        text_upper = text.upper()
        for pattern in dangerous_patterns:
            if re.search(pattern, text_upper):
                return False
        return True

def validate_and_clean_input(input_type: str, value: str) -> Tuple[bool, str]:
    """Fonction principale de validation"""
    validator = InputValidator()
    
    if input_type == "team_id":
        clean = validator.sanitize_team_id(value)
        return bool(clean), clean
    
    elif input_type == "street_name":
        clean = validator.sanitize_street_name(value)
        if not validator.is_sql_safe(clean):
            return False, ""
        return bool(clean), clean
    
    elif input_type == "address":
        clean = validator.sanitize_address_number(value)
        return bool(clean), clean
    
    elif input_type == "note":
        clean = validator.sanitize_note(value)
        if not validator.is_sql_safe(clean):
            return False, ""
        return bool(clean), clean
    
    elif input_type == "sector":
        clean = validator.validate_sector(value)
        return True, clean
    
    elif input_type == "status":
        clean = validator.validate_status(value)
        return True, clean
    
    elif input_type == "password":
        valid, msg = validator.validate_password(value)
        return valid, value if valid else ""
    
    else:
        clean = validator.sanitize_text(value)
        return bool(clean), clean

```n
================================================================================
## FICHIER 4: requirements.txt (Dépendances Python)

```text

streamlit>=1.36.0
pandas>=2.2.0
folium==0.20.0
streamlit-folium>=0.21.0
overpy==0.7
bcrypt>=4.0.0
plotly>=5.18.0
xlsxwriter==3.2.8
reportlab==4.4.3

```n
================================================================================
## FICHIER 5: README.md (Documentation projet)

```markdown

# GuignoMap - Système de gestion pour la Guignolée 2025 🎄

Une application web moderne conçue spécialement pour optimiser la collecte de dons lors de la Guignolée 2025 à Mascouche.

## ✨ Nouvelles fonctionnalités v4.1

### 👔 Interface Superviseur/Gestionnaire
- **Assignations par secteur** : Sélection secteur + équipe et assignation en bloc
- **Compteur rues non assignées** : Vue en temps réel des rues sans équipe
- **Export CSV assignations** : Colonnes secteur, rue, équipe, statut
- **Gestion d'erreur gracieuse** : Masquage des fonctionnalités indisponibles
- **Notifications toast** : Confirmations visuelles des actions

### 🎅 Interface Bénévole "Mes rues"
- **Vue filtrée par équipe** : Seulement les rues assignées à l'équipe connectée
- **Boutons de statut** : "En cours" et "Terminée" avec mise à jour immédiate
- **Gestion des notes** : Ajout/affichage des notes par adresse spécifique
- **Statistiques d'équipe** : Métriques de progression en temps réel
- **Journal d'activité** : Historique des actions de l'équipe

### 🛡️ Sécurité et robustesse v4.1
- **Validation stricte** : Réutilisation des validators pour toutes les entrées
- **Backup automatique** : Décorateur auto_backup_before_critical sur toutes les écritures
- **Logging complet** : Journal d'activité en base de données ET fichier texte
- **Gestion d'erreur** : Dégradation gracieuse sans plantage de l'application

### 📊 Exports professionnels
- **Maintien des exports PDF/Excel** : Aucune modification des fonctionnalités existantes
- **Nouveau CSV assignations** : Export spécialisé pour la gestion des secteurs
- **Interface unifiée** : Tous les exports accessibles depuis l'onglet Export

## ✨ Fonctionnalités v4.0 (acquises)

### 🔒 Sécurité renforcée
- **Migration bcrypt** : Remplacement SHA256 par bcrypt avec salage automatique
- **Migration automatique** des anciens mots de passe
- **Validation d'entrées** : Protection contre injection SQL et XSS
- **Sanitisation complète** de toutes les données utilisateur

### 💾 Système de backup automatique
- **Backup automatique** avant toutes opérations critiques
- **Format ZIP** avec horodatage
- **Rotation automatique** : conservation 7 jours
- **Interface de gestion** des backups avec téléchargement

## ✨ Fonctionnalités v3.0 (acquises)

### 🎄 Interface festive
- **Page d'accueil moderne** avec compte à rebours vers Noël
- **En-tête festif** aux couleurs de la Guignolée 2025
- **Carte de Noël thématique** avec icônes festives

### 📱 Optimisations mobiles
- **Interface responsive** optimisée pour tous les appareils
- **Navigation tactile** adaptée aux smartphones
- **Contrôles de carte** optimisés pour mobile

### 🏆 Système de motivation
- **Badges d'équipe** : Débutants, Actifs, Champions, Légendes
- **Notifications temps réel** pour les accomplissements
- **Tableaux de bord interactifs** avec graphiques Plotly

### 📊 Centre d'export avancé
- **Export Excel professionnel** avec formatage automatique
- **Génération de listes SMS** pour la communication d'équipe
- **Export PDF** (préparation)
- **Rapports détaillés** par équipe et secteur

### 🗺️ Améliorations cartographiques
- **Choix de fonds de carte** : OpenStreetMap France, CARTO Voyager, Esri
- **Zoom optimisé** centré sur Mascouche
- **Zone d'affichage agrandie** : 90% de l'écran sur PC
- **Gestion d'erreur robuste** : secrets.toml optionnel
- **Visibilité améliorée** des rues avec lignes plus épaisses
- **Récupération complète** de toutes les rues via OSM

### 🗺️ Légende de la carte (persistante)
- **4 états visuels** :
  - 🟢 **Vert** : Rues terminées (collecte finie)
  - 🟡 **Jaune** : Rues en cours (équipe active)
  - 🔴 **Rouge plein** : Rues assignées à faire (équipe désignée)
  - 🔴 **Rouge pointillé** : Rues non assignées (aucune équipe)
- **Position fixe** : Bas-droite de la carte
- **Persistance garantie** : Reste visible au zoom/dézoom/déplacement
- **Style moderne** : Fond blanc, bordure, ombre portée

### ⚙️ Compatibilité et modernisation
- **Python 3.13.6** et versions récentes de Streamlit
- **Suppression de use_container_width** (déprécié) ➜ `width="stretch"`
- **Migration pandas Styler** : `applymap()` ➜ `map()` avec helper de compatibilité
- **Légende persistante** via Folium Elements (remplace l'ancien HTML/CSS)
- **Chemins multi-plateformes** avec pathlib
- **Gestion des erreurs robuste** : l'application ne crash jamais
- **Code moderne** : Nettoyage des anciens hacks et workarounds

### 🎨 Affichage des statuts
- **Codes internes** : `a_faire`, `en_cours`, `terminee` (base de données)
- **Affichage UI/exports** : "À faire", "En cours", "Terminée" (interface utilisateur)
- **Style visual** : Fond pastel + texte contrasté, uniquement sur la colonne "Statut"
- **Couleurs harmonisées** : 
  - 🟢 **Terminée** : Fond vert pâle (#E6F5EA)
  - 🟡 **En cours** : Fond jaune pâle (#FFF3CC)  
  - 🔴 **À faire** : Fond rose pâle (#FFE6EC)

### 🔧 Interface assignations
- **Sélecteur secteur** : Label clair "SECTEUR À ASSIGNER", aucun chevauchement
- **Tableau état** : Colonnes Rue / Secteur / Équipe / Statut avec libellés français
- **Style uniforme** : Rendu standard avec thème sombre (fond neutre, texte blanc)
- **Corrections UI** :
  - Fix superposition texte au-dessus du sélecteur 'SECTEUR À ASSIGNER' (suppression des sorties de debug/injections HTML), tableau des assignations sans stylisation spéciale (rendu uniforme)
  - Layout propre avec container/colonnes, sans overlay ni stylisation
  - Équipes : suppression du doublon de titre causant une superposition dans l'expander
  - Mot de passe équipes : minimum 4 caractères, aucune autre contrainte

### 👥 Gestion moderne
- **Terminologie unifiée** : "gestionnaire" au lieu de "superviseur"
- **Navigation sidebar** moderne et intuitive
- **Interface bénévole restreinte** aux rues assignées seulement
- **Authentification simplifiée** avec cartes de connexion
- **Gestion des équipes améliorée** :
  - Ajout d'un champ Confirmer le mot de passe (création d'équipe)
  - Politique : minimum 4 caractères, aucune autre contrainte
  - Option : case Afficher les mots de passe

## 🚀 Installation et utilisation

### Prérequis
- Python 3.8+
- Accès internet pour OSM et les tuiles de carte

### Installation
```bash
git clone https://github.com/votre-repo/GuignoMap.git
cd GuignoMap
pip install -r requirements.txt
```

### Lancement (Windows)
```powershell
# Activer l'environnement virtuel
.\.venv\Scripts\Activate.ps1

# Lancer l'application
cd .\guignomap
streamlit run app.py
```

### Exports PDF/Excel
- **Boutons de téléchargement** : Disponibles dans l'onglet "📥 Export"
- **Emplacement recommandé** : `.\guignomap\exports` pour sauvegarde locale
- **Formats disponibles** : Excel (.xlsx), PDF (.pdf), CSV assignations

### Ouvrir le dernier export (PowerShell)
```powershell
$d = Join-Path $PSScriptRoot 'guignomap'
Set-Location $d
if (-not (Test-Path "..\exports")) { New-Item -ItemType Directory "..\exports" | Out-Null }
$f = Get-ChildItem "..\exports" -File -ErrorAction SilentlyContinue | Sort-Object LastWriteTime | Select-Object -Last 1
if ($f) { ii $f.FullName } else { ii "..\exports" }
```

## 📦 Dépendances principales

- **streamlit** : Interface web moderne
- **folium** : Cartes interactives
- **pandas** : Manipulation des données
- **overpy** : API OpenStreetMap
- **plotly** : Graphiques interactifs
- **xlsxwriter** : Export Excel professionnel
- **reportlab** : Génération PDF professionnelle
- **bcrypt** : Hachage sécurisé des mots de passe

### Sécurité/Robustesse
- **bcrypt** : Migration automatique des anciens hash SHA256 vers bcrypt avec salage
- **Backup automatique** : ZIP créé avant toute écriture critique
- **Validation inputs** : Protection SQL injection et XSS via module validators
- **Logging complet** : Journal d'activité en base de données et fichier

## 🔧 Notes techniques

### Compatibilité pandas 2.4+
L'application utilise un helper `style_map_compat()` pour gérer la transition de `Styler.applymap()` vers `Styler.map()` :
```python
def style_map_compat(df: pd.DataFrame, fn: Callable[[Any], str], subset: Any = None):
    """Helper de compatibilité pandas - applymap() vs map()"""
    styler = df.style
    if hasattr(styler, "map"):
        return styler.map(fn, subset=subset)  # Pandas 2.4+
    return getattr(styler, "applymap")(fn, subset=subset)  # Pandas < 2.4
```

### Environment virtuel (.venv)
- **Développement** : Utiliser exclusivement `.\.venv\Scripts\python.exe`
- **Isolation** : Toutes les dépendances dans `.venv/` pour éviter les conflits
- **Activation** : `.\.venv\Scripts\Activate.ps1` avant utilisation

## 🎯 Guide d'utilisation v4.1

### 👔 Pour les Superviseurs/Gestionnaires

#### Assignation par secteur (nouveau v4.1)
1. **Connexion gestionnaire** : Utilisez vos identifiants superviseur
2. **Onglet "🗺️ Assignation"** : Accédez au nouveau panneau d'assignation
3. **Sélection secteur et équipe** : Choisissez le secteur à assigner et l'équipe destinataire
4. **Assignation en bloc** : Cliquez "🎯 Assigner tout le secteur"
5. **Vérification** : Le tableau des assignations s'actualise automatiquement

#### Export CSV assignations (nouveau v4.1)
1. **Onglet "📥 Export"** : Accédez aux exports spécialisés v4.1
2. **Export CSV Assignations** : Téléchargez le fichier avec colonnes secteur, rue, équipe, statut
3. **Utilisation** : Parfait pour suivi externe ou import dans d'autres outils

### 🎅 Pour les Bénévoles

#### Interface "Mes rues" (nouveau v4.1)
1. **Connexion bénévole** : Connectez-vous avec votre nom d'équipe
2. **Onglet "🏘️ Mes rues"** : Vue filtrée de vos rues assignées uniquement
3. **Mise à jour statuts** : Cliquez "🚀 En cours" ou "✅ Terminée" pour chaque rue
4. **Ajout de notes** : Remplissez numéro civique + commentaire et cliquez "💾 Enregistrer note"
5. **Suivi progression** : Consultez vos métriques en temps réel

#### Gestion des notes par adresse (nouveau v4.1)
1. **Sélection rue** : Développez l'accordéon de la rue souhaitée
2. **Notes existantes** : Consultez les notes déjà saisies
3. **Nouvelle note** : Entrez le numéro civique (ex: 123A) et votre commentaire
4. **Types de notes** : Absent, refus, don reçu, situation particulière...
5. **Validation** : La note est automatiquement horodatée et associée à votre équipe

## 🎯 Fonctionnalités principales

### Pour les bénévoles
- 🗺️ **Carte interactive** avec leurs rues assignées uniquement
- ✅ **Système de validation** rue par rue avec notes
- 🏆 **Badges de progression** et encouragements
- � **Interface mobile** optimisée

### Pour les gestionnaires
- 📊 **Tableau de bord complet** avec KPIs temps réel
- �️ **Vue d'ensemble** de toutes les équipes
- 📈 **Graphiques de progression** par Plotly
- � **Centre d'export** avec formats multiples
- 👥 **Gestion des équipes** et assignation
  - Création encapsulée dans un formulaire (Enter ou bouton)
  - Correction d'un chevauchement de texte au-dessus du formulaire
- � **Notifications** d'activité

### Données et exports
- 📝 **Base de données SQLite** intégrée
- 📊 **Export Excel** avec formatage professionnel
- 📱 **Listes SMS** pour communication
- 📄 **Rapports PDF** avec mise en page professionnelle
source .venv/bin/activate

## 🗃️ Structure du projet

```
GuignoMap/
├── guignomap/
│   ├── app.py              # Application principale Streamlit
│   ├── db.py               # Gestion base de données
│   ├── osm.py              # Interface OpenStreetMap
│   ├── guigno_map.db       # Base de données SQLite
│   ├── osm_cache.json      # Cache des données OSM
│   ├── streets_mascouche.csv # Données des rues
│   └── assets/
│       ├── banner.png      # Bannière Guignolée
│       ├── logo.png        # Logo officiel
│       └── styles.css      # Styles personnalisés
├── requirements.txt        # Dépendances Python
└── README.md              # Documentation
```

## 🎄 Thème Guignolée 2025

L'application adopte une identité visuelle festive pour l'édition 2025 :
- **Couleurs** : Rouge festif (#dc3545), vert sapin, or
- **Typographie** : Poppins pour une lecture moderne
- **Icônes** : Thème de Noël et solidarité
- **Animations** : Compte à rebours dynamique vers Noël

## � Statistiques temps réel

Le système suit automatiquement :
- Progression globale de la collecte
- Performance par équipe et bénévole
- Couverture géographique
- Tendances et objectifs

## 🔐 Sécurité et accès

- **Authentification** par nom d'équipe
- **Restriction d'accès** : bénévoles limités à leurs rues
- **Données locales** : pas de transmission externe
- **Sauvegarde automatique** des progressions

## 🤝 Contribution

GuignoMap est développé pour la Guignolée de Mascouche. Pour toute suggestion ou amélioration, contactez l'équipe organisatrice.

---

**Joyeuses Fêtes et bonne Guignolée 2025 ! 🎄🎁**
2. **Consultez votre liste** de rues assignées
3. **Commencez une rue** :
   - Sélectionnez la rue dans la liste
   - Changez le statut de "À faire" à "En cours"
4. **Pendant la collecte** :
   - Ajoutez des notes pour les adresses spéciales
   - Ex: "145 - Famille absente, denrées déposées"
5. **Terminez la rue** :
   - Une fois la rue complète, changez le statut à "Terminée"
6. **Passez à la rue suivante**

### 🆘 Que faire si...

#### ❓ **Je ne vois pas mes rues**
- Vérifiez que vous êtes connecté comme bénévole
- Demandez au superviseur si des rues vous ont été assignées

#### ❓ **Je ne peux pas me connecter**
- Vérifiez votre code d'équipe et mot de passe
- Contactez le superviseur pour confirmation

#### ❓ **La carte ne s'affiche pas**
- Actualisez la page (F5)
- Le superviseur peut reconstruire les données dans l'onglet Tech

#### ❓ **Je veux voir toute la ville**
- Seuls les superviseurs voient toute la carte
- Les bénévoles ne voient que leurs rues assignées

### 💡 Conseils pratiques

#### Pour les **superviseurs** :
- Créez les équipes AVANT d'assigner des rues
- Assignez des secteurs logiques (ex: même quartier)
- Consultez régulièrement l'onglet "Vue d'ensemble" pour le suivi
- Exportez les données à la fin pour les rapports

#### Pour les **bénévoles** :
- Changez le statut dès que vous commencez une rue
- Ajoutez des notes pour les situations particulières
- N'oubliez pas de marquer "Terminée" quand c'est fini
- Utilisez l'auto-refresh pour voir les mises à jour des autres équipes

### 🎨 Interface rapide
- **Menu gauche** : Navigation principale
- **Carte centrale** : Vue géographique avec couleurs
- **Légende en bas à droite** : Explication des couleurs et statistiques
- **Auto-refresh** : Active le rafraîchissement automatique toutes les 15 secondes

## 🔐 Connexion

### Superviseur
- **Portail** : 🎯 Superviseur
- **Mot de passe** : `admin123`
- **Fonctions** : Gestion complète + opérations techniques

### Bénévoles
- **Portail** : 👥 Bénévole
- **Identifiants** : Créés par le superviseur

## 📁 Structure du projet

```
GuignoMap/
├── guignomap/
│   ├── app.py              # Application principale
│   ├── db.py               # Gestion base de données robuste
│   ├── osm.py              # Intégration OpenStreetMap + adresses
│   ├── guigno_map.db       # Base SQLite
│   ├── osm_cache.json      # Cache géométries
│   ├── osm_addresses.json  # Cache adresses OSM
│   └── assets/
│       ├── styles.css      # Styles personnalisés
│       ├── logo.png        # Logo du Relais
│       └── banner.png      # Bannière (optionnel)
├── .streamlit/
│   └── config.toml         # Configuration Streamlit
├── requirements.txt        # Dépendances Python
└── README.md              # Documentation
```

## 🛠️ Technologies

- **Frontend** : Streamlit + CSS personnalisé
- **Backend** : Python + SQLite avec gestion d'erreurs
- **Cartes** : Folium + OpenStreetMap + API Overpass
- **Données** : Pandas + Overpy avec validation robuste

## 📊 Fonctionnalités détaillées

### Pour les Superviseurs
- Vue d'ensemble avec carte complète de Mascouche
- Gestion des équipes avec création/suppression
- Assignation intelligente des rues
- Export des rapports (rues + notes)
- **Onglet Tech** protégé par PIN pour :
  - Reconstruction du cache géométrique OSM
  - Import/mise à jour des adresses depuis OSM
  - Gestion d'erreurs avancée avec fallback
- Visualisation complète : autoroutes, rues principales, voies privées
- Statistiques en temps réel avec compteurs dynamiques

### Pour les Bénévoles
- Interface dédiée à leur tournée assignée
- Ajout de notes par adresse civique
- Mise à jour du statut des rues (à faire → en cours → terminée)
- Consultation des notes existantes
- Carte centrée sur leur zone de travail
- Ajout de notes par adresse
- Mise à jour du statut des rues
- Suivi en temps réel
- Carte centrée automatiquement sur la zone de travail
- Interface fluide avec rechargement intelligent des données
- **Visibilité totale** des voies de collecte (y compris voies privées)

## 🎨 Thème visuel

Interface moderne aux couleurs du **Relais de Mascouche** :
- Rouge bordeaux (#8B0000)
- Or (#FFD700)
- Design responsive
- Animations fluides

### Légende de la carte améliorée
- 🟢 **Vert** : Rues terminées
- � **Orange** : Rues en cours
- 🔴 **Rouge** : Rues à faire
- **Lignes pleines** : Rues assignées à une équipe
- **Lignes pointillées** : Rues non assignées
- **Compteurs dynamiques** : Total, assignées, non assignées
- **Marqueur centre-ville** : Point de référence Mascouche

## 🚧 Développement

### Base de données renforcée
- Tables : `streets`, `teams`, `notes`, `activity_log`, `addresses`
- Import automatique depuis OpenStreetMap avec validation
- Gestion d'erreurs et création automatique des rues manquantes
- Données de test intégrées et fallback robuste

### Système OSM révolutionnaire v3.1
- **Couverture maximale** : TOUTES les voies nommées + autoroutes (ref)
- **Requête optimisée** : `highway+name OU highway+ref`
- **Cache multi-niveaux** : géométries + adresses OSM
- **Fallback étendu** : 19 voies principales de Mascouche
- **Gestion d'erreurs** : validation, retry, récupération automatique
- **Import adresses** : numéros civiques avec tri intelligent
- **Performance** : cache Streamlit sensible aux modifications

### Couverture des voies complète
- 🛣️ **Autoroutes** : A-25, A-640 (via ref)
- 🏘️ **Voies principales** : Montée Masson, Chemin Sainte-Marie
- 🚗 **Voies résidentielles** : toutes les rues nommées
- 🏠 **Voies d'accès** : service, private roads
- 🔚 **Impasses et allées** : couverture totale
- ✅ **Inclusions** : TOUT sauf limitation technique OSM

### Améliorations critiques v3.1
- **🐛 Fix create_map()** : Gestion robuste des colonnes DataFrame
- **🔧 Fix build_addresses_cache()** : Validation types et tri intelligent  
- **🛡️ Fix import_addresses_from_cache()** : Création automatique des rues
- **⚡ Fix list_streets()** : COALESCE pour éviter les NULL
- **🎯 UI améliorée** : Limites géographiques et zoom adaptatif
- **📊 Statistiques** : Compteurs en temps réel dans la légende

### Architecture technique
- **Frontend** : Streamlit avec gestion d'erreur globale
- **Géolocalisation** : API Overpass OSM avec requête universelle
- **Données** : SQLite + cache JSON double (géo + adresses)
- **Couverture** : Système d'inclusion universelle (name + ref)
- **Robustesse** : Fallback à tous les niveaux avec validation

## 📝 Changelog v3.3

### 🎄 Thème Guignolée festif
- **Header moderne** : Design spécial Guignolée 2025 avec dégradé rouge/vert
- **Animations** : Flocons de neige CSS pour ambiance festive
- **Branding** : "🎅 GUIGNOLÉE 2025 🎁" avec police Manrope
- **Stats temps réel** : Progression visible directement dans le header
- **Support logo** : Détection automatique du logo Guignolée

### 🖼️ Sidebar avec logo intégré
- **Logo professionnel** : Espace dédié 200px en haut de sidebar
- **Positionnement optimal** : Collé au bord supérieur sans espace vide
- **Fallback élégant** : Placeholder festif avec dégradé Guignolée si logo absent
- **Navigation moderne** : Boutons stylisés Accueil/Bénévole/Gestionnaire
- **Branding complet** : Cohérence visuelle avec header festif

### 🎨 Effets de connexion festifs
- **Connexion bénévole** : Effet neige (`st.snow()`) pour ambiance hivernale
- **Connexion gestionnaire** : Effet neige unifié pour cohérence thématique
- **Messages personnalisés** : Accueil par équipe avec design festif

## 📝 Changelog v3.2

### 🗺️ Améliorations cartographiques majeures
- **Fonds multiples** : OSM France (détaillé), CARTO Voyager (moderne), Esri WorldStreetMap (professionnel)
- **Sélecteur de couches** : Contrôle dynamique pour changer de fond à la volée
- **Zoom optimisé** : zoom_start=13 pour meilleur cadrage de Mascouche
- **Performances** : prefer_canvas=True pour rendu fluide + contrôles complets
- **Visibilité** : weight 7/5 et opacity 0.9/0.7 pour meilleure lisibilité
- **Navigation** : zoom_control et scrollWheelZoom activés

### 🎯 Interface utilisateur
- **Terminologie** : "Code" → "Identifiant", "Nom" → "Équipe" pour clarté
- **UX** : Amélioration compréhension des champs par les utilisateurs

## 📝 Changelog v3.1

### 🔧 Corrections critiques
- **create_map()** : Gestion robuste colonnes pandas + limites géographiques
- **build_addresses_cache()** : Tri numérique intelligent + gestion d'erreurs
- **import_addresses_from_cache()** : Validation + création automatique rues
- **list_streets()** : COALESCE pour colonnes NULL + structure garantie
- **Requête OSM** : Inclusion autoroutes via ref + couverture maximale

### ✨ Nouvelles fonctionnalités  
- **Carte centrée Mascouche** : Bounds géographiques + zoom adaptatif
- **Légende avancée** : Statistiques temps réel + compteurs dynamiques
- **Marqueur centre-ville** : Point de référence visuel
- **Fallback étendu** : 19 voies principales + autoroutes
- **Gestion d'erreurs** : Messages informatifs + récupération automatique

## 🔧 Dépannage

### Problèmes de légende
- **Légende invisible** : Appuyez sur F5 pour recharger complètement la page
- **Légende qui clignote** : Normal lors du changement de fond de carte
- **Position incorrecte** : La légende se repositionne automatiquement

### Problèmes de compatibilité Streamlit
- **Erreur use_container_width** : Version récente de Streamlit - l'application s'adapte automatiquement
- **Affichage dégradé** : Mise à jour recommandée vers Streamlit 1.28+
- **Contrôles manquants** : Vérifiez la version folium et streamlit-folium

### Problèmes de compatibilité pandas
- **Erreur "Cannot access attribute 'applymap'"** : Pandas 2.4+ retire applymap - l'application utilise un helper de compatibilité
- **Tables sans style** : Vérifiez la version pandas, le helper `style_map_compat()` gère automatiquement les versions
- **Couleurs manquantes** : Problème temporaire lors du changement de version pandas - redémarrez l'application

### Performance
- **Carte lente** : Réduisez le zoom ou changez de fond de carte
- **Mémoire élevée** : Rechargez l'application avec F5
- **Erreurs OSM** : Vérifiez la connexion internet

### Données
- **Rues manquantes** : Utilisez "Recharger depuis OSM" dans l'onglet Admin
- **Backup corrupt** : Les backups sont vérifiés à la création
- **Données perdues** : Consultez le dossier backups/ pour récupération

## 📝 Support

Développé pour **Le Relais de Mascouche** - Collecte de denrées 2025

---
*Version 3.4 - Interface sidebar complète avec logo intégré et effets festifs*


```n
================================================================================
## FIN DE L'EXPORT - RÉCAPITULATIF FINAL

Tous les fichiers source principaux de GuignoMap ont été exportés :
- guignomap/app.py : Interface utilisateur et logique principale
- guignomap/db.py : Gestion de la base de données et des équipes
- guignomap/validators.py : Validation des entrées utilisateur
- requirements.txt : Dépendances Python
- README.md : Documentation complète du projet

Cet export reflète l'état du code après toutes les améliorations récentes :
 Suppression de la superposition de texte dans l'onglet Équipes
 Ajout de la confirmation du mot de passe
 Politique de mot de passe assouplie (min 4 caractères)
 Case à cocher pour afficher/masquer les mots de passe
 Documentation mise à jour
 Encodage UTF-8 correct (caractères français préservés)

Date d'export : 15 septembre 2025 - Code prêt pour production

================================================================================

```
---8<--- GuignoMap_code_export_20250915_final_UTF8.txt END ---

---8<--- lancer_guignomap.bat BEGIN ---
```bat
@echo off
echo ========================================
echo       GuignoMap - Relais de Mascouche
echo ========================================
echo.
echo Activation de l'environnement virtuel...
echo.

REM Change vers le répertoire de l'application
cd /d "%~dp0"

REM Active l'environnement virtuel
call .venv\Scripts\activate

echo Lancement de l'application...
echo.

REM Lance Streamlit avec l'application
python -m streamlit run guignomap/app.py --server.port 8501 --server.headless true

pause
```
---8<--- lancer_guignomap.bat END ---

---8<--- lancer_guignomap.ps1 BEGIN ---
```ps1
# GuignoMap - Script de lancement PowerShell
# Relais de Mascouche

Write-Host "========================================" -ForegroundColor Green
Write-Host "       GuignoMap - Relais de Mascouche" -ForegroundColor Green  
Write-Host "========================================" -ForegroundColor Green
Write-Host ""
Write-Host "Activation de l'environnement virtuel..." -ForegroundColor Yellow
Write-Host ""

# Change vers le répertoire de l'application
Set-Location $PSScriptRoot

# Active l'environnement virtuel
& .\.venv\Scripts\Activate.ps1

Write-Host "Lancement de l'application..." -ForegroundColor Yellow
Write-Host ""

# Lance Streamlit avec l'application
& python -m streamlit run guignomap/app.py --server.port 8501 --server.headless true

Read-Host "Appuyez sur Entrée pour fermer..."
```
---8<--- lancer_guignomap.ps1 END ---

---8<--- PHASE1_COMMANDS.md BEGIN ---
```md
# GuignoMap v5.0 - Commandes PowerShell PHASE 1
# Migration infrastructure vers prod Streamlit Cloud
# Windows PowerShell - Toutes les commandes prêtes à exécuter

## 1. Configuration initiale de l'environnement

### Activer l'environnement virtuel existant
```powershell
cd c:\Users\nick\guignomap_clone\GuignoMap
.\.venv\Scripts\Activate.ps1
```

### Installer les nouvelles dépendances
```powershell
# Dependencies PostgreSQL + Auth + Storage
pip install --only-binary=all psycopg2-binary
pip install sqlalchemy==2.0.43 alembic==1.16.5 passlib[argon2]==1.7.4 boto3==1.34.144
```

## 2. Configuration Secrets Streamlit

### Éditer le fichier .streamlit\secrets.toml avec vos vraies valeurs :
```toml
[database]
url = "postgresql://user:password@host:5432/database_name"
pool_size = 5
max_overflow = 10

[storage]
s3_bucket = "votre-bucket-s3"
s3_region = "us-east-1"
s3_access_key = "votre-access-key"
s3_secret_key = "votre-secret-key"
```

## 3. Migration base de données

### Générer la première révision Alembic
```powershell
alembic revision --autogenerate -m "initial_schema"
```

### Appliquer les migrations à PostgreSQL
```powershell
alembic upgrade head
```

### Migrer les données SQLite → PostgreSQL
```powershell
python scripts\migrate_sqlite_to_postgres.py
```

## 4. Vérifications et tests

### Analyser les mots de passe existants
```powershell
python scripts\migrate_password_hashes.py analyze
```

### Générer un rapport détaillé de migration
```powershell
python scripts\migrate_password_hashes.py report
```

### Tester les fonctions de stockage
```powershell
python -c "from src.storage import get_storage_info; import json; print(json.dumps(get_storage_info(), indent=2, default=str))"
```

### Tester la connexion PostgreSQL
```powershell
python -c "from src.database.connection import test_connection; print('🔌 Connexion PostgreSQL:', test_connection())"
```

## 5. Lancement de l'application

### Démarrer Streamlit avec la nouvelle configuration
```powershell
# Depuis le répertoire guignomap/
cd guignomap
..\\.venv\Scripts\python.exe -m streamlit run app.py
```

### Ou utiliser la tâche VS Code configurée
```powershell
# Via la palette de commandes VS Code:
# Tasks: Run Task > "GuignoMap: Run (Streamlit)"
```

## 6. Commandes de maintenance

### Backup manuel
```powershell
python -c "from src.storage import upload_backup; from pathlib import Path; upload_backup(Path('guignomap/guigno_map_backup.db'))"
```

### Lister les backups cloud
```powershell
python -c "from src.storage import list_backups; import json; print(json.dumps(list_backups(), indent=2, default=str))"
```

### Purger le cache OSM et forcer rechargement
```powershell
python -c "from src.storage import upload_osm_cache; upload_osm_cache({})"
```

## 7. Monitoring et diagnostics

### Vérifier l'état du stockage
```powershell
python -c "from src.storage import get_storage_info; print('Backend:', get_storage_info()['backend'])"
```

### Analyser les performances DB
```powershell
python -c "from src.database.connection import get_engine; print('Pool info:', get_engine().pool.status())"
```

## 8. Rollback d'urgence (si nécessaire)

### Revenir à SQLite temporairement
```powershell
# 1. Modifier src/config.py pour retourner "sqlite:///guigno_map.db"
# 2. Relancer l'application
..\\.venv\Scripts\python.exe -m streamlit run app.py
```

### Restaurer un backup
```powershell
# Lister les backups disponibles
python -c "from src.storage import list_backups; [print(f'{i}: {b[\"filename\"]}') for i, b in enumerate(list_backups())]"

# Restaurer un backup spécifique (remplacer BACKUP_KEY)
python -c "from src.storage import download_backup; from pathlib import Path; download_backup('BACKUP_KEY', Path('guigno_map_restored.db'))"
```

## Notes importantes

1. **Politique de mot de passe** : Conservée à min 4 caractères + confirmation (UI v4.1)
2. **Migration des hashes** : Automatique lors de la prochaine connexion réussie
3. **Stockage** : S3 si configuré, sinon fallback local automatique
4. **Base de données** : PostgreSQL en production, SQLite en dev/fallback
5. **Retry logic** : Intégrée pour toutes les opérations DB critiques

## Dépannage

### Si erreur PostgreSQL
```powershell
# Vérifier la connexion
python -c "from src.database.connection import test_connection; test_connection()"
```

### Si erreur S3
```powershell
# Vérifier la configuration
python -c "from src.storage import get_storage_info; print(get_storage_info())"
```

### Si erreur Alembic
```powershell
# Vérifier l'état des migrations
alembic current
alembic history
```

## Structure finale v5.0
```
GuignoMap/
├── .streamlit/
│   └── secrets.toml              # Configuration centralisée
├── src/
│   ├── config.py                 # Accès aux secrets
│   ├── auth/
│   │   └── passwords.py          # Argon2 + bcrypt compat
│   ├── database/
│   │   ├── connection.py         # PostgreSQL + retry
│   │   ├── models.py             # SQLAlchemy models
│   │   └── migrations/           # Alembic migrations
│   └── storage/
│       ├── __init__.py           # API unifiée
│       ├── cloud.py              # Client S3
│       └── local.py              # Fallback local
├── scripts/
│   ├── migrate_sqlite_to_postgres.py
│   └── migrate_password_hashes.py
└── guignomap/
    └── app.py                    # Application Streamlit
```
```
---8<--- PHASE1_COMMANDS.md END ---

---8<--- README.md BEGIN ---
```md
# GuignoMap - Système de gestion pour la Guignolée 2025 🎄

Une application web moderne conçue spécialement pour optimiser la collecte de dons lors de la Guignolée 2025 à Mascouche.

## ✨ Nouvelles fonctionnalités v4.1

### 👔 Interface Superviseur/Gestionnaire
- **Assignations par secteur** : Sélection secteur + équipe et assignation en bloc
- **Compteur rues non assignées** : Vue en temps réel des rues sans équipe
- **Export CSV assignations** : Colonnes secteur, rue, équipe, statut
- **Gestion d'erreur gracieuse** : Masquage des fonctionnalités indisponibles
- **Notifications toast** : Confirmations visuelles des actions

### 🎅 Interface Bénévole "Mes rues"
- **Vue filtrée par équipe** : Seulement les rues assignées à l'équipe connectée
- **Boutons de statut** : "En cours" et "Terminée" avec mise à jour immédiate
- **Gestion des notes** : Ajout/affichage des notes par adresse spécifique
- **Statistiques d'équipe** : Métriques de progression en temps réel
- **Journal d'activité** : Historique des actions de l'équipe

### 🛡️ Sécurité et robustesse v4.1
- **Validation stricte** : Réutilisation des validators pour toutes les entrées
- **Backup automatique** : Décorateur auto_backup_before_critical sur toutes les écritures
- **Logging complet** : Journal d'activité en base de données ET fichier texte
- **Gestion d'erreur** : Dégradation gracieuse sans plantage de l'application

### 📊 Exports professionnels
- **Maintien des exports PDF/Excel** : Aucune modification des fonctionnalités existantes
- **Nouveau CSV assignations** : Export spécialisé pour la gestion des secteurs
- **Interface unifiée** : Tous les exports accessibles depuis l'onglet Export

## ✨ Fonctionnalités v4.0 (acquises)

### 🔒 Sécurité renforcée
- **Migration bcrypt** : Remplacement SHA256 par bcrypt avec salage automatique
- **Migration automatique** des anciens mots de passe
- **Validation d'entrées** : Protection contre injection SQL et XSS
- **Sanitisation complète** de toutes les données utilisateur

### 💾 Système de backup automatique
- **Backup automatique** avant toutes opérations critiques
- **Format ZIP** avec horodatage
- **Rotation automatique** : conservation 7 jours
- **Interface de gestion** des backups avec téléchargement

## ✨ Fonctionnalités v3.0 (acquises)

### 🎄 Interface festive
- **Page d'accueil moderne** avec compte à rebours vers Noël
- **En-tête festif** aux couleurs de la Guignolée 2025
- **Carte de Noël thématique** avec icônes festives

### 📱 Optimisations mobiles
- **Interface responsive** optimisée pour tous les appareils
- **Navigation tactile** adaptée aux smartphones
- **Contrôles de carte** optimisés pour mobile

### 🏆 Système de motivation
- **Badges d'équipe** : Débutants, Actifs, Champions, Légendes
- **Notifications temps réel** pour les accomplissements
- **Tableaux de bord interactifs** avec graphiques Plotly

### 📊 Centre d'export avancé
- **Export Excel professionnel** avec formatage automatique
- **Génération de listes SMS** pour la communication d'équipe
- **Export PDF** (préparation)
- **Rapports détaillés** par équipe et secteur

### 🗺️ Améliorations cartographiques
- **Choix de fonds de carte** : OpenStreetMap France, CARTO Voyager, Esri
- **Zoom optimisé** centré sur Mascouche
- **Zone d'affichage agrandie** : 90% de l'écran sur PC
- **Gestion d'erreur robuste** : secrets.toml optionnel
- **Visibilité améliorée** des rues avec lignes plus épaisses
- **Récupération complète** de toutes les rues via OSM

### 🗺️ Légende de la carte (persistante)
- **4 états visuels** :
  - 🟢 **Vert** : Rues terminées (collecte finie)
  - 🟡 **Jaune** : Rues en cours (équipe active)
  - 🔴 **Rouge plein** : Rues assignées à faire (équipe désignée)
  - 🔴 **Rouge pointillé** : Rues non assignées (aucune équipe)
- **Position fixe** : Bas-droite de la carte
- **Persistance garantie** : Reste visible au zoom/dézoom/déplacement
- **Style moderne** : Fond blanc, bordure, ombre portée

### ⚙️ Compatibilité et modernisation
- **Python 3.13.6** et versions récentes de Streamlit
- **Suppression de use_container_width** (déprécié) ➜ `width="stretch"`
- **Migration pandas Styler** : `applymap()` ➜ `map()` avec helper de compatibilité
- **Légende persistante** via Folium Elements (remplace l'ancien HTML/CSS)
- **Chemins multi-plateformes** avec pathlib
- **Gestion des erreurs robuste** : l'application ne crash jamais
- **Code moderne** : Nettoyage des anciens hacks et workarounds

### 🎨 Affichage des statuts
- **Codes internes** : `a_faire`, `en_cours`, `terminee` (base de données)
- **Affichage UI/exports** : "À faire", "En cours", "Terminée" (interface utilisateur)
- **Style visual** : Fond pastel + texte contrasté, uniquement sur la colonne "Statut"
- **Couleurs harmonisées** : 
  - 🟢 **Terminée** : Fond vert pâle (#E6F5EA)
  - 🟡 **En cours** : Fond jaune pâle (#FFF3CC)  
  - 🔴 **À faire** : Fond rose pâle (#FFE6EC)

### 🔧 Interface assignations
- **Sélecteur secteur** : Label clair "SECTEUR À ASSIGNER", aucun chevauchement
- **Tableau état** : Colonnes Rue / Secteur / Équipe / Statut avec libellés français
- **Style uniforme** : Rendu standard avec thème sombre (fond neutre, texte blanc)
- **Corrections UI** :
  - Fix superposition texte au-dessus du sélecteur 'SECTEUR À ASSIGNER' (suppression des sorties de debug/injections HTML), tableau des assignations sans stylisation spéciale (rendu uniforme)
  - Layout propre avec container/colonnes, sans overlay ni stylisation
  - Équipes : suppression du doublon de titre causant une superposition dans l'expander
  - Mot de passe équipes : minimum 4 caractères, aucune autre contrainte

### 👥 Gestion moderne
- **Terminologie unifiée** : "gestionnaire" au lieu de "superviseur"
- **Navigation sidebar** moderne et intuitive
- **Interface bénévole restreinte** aux rues assignées seulement
- **Authentification simplifiée** avec cartes de connexion
- **Gestion des équipes améliorée** :
  - Ajout d'un champ Confirmer le mot de passe (création d'équipe)
  - Politique : minimum 4 caractères, aucune autre contrainte
  - Option : case Afficher les mots de passe

## 🚀 Installation et utilisation

### Prérequis
- Python 3.8+
- Accès internet pour OSM et les tuiles de carte

### Installation
```bash
git clone https://github.com/votre-repo/GuignoMap.git
cd GuignoMap
pip install -r requirements.txt
```

### Lancement (Windows)
```powershell
# Activer l'environnement virtuel
.\.venv\Scripts\Activate.ps1

# Lancer l'application
cd .\guignomap
streamlit run app.py
```

### Exports PDF/Excel
- **Boutons de téléchargement** : Disponibles dans l'onglet "📥 Export"
- **Emplacement recommandé** : `.\guignomap\exports` pour sauvegarde locale
- **Formats disponibles** : Excel (.xlsx), PDF (.pdf), CSV assignations

### Ouvrir le dernier export (PowerShell)
```powershell
$d = Join-Path $PSScriptRoot 'guignomap'
Set-Location $d
if (-not (Test-Path "..\exports")) { New-Item -ItemType Directory "..\exports" | Out-Null }
$f = Get-ChildItem "..\exports" -File -ErrorAction SilentlyContinue | Sort-Object LastWriteTime | Select-Object -Last 1
if ($f) { ii $f.FullName } else { ii "..\exports" }
```

## 📦 Dépendances principales

- **streamlit** : Interface web moderne
- **folium** : Cartes interactives
- **pandas** : Manipulation des données
- **overpy** : API OpenStreetMap
- **plotly** : Graphiques interactifs
- **xlsxwriter** : Export Excel professionnel
- **reportlab** : Génération PDF professionnelle
- **bcrypt** : Hachage sécurisé des mots de passe

### Sécurité/Robustesse
- **bcrypt** : Migration automatique des anciens hash SHA256 vers bcrypt avec salage
- **Backup automatique** : ZIP créé avant toute écriture critique
- **Validation inputs** : Protection SQL injection et XSS via module validators
- **Logging complet** : Journal d'activité en base de données et fichier

## 🔧 Notes techniques

### Compatibilité pandas 2.4+
L'application utilise un helper `style_map_compat()` pour gérer la transition de `Styler.applymap()` vers `Styler.map()` :
```python
def style_map_compat(df: pd.DataFrame, fn: Callable[[Any], str], subset: Any = None):
    """Helper de compatibilité pandas - applymap() vs map()"""
    styler = df.style
    if hasattr(styler, "map"):
        return styler.map(fn, subset=subset)  # Pandas 2.4+
    return getattr(styler, "applymap")(fn, subset=subset)  # Pandas < 2.4
```

### Environment virtuel (.venv)
- **Développement** : Utiliser exclusivement `.\.venv\Scripts\python.exe`
- **Isolation** : Toutes les dépendances dans `.venv/` pour éviter les conflits
- **Activation** : `.\.venv\Scripts\Activate.ps1` avant utilisation

## 🎯 Guide d'utilisation v4.1

### 👔 Pour les Superviseurs/Gestionnaires

#### Assignation par secteur (nouveau v4.1)
1. **Connexion gestionnaire** : Utilisez vos identifiants superviseur
2. **Onglet "🗺️ Assignation"** : Accédez au nouveau panneau d'assignation
3. **Sélection secteur et équipe** : Choisissez le secteur à assigner et l'équipe destinataire
4. **Assignation en bloc** : Cliquez "🎯 Assigner tout le secteur"
5. **Vérification** : Le tableau des assignations s'actualise automatiquement

#### Export CSV assignations (nouveau v4.1)
1. **Onglet "📥 Export"** : Accédez aux exports spécialisés v4.1
2. **Export CSV Assignations** : Téléchargez le fichier avec colonnes secteur, rue, équipe, statut
3. **Utilisation** : Parfait pour suivi externe ou import dans d'autres outils

### 🎅 Pour les Bénévoles

#### Interface "Mes rues" (nouveau v4.1)
1. **Connexion bénévole** : Connectez-vous avec votre nom d'équipe
2. **Onglet "🏘️ Mes rues"** : Vue filtrée de vos rues assignées uniquement
3. **Mise à jour statuts** : Cliquez "🚀 En cours" ou "✅ Terminée" pour chaque rue
4. **Ajout de notes** : Remplissez numéro civique + commentaire et cliquez "💾 Enregistrer note"
5. **Suivi progression** : Consultez vos métriques en temps réel

#### Gestion des notes par adresse (nouveau v4.1)
1. **Sélection rue** : Développez l'accordéon de la rue souhaitée
2. **Notes existantes** : Consultez les notes déjà saisies
3. **Nouvelle note** : Entrez le numéro civique (ex: 123A) et votre commentaire
4. **Types de notes** : Absent, refus, don reçu, situation particulière...
5. **Validation** : La note est automatiquement horodatée et associée à votre équipe

## 🎯 Fonctionnalités principales

### Pour les bénévoles
- 🗺️ **Carte interactive** avec leurs rues assignées uniquement
- ✅ **Système de validation** rue par rue avec notes
- 🏆 **Badges de progression** et encouragements
- � **Interface mobile** optimisée

### Pour les gestionnaires
- 📊 **Tableau de bord complet** avec KPIs temps réel
- �️ **Vue d'ensemble** de toutes les équipes
- 📈 **Graphiques de progression** par Plotly
- � **Centre d'export** avec formats multiples
- 👥 **Gestion des équipes** et assignation
  - Création encapsulée dans un formulaire (Enter ou bouton)
  - Correction d'un chevauchement de texte au-dessus du formulaire
- � **Notifications** d'activité

### Données et exports
- 📝 **Base de données SQLite** intégrée
- 📊 **Export Excel** avec formatage professionnel
- 📱 **Listes SMS** pour communication
- 📄 **Rapports PDF** avec mise en page professionnelle
source .venv/bin/activate

## 🗃️ Structure du projet

```
GuignoMap/
├── guignomap/
│   ├── app.py              # Application principale Streamlit
│   ├── db.py               # Gestion base de données
│   ├── osm.py              # Interface OpenStreetMap
│   ├── guigno_map.db       # Base de données SQLite
│   ├── osm_cache.json      # Cache des données OSM
│   ├── streets_mascouche.csv # Données des rues
│   └── assets/
│       ├── banner.png      # Bannière Guignolée
│       ├── logo.png        # Logo officiel
│       └── styles.css      # Styles personnalisés
├── requirements.txt        # Dépendances Python
└── README.md              # Documentation
```

## 🎄 Thème Guignolée 2025

L'application adopte une identité visuelle festive pour l'édition 2025 :
- **Couleurs** : Rouge festif (#dc3545), vert sapin, or
- **Typographie** : Poppins pour une lecture moderne
- **Icônes** : Thème de Noël et solidarité
- **Animations** : Compte à rebours dynamique vers Noël

## � Statistiques temps réel

Le système suit automatiquement :
- Progression globale de la collecte
- Performance par équipe et bénévole
- Couverture géographique
- Tendances et objectifs

## 🔐 Sécurité et accès

- **Authentification** par nom d'équipe
- **Restriction d'accès** : bénévoles limités à leurs rues
- **Données locales** : pas de transmission externe
- **Sauvegarde automatique** des progressions

## 🤝 Contribution

GuignoMap est développé pour la Guignolée de Mascouche. Pour toute suggestion ou amélioration, contactez l'équipe organisatrice.

---

**Joyeuses Fêtes et bonne Guignolée 2025 ! 🎄🎁**
2. **Consultez votre liste** de rues assignées
3. **Commencez une rue** :
   - Sélectionnez la rue dans la liste
   - Changez le statut de "À faire" à "En cours"
4. **Pendant la collecte** :
   - Ajoutez des notes pour les adresses spéciales
   - Ex: "145 - Famille absente, denrées déposées"
5. **Terminez la rue** :
   - Une fois la rue complète, changez le statut à "Terminée"
6. **Passez à la rue suivante**

### 🆘 Que faire si...

#### ❓ **Je ne vois pas mes rues**
- Vérifiez que vous êtes connecté comme bénévole
- Demandez au superviseur si des rues vous ont été assignées

#### ❓ **Je ne peux pas me connecter**
- Vérifiez votre code d'équipe et mot de passe
- Contactez le superviseur pour confirmation

#### ❓ **La carte ne s'affiche pas**
- Actualisez la page (F5)
- Le superviseur peut reconstruire les données dans l'onglet Tech

#### ❓ **Je veux voir toute la ville**
- Seuls les superviseurs voient toute la carte
- Les bénévoles ne voient que leurs rues assignées

### 💡 Conseils pratiques

#### Pour les **superviseurs** :
- Créez les équipes AVANT d'assigner des rues
- Assignez des secteurs logiques (ex: même quartier)
- Consultez régulièrement l'onglet "Vue d'ensemble" pour le suivi
- Exportez les données à la fin pour les rapports

#### Pour les **bénévoles** :
- Changez le statut dès que vous commencez une rue
- Ajoutez des notes pour les situations particulières
- N'oubliez pas de marquer "Terminée" quand c'est fini
- Utilisez l'auto-refresh pour voir les mises à jour des autres équipes

### 🎨 Interface rapide
- **Menu gauche** : Navigation principale
- **Carte centrale** : Vue géographique avec couleurs
- **Légende en bas à droite** : Explication des couleurs et statistiques
- **Auto-refresh** : Active le rafraîchissement automatique toutes les 15 secondes

## 🔐 Connexion

### Superviseur
- **Portail** : 🎯 Superviseur
- **Mot de passe** : `admin123`
- **Fonctions** : Gestion complète + opérations techniques

### Bénévoles
- **Portail** : 👥 Bénévole
- **Identifiants** : Créés par le superviseur

## 📁 Structure du projet

```
GuignoMap/
├── guignomap/
│   ├── app.py              # Application principale
│   ├── db.py               # Gestion base de données robuste
│   ├── osm.py              # Intégration OpenStreetMap + adresses
│   ├── guigno_map.db       # Base SQLite
│   ├── osm_cache.json      # Cache géométries
│   ├── osm_addresses.json  # Cache adresses OSM
│   └── assets/
│       ├── styles.css      # Styles personnalisés
│       ├── logo.png        # Logo du Relais
│       └── banner.png      # Bannière (optionnel)
├── .streamlit/
│   └── config.toml         # Configuration Streamlit
├── requirements.txt        # Dépendances Python
└── README.md              # Documentation
```

## 🛠️ Technologies

- **Frontend** : Streamlit + CSS personnalisé
- **Backend** : Python + SQLite avec gestion d'erreurs
- **Cartes** : Folium + OpenStreetMap + API Overpass
- **Données** : Pandas + Overpy avec validation robuste

## 📊 Fonctionnalités détaillées

### Pour les Superviseurs
- Vue d'ensemble avec carte complète de Mascouche
- Gestion des équipes avec création/suppression
- Assignation intelligente des rues
- Export des rapports (rues + notes)
- **Onglet Tech** protégé par PIN pour :
  - Reconstruction du cache géométrique OSM
  - Import/mise à jour des adresses depuis OSM
  - Gestion d'erreurs avancée avec fallback
- Visualisation complète : autoroutes, rues principales, voies privées
- Statistiques en temps réel avec compteurs dynamiques

### Pour les Bénévoles
- Interface dédiée à leur tournée assignée
- Ajout de notes par adresse civique
- Mise à jour du statut des rues (à faire → en cours → terminée)
- Consultation des notes existantes
- Carte centrée sur leur zone de travail
- Ajout de notes par adresse
- Mise à jour du statut des rues
- Suivi en temps réel
- Carte centrée automatiquement sur la zone de travail
- Interface fluide avec rechargement intelligent des données
- **Visibilité totale** des voies de collecte (y compris voies privées)

## 🎨 Thème visuel

Interface moderne aux couleurs du **Relais de Mascouche** :
- Rouge bordeaux (#8B0000)
- Or (#FFD700)
- Design responsive
- Animations fluides

### Légende de la carte améliorée
- 🟢 **Vert** : Rues terminées
- � **Orange** : Rues en cours
- 🔴 **Rouge** : Rues à faire
- **Lignes pleines** : Rues assignées à une équipe
- **Lignes pointillées** : Rues non assignées
- **Compteurs dynamiques** : Total, assignées, non assignées
- **Marqueur centre-ville** : Point de référence Mascouche

## 🚧 Développement

### Base de données renforcée
- Tables : `streets`, `teams`, `notes`, `activity_log`, `addresses`
- Import automatique depuis OpenStreetMap avec validation
- Gestion d'erreurs et création automatique des rues manquantes
- Données de test intégrées et fallback robuste

### Système OSM révolutionnaire v3.1
- **Couverture maximale** : TOUTES les voies nommées + autoroutes (ref)
- **Requête optimisée** : `highway+name OU highway+ref`
- **Cache multi-niveaux** : géométries + adresses OSM
- **Fallback étendu** : 19 voies principales de Mascouche
- **Gestion d'erreurs** : validation, retry, récupération automatique
- **Import adresses** : numéros civiques avec tri intelligent
- **Performance** : cache Streamlit sensible aux modifications

### Couverture des voies complète
- 🛣️ **Autoroutes** : A-25, A-640 (via ref)
- 🏘️ **Voies principales** : Montée Masson, Chemin Sainte-Marie
- 🚗 **Voies résidentielles** : toutes les rues nommées
- 🏠 **Voies d'accès** : service, private roads
- 🔚 **Impasses et allées** : couverture totale
- ✅ **Inclusions** : TOUT sauf limitation technique OSM

### Améliorations critiques v3.1
- **🐛 Fix create_map()** : Gestion robuste des colonnes DataFrame
- **🔧 Fix build_addresses_cache()** : Validation types et tri intelligent  
- **🛡️ Fix import_addresses_from_cache()** : Création automatique des rues
- **⚡ Fix list_streets()** : COALESCE pour éviter les NULL
- **🎯 UI améliorée** : Limites géographiques et zoom adaptatif
- **📊 Statistiques** : Compteurs en temps réel dans la légende

### Architecture technique
- **Frontend** : Streamlit avec gestion d'erreur globale
- **Géolocalisation** : API Overpass OSM avec requête universelle
- **Données** : SQLite + cache JSON double (géo + adresses)
- **Couverture** : Système d'inclusion universelle (name + ref)
- **Robustesse** : Fallback à tous les niveaux avec validation

## 📝 Changelog v3.3

### 🎄 Thème Guignolée festif
- **Header moderne** : Design spécial Guignolée 2025 avec dégradé rouge/vert
- **Animations** : Flocons de neige CSS pour ambiance festive
- **Branding** : "🎅 GUIGNOLÉE 2025 🎁" avec police Manrope
- **Stats temps réel** : Progression visible directement dans le header
- **Support logo** : Détection automatique du logo Guignolée

### 🖼️ Sidebar avec logo intégré
- **Logo professionnel** : Espace dédié 200px en haut de sidebar
- **Positionnement optimal** : Collé au bord supérieur sans espace vide
- **Fallback élégant** : Placeholder festif avec dégradé Guignolée si logo absent
- **Navigation moderne** : Boutons stylisés Accueil/Bénévole/Gestionnaire
- **Branding complet** : Cohérence visuelle avec header festif

### 🎨 Effets de connexion festifs
- **Connexion bénévole** : Effet neige (`st.snow()`) pour ambiance hivernale
- **Connexion gestionnaire** : Effet neige unifié pour cohérence thématique
- **Messages personnalisés** : Accueil par équipe avec design festif

## 📝 Changelog v3.2

### 🗺️ Améliorations cartographiques majeures
- **Fonds multiples** : OSM France (détaillé), CARTO Voyager (moderne), Esri WorldStreetMap (professionnel)
- **Sélecteur de couches** : Contrôle dynamique pour changer de fond à la volée
- **Zoom optimisé** : zoom_start=13 pour meilleur cadrage de Mascouche
- **Performances** : prefer_canvas=True pour rendu fluide + contrôles complets
- **Visibilité** : weight 7/5 et opacity 0.9/0.7 pour meilleure lisibilité
- **Navigation** : zoom_control et scrollWheelZoom activés

### 🎯 Interface utilisateur
- **Terminologie** : "Code" → "Identifiant", "Nom" → "Équipe" pour clarté
- **UX** : Amélioration compréhension des champs par les utilisateurs

## 📝 Changelog v3.1

### 🔧 Corrections critiques
- **create_map()** : Gestion robuste colonnes pandas + limites géographiques
- **build_addresses_cache()** : Tri numérique intelligent + gestion d'erreurs
- **import_addresses_from_cache()** : Validation + création automatique rues
- **list_streets()** : COALESCE pour colonnes NULL + structure garantie
- **Requête OSM** : Inclusion autoroutes via ref + couverture maximale

### ✨ Nouvelles fonctionnalités  
- **Carte centrée Mascouche** : Bounds géographiques + zoom adaptatif
- **Légende avancée** : Statistiques temps réel + compteurs dynamiques
- **Marqueur centre-ville** : Point de référence visuel
- **Fallback étendu** : 19 voies principales + autoroutes
- **Gestion d'erreurs** : Messages informatifs + récupération automatique

## 🔧 Dépannage

### Problèmes de légende
- **Légende invisible** : Appuyez sur F5 pour recharger complètement la page
- **Légende qui clignote** : Normal lors du changement de fond de carte
- **Position incorrecte** : La légende se repositionne automatiquement

### Problèmes de compatibilité Streamlit
- **Erreur use_container_width** : Version récente de Streamlit - l'application s'adapte automatiquement
- **Affichage dégradé** : Mise à jour recommandée vers Streamlit 1.28+
- **Contrôles manquants** : Vérifiez la version folium et streamlit-folium

### Problèmes de compatibilité pandas
- **Erreur "Cannot access attribute 'applymap'"** : Pandas 2.4+ retire applymap - l'application utilise un helper de compatibilité
- **Tables sans style** : Vérifiez la version pandas, le helper `style_map_compat()` gère automatiquement les versions
- **Couleurs manquantes** : Problème temporaire lors du changement de version pandas - redémarrez l'application

### Performance
- **Carte lente** : Réduisez le zoom ou changez de fond de carte
- **Mémoire élevée** : Rechargez l'application avec F5
- **Erreurs OSM** : Vérifiez la connexion internet

### Données
- **Rues manquantes** : Utilisez "Recharger depuis OSM" dans l'onglet Admin
- **Backup corrupt** : Les backups sont vérifiés à la création
- **Données perdues** : Consultez le dossier backups/ pour récupération

## 📝 Support

Développé pour **Le Relais de Mascouche** - Collecte de denrées 2025

---
*Version 3.4 - Interface sidebar complète avec logo intégré et effets festifs*

```
---8<--- README.md END ---

---8<--- README_VENV.md BEGIN ---
```md
# 🐍 GuignoMap - Instructions d'environnement virtuel

## 🎯 Avantages de l'environnement virtuel

✅ **Isolation des dépendances** : Évite les conflits entre projets  
✅ **Versions spécifiques** : Garantit la reproductibilité  
✅ **Facilité de déploiement** : Package complet et maîtrisé  

## 🚀 Utilisation

### Option 1 - Scripts automatiques (Recommandé)
```cmd
# Double-cliquez sur un de ces fichiers :
lancer_guignomap.bat          # Script Batch
lancer_guignomap.ps1          # Script PowerShell
```

### Option 2 - Activation manuelle
```cmd
# 1. Activer l'environnement virtuel
.venv\Scripts\activate

# 2. Lancer l'application
python -m streamlit run guignomap/app.py

# 3. Désactiver (optionnel)
deactivate
```

### Option 3 - PowerShell
```powershell
# 1. Activer l'environnement virtuel
.\.venv\Scripts\Activate.ps1

# 2. Lancer l'application
python -m streamlit run guignomap/app.py
```

## 🔧 Gestion des dépendances

### Installer de nouveaux packages
```cmd
# Avec l'environnement activé :
pip install nom_du_package

# Mettre à jour requirements.txt :
pip freeze > requirements.txt
```

### Recréer l'environnement
```cmd
# Supprimer l'ancien environnement
rmdir /s .venv

# Recréer
py -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

## 📊 Status actuel
- ✅ Environnement virtuel créé : `.venv/`
- ✅ Dépendances installées et testées
- ✅ Scripts de lancement mis à jour
- ✅ `.gitignore` configuré
```
---8<--- README_VENV.md END ---

---8<--- requirements.txt BEGIN ---
```txt
streamlit>=1.36.0
pandas>=2.2.0
folium==0.20.0
streamlit-folium>=0.21.0
overpy==0.7
bcrypt>=4.0.0
plotly>=5.18.0
xlsxwriter==3.2.8
reportlab==4.4.3

# Database - PostgreSQL
psycopg2-binary>=2.9.7
sqlalchemy==2.0.23
alembic==1.13.1

# Authentication - Argon2
passlib[argon2]==1.7.4

# Storage - S3/Cloud
boto3==1.34.144
```
---8<--- requirements.txt END ---

---8<--- scripts/export_repo_snapshot.py BEGIN ---
```py
# coding: utf-8
"""
Export complet du code GuignoMap → exports/export_full_YYYYMMDD_HHMMSS.txt
- UTF-8 (sans BOM), normalise les fins de lignes.
- Inclut le contenu des fichiers code/texte utiles.
- Exclut .git, .venv, caches, binaires, gros fichiers.
- Ne lit jamais .streamlit/secrets.toml (sécurité).
"""

from __future__ import annotations
import sys, os, io, time
from pathlib import Path
from datetime import datetime

ROOT = Path(__file__).resolve().parents[1]
OUTDIR = ROOT / "exports"
OUTDIR.mkdir(parents=True, exist_ok=True)
ts = datetime.now().strftime("%Y%m%d_%H%M%S")
OUTFILE = OUTDIR / f"export_full_{ts}.txt"

# Dossiers à exclure
EXCLUDE_DIRS = {
    ".git", ".github", ".venv", ".vscode", "__pycache__", ".mypy_cache", ".pytest_cache",
    "node_modules", "dist", "build", "storage_local", ".idea"
}

# Fichiers à exclure (par nom exact)
EXCLUDE_FILES = {
    "secrets.toml",  # ne jamais exposer des secrets
}

# Extensions à inclure (code/texte)
INCLUDE_EXTS = {
    ".py", ".txt", ".md", ".ps1", ".bat", ".toml", ".ini", ".cfg",
    ".yml", ".yaml", ".json", ".sql"
}

# Extensions à exclure d’office (binaires/pondéreux)
BINARY_EXTS = {
    ".db", ".sqlite", ".sqlite3", ".pkl", ".zip", ".7z", ".rar", ".exe", ".dll",
    ".png", ".jpg", ".jpeg", ".gif", ".ico", ".pdf", ".parquet"
}

# Taille max (Ko) par fichier pour éviter les énormes blobs
SIZE_LIMIT_KB = 300  # ajuste si besoin

def should_skip(path: Path) -> bool:
    # Exclure par dossier
    for part in path.parts:
        if part in EXCLUDE_DIRS:
            return True
    # Exclure par extension binaire
    if path.suffix.lower() in BINARY_EXTS:
        return True
    # Exclure fichier secrets explicites
    if path.name in EXCLUDE_FILES:
        return True
    # Filtre d’extensions
    if path.suffix and path.suffix.lower() not in INCLUDE_EXTS:
        return True
    # Limite de taille
    try:
        if path.stat().st_size > SIZE_LIMIT_KB * 1024:
            return True
    except Exception:
        return True
    return False

def read_text_safely(path: Path) -> str:
    # Toujours lire en UTF-8 avec remplacement pour éviter les caractères corrompus
    try:
        with open(path, "r", encoding="utf-8", errors="replace") as f:
            txt = f.read()
    except Exception as e:
        txt = f"<<ERREUR LECTURE {path}: {e}>>"
    # Normaliser fins de lignes
    return txt.replace("\r\n", "\n").replace("\r", "\n")

def main() -> int:
    files: list[Path] = []
    for p in ROOT.rglob("*"):
        if not p.is_file():
            continue
        if should_skip(p):
            continue
        files.append(p)

    files.sort(key=lambda x: str(x).lower())

    header = f"""# GuignoMap - Export de code COMPLET
# Date : {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
# Racine : {ROOT}
# Fichiers inclus : {len(files)}
# Encodage : UTF-8 (sans BOM)
# Règles : exclusions .git/.venv/binaires/gros fichiers, NO secrets.toml
"""

    with open(OUTFILE, "w", encoding="utf-8", newline="\n") as out:
        out.write(header + "\n")
        out.write("## INDEX\n")
        for p in files:
            rel = p.relative_to(ROOT)
            out.write(f"- {rel.as_posix()}\n")

        out.write("\n## CONTENU DES FICHIERS\n")
        for p in files:
            rel = p.relative_to(ROOT)
            out.write("\n")
            out.write(f"---8<--- {rel.as_posix()} BEGIN ---\n")
            out.write("```" + f"{p.suffix.lower().lstrip('.') or 'txt'}" + "\n")
            out.write(read_text_safely(p))
            out.write("\n```\n")
            out.write(f"---8<--- {rel.as_posix()} END ---\n")

        out.write("\n## STATISTIQUES\n")
        total_bytes = sum((p.stat().st_size for p in files), 0)
        out.write(f"- Total fichiers exportés : {len(files)}\n")
        out.write(f"- Poids cumulé (approx) : {total_bytes/1024:.1f} Ko\n")
        out.write(f"- Limite par fichier : {SIZE_LIMIT_KB} Ko\n")

    print(f"✅ Export écrit : {OUTFILE}")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

```
---8<--- scripts/export_repo_snapshot.py END ---

---8<--- scripts/fix_app_types.py BEGIN ---
```py
#!/usr/bin/env python3
"""
Script de migration automatique des types DataFrame vers List[Dict] dans app.py
Corrige les incompatibilités entre l'ancien db.py et le nouveau db_v5.py
"""

import re
from pathlib import Path

def fix_app_py():
    """Corrige automatiquement les incompatibilités de types dans app.py"""
    
    app_path = Path("guignomap/app.py")
    content = app_path.read_text(encoding='utf-8')
    
    # Corrections par regex
    corrections = [
        # 1. .empty sur listes -> len() == 0
        (r'if not (\w+)\.empty:', r'if \1:  # Liste non vide'),
        (r'if (\w+)\.empty:', r'if not \1:  # Liste vide'),
        
        # 2. .iterrows() -> enumerate() ou iteration directe
        (r'for _, (\w+) in (\w+)\.iterrows\(\):', r'for \1 in \2:'),
        (r'for (\w+), (\w+) in (\w+)\.iterrows\(\):', r'for \1, \2 in enumerate(\3):'),
        
        # 3. DataFrame['column'] -> list access pour unassigned
        (r"unassigned\['name'\]\.tolist\(\)", r"unassigned"),
        
        # 4. to_csv() sur listes -> DataFrame conversion
        (r'(\w+)\.to_csv\(([^)]+)\)', r'pd.DataFrame(\1).to_csv(\2)'),
        
        # 5. team_streets filtering (fonction get_team_streets retourne List[str])
        (r"team_streets\[team_streets\['status'\] == '(\w+)'\]", r"[s for s in team_streets if hasattr(s, 'status') and s.status == '\1']"),
        
        # 6. Accès par index sur dictionnaires (notes)
        (r"note\[(\d+)\]", r"list(note.values())[\1] if isinstance(note, dict) else note[\1]"),
    ]
    
    for pattern, replacement in corrections:
        content = re.sub(pattern, replacement, content)
    
    # Corrections manuelles spécifiques
    
    # Fix pour get_team_streets qui doit retourner les données complètes, pas juste les noms
    content = content.replace(
        'def get_team_streets(team_id: str) -> List[str]:',
        'def get_team_streets(team_id: str) -> List[Dict[str, Any]]:'
    )
    
    # Fix pour l'utilisation de team_streets dans l'interface équipe
    content = re.sub(
        r'if team_streets\.empty:',
        'if not team_streets:',
        content
    )
    
    content = re.sub(
        r'done_streets = len\(team_streets\[team_streets\[\'status\'\] == \'terminee\'\]\)',
        'done_streets = len([s for s in team_streets if isinstance(s, dict) and s.get("status") == "terminee"])',
        content
    )
    
    content = re.sub(
        r'in_progress = len\(team_streets\[team_streets\[\'status\'\] == \'en_cours\'\]\)',
        'in_progress = len([s for s in team_streets if isinstance(s, dict) and s.get("status") == "en_cours"])',
        content
    )
    
    # Fix pour l'iteration sur team_streets
    content = re.sub(
        r'for street in team_streets:',
        'for street in team_streets:\n            if isinstance(street, str):\n                street_name = street\n            else:\n                street_name = street.get("name", street)',
        content
    )
    
    # Fix pour les notes dans l'affichage
    content = re.sub(
        r'st\.markdown\(f"• \*\*#{note\[0\]}\*\* : {note\[1\]} _{note\[2\]}_"\)',
        'st.markdown(f"• **#{note.get(\'address_number\', \'?\')}** : {note.get(\'comment\', \'\')} _{note.get(\'created_at\', \'\')}_ ")',
        content
    )
    
    # Sauvegarder
    app_path.write_text(content, encoding='utf-8')
    print("✅ app.py corrigé automatiquement")

if __name__ == "__main__":
    fix_app_py()
```
---8<--- scripts/fix_app_types.py END ---

---8<--- scripts/fix_specific.py BEGIN ---
```py
#!/usr/bin/env python3
"""
Script de correction fine pour les types de retour dans app.py
"""

import re
from pathlib import Path

def fix_specific_issues():
    """Corrige les problèmes spécifiques identifiés"""
    
    app_path = Path("guignomap/app.py")
    content = app_path.read_text(encoding='utf-8')
    
    # 1. Revert les corrections sur DataFrames (list_streets retourne bien un DataFrame)
    content = re.sub(
        r'if df_all:  # Liste non vide',
        'if not df_all.empty:',
        content
    )
    
    content = re.sub(
        r'if not df_team:  # Liste vide',
        'if df_team.empty:',
        content
    )
    
    # 2. Fix team_streets access patterns
    content = re.sub(
        r'done_streets = len\(\[s for s in team_streets if hasattr\(s, \'status\'\) and s\.status == \'terminee\'\]\)',
        'done_streets = len([s for s in team_streets if s.get("status") == "terminee"])',
        content
    )
    
    content = re.sub(
        r'in_progress = len\(\[s for s in team_streets if hasattr\(s, \'status\'\) and s\.status == \'en_cours\'\]\)',
        'in_progress = len([s for s in team_streets if s.get("status") == "en_cours"])',
        content
    )
    
    # 3. Fix row access in iterrows (certains endroits ont encore des DataFrames)
    content = re.sub(
        r"for row in df_team:\s*street = row\['name'\]\s*status = row\['status'\]\s*notes_count = row\.get\('notes', 0\)",
        """for _, row in df_team.iterrows():
            street = row['name']
            status = row['status'] 
            notes_count = row.get('notes', 0)""",
        content, flags=re.MULTILINE
    )
    
    app_path.write_text(content, encoding='utf-8')
    print("✅ Corrections spécifiques appliquées")

if __name__ == "__main__":
    fix_specific_issues()
```
---8<--- scripts/fix_specific.py END ---

---8<--- scripts/migrate_password_hashes.py BEGIN ---
```py
"""
Script de migration des hashes de mots de passe bcrypt → Argon2
Migration paresseuse : les anciens hashes bcrypt sont migrés lors de la prochaine connexion
"""
import sys
import sqlite3
from pathlib import Path
from datetime import datetime

# Ajouter le répertoire parent au PYTHONPATH pour les imports
sys.path.append(str(Path(__file__).parent.parent))

from src.auth.passwords import get_password_hash_info, is_bcrypt_hash, is_argon2_hash


def get_sqlite_connection():
    """Connexion à la base SQLite existante"""
    sqlite_path = Path(__file__).parent.parent / "guignomap" / "guigno_map.db"
    if not sqlite_path.exists():
        print(f"❌ Base SQLite non trouvée: {sqlite_path}")
        return None
    
    conn = sqlite3.connect(str(sqlite_path))
    conn.row_factory = sqlite3.Row
    return conn


def analyze_password_hashes():
    """
    Analyse des hashes de mots de passe dans la base
    Identifie les équipes avec des hashes bcrypt qui nécessitent une migration
    """
    conn = get_sqlite_connection()
    if not conn:
        return
    
    try:
        print("🔍 Analyse des hashes de mots de passe...")
        print("=" * 50)
        
        # Récupérer toutes les équipes
        cursor = conn.execute("SELECT id, name, password_hash, created_at FROM teams ORDER BY id")
        teams = cursor.fetchall()
        
        if not teams:
            print("ℹ️ Aucune équipe trouvée dans la base")
            return
        
        bcrypt_count = 0
        argon2_count = 0
        unknown_count = 0
        
        print(f"{'Équipe':<15} {'Algorithme':<10} {'Statut':<20} {'Créé le'}")
        print("-" * 65)
        
        for team in teams:
            team_id = team['id']
            name = team['name']
            hash_value = team['password_hash']
            created_at = team['created_at']
            
            # Analyser le hash
            hash_info = get_password_hash_info(hash_value)
            algorithm = hash_info['algorithm']
            needs_update = hash_info['needs_update']
            
            if algorithm == 'bcrypt':
                bcrypt_count += 1
                status = "🔄 À migrer"
            elif algorithm == 'argon2':
                argon2_count += 1
                status = "✅ Moderne" if not needs_update else "🔄 À mettre à jour"
            else:
                unknown_count += 1
                status = "❓ Inconnu"
            
            print(f"{team_id:<15} {algorithm:<10} {status:<20} {created_at or 'N/A'}")
        
        print("-" * 65)
        print(f"\n📊 Résumé de l'analyse:")
        print(f"   • Hashes bcrypt (à migrer) : {bcrypt_count}")
        print(f"   • Hashes Argon2 (modernes) : {argon2_count}")
        print(f"   • Hashes inconnus          : {unknown_count}")
        print(f"   • Total équipes            : {len(teams)}")
        
        if bcrypt_count > 0:
            print(f"\n💡 Migration nécessaire:")
            print(f"   Les {bcrypt_count} équipe(s) avec bcrypt seront automatiquement")
            print(f"   migrées vers Argon2 lors de leur prochaine connexion réussie.")
            print(f"   Aucune action manuelle n'est requise.")
        else:
            print(f"\n🎉 Toutes les équipes utilisent déjà Argon2 !")
        
    except Exception as e:
        print(f"❌ Erreur lors de l'analyse: {e}")
    finally:
        conn.close()


def generate_migration_report():
    """
    Génère un rapport détaillé de migration
    """
    conn = get_sqlite_connection()
    if not conn:
        return
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = Path(__file__).parent.parent / f"password_migration_report_{timestamp}.txt"
    
    try:
        with open(report_path, 'w', encoding='utf-8') as report:
            report.write(f"Rapport de migration des mots de passe - {datetime.now()}\n")
            report.write("=" * 70 + "\n\n")
            
            # Récupérer toutes les équipes
            cursor = conn.execute("SELECT id, name, password_hash, created_at FROM teams ORDER BY id")
            teams = cursor.fetchall()
            
            teams_to_migrate = []
            
            for team in teams:
                team_id = team['id']
                name = team['name']
                hash_value = team['password_hash']
                created_at = team['created_at']
                
                hash_info = get_password_hash_info(hash_value)
                
                report.write(f"Équipe: {team_id} ({name})\n")
                report.write(f"  Créée: {created_at or 'Date inconnue'}\n")
                report.write(f"  Algorithme: {hash_info['algorithm']}\n")
                report.write(f"  Nécessite mise à jour: {hash_info['needs_update']}\n")
                
                if 'passlib_scheme' in hash_info:
                    report.write(f"  Schéma passlib: {hash_info['passlib_scheme']}\n")
                
                if hash_info['algorithm'] == 'bcrypt':
                    teams_to_migrate.append(team_id)
                    report.write(f"  🔄 MIGRATION REQUISE lors de la prochaine connexion\n")
                elif hash_info['algorithm'] == 'argon2':
                    report.write(f"  ✅ Hash moderne\n")
                else:
                    report.write(f"  ⚠️ Hash de type inconnu\n")
                
                report.write("\n")
            
            report.write(f"RÉSUMÉ DE MIGRATION\n")
            report.write("=" * 30 + "\n")
            report.write(f"Équipes à migrer: {len(teams_to_migrate)}\n")
            if teams_to_migrate:
                report.write(f"IDs concernés: {', '.join(teams_to_migrate)}\n")
            report.write(f"Total équipes: {len(teams)}\n\n")
            
            report.write("PROCÉDURE DE MIGRATION\n")
            report.write("=" * 30 + "\n")
            report.write("1. La migration est automatique et transparente\n")
            report.write("2. Elle se déclenche lors de la prochaine connexion réussie\n")
            report.write("3. L'ancien hash bcrypt est remplacé par un nouveau hash Argon2\n")
            report.write("4. Le mot de passe de l'utilisateur reste inchangé\n")
            report.write("5. Aucune action manuelle n'est requise\n\n")
            
            report.write("POLITIQUE DE MOT DE PASSE\n")
            report.write("=" * 30 + "\n")
            report.write("• Minimum 4 caractères (politique UI v4.1 conservée)\n")
            report.write("• Confirmation requise lors de la création (UI)\n")
            report.write("• Algorithme Argon2 pour nouveaux comptes\n")
            report.write("• Compatibilité bcrypt maintenue\n")
        
        print(f"📄 Rapport généré: {report_path}")
        
    except Exception as e:
        print(f"❌ Erreur génération rapport: {e}")
    finally:
        conn.close()


def test_migration_functions():
    """
    Test des fonctions de migration avec des données d'exemple
    """
    print("🧪 Test des fonctions de migration...")
    
    try:
        from src.auth.passwords import create_test_hashes, verify_password, migrate_password_if_needed
        
        # Créer des hashes de test
        test_password = "test123"
        hashes = create_test_hashes(test_password)
        
        print(f"\n🔑 Mot de passe de test: {test_password}")
        print(f"Hash Argon2: {hashes['argon2'][:50]}...")
        print(f"Hash bcrypt: {hashes['bcrypt_legacy'][:50]}...")
        
        # Tester la vérification
        print(f"\n✅ Tests de vérification:")
        
        # Test Argon2
        ok, needs_rehash = verify_password(test_password, hashes['argon2'])
        print(f"Argon2: OK={ok}, Rehash={needs_rehash}")
        
        # Test bcrypt
        ok, needs_rehash = verify_password(test_password, hashes['bcrypt_legacy'])
        print(f"bcrypt: OK={ok}, Rehash={needs_rehash}")
        
        # Test migration
        print(f"\n🔄 Test de migration:")
        migrated, new_hash = migrate_password_if_needed(test_password, hashes['bcrypt_legacy'])
        print(f"Migration effectuée: {migrated}")
        if migrated:
            print(f"Nouveau hash: {new_hash[:50]}...")
        
        print(f"✅ Tests terminés avec succès")
        
    except Exception as e:
        print(f"❌ Erreur durant les tests: {e}")


def main():
    """Point d'entrée principal du script"""
    print("🔐 Script de migration des mots de passe GuignoMap v5.0")
    print("bcrypt → Argon2 avec migration paresseuse")
    print("=" * 60)
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "analyze":
            analyze_password_hashes()
        elif command == "report":
            generate_migration_report()
        elif command == "test":
            test_migration_functions()
        else:
            print(f"❌ Commande inconnue: {command}")
            print_usage()
    else:
        # Par défaut, faire l'analyse
        analyze_password_hashes()


def print_usage():
    """Affiche l'aide d'utilisation"""
    print("\nUtilisation:")
    print("  python scripts/migrate_password_hashes.py [commande]")
    print("\nCommandes disponibles:")
    print("  analyze  - Analyser les hashes actuels (défaut)")
    print("  report   - Générer un rapport détaillé")
    print("  test     - Tester les fonctions de migration")
    print("\nExemples:")
    print("  python scripts/migrate_password_hashes.py analyze")
    print("  python scripts/migrate_password_hashes.py report")


if __name__ == "__main__":
    main()
```
---8<--- scripts/migrate_password_hashes.py END ---

---8<--- scripts/migrate_sqlite_to_postgres.py BEGIN ---
```py
"""
Script de migration SQLite → PostgreSQL pour GuignoMap v5.0
Copie toutes les données existantes de SQLite vers PostgreSQL
"""
import sqlite3
import sys
import os
from pathlib import Path

# Ajouter le répertoire parent au PYTHONPATH pour les imports
sys.path.append(str(Path(__file__).parent.parent))

from src.database.connection import get_engine, execute_transaction
from src.database.models import Base, Street, Team, Note, ActivityLog, Address
from sqlalchemy.orm import sessionmaker
from datetime import datetime
import pandas as pd


def get_sqlite_connection():
    """Connexion en lecture seule à la base SQLite existante"""
    sqlite_path = Path(__file__).parent.parent / "guignomap" / "guigno_map.db"
    if not sqlite_path.exists():
        print(f"❌ Base SQLite non trouvée: {sqlite_path}")
        return None
    
    conn = sqlite3.connect(str(sqlite_path))
    conn.row_factory = sqlite3.Row
    return conn


def create_postgres_tables():
    """Créer les tables PostgreSQL via Alembic/SQLAlchemy"""
    try:
        engine = get_engine()
        Base.metadata.create_all(engine)
        print("✅ Tables PostgreSQL créées")
        return True
    except Exception as e:
        print(f"❌ Erreur création tables PostgreSQL: {e}")
        return False


def copy_teams(sqlite_conn, postgres_session):
    """Copier les équipes SQLite → PostgreSQL"""
    try:
        # Lire depuis SQLite
        teams_data = pd.read_sql_query("""
            SELECT id, name, password_hash, created_at, active 
            FROM teams 
            ORDER BY created_at
        """, sqlite_conn)
        
        if teams_data.empty:
            print("ℹ️ Aucune équipe à migrer")
            return 0
        
        # Insérer dans PostgreSQL
        count = 0
        for _, row in teams_data.iterrows():
            team = Team(
                id=row['id'],
                name=row['name'],
                password_hash=row['password_hash'],
                created_at=pd.to_datetime(row['created_at']) if row['created_at'] else datetime.utcnow(),
                active=bool(row['active'])
            )
            postgres_session.merge(team)  # merge pour éviter les doublons
            count += 1
        
        postgres_session.commit()
        print(f"✅ {count} équipes migrées")
        return count
        
    except Exception as e:
        postgres_session.rollback()
        print(f"❌ Erreur migration équipes: {e}")
        return 0


def copy_streets(sqlite_conn, postgres_session):
    """Copier les rues SQLite → PostgreSQL"""
    try:
        # Lire depuis SQLite
        streets_data = pd.read_sql_query("""
            SELECT id, name, sector, team, status 
            FROM streets 
            ORDER BY id
        """, sqlite_conn)
        
        if streets_data.empty:
            print("ℹ️ Aucune rue à migrer")
            return 0
        
        # Insérer dans PostgreSQL
        count = 0
        for _, row in streets_data.iterrows():
            street = Street(
                id=row['id'] if row['id'] else None,
                name=row['name'],
                sector=row['sector'],
                team=row['team'],
                status=row['status'] or 'a_faire'
            )
            postgres_session.merge(street)
            count += 1
        
        postgres_session.commit()
        print(f"✅ {count} rues migrées")
        return count
        
    except Exception as e:
        postgres_session.rollback()
        print(f"❌ Erreur migration rues: {e}")
        return 0


def copy_notes(sqlite_conn, postgres_session):
    """Copier les notes SQLite → PostgreSQL"""
    try:
        # Lire depuis SQLite
        notes_data = pd.read_sql_query("""
            SELECT id, street_name, team_id, address_number, comment, created_at 
            FROM notes 
            ORDER BY created_at
        """, sqlite_conn)
        
        if notes_data.empty:
            print("ℹ️ Aucune note à migrer")
            return 0
        
        # Insérer dans PostgreSQL
        count = 0
        for _, row in notes_data.iterrows():
            note = Note(
                id=row['id'] if row['id'] else None,
                street_name=row['street_name'],
                team_id=row['team_id'],
                address_number=row['address_number'],
                comment=row['comment'],
                created_at=pd.to_datetime(row['created_at']) if row['created_at'] else datetime.utcnow()
            )
            postgres_session.merge(note)
            count += 1
        
        postgres_session.commit()
        print(f"✅ {count} notes migrées")
        return count
        
    except Exception as e:
        postgres_session.rollback()
        print(f"❌ Erreur migration notes: {e}")
        return 0


def copy_activity_logs(sqlite_conn, postgres_session):
    """Copier les logs d'activité SQLite → PostgreSQL"""
    try:
        # Vérifier si la table existe
        cursor = sqlite_conn.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='activity_log'
        """)
        if not cursor.fetchone():
            print("ℹ️ Table activity_log non présente dans SQLite")
            return 0
        
        # Lire depuis SQLite
        logs_data = pd.read_sql_query("""
            SELECT id, team_id, action, details, created_at 
            FROM activity_log 
            ORDER BY created_at
        """, sqlite_conn)
        
        if logs_data.empty:
            print("ℹ️ Aucun log d'activité à migrer")
            return 0
        
        # Insérer dans PostgreSQL
        count = 0
        for _, row in logs_data.iterrows():
            log = ActivityLog(
                id=row['id'] if row['id'] else None,
                team_id=row['team_id'],
                action=row['action'],
                details=row['details'],
                created_at=pd.to_datetime(row['created_at']) if row['created_at'] else datetime.utcnow()
            )
            postgres_session.merge(log)
            count += 1
        
        postgres_session.commit()
        print(f"✅ {count} logs d'activité migrés")
        return count
        
    except Exception as e:
        postgres_session.rollback()
        print(f"❌ Erreur migration logs: {e}")
        return 0


def copy_addresses(sqlite_conn, postgres_session):
    """Copier les adresses OSM SQLite → PostgreSQL"""
    try:
        # Vérifier si la table existe
        cursor = sqlite_conn.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='addresses'
        """)
        if not cursor.fetchone():
            print("ℹ️ Table addresses non présente dans SQLite")
            return 0
        
        # Lire depuis SQLite
        addresses_data = pd.read_sql_query("""
            SELECT id, street_name, house_number, latitude, longitude, osm_type, created_at 
            FROM addresses 
            ORDER BY created_at
        """, sqlite_conn)
        
        if addresses_data.empty:
            print("ℹ️ Aucune adresse à migrer")
            return 0
        
        # Insérer dans PostgreSQL
        count = 0
        for _, row in addresses_data.iterrows():
            address = Address(
                id=row['id'] if row['id'] else None,
                street_name=row['street_name'],
                house_number=row['house_number'],
                latitude=row['latitude'],
                longitude=row['longitude'],
                osm_type=row['osm_type'],
                created_at=pd.to_datetime(row['created_at']) if row['created_at'] else datetime.utcnow()
            )
            postgres_session.merge(address)
            count += 1
        
        postgres_session.commit()
        print(f"✅ {count} adresses migrées")
        return count
        
    except Exception as e:
        postgres_session.rollback()
        print(f"❌ Erreur migration adresses: {e}")
        return 0


def main():
    """Migration complète SQLite → PostgreSQL"""
    print("🔄 Début migration SQLite → PostgreSQL...")
    
    # Connexions
    sqlite_conn = get_sqlite_connection()
    if not sqlite_conn:
        return False
    
    try:
        # Créer les tables PostgreSQL
        if not create_postgres_tables():
            return False
        
        # Session PostgreSQL
        engine = get_engine()
        Session = sessionmaker(bind=engine)
        postgres_session = Session()
        
        # Migration par table
        total_migrated = 0
        total_migrated += copy_teams(sqlite_conn, postgres_session)
        total_migrated += copy_streets(sqlite_conn, postgres_session)
        total_migrated += copy_notes(sqlite_conn, postgres_session)
        total_migrated += copy_activity_logs(sqlite_conn, postgres_session)
        total_migrated += copy_addresses(sqlite_conn, postgres_session)
        
        postgres_session.close()
        sqlite_conn.close()
        
        print(f"🎉 Migration terminée ! {total_migrated} enregistrements migrés")
        return True
        
    except Exception as e:
        print(f"❌ Erreur générale migration: {e}")
        if 'postgres_session' in locals():
            postgres_session.close()
        sqlite_conn.close()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
```
---8<--- scripts/migrate_sqlite_to_postgres.py END ---

---8<--- scripts/validation_dataframe.ps1 BEGIN ---
```ps1
# =============================================================================
# SCRIPTS POWERSHELL - VALIDATION DATAFRAME
# =============================================================================

Write-Host "🔍 AUDIT DATAFRAME - SCRIPTS DE VALIDATION" -ForegroundColor Green
Write-Host "=========================================" -ForegroundColor Green

Write-Host "`n1️⃣ PATTERNS DATAFRAME PROBLÉMATIQUES" -ForegroundColor Yellow
Write-Host "Recherche: .columns, .iterrows, .empty, .loc[], .iloc[]" -ForegroundColor Gray
Select-String -Path .\guignomap\app.py -Pattern '\.columns|\.iterrows|\.empty|\.loc\[|\.iloc\[' -CaseSensitive | 
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`n2️⃣ ASSIGNATIONS DE FONCTIONS DB" -ForegroundColor Yellow  
Write-Host "Recherche: variables = db.fonction()" -ForegroundColor Gray
Select-String -Path .\guignomap\app.py -Pattern '\s*\w+\s*=\s*db\.\w+\(' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`n3️⃣ UTILISATION ST.DATAFRAME" -ForegroundColor Yellow
Write-Host "Recherche: st.dataframe() pour vérifier les types" -ForegroundColor Gray  
Select-String -Path .\guignomap\app.py -Pattern 'st\.dataframe\(' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`n4️⃣ FONCTIONS DB QUI RETOURNENT DES DONNÉES" -ForegroundColor Yellow
Write-Host "Recherche: Fonctions db_v5 qui peuvent retourner listes vs DataFrames" -ForegroundColor Gray
Select-String -Path .\guignomap\db_v5.py -Pattern 'def (list_|get_|stats_|teams|recent_)' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`n5️⃣ IMPORTS PANDAS DANS APP.PY" -ForegroundColor Yellow  
Write-Host "Recherche: import pandas et pd.DataFrame" -ForegroundColor Gray
Select-String -Path .\guignomap\app.py -Pattern 'import pandas|pd\.DataFrame' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`n✅ RAPPORT COMPLET GÉNÉRÉ DANS: AUDIT_DATAFRAME.md" -ForegroundColor Green
```
---8<--- scripts/validation_dataframe.ps1 END ---

---8<--- src/auth/passwords.py BEGIN ---
```py
"""
Gestion des mots de passe avec Argon2 pour GuignoMap v5.0
Migration compatible depuis bcrypt + politique UI inchangée (min 4 + confirmation)
"""
from passlib.context import CryptContext
from typing import Tuple
import bcrypt


# Configuration passlib avec Argon2 comme algorithme principal
# Garde bcrypt pour la compatibilité ascendante (lecture uniquement)
pwd_context = CryptContext(
    schemes=["argon2", "bcrypt"],
    deprecated="auto",  # Marque bcrypt comme obsolète
    argon2__rounds=2,   # Paramètres Argon2 pour performance/sécurité équilibrée
    argon2__memory_cost=65536,  # 64 MB
    argon2__parallelism=1,
    argon2__hash_len=32
)


def hash_password(password: str) -> str:
    """
    Hash un mot de passe avec Argon2
    
    Args:
        password: Mot de passe en texte clair
        
    Returns:
        Hash Argon2 du mot de passe
    """
    return pwd_context.hash(password)


def verify_password(password: str, hashed: str) -> Tuple[bool, bool]:
    """
    Vérifie un mot de passe contre son hash
    Supporte la migration automatique bcrypt → Argon2
    
    Args:
        password: Mot de passe en texte clair
        hashed: Hash stocké (bcrypt ou Argon2)
        
    Returns:
        Tuple (verification_ok, needs_rehash)
        - verification_ok: True si le mot de passe est correct
        - needs_rehash: True si le hash doit être mis à jour (migration paresseuse)
    """
    try:
        # Vérification avec passlib (supporte bcrypt et Argon2)
        verification_ok = pwd_context.verify(password, hashed)
        
        if verification_ok:
            # Vérifier si une mise à jour du hash est nécessaire
            needs_rehash = pwd_context.needs_update(hashed)
            return True, needs_rehash
        else:
            return False, False
            
    except Exception as e:
        print(f"Erreur vérification mot de passe: {e}")
        return False, False


def is_bcrypt_hash(hashed: str) -> bool:
    """
    Détermine si un hash est au format bcrypt
    
    Args:
        hashed: Hash à vérifier
        
    Returns:
        True si c'est un hash bcrypt
    """
    return hashed.startswith('$2b$') or hashed.startswith('$2a$') or hashed.startswith('$2y$')


def is_argon2_hash(hashed: str) -> bool:
    """
    Détermine si un hash est au format Argon2
    
    Args:
        hashed: Hash à vérifier
        
    Returns:
        True si c'est un hash Argon2
    """
    return hashed.startswith('$argon2')


def migrate_password_if_needed(password: str, old_hash: str) -> Tuple[bool, str]:
    """
    Migration paresseuse d'un mot de passe bcrypt vers Argon2
    Appelé lors d'une connexion réussie
    
    Args:
        password: Mot de passe en texte clair (fourni lors de la connexion)
        old_hash: Hash actuel stocké
        
    Returns:
        Tuple (migrated, new_hash)
        - migrated: True si une migration a eu lieu
        - new_hash: Nouveau hash Argon2 (ou old_hash si pas de migration)
    """
    verification_ok, needs_rehash = verify_password(password, old_hash)
    
    if verification_ok and needs_rehash:
        # Migration nécessaire : re-hasher avec Argon2
        new_hash = hash_password(password)
        print(f"🔄 Migration hash bcrypt → Argon2")
        return True, new_hash
    
    return False, old_hash


def validate_password_policy(password: str) -> Tuple[bool, str]:
    """
    Validation de la politique de mot de passe
    IMPORTANT: Garder la politique UI v4.1 (min 4 caractères + confirmation)
    
    Args:
        password: Mot de passe à valider
        
    Returns:
        Tuple (valid, error_message)
    """
    if not password:
        return False, "Le mot de passe est requis"
    
    if len(password) < 4:
        return False, "Le mot de passe doit contenir au moins 4 caractères"
    
    # Note: La confirmation est gérée côté UI, pas ici
    return True, ""


def get_password_hash_info(hashed: str) -> dict:
    """
    Informations sur un hash de mot de passe
    Utile pour diagnostics et migration
    
    Args:
        hashed: Hash à analyser
        
    Returns:
        Dictionnaire avec les informations du hash
    """
    info = {
        'algorithm': 'unknown',
        'needs_update': False,
        'is_bcrypt': is_bcrypt_hash(hashed),
        'is_argon2': is_argon2_hash(hashed)
    }
    
    try:
        if is_bcrypt_hash(hashed):
            info['algorithm'] = 'bcrypt'
            info['needs_update'] = True  # Tous les bcrypt doivent migrer
        elif is_argon2_hash(hashed):
            info['algorithm'] = 'argon2'
            info['needs_update'] = pwd_context.needs_update(hashed)
        
        # Informations supplémentaires via passlib
        hash_info = pwd_context.identify(hashed)
        if hash_info:
            info['passlib_scheme'] = hash_info
            
    except Exception as e:
        info['error'] = str(e)
    
    return info


# Fonctions de compatibilité avec l'ancien système bcrypt
def legacy_verify_bcrypt(password: str, bcrypt_hash: str) -> bool:
    """
    Vérification directe bcrypt pour rétrocompatibilité
    Utilisé uniquement si passlib échoue
    
    Args:
        password: Mot de passe en texte clair
        bcrypt_hash: Hash bcrypt à vérifier
        
    Returns:
        True si le mot de passe correspond
    """
    try:
        return bcrypt.checkpw(password.encode('utf-8'), bcrypt_hash.encode('utf-8'))
    except Exception as e:
        print(f"Erreur vérification bcrypt legacy: {e}")
        return False


def create_test_hashes(password: str = "test123") -> dict:
    """
    Utilitaire pour créer des hashes de test
    Aide au développement et aux tests
    
    Args:
        password: Mot de passe de test
        
    Returns:
        Dictionnaire avec les différents hashes
    """
    return {
        'password': password,
        'argon2': hash_password(password),
        'bcrypt_legacy': bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
    }
```
---8<--- src/auth/passwords.py END ---

---8<--- src/config.py BEGIN ---
```py
"""
Configuration centralisée pour GuignoMap v5.0
Accès aux secrets Streamlit et paramètres applicatifs
"""
import streamlit as st
import os


def get_database_url():
    """Récupère l'URL de la base de données depuis les secrets"""
    try:
        return st.secrets["database"]["url"]
    except (KeyError, AttributeError):
        # Fallback pour développement local ou tests
        return os.getenv("DATABASE_URL", "sqlite:///guigno_map.db")


def get_database_pool_config():
    """Configuration du pool de connexions PostgreSQL"""
    try:
        return {
            "pool_size": st.secrets["database"].get("pool_size", 5),
            "max_overflow": st.secrets["database"].get("max_overflow", 10)
        }
    except (KeyError, AttributeError):
        return {"pool_size": 5, "max_overflow": 10}


def get_s3_config():
    """Configuration S3 pour le stockage cloud"""
    try:
        return {
            "bucket": st.secrets["storage"]["s3_bucket"],
            "region": st.secrets["storage"]["s3_region"],
            "access_key": st.secrets["storage"]["s3_access_key"],
            "secret_key": st.secrets["storage"]["s3_secret_key"]
        }
    except (KeyError, AttributeError):
        return {
            "bucket": os.getenv("S3_BUCKET", "guignomap-dev"),
            "region": os.getenv("S3_REGION", "us-east-1"),
            "access_key": os.getenv("S3_ACCESS_KEY", ""),
            "secret_key": os.getenv("S3_SECRET_KEY", "")
        }


def get_cdn_base_url():
    """URL de base CDN pour les assets (optionnel)"""
    try:
        return st.secrets["storage"].get("cdn_base_url", "")
    except (KeyError, AttributeError):
        return os.getenv("CDN_BASE_URL", "")
```
---8<--- src/config.py END ---

---8<--- src/database/connection.py BEGIN ---
```py
"""
Connexion PostgreSQL avec SQLAlchemy pour GuignoMap v5.0
Engine + QueuePool + cache Streamlit + retry logic
"""
import time
import functools
import streamlit as st
from sqlalchemy import create_engine, text
from sqlalchemy.pool import QueuePool
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import SQLAlchemyError
from src.config import get_database_url, get_database_pool_config


def db_retry(max_retries=3, backoff_factor=1):
    """
    Décorateur retry exponentiel pour opérations DB critiques
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except SQLAlchemyError as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        wait_time = backoff_factor * (2 ** attempt)
                        print(f"Retry DB operation {func.__name__} in {wait_time}s (attempt {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                    else:
                        print(f"Max retries reached for {func.__name__}")
                        break
            raise last_exception
        return wrapper
    return decorator


@st.cache_resource
def get_engine():
    """
    Engine PostgreSQL avec cache Streamlit et configuration pool
    Conformément au plan v5.0
    """
    database_url = get_database_url()
    pool_config = get_database_pool_config()
    
    # Configuration PostgreSQL avec QueuePool
    engine = create_engine(
        database_url,
        poolclass=QueuePool,
        pool_size=pool_config["pool_size"],
        max_overflow=pool_config["max_overflow"],
        pool_pre_ping=True,
        pool_recycle=300,
        echo=False  # Set to True for SQL debugging
    )
    
    return engine


def get_session():
    """Fabrique de session SQLAlchemy"""
    engine = get_engine()
    Session = sessionmaker(bind=engine)
    return Session()


@db_retry(max_retries=3)
def test_connection():
    """Test de connexion à la base PostgreSQL"""
    try:
        engine = get_engine()
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1 as test"))
            return result.fetchone()[0] == 1
    except Exception as e:
        print(f"Erreur test connexion DB: {e}")
        return False


@db_retry(max_retries=3)
def execute_query(query, params=None):
    """
    Exécution de requête avec retry automatique
    Pour transition progressive vers SQLAlchemy
    """
    engine = get_engine()
    with engine.connect() as conn:
        if params:
            return conn.execute(text(query), params)
        else:
            return conn.execute(text(query))


@db_retry(max_retries=3)  
def execute_transaction(queries_and_params):
    """
    Exécution de transaction multi-requêtes avec retry
    queries_and_params: liste de tuples (query, params)
    """
    engine = get_engine()
    with engine.begin() as conn:
        results = []
        for query, params in queries_and_params:
            if params:
                result = conn.execute(text(query), params)
            else:
                result = conn.execute(text(query))
            results.append(result)
        return results
```
---8<--- src/database/connection.py END ---

---8<--- src/database/db_v5.py BEGIN ---
```py
"""
GuignoMap v5.0 - Database operation            admin_exists = session.execute(
                text("SELECT COUNT(*) FROM teams WHERE id = 'ADMIN'")
            ).scalar() or 0
            
            if admin_exists > 0:h SQLAlchemy
Migration from raw sqlite3 to SQLAlchemy + PostgreSQL support
"""
import os
import pandas as pd
import hashlib
import bcrypt
from datetime import datetime
import json
from pathlib import Path
import secrets
import string
from typing import Optional, List, Dict, Any

from sqlalchemy import text, and_, or_
from src.database.connection import get_session, db_retry
from src.database.models import Street, Team, Note, ActivityLog, Address
from backup import auto_backup_before_critical, BackupManager
from validators import validate_and_clean_input, InputValidator


# =============================================================================
# CONFIGURATION & CONSTANTES
# =============================================================================

# Schéma de migration - utilisé pour vérifier les tables existantes
REQUIRED_TABLES = ['streets', 'teams', 'notes', 'activity_log', 'addresses']


# =============================================================================
# FONCTIONS DE CONNEXION ET INITIALISATION
# =============================================================================

@db_retry(max_retries=3)
def init_db():
    """Initialise la base de données avec les données initiales"""
    try:
        with get_session() as session:
            # Vérifier si admin existe
            admin_exists = session.execute(
                text("SELECT COUNT(*) FROM teams WHERE id = 'ADMIN'")
            ).scalar()
            
            if admin_exists == 0:
                pwd = os.getenv("GM_ADMIN_PWD", "RELAIS2025")
                create_team('ADMIN', 'Superviseur', pwd)
            
            # Auto-import des rues si vide
            streets_count = session.execute(
                text("SELECT COUNT(*) FROM streets")
            ).scalar()
            
            if streets_count == 0:
                print("🔄 Aucune rue trouvée. Import automatique depuis OpenStreetMap...")
                auto_import_streets()
                
    except Exception as e:
        print(f"❌ Erreur init_db: {e}")
        raise


def auto_import_streets():
    """Import automatique des rues depuis OSM cache"""
    try:
        from osm import load_geometry_cache
        
        with get_session() as session:
            cache = load_geometry_cache()
            if not cache:
                print("⚠️ Aucun cache OSM trouvé. Utilisez 'Construire carte' dans l'admin.")
                return
            
            imported = 0
            for street_name in cache.keys():
                if street_name and street_name.strip():
                    # Vérifier si existe déjà
                    exists = session.execute(
                        text("SELECT COUNT(*) FROM streets WHERE name = :name"),
                        {"name": street_name.strip()}
                    ).scalar()
                    
                    if exists == 0:
                        session.execute(text("""
                            INSERT INTO streets (name, status) 
                            VALUES (:name, 'a_faire')
                        """), {"name": street_name.strip()})
                        imported += 1
            
            session.commit()
            print(f"✅ {imported} rues importées depuis OSM")
            
    except Exception as e:
        print(f"❌ Erreur auto_import_streets: {e}")


# =============================================================================
# GESTION DES ÉQUIPES ET AUTHENTIFICATION
# =============================================================================

def hash_password(password: str) -> str:
    """Hash un mot de passe avec bcrypt"""
    return bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')


@db_retry(max_retries=2)
def create_team(team_id: str, name: str, password: str) -> bool:
    """Crée une nouvelle équipe"""
    try:
        with get_session() as session:
            # Vérifier si l'équipe existe déjà
            exists = session.execute(
                text("SELECT COUNT(*) FROM teams WHERE id = :id"),
                {"id": team_id}
            ).scalar() or 0
            
            if exists > 0:
                return False
            
            password_hash = hash_password(password)
            session.execute(text("""
                INSERT INTO teams (id, name, password_hash, created_at, active)
                VALUES (:id, :name, :hash, CURRENT_TIMESTAMP, 1)
            """), {
                "id": team_id,
                "name": name, 
                "hash": password_hash
            })
            session.commit()
            
            # Log de l'activité
            log_activity(session, team_id, 'create_team', f"Équipe '{name}' créée")
            
            return True
            
    except Exception as e:
        print(f"❌ Erreur create_team: {e}")
        return False


@db_retry(max_retries=2)
def verify_team(team_id: str, password: str) -> bool:
    """Vérifie les identifiants d'une équipe"""
    try:
        with get_session() as session:
            result = session.execute(
                text("SELECT password_hash FROM teams WHERE id = :id AND active = 1"),
                {"id": team_id}
            ).first()
            
            if not result:
                return False
            
            stored_hash = result[0]
            
            # Support bcrypt (nouveau) et MD5 legacy (migration)
            if stored_hash.startswith('$2b$'):
                # bcrypt
                return bcrypt.checkpw(password.encode('utf-8'), stored_hash.encode('utf-8'))
            else:
                # MD5 legacy - migrer automatiquement
                if hashlib.md5(password.encode()).hexdigest() == stored_hash:
                    # Migrer vers bcrypt
                    new_hash = hash_password(password)
                    session.execute(
                        text("UPDATE teams SET password_hash = :hash WHERE id = :id"),
                        {"hash": new_hash, "id": team_id}
                    )
                    session.commit()
                    return True
                return False
                
    except Exception as e:
        print(f"❌ Erreur verify_team: {e}")
        return False


def get_all_teams() -> List[Dict[str, Any]]:
    """Récupère toutes les équipes actives"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT id, name, created_at, 
                       (SELECT COUNT(*) FROM streets WHERE team = teams.id) as assigned_streets
                FROM teams 
                WHERE active = 1 
                ORDER BY name
            """))
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"❌ Erreur get_all_teams: {e}")
        return []


def teams() -> List[str]:
    """Récupère la liste des IDs d'équipes actives"""
    try:
        with get_session() as session:
            result = session.execute(
                text("SELECT id FROM teams WHERE active = 1 ORDER BY name")
            )
            return [row[0] for row in result]
            
    except Exception as e:
        print(f"❌ Erreur teams: {e}")
        return []


@auto_backup_before_critical
def delete_team(team_id: str) -> bool:
    """Supprime une équipe (soft delete)"""
    try:
        with get_session() as session:
            session.execute(
                text("UPDATE teams SET active = 0 WHERE id = :id"),
                {"id": team_id}
            )
            session.commit()
            return True
            
    except Exception as e:
        print(f"❌ Erreur delete_team: {e}")
        return False


# =============================================================================
# GESTION DES RUES ET STATUTS  
# =============================================================================

def list_streets(team: Optional[str] = None) -> pd.DataFrame:
    """Liste les rues avec filtrage optionnel par équipe"""
    try:
        with get_session() as session:
            if team:
                query = text("""
                    SELECT id, name, sector, team, status
                    FROM streets 
                    WHERE team = :team
                    ORDER BY name
                """)
                result = session.execute(query, {"team": team})
            else:
                query = text("""
                    SELECT id, name, sector, team, status
                    FROM streets 
                    ORDER BY name
                """)
                result = session.execute(query)
            
            # Convertir en DataFrame
            rows = [dict(row._mapping) for row in result]
            return pd.DataFrame(rows) if rows else pd.DataFrame(columns=['id', 'name', 'sector', 'team', 'status'])
            
    except Exception as e:
        print(f"❌ Erreur list_streets: {e}")
        return pd.DataFrame(columns=['id', 'name', 'sector', 'team', 'status'])


def get_unassigned_streets() -> List[str]:
    """Récupère les rues non assignées à une équipe"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT name FROM streets 
                WHERE team IS NULL OR team = ''
                ORDER BY name
            """))
            return [row[0] for row in result]
            
    except Exception as e:
        print(f"❌ Erreur get_unassigned_streets: {e}")
        return []


@auto_backup_before_critical
def assign_streets_to_team(street_names: List[str], team_id: str) -> int:
    """Assigne plusieurs rues à une équipe"""
    try:
        with get_session() as session:
            count = 0
            for street_name in street_names:
                # Vérifier si la rue existe et n'est pas assignée
                existing = session.execute(text("""
                    SELECT COUNT(*) FROM streets 
                    WHERE name = :name AND (team IS NULL OR team = '')
                """), {"name": street_name}).scalar() or 0
                
                if existing > 0:
                    session.execute(text("""
                        UPDATE streets 
                        SET team = :team 
                        WHERE name = :name AND (team IS NULL OR team = '')
                    """), {"team": team_id, "name": street_name})
                    count += 1
            
            session.commit()
            
            # Log de l'activité
            if count > 0:
                log_activity(session, team_id, 'assign_streets', 
                           f"{count} rues assignées à l'équipe")
            
            return count
            
    except Exception as e:
        print(f"❌ Erreur assign_streets_to_team: {e}")
        return 0


@auto_backup_before_critical
def set_status(name: str, status: str) -> bool:
    """Met à jour le statut d'une rue"""
    try:
        # Validation du statut
        valid_statuses = ['a_faire', 'en_cours', 'terminee']
        if status not in valid_statuses:
            return False
        
        with get_session() as session:
            # Vérifier si la rue existe
            exists = session.execute(
                text("SELECT COUNT(*) FROM streets WHERE name = :name"),
                {"name": name}
            ).scalar() or 0
            
            if exists > 0:
                session.execute(text("""
                    UPDATE streets 
                    SET status = :status 
                    WHERE name = :name
                """), {"status": status, "name": name})
                
                session.commit()
                
                # Log de l'activité
                team = session.execute(
                    text("SELECT team FROM streets WHERE name = :name"),
                    {"name": name}
                ).scalar()
                
                if team:
                    log_activity(session, team, 'status_change', 
                               f"Rue '{name}' -> {status}")
                
                return True
            return False
            
    except Exception as e:
        print(f"❌ Erreur set_status: {e}")
        return False


# =============================================================================
# GESTION DES NOTES ET ADRESSES
# =============================================================================

@auto_backup_before_critical
def add_note_for_address(street_name: str, team_id: str, address_number: str, comment: str) -> bool:
    """Ajoute une note pour une adresse spécifique"""
    try:
        # Validation et nettoyage
        _, comment = validate_and_clean_input("comment", comment)
        _, address_number = validate_and_clean_input("address_number", address_number)
        
        with get_session() as session:
            session.execute(text("""
                INSERT INTO notes (street_name, team_id, address_number, comment, created_at)
                VALUES (:street, :team, :addr, :comment, CURRENT_TIMESTAMP)
            """), {
                "street": street_name,
                "team": team_id,
                "addr": address_number,
                "comment": comment
            })
            session.commit()
            
            # Log de l'activité
            log_activity(session, team_id, 'add_note', 
                       f"Note ajoutée: {street_name} #{address_number}")
            
            return True
            
    except Exception as e:
        print(f"❌ Erreur add_note_for_address: {e}")
        return False


def get_street_addresses_with_notes(street_name: str) -> List[Dict[str, Any]]:
    """Récupère les adresses avec notes pour une rue"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT address_number, comment, team_id, created_at
                FROM notes 
                WHERE street_name = :street
                ORDER BY CAST(address_number AS INTEGER), created_at DESC
            """), {"street": street_name})
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"❌ Erreur get_street_addresses_with_notes: {e}")
        return []


def get_team_notes(team_id: str) -> List[Dict[str, Any]]:
    """Récupère toutes les notes d'une équipe"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT street_name, address_number, comment, created_at
                FROM notes 
                WHERE team_id = :team
                ORDER BY created_at DESC
            """), {"team": team_id})
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"❌ Erreur get_team_notes: {e}")
        return []


# =============================================================================
# STATISTIQUES ET RAPPORTS
# =============================================================================

def extended_stats() -> Dict[str, Any]:
    """Statistiques étendues de l'application"""
    try:
        with get_session() as session:
            # Stats de base
            total_streets = session.execute(text("SELECT COUNT(*) FROM streets")).scalar() or 0
            assigned_streets = session.execute(text("SELECT COUNT(*) FROM streets WHERE team IS NOT NULL AND team != ''")).scalar() or 0
            completed_streets = session.execute(text("SELECT COUNT(*) FROM streets WHERE status = 'terminee'")).scalar() or 0
            in_progress_streets = session.execute(text("SELECT COUNT(*) FROM streets WHERE status = 'en_cours'")).scalar() or 0
            
            # Stats par statut
            status_counts = session.execute(text("""
                SELECT status, COUNT(*) as count
                FROM streets 
                GROUP BY status
            """))
            status_data = {row[0]: row[1] for row in status_counts}
            
            return {
                'total_streets': total_streets,
                'assigned_streets': assigned_streets,
                'unassigned_streets': total_streets - assigned_streets,
                'completed_streets': completed_streets,
                'in_progress_streets': in_progress_streets,
                'todo_streets': total_streets - completed_streets - in_progress_streets,
                'completion_rate': (completed_streets / total_streets * 100) if total_streets > 0 else 0,
                'status_breakdown': status_data
            }
            
    except Exception as e:
        print(f"❌ Erreur extended_stats: {e}")
        return {}


def stats_by_team() -> List[Dict[str, Any]]:
    """Statistiques par équipe"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT 
                    t.id,
                    t.name,
                    COUNT(s.id) as total_streets,
                    SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as completed,
                    SUM(CASE WHEN s.status = 'en_cours' THEN 1 ELSE 0 END) as in_progress,
                    SUM(CASE WHEN s.status = 'a_faire' THEN 1 ELSE 0 END) as todo
                FROM teams t
                LEFT JOIN streets s ON s.team = t.id
                WHERE t.active = 1
                GROUP BY t.id, t.name
                ORDER BY t.name
            """))
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"❌ Erreur stats_by_team: {e}")
        return []


def recent_activity(limit: int = 10) -> List[Dict[str, Any]]:
    """Activité récente dans l'application"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT team_id, action, details, created_at
                FROM activity_log 
                ORDER BY created_at DESC 
                LIMIT :limit
            """), {"limit": limit})
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"❌ Erreur recent_activity: {e}")
        return []


def export_to_csv() -> str:
    """Exporte les données vers CSV"""
    try:
        from datetime import datetime
        
        df = list_streets()
        if df.empty:
            return ""
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        export_dir = Path(__file__).parent.parent / "exports"
        export_dir.mkdir(exist_ok=True)
        
        filename = f"guignomap_export_{timestamp}.csv"
        filepath = export_dir / filename
        
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        return str(filepath)
        
    except Exception as e:
        print(f"❌ Erreur export_to_csv: {e}")
        return ""


# =============================================================================
# LOG D'ACTIVITÉ
# =============================================================================

def log_activity(session, team_id: str, action: str, details: str):
    """Log une activité dans la base de données"""
    try:
        session.execute(text("""
            INSERT INTO activity_log (team_id, action, details, created_at)
            VALUES (:team, :action, :details, CURRENT_TIMESTAMP)
        """), {
            "team": team_id,
            "action": action,
            "details": details
        })
        # Note: commit fait par la fonction appelante
        
    except Exception as e:
        print(f"❌ Erreur log_activity: {e}")


# =============================================================================
# FONCTIONS MANQUANTES POUR COMPATIBILITÉ APP.PY
# =============================================================================

def get_team_streets(team_id: str) -> List[Dict[str, Any]]:
    """Récupère les rues assignées à une équipe avec tous les détails"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT id, name, sector, team, status
                FROM streets 
                WHERE team = :team 
                ORDER BY name
            """), {"team": team_id})
            return [dict(row._mapping) for row in result]
    except Exception as e:
        print(f"❌ Erreur get_team_streets: {e}")
        return []


def get_unassigned_streets_count() -> int:
    """Compte les rues non assignées"""
    try:
        with get_session() as session:
            count = session.execute(text("""
                SELECT COUNT(*) FROM streets 
                WHERE team IS NULL OR team = ''
            """)).scalar() or 0
            return count
    except Exception as e:
        print(f"❌ Erreur get_unassigned_streets_count: {e}")
        return 0


def get_sectors_list() -> List[str]:
    """Récupère la liste des secteurs"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT DISTINCT sector FROM streets 
                WHERE sector IS NOT NULL AND sector != ''
                ORDER BY sector
            """))
            return [row[0] for row in result]
    except Exception as e:
        print(f"❌ Erreur get_sectors_list: {e}")
        return []


def get_teams_list() -> List[str]:
    """Récupère la liste des équipes (alias pour teams())"""
    return teams()


def bulk_assign_sector(sector: str, team_id: str) -> int:
    """Assigne toutes les rues d'un secteur à une équipe"""
    try:
        with get_session() as session:
            # Récupérer les rues non assignées du secteur
            result = session.execute(text("""
                SELECT name FROM streets 
                WHERE sector = :sector AND (team IS NULL OR team = '')
            """), {"sector": sector})
            
            street_names = [row[0] for row in result]
            
            if street_names:
                return assign_streets_to_team(street_names, team_id)
            return 0
            
    except Exception as e:
        print(f"❌ Erreur bulk_assign_sector: {e}")
        return 0


def get_assignations_export_data() -> List[Dict[str, Any]]:
    """Données pour export des assignations"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT s.name as street_name, s.sector, s.team, s.status,
                       t.name as team_name
                FROM streets s
                LEFT JOIN teams t ON s.team = t.id
                ORDER BY s.name
            """))
            return [dict(row._mapping) for row in result]
    except Exception as e:
        print(f"❌ Erreur get_assignations_export_data: {e}")
        return []


def export_notes_csv() -> str:
    """Exporte les notes vers CSV"""
    try:
        from datetime import datetime
        
        with get_session() as session:
            result = session.execute(text("""
                SELECT n.street_name, n.team_id, n.address_number, 
                       n.comment, n.created_at,
                       t.name as team_name
                FROM notes n
                LEFT JOIN teams t ON n.team_id = t.id
                ORDER BY n.created_at DESC
            """))
            
            if not result:
                return ""
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            export_dir = Path(__file__).parent.parent / "exports"
            export_dir.mkdir(exist_ok=True)
            
            filename = f"notes_export_{timestamp}.csv"
            filepath = export_dir / filename
            
            import pandas as pd
            df = pd.DataFrame([dict(row._mapping) for row in result])
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            
            return str(filepath)
            
    except Exception as e:
        print(f"❌ Erreur export_notes_csv: {e}")
        return ""


def import_addresses_from_cache(addr_cache: Dict) -> int:
    """Importe les adresses depuis le cache OSM"""
    try:
        with get_session() as session:
            imported = 0
            
            for street_name, addresses in addr_cache.items():
                if isinstance(addresses, list):
                    for addr in addresses:
                        # Insérer l'adresse si elle n'existe pas
                        exists = session.execute(text("""
                            SELECT COUNT(*) FROM addresses 
                            WHERE street_name = :street AND house_number = :num
                        """), {"street": street_name, "num": str(addr)}).scalar() or 0
                        
                        if exists == 0:
                            session.execute(text("""
                                INSERT INTO addresses (street_name, house_number)
                                VALUES (:street, :num)
                            """), {"street": street_name, "num": str(addr)})
                            imported += 1
            
            session.commit()
            return imported
            
    except Exception as e:
        print(f"❌ Erreur import_addresses_from_cache: {e}")
        return 0


def update_street_status(street_name: str, status: str, team_id: str) -> bool:
    """Met à jour le statut d'une rue (alias pour set_status)"""
    return set_status(street_name, status)


def get_street_notes_for_team(street_name: str, team_id: str) -> List[Dict[str, Any]]:
    """Récupère les notes d'une rue pour une équipe spécifique"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT address_number, comment, created_at
                FROM notes 
                WHERE street_name = :street AND team_id = :team
                ORDER BY created_at DESC
            """), {"street": street_name, "team": team_id})
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"❌ Erreur get_street_notes_for_team: {e}")
        return []


def add_street_note(street_name: str, team_id: str, address_number: str, comment: str) -> bool:
    """Ajoute une note pour une rue (alias pour add_note_for_address)"""
    return add_note_for_address(street_name, team_id, address_number, comment)


# =============================================================================
# COMPATIBILITÉ LEGACY
# =============================================================================

def get_backup_manager(db_path=None):
    """Compatibilité avec backup.py - retourne le BackupManager"""
    # Pour l'instant, utilise encore l'ancien système de backup
    # TODO: Migrer le backup vers SQLAlchemy dans Phase 2
    if db_path is None:
        db_path = Path(__file__).parent / "guigno_map.db"
    return BackupManager(db_path)


# =============================================================================
# MIGRATION PASSWORD LEGACY
# =============================================================================

def migrate_all_passwords_to_bcrypt():
    """Migre tous les mots de passe MD5 vers bcrypt"""
    try:
        with get_session() as session:
            # Récupérer toutes les équipes avec hash MD5
            result = session.execute(text("""
                SELECT id, password_hash 
                FROM teams 
                WHERE password_hash NOT LIKE '$2b$%' AND active = 1
            """))
            
            migrated = 0
            for row in result:
                team_id, old_hash = row
                print(f"⚠️ Équipe {team_id} a un hash MD5 legacy")
                print("La migration automatique se fera lors de la prochaine connexion")
                # Note: la migration se fait automatiquement dans verify_team()
                
            print(f"✅ {migrated} mots de passe à migrer détectés")
            
    except Exception as e:
        print(f"❌ Erreur migrate_all_passwords_to_bcrypt: {e}")
```
---8<--- src/database/db_v5.py END ---

---8<--- src/database/migrations/env.py BEGIN ---
```py
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

# Import our models and config
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))

from src.database.models import Base
from src.config import get_database_url

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
target_metadata = Base.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = get_database_url()
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    # Use our custom database URL instead of config
    configuration = config.get_section(config.config_ini_section, {})
    configuration["sqlalchemy.url"] = get_database_url()
    
    connectable = engine_from_config(
        configuration,
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()

```
---8<--- src/database/migrations/env.py END ---

---8<--- src/database/migrations/README BEGIN ---
```txt
Generic single-database configuration.
```
---8<--- src/database/migrations/README END ---

---8<--- src/database/models.py BEGIN ---
```py
"""
Modèles SQLAlchemy pour GuignoMap v5.0
Basés sur le schéma SQLite existant pour compatibilité
"""
from sqlalchemy import Column, Integer, String, Text, DateTime, Boolean, ForeignKey, Float
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime

Base = declarative_base()


class Street(Base):
    __tablename__ = 'streets'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    name = Column(Text, nullable=False, unique=True)
    sector = Column(Text)
    team = Column(Text)
    status = Column(Text, nullable=False, default='a_faire')
    
    # Relations
    notes = relationship("Note", back_populates="street", cascade="all, delete-orphan")
    addresses = relationship("Address", back_populates="street", cascade="all, delete-orphan")


class Team(Base):
    __tablename__ = 'teams'
    
    id = Column(Text, primary_key=True)
    name = Column(Text, nullable=False)
    password_hash = Column(Text, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)
    active = Column(Boolean, default=True)


class Note(Base):
    __tablename__ = 'notes'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    street_name = Column(Text, ForeignKey('streets.name'), nullable=False)
    team_id = Column(Text, ForeignKey('teams.id'), nullable=False)
    address_number = Column(Text)
    comment = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relations
    street = relationship("Street", back_populates="notes")


class ActivityLog(Base):
    __tablename__ = 'activity_log'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    team_id = Column(Text)
    action = Column(Text, nullable=False)
    details = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)


class Address(Base):
    __tablename__ = 'addresses'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    street_name = Column(Text, ForeignKey('streets.name'), nullable=False)
    house_number = Column(Text, nullable=False)
    latitude = Column(Float)
    longitude = Column(Float)
    osm_type = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relations
    street = relationship("Street", back_populates="addresses")
```
---8<--- src/database/models.py END ---

---8<--- src/storage/__init__.py BEGIN ---
```py
"""
Adapter de stockage pour GuignoMap v5.0
Sélection automatique entre cloud S3 et local selon configuration
"""
import os
from typing import Optional, Dict, Any
from pathlib import Path

try:
    from src.storage.cloud import (
        upload_osm_cache as cloud_upload_osm_cache,
        download_osm_cache as cloud_download_osm_cache,
        upload_backup_to_cloud as cloud_upload_backup,
        list_cloud_backups as cloud_list_backups,
        download_backup_from_cloud as cloud_download_backup
    )
    CLOUD_AVAILABLE = True
except ImportError as e:
    print(f"⚠️ Stockage cloud non disponible: {e}")
    CLOUD_AVAILABLE = False

from src.storage.local import (
    upload_osm_cache as local_upload_osm_cache,
    download_osm_cache as local_download_osm_cache,
    upload_backup_to_cloud as local_upload_backup,
    list_cloud_backups as local_list_backups,
    download_backup_from_cloud as local_download_backup
)


def is_cloud_storage_enabled() -> bool:
    """
    Détermine si le stockage cloud est activé
    Vérifie la présence des secrets S3 et la disponibilité des libs
    """
    if not CLOUD_AVAILABLE:
        return False
    
    try:
        from src.config import get_s3_config
        config = get_s3_config()
        
        # Vérifier que les clés essentielles sont présentes et non vides
        required_keys = ['bucket', 'access_key', 'secret_key']
        for key in required_keys:
            if not config.get(key) or config[key] in ['', 'xxx']:
                return False
        
        return True
    except Exception:
        return False


def get_storage_backend() -> str:
    """Retourne 'cloud' ou 'local' selon la configuration"""
    return 'cloud' if is_cloud_storage_enabled() else 'local'


# API unifiée pour le stockage
def upload_osm_cache(cache_data: Dict[Any, Any]) -> bool:
    """Upload du cache OSM (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("📡 Upload cache OSM vers S3...")
        return cloud_upload_osm_cache(cache_data)
    else:
        print("💾 Sauvegarde cache OSM en local...")
        return local_upload_osm_cache(cache_data)


def download_osm_cache() -> Optional[Dict[Any, Any]]:
    """Download du cache OSM (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("📡 Téléchargement cache OSM depuis S3...")
        return cloud_download_osm_cache()
    else:
        print("💾 Lecture cache OSM local...")
        return local_download_osm_cache()


def upload_backup(backup_path: Path) -> bool:
    """Upload d'un backup (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("📡 Upload backup vers S3...")
        return cloud_upload_backup(backup_path)
    else:
        print("💾 Copie backup en local...")
        return local_upload_backup(backup_path)


def list_backups() -> list:
    """Liste des backups disponibles (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("📡 Liste backups S3...")
        return cloud_list_backups()
    else:
        print("💾 Liste backups locaux...")
        return local_list_backups()


def download_backup(backup_key: str, local_path: Path) -> bool:
    """Download d'un backup (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("📡 Téléchargement backup depuis S3...")
        return cloud_download_backup(backup_key, local_path)
    else:
        print("💾 Copie backup depuis local...")
        return local_download_backup(backup_key, local_path)


def get_storage_info() -> Dict[str, Any]:
    """Informations sur le backend de stockage actuel"""
    backend = get_storage_backend()
    info = {
        'backend': backend,
        'cloud_available': CLOUD_AVAILABLE,
        'cloud_enabled': is_cloud_storage_enabled()
    }
    
    if backend == 'cloud':
        try:
            from src.config import get_s3_config
            config = get_s3_config()
            info.update({
                'bucket': config.get('bucket', ''),
                'region': config.get('region', ''),
                'cdn_enabled': bool(config.get('cdn_base_url', ''))
            })
        except:
            pass
    
    return info
```
---8<--- src/storage/__init__.py END ---

---8<--- src/storage/cloud.py BEGIN ---
```py
"""
Stockage cloud S3 pour GuignoMap v5.0
Client boto3 pour osm_cache.json et backups
"""
import boto3
import json
import io
import os
import streamlit as st
from typing import Optional, Dict, Any, BinaryIO
from pathlib import Path
from datetime import datetime
from src.config import get_s3_config, get_cdn_base_url


class S3StorageClient:
    """Client S3 pour gérer osm_cache.json et backups"""
    
    def __init__(self):
        self.config = get_s3_config()
        self.cdn_base_url = get_cdn_base_url()
        self._client = None
    
    @property
    def client(self):
        """Client S3 avec lazy loading et cache Streamlit"""
        if self._client is None:
            try:
                self._client = boto3.client(
                    's3',
                    region_name=self.config['region'],
                    aws_access_key_id=self.config['access_key'],
                    aws_secret_access_key=self.config['secret_key']
                )
            except Exception as e:
                print(f"Erreur initialisation client S3: {e}")
                raise
        return self._client
    
    def upload_json_file(self, key: str, data: Dict[Any, Any], metadata: Optional[Dict[str, str]] = None) -> bool:
        """
        Upload d'un fichier JSON vers S3
        """
        try:
            json_content = json.dumps(data, ensure_ascii=False, indent=2)
            json_bytes = json_content.encode('utf-8')
            
            extra_args = {
                'ContentType': 'application/json',
                'ContentEncoding': 'utf-8'
            }
            
            if metadata:
                extra_args['Metadata'] = metadata
            
            self.client.put_object(
                Bucket=self.config['bucket'],
                Key=key,
                Body=json_bytes,
                **extra_args
            )
            
            print(f"✅ JSON uploadé vers S3: {key}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur upload JSON S3 {key}: {e}")
            return False
    
    def download_json_file(self, key: str) -> Optional[Dict[Any, Any]]:
        """
        Download d'un fichier JSON depuis S3
        """
        try:
            response = self.client.get_object(
                Bucket=self.config['bucket'],
                Key=key
            )
            
            content = response['Body'].read().decode('utf-8')
            data = json.loads(content)
            
            print(f"✅ JSON téléchargé depuis S3: {key}")
            return data
            
        except self.client.exceptions.NoSuchKey:
            print(f"ℹ️ Fichier JSON S3 non trouvé: {key}")
            return None
        except Exception as e:
            print(f"❌ Erreur download JSON S3 {key}: {e}")
            return None
    
    def upload_backup(self, backup_file_path: Path, s3_key: Optional[str] = None) -> bool:
        """
        Upload d'un fichier backup vers S3
        """
        try:
            if not backup_file_path.exists():
                print(f"❌ Fichier backup non trouvé: {backup_file_path}")
                return False
            
            # Générer la clé S3 si non fournie
            if not s3_key:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                s3_key = f"backups/{backup_file_path.stem}_{timestamp}{backup_file_path.suffix}"
            
            # Upload avec streaming pour gros fichiers
            with open(backup_file_path, 'rb') as f:
                self.client.upload_fileobj(
                    f,
                    self.config['bucket'],
                    s3_key,
                    ExtraArgs={
                        'ContentType': 'application/zip',
                        'Metadata': {
                            'original_filename': backup_file_path.name,
                            'upload_timestamp': datetime.utcnow().isoformat()
                        }
                    }
                )
            
            print(f"✅ Backup uploadé vers S3: {s3_key}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur upload backup S3: {e}")
            return False
    
    def download_backup(self, s3_key: str, local_path: Path) -> bool:
        """
        Download d'un backup depuis S3
        """
        try:
            # Créer le répertoire parent si nécessaire
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Download avec streaming
            with open(local_path, 'wb') as f:
                self.client.download_fileobj(
                    self.config['bucket'],
                    s3_key,
                    f
                )
            
            print(f"✅ Backup téléchargé depuis S3: {s3_key} → {local_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur download backup S3 {s3_key}: {e}")
            return False
    
    def list_backups(self, prefix: str = "backups/") -> list:
        """
        Liste des backups disponibles sur S3
        """
        try:
            response = self.client.list_objects_v2(
                Bucket=self.config['bucket'],
                Prefix=prefix
            )
            
            backups = []
            if 'Contents' in response:
                for obj in response['Contents']:
                    backups.append({
                        'key': obj['Key'],
                        'size': obj['Size'],
                        'last_modified': obj['LastModified'],
                        'filename': Path(obj['Key']).name
                    })
                
                # Trier par date de modification (plus récent en premier)
                backups.sort(key=lambda x: x['last_modified'], reverse=True)
            
            return backups
            
        except Exception as e:
            print(f"❌ Erreur liste backups S3: {e}")
            return []
    
    def delete_file(self, key: str) -> bool:
        """
        Suppression d'un fichier sur S3
        """
        try:
            self.client.delete_object(
                Bucket=self.config['bucket'],
                Key=key
            )
            print(f"✅ Fichier supprimé de S3: {key}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur suppression S3 {key}: {e}")
            return False
    
    def file_exists(self, key: str) -> bool:
        """
        Vérifier si un fichier existe sur S3
        """
        try:
            self.client.head_object(
                Bucket=self.config['bucket'],
                Key=key
            )
            return True
        except self.client.exceptions.NoSuchKey:
            return False
        except Exception as e:
            print(f"❌ Erreur vérification existence S3 {key}: {e}")
            return False
    
    def get_public_url(self, key: str, expires_in: int = 3600) -> Optional[str]:
        """
        Générer URL publique signée pour un fichier S3
        """
        try:
            # Si CDN configuré, utiliser l'URL CDN
            if self.cdn_base_url:
                return f"{self.cdn_base_url.rstrip('/')}/{key}"
            
            # Sinon, générer URL signée S3
            url = self.client.generate_presigned_url(
                'get_object',
                Params={'Bucket': self.config['bucket'], 'Key': key},
                ExpiresIn=expires_in
            )
            return url
            
        except Exception as e:
            print(f"❌ Erreur génération URL publique S3 {key}: {e}")
            return None


# Instance globale pour cache Streamlit
@st.cache_resource
def get_s3_client() -> S3StorageClient:
    """Factory avec cache Streamlit pour client S3"""
    return S3StorageClient()


# API simplifiée pour les fonctions métier
def upload_osm_cache(cache_data: Dict[Any, Any]) -> bool:
    """Upload du cache OSM vers S3"""
    client = get_s3_client()
    return client.upload_json_file(
        "osm_cache.json", 
        cache_data,
        metadata={
            'type': 'osm_cache',
            'updated_at': datetime.utcnow().isoformat()
        }
    )


def download_osm_cache() -> Optional[Dict[Any, Any]]:
    """Download du cache OSM depuis S3"""
    client = get_s3_client()
    return client.download_json_file("osm_cache.json")


def upload_backup_to_cloud(backup_path: Path) -> bool:
    """Upload d'un backup vers S3"""
    client = get_s3_client()
    return client.upload_backup(backup_path)


def list_cloud_backups() -> list:
    """Liste des backups cloud disponibles"""
    client = get_s3_client()
    return client.list_backups()


def download_backup_from_cloud(s3_key: str, local_path: Path) -> bool:
    """Download d'un backup depuis S3"""
    client = get_s3_client()
    return client.download_backup(s3_key, local_path)
```
---8<--- src/storage/cloud.py END ---

---8<--- src/storage/local.py BEGIN ---
```py
"""
Stockage local pour GuignoMap v5.0  
Fallback avec API identique à cloud.py
"""
import json
import shutil
import os
from typing import Optional, Dict, Any
from pathlib import Path
from datetime import datetime


class LocalStorageClient:
    """Client stockage local avec API identique au client S3"""
    
    def __init__(self, base_path: Optional[Path] = None):
        # Répertoire de base pour le stockage local
        if base_path is None:
            base_path = Path(__file__).parent.parent.parent / "storage_local"
        
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
        
        # Sous-répertoires
        self.backups_dir = self.base_path / "backups"
        self.backups_dir.mkdir(exist_ok=True)
    
    def upload_json_file(self, key: str, data: Dict[Any, Any], metadata: Optional[Dict[str, str]] = None) -> bool:
        """
        Sauvegarde d'un fichier JSON en local
        """
        try:
            file_path = self.base_path / key
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Sauvegarder les données JSON
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # Sauvegarder les métadonnées si fournies
            if metadata:
                metadata_path = file_path.with_suffix('.metadata.json')
                with open(metadata_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"✅ JSON sauvé localement: {file_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur sauvegarde JSON local {key}: {e}")
            return False
    
    def download_json_file(self, key: str) -> Optional[Dict[Any, Any]]:
        """
        Lecture d'un fichier JSON local
        """
        try:
            file_path = self.base_path / key
            
            if not file_path.exists():
                print(f"ℹ️ Fichier JSON local non trouvé: {file_path}")
                return None
            
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"✅ JSON lu localement: {file_path}")
            return data
            
        except Exception as e:
            print(f"❌ Erreur lecture JSON local {key}: {e}")
            return None
    
    def upload_backup(self, backup_file_path: Path, s3_key: Optional[str] = None) -> bool:
        """
        Copie d'un fichier backup vers le répertoire local
        """
        try:
            if not backup_file_path.exists():
                print(f"❌ Fichier backup non trouvé: {backup_file_path}")
                return False
            
            # Générer le nom de destination si non fourni
            if not s3_key:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                dest_name = f"{backup_file_path.stem}_{timestamp}{backup_file_path.suffix}"
            else:
                # Extraire le nom du fichier de la clé S3
                dest_name = Path(s3_key).name
            
            dest_path = self.backups_dir / dest_name
            
            # Copier le fichier
            shutil.copy2(backup_file_path, dest_path)
            
            # Créer un fichier de métadonnées
            metadata = {
                'original_filename': backup_file_path.name,
                'original_path': str(backup_file_path),
                'upload_timestamp': datetime.utcnow().isoformat(),
                'size': backup_file_path.stat().st_size
            }
            
            metadata_path = dest_path.with_suffix(dest_path.suffix + '.metadata.json')
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"✅ Backup copié localement: {dest_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur copie backup local: {e}")
            return False
    
    def download_backup(self, s3_key: str, local_path: Path) -> bool:
        """
        Copie d'un backup depuis le stockage local
        """
        try:
            # Trouver le fichier source
            source_name = Path(s3_key).name
            source_path = self.backups_dir / source_name
            
            if not source_path.exists():
                print(f"❌ Backup local non trouvé: {source_path}")
                return False
            
            # Créer le répertoire de destination
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Copier le fichier
            shutil.copy2(source_path, local_path)
            
            print(f"✅ Backup copié depuis local: {source_path} → {local_path}")
            return True
            
        except Exception as e:
            print(f"❌ Erreur copie backup depuis local {s3_key}: {e}")
            return False
    
    def list_backups(self, prefix: str = "backups/") -> list:
        """
        Liste des backups disponibles en local
        """
        try:
            backups = []
            
            # Lister tous les fichiers (sauf métadonnées)
            for backup_file in self.backups_dir.glob("*"):
                if backup_file.is_file() and not backup_file.name.endswith('.metadata.json'):
                    # Lire les métadonnées si disponibles
                    metadata_path = backup_file.with_suffix(backup_file.suffix + '.metadata.json')
                    metadata = {}
                    if metadata_path.exists():
                        try:
                            with open(metadata_path, 'r', encoding='utf-8') as f:
                                metadata = json.load(f)
                        except:
                            pass
                    
                    stat = backup_file.stat()
                    backups.append({
                        'key': f"backups/{backup_file.name}",
                        'size': stat.st_size,
                        'last_modified': datetime.fromtimestamp(stat.st_mtime),
                        'filename': backup_file.name,
                        'metadata': metadata
                    })
            
            # Trier par date de modification (plus récent en premier)
            backups.sort(key=lambda x: x['last_modified'], reverse=True)
            return backups
            
        except Exception as e:
            print(f"❌ Erreur liste backups locaux: {e}")
            return []
    
    def delete_file(self, key: str) -> bool:
        """
        Suppression d'un fichier local
        """
        try:
            file_path = self.base_path / key
            
            if file_path.exists():
                file_path.unlink()
                
                # Supprimer les métadonnées si elles existent
                metadata_path = file_path.with_suffix('.metadata.json')
                if metadata_path.exists():
                    metadata_path.unlink()
                
                print(f"✅ Fichier supprimé localement: {file_path}")
                return True
            else:
                print(f"ℹ️ Fichier local non trouvé: {file_path}")
                return False
            
        except Exception as e:
            print(f"❌ Erreur suppression fichier local {key}: {e}")
            return False
    
    def file_exists(self, key: str) -> bool:
        """
        Vérifier si un fichier existe en local
        """
        file_path = self.base_path / key
        return file_path.exists()
    
    def get_public_url(self, key: str, expires_in: int = 3600) -> Optional[str]:
        """
        Générer un chemin local pour un fichier (pas d'URL publique)
        """
        file_path = self.base_path / key
        if file_path.exists():
            return f"file://{file_path.absolute()}"
        return None


# Instance globale pour le stockage local
_local_client = None

def get_local_client() -> LocalStorageClient:
    """Factory pour client de stockage local"""
    global _local_client
    if _local_client is None:
        _local_client = LocalStorageClient()
    return _local_client


# API simplifiée pour les fonctions métier (identique à cloud.py)
def upload_osm_cache(cache_data: Dict[Any, Any]) -> bool:
    """Upload du cache OSM en local"""
    client = get_local_client()
    return client.upload_json_file(
        "osm_cache.json", 
        cache_data,
        metadata={
            'type': 'osm_cache',
            'updated_at': datetime.utcnow().isoformat()
        }
    )


def download_osm_cache() -> Optional[Dict[Any, Any]]:
    """Download du cache OSM depuis local"""
    client = get_local_client()
    return client.download_json_file("osm_cache.json")


def upload_backup_to_cloud(backup_path: Path) -> bool:
    """Upload d'un backup en local"""
    client = get_local_client()
    return client.upload_backup(backup_path)


def list_cloud_backups() -> list:
    """Liste des backups locaux disponibles"""
    client = get_local_client()
    return client.list_backups()


def download_backup_from_cloud(s3_key: str, local_path: Path) -> bool:
    """Download d'un backup depuis local"""
    client = get_local_client()
    return client.download_backup(s3_key, local_path)
```
---8<--- src/storage/local.py END ---

---8<--- src/utils/__init__.py BEGIN ---
```py
# Utils module for GuignoMap
```
---8<--- src/utils/__init__.py END ---

---8<--- src/utils/adapters.py BEGIN ---
```py
import pandas as pd
from typing import Any, Iterable

def to_dataframe(records: Any) -> pd.DataFrame:
    if isinstance(records, pd.DataFrame):
        return records
    # RowMapping unique
    try:
        if hasattr(records, "keys") and hasattr(records, "__getitem__"):
            return pd.DataFrame([dict(records)])
    except Exception:
        pass
    # Séquences (list[dict]/list[Row]/list[ORM])
    if isinstance(records, Iterable):
        items = list(records)
        if items and not isinstance(items[0], dict):
            dicts = []
            for r in items:
                if hasattr(r, "__dict__"):
                    d = {k:v for k,v in r.__dict__.items() if not k.startswith("_sa_")}
                    dicts.append(d)
                else:
                    try: dicts.append(dict(r))
                    except Exception: dicts.append({"value": r})
            return pd.DataFrame(dicts)
        return pd.DataFrame(items)
    return pd.DataFrame([])
```
---8<--- src/utils/adapters.py END ---

---8<--- tests/manual/test_db_connection.py BEGIN ---
```py
import os
import sys
import socket
import psycopg2

def test_connection_with_ip():
    """Test connection with direct IPv6 address"""
    # Configuration manuelle avec l'adresse IPv6 résolue
    ipv6_host = "2600:1f11:4e2:e202:6514:7431:494f:c00f"
    
    connection_string = f"postgresql://postgres:4everSab!2304@[{ipv6_host}]:5432/postgres"
    
    print(f"Test de connexion avec IPv6 directe: {ipv6_host}")
    
    try:
        conn = psycopg2.connect(connection_string)
        print("✅ Connexion IPv6 réussie!")
        
        with conn.cursor() as cursor:
            cursor.execute("SELECT version();")
            version = cursor.fetchone()[0]
            print(f"Version PostgreSQL: {version}")
        
        conn.close()
        return True
        
    except Exception as e:
        print(f"❌ Erreur de connexion IPv6: {e}")
        return False

def test_connection_with_hostname():
    """Test connection with hostname via custom DNS"""
    import socket
    
    # Forcer IPv4 si possible
    try:
        socket.setdefaulttimeout(10)
        original_getaddrinfo = socket.getaddrinfo
        
        def custom_getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):
            if host == "db.kdxqspmfycnwzzrmhzpa.supabase.co":
                # Retourner directement l'IPv6 connue
                return [(socket.AF_INET6, socket.SOCK_STREAM, 6, '', 
                        ('2600:1f11:4e2:e202:6514:7431:494f:c00f', port, 0, 0))]
            return original_getaddrinfo(host, port, family, type, proto, flags)
        
        socket.getaddrinfo = custom_getaddrinfo
        
        connection_string = "postgresql://postgres:4everSab!2304@db.kdxqspmfycnwzzrmhzpa.supabase.co:5432/postgres"
        
        print("Test de connexion avec hostname (DNS custom)")
        conn = psycopg2.connect(connection_string)
        print("✅ Connexion hostname réussie!")
        
        with conn.cursor() as cursor:
            cursor.execute("SELECT version();")
            version = cursor.fetchone()[0]
            print(f"Version PostgreSQL: {version}")
        
        conn.close()
        socket.getaddrinfo = original_getaddrinfo
        return True
        
    except Exception as e:
        print(f"❌ Erreur de connexion hostname: {e}")
        socket.getaddrinfo = original_getaddrinfo
        return False

if __name__ == "__main__":
    print("=== Test de connectivité Supabase PostgreSQL ===")
    
    print("\n1. Test avec adresse IPv6 directe:")
    ipv6_success = test_connection_with_ip()
    
    print("\n2. Test avec hostname (DNS custom):")
    hostname_success = test_connection_with_hostname()
    
    if ipv6_success or hostname_success:
        print("\n✅ Au moins une méthode de connexion fonctionne!")
    else:
        print("\n❌ Aucune méthode de connexion ne fonctionne")
        print("Problème potentiel: connectivité IPv6 ou firewall")
```
---8<--- tests/manual/test_db_connection.py END ---

---8<--- tests/manual/test_db_simple.py BEGIN ---
```py
#!/usr/bin/env python3
"""Test simple de connexion base de données"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_db_simple():
    try:
        from src.database.connection import get_engine, test_connection
        
        print("=== Test de connexion base de données ===")
        
        # Test avec la fonction dédiée
        print("1. Test avec test_connection():")
        test_connection()
        
        # Test manuel avec engine
        print("\n2. Test manuel avec engine:")
        engine = get_engine()
        print(f"✅ Engine créé: {engine.url}")
        
        # Tester la connexion
        with engine.connect() as conn:
            result = conn.execute("SELECT 1 as test")
            test_value = result.fetchone()[0]
            print(f"✅ Connexion réussie! Test query result: {test_value}")
        
        print("✅ Connexion base de données fonctionnelle!")
        return True
        
    except Exception as e:
        print(f"❌ Erreur de connexion: {e}")
        return False

if __name__ == "__main__":
    success = test_db_simple()
    sys.exit(0 if success else 1)
```
---8<--- tests/manual/test_db_simple.py END ---

---8<--- tools/quick_sanity.py BEGIN ---
```py
#!/usr/bin/env python3
"""
Quick sanity check script for GuignoMap v4.1
Generates audit CSV files and validates data integrity with assertions.
"""

import sqlite3
import csv
import sys
from datetime import datetime
from pathlib import Path

def main():
    """Main sanity check function with data integrity assertions."""
    # Paths
    db_path = Path("guignomap") / "guigno_map.db"
    exports_dir = Path("exports")
    
    # Create exports directory if missing
    exports_dir.mkdir(exist_ok=True)
    
    # Check if database exists
    if not db_path.exists():
        print(f"❌ Database not found: {db_path}")
        print("ℹ️  Run the application first to create the database.")
        print("SANITY: FAIL - Database missing")
        return 1
    
    try:
        # Connect to database
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Generate timestamp for files
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        
        print("🔍 GuignoMap v4.1 - Quick Sanity Check with Assertions")
        print("=" * 60)
        
        # Check if required tables exist
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]
        
        if 'streets' not in tables:
            print("❌ Table 'streets' not found")
            print("SANITY: FAIL - Missing streets table")
            return 1
        
        # === DATA COLLECTION ===
        
        # 1. Total streets count
        cursor.execute("SELECT COUNT(*) FROM streets")
        total_streets = cursor.fetchone()[0]
        
        # 2. Count unassigned streets (team IS NULL OR team = '')
        cursor.execute("SELECT COUNT(*) FROM streets WHERE team IS NULL OR team = ''")
        unassigned_count = cursor.fetchone()[0]
        
        # 3. Status distribution with counts
        cursor.execute("""
            SELECT 
                COALESCE(status, 'Non défini') as status,
                COUNT(*) as count
            FROM streets 
            GROUP BY status 
            ORDER BY count DESC
        """)
        status_counts = cursor.fetchall()
        
        # 4. Unassigned streets by sector (for CSV)
        cursor.execute("""
            SELECT 
                COALESCE(sector, 'Aucun') as sector,
                name
            FROM streets 
            WHERE team IS NULL OR team = ''
            ORDER BY sector, name
        """)
        unassigned_streets = cursor.fetchall()
        
        # 5. Top 10 streets (for display)
        cursor.execute("""
            SELECT 
                COALESCE(sector, 'Aucun') as sector,
                name,
                COALESCE(team, 'Non assignée') as team,
                COALESCE(status, 'Non défini') as status
            FROM streets 
            ORDER BY name 
            LIMIT 10
        """)
        top_streets = cursor.fetchall()
        
        # === ASSERTIONS & DATA INTEGRITY CHECKS ===
        
        sanity_pass = True
        fail_reasons = []
        
        # Assertion 1: Total should equal sum of status counts
        sum_status_counts = sum(count for _, count in status_counts)
        if total_streets != sum_status_counts:
            sanity_pass = False
            fail_reasons.append(f"Total streets ({total_streets}) != sum of status counts ({sum_status_counts})")
        
        # Assertion 2: Unassigned count should match COUNT(team IS NULL OR team = '')
        # (This is redundant since we're using the same query, but validates consistency)
        cursor.execute("SELECT COUNT(*) FROM streets WHERE team IS NULL OR team = ''")
        unassigned_recheck = cursor.fetchone()[0]
        if unassigned_count != unassigned_recheck:
            sanity_pass = False
            fail_reasons.append(f"Unassigned count inconsistent ({unassigned_count} vs {unassigned_recheck})")
        
        # Assertion 3: No negative counts
        for status, count in status_counts:
            if count < 0:
                sanity_pass = False
                fail_reasons.append(f"Negative count for status '{status}': {count}")
        
        # Assertion 4: Total should be positive if any data exists
        if status_counts and total_streets <= 0:
            sanity_pass = False
            fail_reasons.append(f"Invalid total streets count: {total_streets}")
        
        # === DISPLAY RESULTS ===
        
        print(f"📊 Total des rues: {total_streets}")
        print(f"📊 Rues non assignées: {unassigned_count}")
        print()
        
        print("📈 Répartition par statut:")
        for status, count in status_counts:
            print(f"  • {status}: {count}")
        print(f"  📋 Somme des statuts: {sum_status_counts}")
        print()
        
        print("📍 Top 10 rues (alphabétique):")
        for sector, name, team, status in top_streets[:10]:
            print(f"  • {sector} | {name} | {team} | {status}")
        print()
        
        # === WRITE CSV FILES (ALWAYS) ===
        
        status_file = exports_dir / f"sanity_status_counts_{timestamp}.csv"
        unassigned_file = exports_dir / f"sanity_unassigned_{timestamp}.csv"
        
        try:
            # Status counts CSV
            with open(status_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['status', 'count'])
                writer.writerows(status_counts)
            
            # Unassigned streets CSV
            with open(unassigned_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['secteur', 'rue'])
                writer.writerows(unassigned_streets)
            
            print("📁 Fichiers CSV créés:")
            print(f"  • {status_file}")
            print(f"  • {unassigned_file}")
            print()
            
        except Exception as e:
            print(f"⚠️  Erreur lors de l'écriture des CSV: {e}")
            print()
        
        # === FINAL SANITY CHECK RESULT ===
        
        conn.close()
        
        if sanity_pass:
            print("✅ Tous les tests de cohérence sont passés")
            print("SANITY: PASS")
            return 0
        else:
            print("❌ Échec des tests de cohérence:")
            for reason in fail_reasons:
                print(f"  • {reason}")
            print("SANITY: FAIL - Data integrity issues")
            return 1
            
    except sqlite3.Error as e:
        print(f"❌ Erreur base de données: {e}")
        print("SANITY: FAIL - Database error")
        return 1
    except Exception as e:
        print(f"❌ Erreur inattendue: {e}")
        print("SANITY: FAIL - Unexpected error")
        return 1

if __name__ == "__main__":
    sys.exit(main())
```
---8<--- tools/quick_sanity.py END ---

## STATISTIQUES
- Total fichiers exportés : 44
- Poids cumulé (approx) : 663.0 Ko
- Limite par fichier : 300 Ko
