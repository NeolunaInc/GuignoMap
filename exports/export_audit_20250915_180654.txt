# GuignoMap ‚Äî Export d‚Äôaudit COMPLET (code et config utiles)
# Date : 2025-09-15 18:06:55
# Racine : C:\Users\nick\guignomap_clone\GuignoMap
# Contenu : 100% des .py (zones pertinentes) + fichiers de config/migrations essentiels
# Exclus : backups, exports, caches, venv, .git, binaires, secrets (.streamlit/secrets.toml)

## ENVIRONNEMENT
- Python : 3.13.6 (tags/v3.13.6:4e66535, Aug  6 2025, 14:36:00) [MSC v.1944 64 bit (AMD64)]
- Ex√©cutable : C:\Users\nick\guignomap_clone\GuignoMap\.venv\Scripts\python.exe
- Plateforme : Windows-11-10.0.26100-SP0
- streamlit : 1.49.1
- sqlalchemy : 2.0.43
- pandas : 2.3.2
- boto3 : 1.34.144
- passlib : pr√©sent

### D√©pendances install√©es (inventaire)
alembic==1.16.5
altair==5.5.0
argon2-cffi-bindings==25.1.0
argon2-cffi==25.1.0
attrs==25.3.0
bcrypt==4.3.0
blinker==1.9.0
boto3==1.34.144
botocore==1.34.162
branca==0.8.1
cachetools==6.2.0
certifi==2025.8.3
cffi==2.0.0
charset-normalizer==3.4.3
click==8.2.1
colorama==0.4.6
folium==0.20.0
gitdb==4.0.12
GitPython==3.1.45
greenlet==3.2.4
idna==3.10
Jinja2==3.1.6
jmespath==1.0.1
jsonschema-specifications==2025.9.1
jsonschema==4.25.1
Mako==1.3.10
MarkupSafe==3.0.2
narwhals==2.5.0
numpy==2.3.3
overpy==0.7
packaging==25.0
pandas==2.3.2
passlib==1.7.4
pillow==11.3.0
pip==25.2
plotly==6.3.0
protobuf==6.32.1
psycopg2-binary==2.9.10
pyarrow==21.0.0
pycparser==2.23
pydeck==0.9.1
python-dateutil==2.9.0.post0
pytz==2025.2
referencing==0.36.2
reportlab==4.4.3
requests==2.32.5
rpds-py==0.27.1
s3transfer==0.10.4
six==1.17.0
smmap==5.0.2
SQLAlchemy==2.0.43
streamlit-folium==0.25.1
streamlit==1.49.1
tenacity==9.1.2
toml==0.10.2
tornado==6.5.2
typing_extensions==4.15.0
tzdata==2025.2
urllib3==2.5.0
watchdog==6.0.0
xlsxwriter==3.2.8
xyzservices==2025.4.0

## INDEX DES FICHIERS INCLUS
- .gitignore
- .streamlit/config.toml
- alembic.ini
- guignomap/__init__.py
- guignomap/app.py
- guignomap/backup.py
- guignomap/db.py
- guignomap/osm.py
- guignomap/reports.py
- guignomap/validators.py
- requirements.txt
- scripts/export_repo_audit.py
- scripts/export_repo_min.py
- scripts/export_repo_snapshot.py
- scripts/fix_app_types.py
- scripts/fix_specific.py
- scripts/migrate_password_hashes.py
- scripts/migrate_sqlite_to_postgres.py
- scripts/validation_dataframe.ps1
- src/auth/passwords.py
- src/config.py
- src/database/connection.py
- src/database/db_v5.py
- src/database/migrations/env.py
- src/database/models.py
- src/storage/__init__.py
- src/storage/cloud.py
- src/storage/local.py
- src/utils/__init__.py
- src/utils/adapters.py
- tests/manual/test_db_connection.py
- tests/manual/test_db_simple.py

## CONTENU DES FICHIERS

---8<--- .gitignore BEGIN ---
```txt
# ===============================================
# GITIGNORE POUR GUIGNO-MAP
# ===============================================

# ----------------------------------------
# ENVIRONNEMENTS PYTHON
# ----------------------------------------
.venv/
venv/
env/
ENV/
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
pip-log.txt
pip-delete-this-directory.txt

# ----------------------------------------
# BASES DE DONN√âES
# ----------------------------------------
*.db
*.sqlite
*.sqlite3
guigno_map.db

# ----------------------------------------
# CACHES & DONN√âES TEMPORAIRES
# ----------------------------------------
osm_cache.json
*.cache
*.tmp
.DS_Store
Thumbs.db

# ----------------------------------------
# LOGS & EXPORTS
# ----------------------------------------
*.log
export_*.txt
rapport_*.csv

# ----------------------------------------
# VS CODE & √âDITEURS
# ----------------------------------------
.vscode/
*.swp
*.swo
*~

# ----------------------------------------
# SYST√àME WINDOWS/LINUX
# ----------------------------------------
*.Zone.Identifier
.Trash-*
Desktop.ini

# ----------------------------------------
# D√âPENDANCES NODE (si ajout√©es plus tard)
# ----------------------------------------
node_modules/
npm-debug.log*

# ----------------------------------------
# STREAMLIT
# ----------------------------------------
.streamlit/secrets.toml

# ----------------------------------------
# DONN√âES SENSIBLES
# ----------------------------------------
*.key
*.pem
.env
config.ini

# ----------------------------------------
# FICHIERS DE SAUVEGARDE
# ----------------------------------------
*.bak
*.backup
*.save
*~

# ----------------------------------------
# KEEP THESE FILES (exceptions)
# ----------------------------------------
!.streamlit/config.toml
!guignomap/assets/
!requirements.txt
!README.md
# exports snapshots
/exports/
export.txt

```
---8<--- .gitignore END ---

---8<--- .streamlit/config.toml BEGIN ---
```toml
[theme]
# Th√®me sombre avec les couleurs du Relais
base = "dark"
primaryColor = "#A9CF3B"              # Vert du Relais
backgroundColor = "#0F1318"           # Fond tr√®s sombre
secondaryBackgroundColor = "#1A1F26"  # Fond secondaire
textColor = "#F2F3F5"                 # Texte clair
font = "sans serif"

[client]
# Configuration minimale de la toolbar
toolbarMode = "minimal"
showErrorDetails = false

[runner]
# Optimisations de performance
magicEnabled = true
installTracer = false
fixMatplotlib = true

[server]
# Configuration serveur
headless = true
runOnSave = true
maxUploadSize = 10
enableCORS = false
enableXsrfProtection = true

[deprecation]
# D√©sactiver les avertissements de d√©pr√©ciation
showImageFormat = false
showPyplotGlobalUse = false
```
---8<--- .streamlit/config.toml END ---

---8<--- alembic.ini BEGIN ---
```ini
# A generic, single database configuration.

[alembic]
# path to migration scripts.
# this is typically a path given in POSIX (e.g. forward slashes)
# format, relative to the token %(here)s which refers to the location of this
# ini file
script_location = %(here)s/src/database/migrations

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.  for multiple paths, the path separator
# is defined by "path_separator" below.
prepend_sys_path = .


# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library and tzdata library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to <script_location>/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "path_separator"
# below.
# version_locations = %(here)s/bar:%(here)s/bat:%(here)s/alembic/versions

# path_separator; This indicates what character is used to split lists of file
# paths, including version_locations and prepend_sys_path within configparser
# files such as alembic.ini.
# The default rendered in new alembic.ini files is "os", which uses os.pathsep
# to provide os-dependent path splitting.
#
# Note that in order to support legacy alembic.ini files, this default does NOT
# take place if path_separator is not present in alembic.ini.  If this
# option is omitted entirely, fallback logic is as follows:
#
# 1. Parsing of the version_locations option falls back to using the legacy
#    "version_path_separator" key, which if absent then falls back to the legacy
#    behavior of splitting on spaces and/or commas.
# 2. Parsing of the prepend_sys_path option falls back to the legacy
#    behavior of splitting on spaces, commas, or colons.
#
# Valid values for path_separator are:
#
# path_separator = :
# path_separator = ;
# path_separator = space
# path_separator = newline
#
# Use os.pathsep. Default configuration used for new projects.
path_separator = os

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

# database URL.  This is consumed by the user-maintained env.py script only.
# other means of configuring database URLs may be customized within the env.py
# file.
# sqlalchemy.url = driver://user:pass@localhost/dbname
# Note: URL configured programmatically via src.config in env.py


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the module runner, against the "ruff" module
# hooks = ruff
# ruff.type = module
# ruff.module = ruff
# ruff.options = check --fix REVISION_SCRIPT_FILENAME

# Alternatively, use the exec runner to execute a binary found on your PATH
# hooks = ruff
# ruff.type = exec
# ruff.executable = ruff
# ruff.options = check --fix REVISION_SCRIPT_FILENAME

# Logging configuration.  This is also consumed by the user-maintained
# env.py script only.
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S

```
---8<--- alembic.ini END ---

---8<--- guignomap/__init__.py BEGIN ---
```py

```
---8<--- guignomap/__init__.py END ---

---8<--- guignomap/app.py BEGIN ---
```py
"""
Guigno-Map - Application de gestion de collecte de denr√©es
Le Relais de Mascouche
Version 3.0 - Production
"""

from pathlib import Path
import time
from datetime import datetime
import pandas as pd
import streamlit as st
import folium
from streamlit_folium import st_folium

# Import des modules locaux
import db_v5 as db
from validators import validate_and_clean_input
from osm import build_geometry_cache, load_geometry_cache, build_addresses_cache, load_addresses_cache, CACHE_FILE
from src.utils.adapters import to_dataframe

# Configuration des chemins - Legacy pour backup seulement
DB_PATH = Path(__file__).parent / "guigno_map.db"

# --- Utilitaire de compatibilit√© pandas Styler ---
from typing import Callable, Any

def style_map_compat(df: pd.DataFrame, fn: Callable[[Any], str], subset: Any = None):
    """Applique un style cellule-√†-cellule en utilisant Styler.map si disponible,
    sinon fallback dynamique vers applymap sans exposer l'attribut (OK pour Pylance).
    
    Args:
        df: DataFrame √† styliser
        fn: Fonction qui prend une valeur cellule et retourne une string CSS
        subset: Colonnes √† cibler (ex: ['status'] ou None pour toutes)
    """
    styler = df.style
    if hasattr(styler, "map"):
        # Pandas 2.4+ : utilise la nouvelle API map()
        return styler.map(fn, subset=subset)
    # Pandas < 2.4 : fallback vers applymap (sans r√©f√©rence statique)
    return getattr(styler, "applymap")(fn, subset=subset)

# --- Mapping des statuts pour l'affichage ---
STATUS_TO_LABEL = {"a_faire": "√Ä faire", "en_cours": "En cours", "terminee": "Termin√©e"}
LABEL_TO_STATUS = {v: k for k, v in STATUS_TO_LABEL.items()}

ASSETS = Path(__file__).parent / "assets"

# Configuration Streamlit
st.set_page_config(
    page_title="Guigno-Map | Relais de Mascouche",
    page_icon="üéÅ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialisation session
if "auth" not in st.session_state:
    st.session_state.auth = None

# ============================================
# COMPOSANTS UI
# ============================================

def inject_css():
    """Charge le CSS depuis le fichier externe"""
    css_file = ASSETS / "styles.css"
    if css_file.exists():
        css = css_file.read_text(encoding="utf-8")
        st.markdown(f"<style>{css}</style>", unsafe_allow_html=True)

def render_header():
    """Header moderne avec logo Guignol√©e et design festif"""
    
    # Container principal avec fond festif
    st.markdown("""
    <div style="
        background: linear-gradient(135deg, #c41e3a 0%, #165b33 100%);
        border-radius: 20px;
        padding: 2rem;
        margin-bottom: 2rem;
        position: relative;
        overflow: hidden;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    ">
        <!-- Flocons de neige anim√©s en CSS -->
        <div style="position: absolute; width: 100%; height: 100%; opacity: 0.1;">
            <span style="position: absolute; top: 10%; left: 10%; font-size: 2rem;">‚ùÑÔ∏è</span>
            <span style="position: absolute; top: 20%; left: 80%; font-size: 1.5rem;">‚ùÑÔ∏è</span>
            <span style="position: absolute; top: 60%; left: 30%; font-size: 1.8rem;">‚ùÑÔ∏è</span>
        </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([2, 5, 2])
    
    with col1:
        # Logo Guignol√©e
        if (ASSETS / "guignolee.png").exists():
            st.image(str(ASSETS / "guignolee.png"), width=150)
    
    with col2:
        st.markdown("""
        <div style="text-align: center;">
            <h1 style="
                color: white;
                font-family: 'Manrope', sans-serif;
                font-size: 2.5rem;
                margin: 0;
                text-shadow: 3px 3px 6px rgba(0,0,0,0.5);
                letter-spacing: 2px;
            ">üéÖ GUIGNOL√âE 2025 üéÅ</h1>
            <p style="
                color: #FFD700;
                font-size: 1.2rem;
                margin: 0.5rem 0 0 0;
                font-weight: 600;
            ">Le Relais de Mascouche - 1er d√©cembre</p>
            <p style="
                color: rgba(255,255,255,0.9);
                font-size: 1rem;
                margin-top: 0.5rem;
            ">Syst√®me de gestion de collecte</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        # Stats en temps r√©el
        stats = db.extended_stats()
        progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
        
        st.markdown(f"""
        <div style="
            background: rgba(255,255,255,0.2);
            border-radius: 15px;
            padding: 1rem;
            text-align: center;
        ">
            <div style="color: #FFD700; font-size: 2rem; font-weight: bold;">
                {progress:.0f}%
            </div>
            <div style="color: white; font-size: 0.9rem;">
                Compl√©t√©
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

def render_login_card(role="benevole", conn=None):
    """Carte de connexion moderne avec design festif"""
    
    # Container de connexion stylis√©
    st.markdown("""
    <div style="
        max-width: 400px;
        margin: 3rem auto;
        background: linear-gradient(135deg, rgba(255,255,255,0.1), rgba(255,255,255,0.05));
        backdrop-filter: blur(10px);
        border: 2px solid rgba(255,215,0,0.3);
        border-radius: 20px;
        padding: 2rem;
        box-shadow: 0 20px 40px rgba(0,0,0,0.3);
    ">
    """, unsafe_allow_html=True)
    
    # Ic√¥ne et titre
    if role == "superviseur" or role == "gestionnaire":
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <div style="font-size: 3rem;">üëî</div>
            <h2 style="color: #FFD700; margin: 1rem 0;">Espace Gestionnaire</h2>
            <p style="color: #cbd5e1;">G√©rez la collecte et les √©quipes</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_gestionnaire", clear_on_submit=False):
            password = st.text_input(
                "üîê Mot de passe",
                type="password",
                placeholder="Entrez le mot de passe gestionnaire"
            )
            
            col1, col2, col3 = st.columns([1,2,1])
            with col2:
                submit = st.form_submit_button(
                    "üöÄ Connexion",
                    width="stretch"
                )
            
            if submit:
                if db.verify_team("ADMIN", password):
                    st.session_state.auth = {"role": "supervisor", "team_id": "ADMIN"}
                    st.success("‚úÖ Bienvenue dans l'espace gestionnaire!")
                    st.snow()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("‚ùå Mot de passe incorrect")
    
    else:  # B√©n√©vole
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <div style="font-size: 3rem;">üéÖ</div>
            <h2 style="color: #FFD700; margin: 1rem 0;">Espace B√©n√©vole</h2>
            <p style="color: #cbd5e1;">Acc√©dez √† vos rues assign√©es</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("login_benevole", clear_on_submit=False):
            col1, col2 = st.columns(2)
            
            with col1:
                team_id = st.text_input(
                    "üë• Identifiant d'√©quipe",
                    placeholder="Ex: EQ001"
                )
            
            with col2:
                password = st.text_input(
                    "üîê Mot de passe",
                    type="password",
                    placeholder="Mot de passe √©quipe"
                )
            
            col1, col2, col3 = st.columns([1,2,1])
            with col2:
                submit = st.form_submit_button(
                    "üéÑ Connexion",
                    width="stretch"
                )
            
            if submit:
                if db.verify_team(team_id, password):
                    st.session_state.auth = {"role": "volunteer", "team_id": team_id}
                    st.success(f"‚úÖ Bienvenue √©quipe {team_id}!")
                    st.snow()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("‚ùå Identifiants incorrects")
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    # Aide en bas
    st.markdown("""
    <div style="text-align: center; margin-top: 2rem; color: #8b92a4;">
        <small>
        Besoin d'aide? Contactez votre gestionnaire<br>
        üìû 450-474-4133
        </small>
    </div>
    """, unsafe_allow_html=True)

def render_metrics(stats):
    """Affiche les m√©triques principales"""
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Rues", stats['total'])
    
    with col2:
        st.metric("Rues Termin√©es", stats['done'])
    
    with col3:
        st.metric("En Cours", stats.get('partial', 0))
    
    with col4:
        st.metric("Progression", f"{progress:.1f}%")

def render_dashboard_gestionnaire(conn, geo):
    """Dashboard moderne pour gestionnaires avec KPIs visuels"""
    
    # KPIs principaux en cartes color√©es
    stats = db.extended_stats()
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    st.markdown("### üìä Tableau de bord en temps r√©el")
    
    # Ligne de KPIs avec ic√¥nes festives
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #22c55e, #16a34a);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(34,197,94,0.3);
        ">
            <div style="font-size: 2.5rem;">üèòÔ∏è</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats['total']}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Total Rues</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(59,130,246,0.3);
        ">
            <div style="font-size: 2.5rem;">‚úÖ</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats['done']}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Termin√©es</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #f59e0b, #d97706);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(245,158,11,0.3);
        ">
            <div style="font-size: 2.5rem;">üö∂</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{stats.get('partial', 0)}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">En cours</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        # Nombre d'√©quipes actives
        teams_count = len(db.teams())
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #8b5cf6, #7c3aed);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(139,92,246,0.3);
        ">
            <div style="font-size: 2.5rem;">üë•</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{teams_count}</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">√âquipes</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col5:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #c41e3a, #165b33);
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(196,30,58,0.3);
        ">
            <div style="font-size: 2.5rem;">üéØ</div>
            <div style="color: white; font-size: 2rem; font-weight: bold;">{progress:.0f}%</div>
            <div style="color: rgba(255,255,255,0.9); font-size: 0.9rem;">Progression</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Barre de progression visuelle
    st.markdown("### üéÑ Progression globale")
    st.progress(progress / 100)
    
    # Graphique par secteur (si disponible)
    st.markdown("### üìà Performance par √©quipe")
    try:
        teams_stats = db.stats_by_team()
        if teams_stats:  # Liste non vide
            # Convertir en DataFrame pour plotly
            import pandas as pd
            teams_df = pd.DataFrame(teams_stats)
            
            # Calculer le pourcentage de progression
            teams_df['progress'] = ((teams_df['completed'] / teams_df['total_streets']) * 100).fillna(0)
            
            # Graphique en barres color√©es
            import plotly.express as px
            fig = px.bar(
                teams_df, 
                x='id', 
                y='progress',
                color='progress',
                color_continuous_scale=['#ef4444', '#f59e0b', '#22c55e'],
                labels={'team': '√âquipe', 'progress': 'Progression (%)'},
                title="Performance des √©quipes"
            )
            fig.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig, width="stretch")
        else:
            st.info("Aucune statistique d'√©quipe disponible")
    except Exception as e:
        st.warning("Graphiques non disponibles (module plotly manquant)")
        # Fallback vers un tableau simple
        try:
            teams_stats = db.stats_by_team()
            if teams_stats:  # Liste non vide
                st.dataframe(to_dataframe(teams_stats), width="stretch")
        except:
            st.info("Aucune statistique d'√©quipe disponible")

def add_persistent_legend(m):
    """Ajoute une l√©gende persistante pour les 4 √©tats des rues via contr√¥le HTML"""
    legend_html = """
    <div id='gm-legend' class='leaflet-control-layers leaflet-control' 
         style='position: absolute; bottom: 10px; right: 10px; z-index: 1000;
                background: white; border: 2px solid rgba(0,0,0,0.2); 
                border-radius: 5px; padding: 10px; box-shadow: 0 1px 5px rgba(0,0,0,0.2);
                font-family: "Helvetica Neue", Arial, Helvetica, sans-serif; 
                font-size: 12px; line-height: 18px; color: #333;'>
        <strong style='margin-bottom: 8px; display: block;'>L√©gende</strong>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #28a745; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Termin√©e</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #f1c40f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>En cours</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px solid #ff4d4f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Assign√©e (√† faire)</span>
        </div>
        <div style='margin: 4px 0; display: flex; align-items: center;'>
            <span style='width: 20px; height: 0; border-top: 3px dashed #ff4d4f; 
                         display: inline-block; margin-right: 8px;'></span>
            <span>Non assign√©e</span>
        </div>
    </div>
    """
    m.get_root().html.add_child(folium.Element(legend_html))

def create_map(df, geo):
    """Cr√©e la carte Folium centr√©e sur Mascouche avec toutes les rues"""
    # 1) Coercition s√ªre en DataFrame
    if not isinstance(df, pd.DataFrame):
        try:
            df = pd.DataFrame(df)
        except Exception:
            df = pd.DataFrame([])
    
    # Limites de Mascouche
    bounds = {
        "north": 45.78,
        "south": 45.70,
        "east": -73.55,
        "west": -73.70
    }
    center = [(bounds["north"] + bounds["south"]) / 2, 
              (bounds["east"] + bounds["west"]) / 2]
    
    # Cr√©er la carte
    m = folium.Map(
        location=center,
        zoom_start=13,  # Zoom optimis√© pour voir toute la ville
        tiles="https://{s}.tile.openstreetmap.fr/osmfr/{z}/{x}/{y}.png",
        attr='¬© OpenStreetMap France',
        control_scale=True,
        max_bounds=True,
        min_zoom=11,
        max_zoom=18,
        prefer_canvas=True,
        zoom_control=True,
        scrollWheelZoom=True
    )
    
    # Ajouter plusieurs couches de fond
    folium.TileLayer(
        tiles='https://{s}.tile.openstreetmap.fr/osmfr/{z}/{x}/{y}.png',
        attr='¬© OpenStreetMap France',
        name='OSM France (D√©taill√©)',
        overlay=False,
        control=True
    ).add_to(m)

    folium.TileLayer(
        tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager/{z}/{x}/{y}.png',
        attr='¬© CARTO',
        name='CARTO Voyager',
        overlay=False,
        control=True
    ).add_to(m)

    folium.TileLayer(
        tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Street_Map/MapServer/tile/{z}/{y}/{x}',
        attr='¬© Esri',
        name='Esri WorldStreetMap',
        overlay=False,
        control=True
    ).add_to(m)

    # Ajouter le contr√¥le des couches
    folium.LayerControl().add_to(m)
    
    # D√©finir les limites de la carte sur Mascouche
    m.fit_bounds([[bounds["south"], bounds["west"]], 
                  [bounds["north"], bounds["east"]]])
    
    if not geo:
        st.warning("Aucune donn√©e g√©om√©trique disponible")
        return m
    
    # Construire le lookup des infos DB
    street_info = {}
    if not df.empty:  # DataFrame non vide
        for idx, row in df.iterrows():
            name = str(row.get('name', '')) if pd.notna(row.get('name', '')) else ''
            status = row.get('status', 'a_faire')
            status = status if pd.notna(status) else 'a_faire'
            team = row.get('team', '')
            team = team if pd.notna(team) else ''
            notes = str(row.get('notes', '0')) if pd.notna(row.get('notes', '0')) else '0'
            
            street_info[name] = {
                'status': status,
                'team': str(team).strip() if team else '',
                'notes': notes
            }
    
    # Couleurs par statut
    status_colors = {
        'terminee': '#22c55e',  # Vert
        'en_cours': '#f59e0b',  # Orange
        'a_faire': '#ef4444'    # Rouge
    }
    
    # Compteurs pour stats
    stats = {"total": 0, "assigned": 0, "unassigned": 0}
    
    # Ajouter TOUTES les rues de la g√©om√©trie
    for name, paths in geo.items():
        stats["total"] += 1
        
        # Info depuis DB ou d√©faut (rouge pointill√©)
        info = street_info.get(name, {
            'status': 'a_faire',
            'team': '',
            'notes': '0'
        })
        
        status = info['status']
        team = info['team']
        notes = info['notes']
        
        # Style: TOUJOURS pointill√© si pas d'√©quipe
        has_team = bool(team)
        color = status_colors.get(status, '#ef4444')  # Rouge par d√©faut
        opacity = 0.9 if has_team else 0.7
        dash = None if has_team else '8,12'  # Pointill√©s si non assign√©
        weight = 7 if has_team else 5
        
        if has_team:
            stats["assigned"] += 1
        else:
            stats["unassigned"] += 1
        
        # Tooltip informatif
        tooltip_html = f"""
        <div style='font-family: sans-serif'>
            <strong style='font-size: 14px'>{name}</strong><br>
            <span style='color: {color}'>‚óè Statut: {status.replace('_', ' ').title()}</span><br>
            <span>üìã √âquipe: {team if team else '‚ö†Ô∏è NON ASSIGN√âE'}</span><br>
            <span>üìù Notes: {notes}</span>
        </div>
        """
        
        # Ajouter chaque segment de la rue
        for path in paths:
            if path and len(path) >= 2:
                folium.PolyLine(
                    path,
                    color=color,
                    weight=weight,
                    opacity=opacity,
                    dash_array=dash,
                    tooltip=folium.Tooltip(tooltip_html, sticky=True)
                ).add_to(m)
    
    # Ajouter un marqueur au centre-ville
    folium.Marker(
        [45.7475, -73.6005],
        popup="Centre-ville de Mascouche",
        tooltip="Centre-ville",
        icon=folium.Icon(color='red', icon='info-sign')
    ).add_to(m)
    
    # Ajouter la l√©gende persistante
    add_persistent_legend(m)
    
    return m


# ============================================
# UTILITAIRES EXPORT
# ============================================

def export_excel_professionnel(conn):
    """Export Excel avec mise en forme professionnelle"""
    try:
        from reports import ReportGenerator
        generator = ReportGenerator(conn)
        return generator.generate_excel()
    except ImportError:
        # Fallback si les d√©pendances ne sont pas install√©es
        return db.export_to_csv()


# ============================================
# FONCTIONNALIT√âS AVANC√âES
# ============================================

def detect_mobile():
    """D√©tecte si l'utilisateur est sur mobile"""
    try:
        # R√©cup√©rer les param√®tres de l'URL pour forcer le mode mobile
        query_params = st.experimental_get_query_params()
        if 'mobile' in query_params:
            return True
        
        # Mobile-first approach pour l'instant
        return True
    except:
        return False

def show_notification(message, type="success"):
    """Affiche une notification stylis√©e"""
    icons = {
        "success": "‚úÖ",
        "error": "‚ùå",
        "warning": "‚ö†Ô∏è",
        "info": "‚ÑπÔ∏è"
    }
    colors = {
        "success": "#22c55e",
        "error": "#ef4444", 
        "warning": "#f59e0b",
        "info": "#3b82f6"
    }
    
    st.markdown(f"""
    <div style="
        position: fixed;
        top: 20px;
        right: 20px;
        background: {colors[type]};
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 10px;
        box-shadow: 0 5px 15px rgba(0,0,0,0.3);
        z-index: 9999;
        animation: slideIn 0.3s ease-out;
    ">
        <strong>{icons[type]} {message}</strong>
    </div>
    <style>
    @keyframes slideIn {{
        from {{ transform: translateX(100%); opacity: 0; }}
        to {{ transform: translateX(0); opacity: 1; }}
    }}
    </style>
    """, unsafe_allow_html=True)

def show_team_badges(conn, team_id):
    """Affiche les badges de r√©ussite de l'√©quipe"""
    try:
        df = db.list_streets(team=team_id)
        done = len(df[df['status'] == 'terminee'])
        total = len(df)
        
        badges = []
        if done >= 1:
            badges.append("üèÜ Premi√®re rue!")
        if done >= total * 0.25:
            badges.append("ü•â 25% compl√©t√©")
        if done >= total * 0.5:
            badges.append("ü•à 50% compl√©t√©")
        if done >= total * 0.75:
            badges.append("ü•á 75% compl√©t√©")
        if done == total:
            badges.append("üåü CHAMPION!")
        
        if badges:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #FFD700, #FFA500);
                padding: 1rem;
                border-radius: 10px;
                text-align: center;
                margin: 1rem 0;
            ">
                <strong>Vos badges:</strong><br>
                <div style="font-size: 2rem; margin-top: 0.5rem;">
                    {' '.join(badges)}
                </div>
            </div>
            """, unsafe_allow_html=True)
    except:
        pass

def generate_sms_list(conn):
    """G√©n√®re une liste de t√©l√©phones pour SMS de groupe"""
    try:
        # Cette fonction n√©cessiterait une table de t√©l√©phones
        # Pour l'instant, retourne un exemple
        return "# Liste des t√©l√©phones b√©n√©voles\n# 450-XXX-XXXX\n# 438-XXX-XXXX"
    except:
        return "Liste non disponible"

def page_export_gestionnaire(conn):
    """Section export avec formats multiples"""
    
    st.markdown("### üìä Centre d'export des donn√©es")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>ÔøΩ Rapport PDF</h4>
            <p><small>Format professionnel pour pr√©sentation</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            from reports import ReportGenerator
            generator = ReportGenerator(conn)
            pdf_data = generator.generate_pdf()
            st.download_button(
                "üì• T√©l√©charger PDF",
                pdf_data,
                "rapport_guignolee_2025.pdf",
                "application/pdf",
                width="stretch"
            )
        except ImportError:
            st.button("PDF (Installer reportlab)", disabled=True, width="stretch")
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>üìä Excel d√©taill√©</h4>
            <p><small>Avec graphiques et mise en forme</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            excel_data = export_excel_professionnel(conn)
            st.download_button(
                "üì• T√©l√©charger Excel",
                excel_data,
                "guignolee_2025.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width="stretch"
            )
        except:
            st.button("Excel (Non disponible)", disabled=True, width="stretch")
    
    with col3:
        st.markdown("""
        <div style="text-align: center; padding: 1rem; border: 2px dashed #ccc; border-radius: 10px;">
            <h4>üì± Liste SMS</h4>
            <p><small>T√©l√©phones des b√©n√©voles</small></p>
        </div>
        """, unsafe_allow_html=True)
        
        sms_list = generate_sms_list(conn)
        st.download_button(
            "üì• Liste t√©l√©phones",
            sms_list,
            "telephones_benevoles.txt",
            "text/plain",
            width="stretch"
        )


# ============================================
# PAGES
# ============================================

def page_accueil(conn, geo):
    """Page d'accueil"""
    st.markdown("### üéÅ Bienvenue sur Guigno-Map!")
    st.info("S√©lectionnez votre mode dans le menu de gauche pour commencer.")
    
    st.markdown("---")
    st.markdown("#### üìä Aper√ßu de la collecte")
    
    stats = db.extended_stats()
    render_metrics(stats)
    
    df_all = db.list_streets()
    if df_all:  # Liste non vide
        m = create_map(df_all, geo)
        st_folium(m, height=800, width=None, returned_objects=[])

def page_accueil_v2(conn, geo):
    """Page d'accueil festive avec compte √† rebours"""
    
    # Compte √† rebours jusqu'au 1er d√©cembre
    from datetime import datetime, timedelta
    target = datetime(2025, 12, 1, 8, 0, 0)
    now = datetime.now()
    diff = target - now
    
    if diff.days > 0:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #c41e3a, #165b33);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h2 style="color: #FFD700; margin: 0;">‚è∞ Compte √† rebours Guignol√©e</h2>
            <div style="font-size: 3rem; color: white; margin: 1rem 0;">
                {diff.days} jours {diff.seconds//3600} heures
            </div>
            <p style="color: rgba(255,255,255,0.9);">avant le grand jour!</p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #FFD700, #FFA500);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h2 style="color: #c41e3a; margin: 0;">üéâ C'EST AUJOURD'HUI!</h2>
            <div style="font-size: 2rem; color: #165b33; margin: 1rem 0;">
                Bonne Guignol√©e 2025!
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # Hero section festif
    st.markdown("""
    <div style="
        text-align: center;
        padding: 3rem 1rem;
        background: linear-gradient(135deg, rgba(196,30,58,0.1), rgba(22,91,51,0.1));
        border-radius: 20px;
        margin-bottom: 2rem;
    ">
        <h1 style="font-size: 3rem; margin: 0;">üéÑ Bienvenue sur Guigno-Map üéÑ</h1>
        <p style="font-size: 1.3rem; color: #666; margin: 1rem 0;">
            Votre plateforme digitale pour la Guignol√©e 2025
        </p>
        <p style="color: #888;">
            G√©rez efficacement votre collecte de denr√©es avec une interface moderne
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Stats visuelles am√©lior√©es
    stats = db.extended_stats()
    progress = (stats['done'] / stats['total'] * 100) if stats['total'] > 0 else 0
    
    st.markdown("### üìä √âtat de la collecte en temps r√©el")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #22c55e, #16a34a);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(34,197,94,0.3);
        ">
            <div style="font-size: 3rem;">üèòÔ∏è</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats['total']}</div>
            <div>Total Rues</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(59,130,246,0.3);
        ">
            <div style="font-size: 3rem;">‚úÖ</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats['done']}</div>
            <div>Compl√©t√©es</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #f59e0b, #d97706);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(245,158,11,0.3);
        ">
            <div style="font-size: 3rem;">üö∂</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{stats.get('partial', 0)}</div>
            <div>En Cours</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div style="
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #c41e3a, #165b33);
            border-radius: 15px;
            color: white;
            box-shadow: 0 4px 15px rgba(196,30,58,0.3);
        ">
            <div style="font-size: 3rem;">üéØ</div>
            <div style="font-size: 2.5rem; font-weight: bold;">{progress:.0f}%</div>
            <div>Progression</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Barre de progression globale
    st.markdown("### üéÑ Progression globale de la collecte")
    st.progress(progress / 100)
    
    # Carte festive
    st.markdown("### üó∫Ô∏è Vue d'ensemble de Mascouche")
    df_all = db.list_streets()
    if df_all:  # Liste non vide
        m = create_map(df_all, geo)
        st_folium(m, height=750, width=None, returned_objects=[])
    
    # CSS pour r√©duire l'espace apr√®s la carte
    st.markdown("""
    <style>
    div[data-testid="stVerticalBlock"] > div:has(iframe) {
        margin-bottom: 0 !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Call to action
    st.markdown("""
    <div style="
        text-align: center;
        padding: 2rem;
        background: linear-gradient(135deg, rgba(255,215,0,0.1), rgba(255,215,0,0.05));
        border: 2px solid rgba(255,215,0,0.3);
        border-radius: 15px;
        margin-top: 1rem;
    ">
        <h3>üéÖ Pr√™t √† participer ?</h3>
        <p>Choisissez votre r√¥le dans le menu de gauche pour commencer</p>
        <p style="font-size: 0.9rem; color: #666;">
            B√©n√©voles : Acc√©dez √† vos rues assign√©es<br>
            Gestionnaires : Supervisez toute la collecte
        </p>
    </div>
    """, unsafe_allow_html=True)

def page_benevole(conn, geo):
    """Interface b√©n√©vole moderne avec vue limit√©e"""
    
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        render_login_card("benevole", conn)
        return
    
    team_id = st.session_state.auth["team_id"]
    
    # Header d'√©quipe personnalis√©
    st.markdown(f"""
    <div style="
        background: linear-gradient(135deg, #165b33, #c41e3a);
        padding: 1.5rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
    ">
        <h2 style="color: white; margin: 0;">üéÖ √âquipe {team_id}</h2>
        <p style="color: #FFD700; margin: 0.5rem 0 0 0;">Bonne collecte!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Stats de l'√©quipe
    df_team = db.list_streets(team=team_id)
    if not df_team:  # Liste vide
        st.warning("Aucune rue assign√©e. Contactez votre superviseur.")
        return
    
    done = len(df_team[df_team['status'] == 'terminee'])
    total = len(df_team)
    progress = (done / total * 100) if total > 0 else 0
    
    # Mini dashboard √©quipe
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìç Vos rues", total)
    with col2:
        st.metric("‚úÖ Compl√©t√©es", done)
    with col3:
        st.metric("üéØ Progression", f"{progress:.0f}%")
    
    # Syst√®me de badges
    show_team_badges(conn, team_id)
    
    # Barre de progression
    st.progress(progress / 100)
    
    # Tabs modernis√©s
    tab1, tab2, tab3 = st.tabs(["üó∫Ô∏è Ma carte", "üìù Collecte", "üìä Historique"])
    
    with tab1:
        # CARTE LIMIT√âE AUX RUES DE L'√âQUIPE
        st.markdown("### Vos rues assign√©es")
        
        # Cr√©er une carte avec SEULEMENT les rues de l'√©quipe
        m = folium.Map(
            location=[45.7475, -73.6005],
            zoom_start=14,
            tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager/{z}/{x}/{y}.png',
            attr='¬© CARTO'
        )
        
        # Filtrer geo pour n'afficher QUE les rues de l'√©quipe
        team_streets = df_team['name'].tolist()
        
        for street_name in team_streets:
            if street_name in geo:
                status = df_team[df_team['name'] == street_name]['status'].iloc[0]
                
                # Couleurs selon statut
                colors = {
                    'terminee': '#22c55e',
                    'en_cours': '#f59e0b',
                    'a_faire': '#ef4444'
                }
                color = colors.get(status, '#ef4444')
                
                # Ajouter les segments de cette rue
                for path in geo[street_name]:
                    if path and len(path) >= 2:
                        folium.PolyLine(
                            path,
                            color=color,
                            weight=8,  # Plus √©pais pour mobile
                            opacity=0.9,
                            tooltip=f"{street_name} - {status.replace('_', ' ').title()}"
                        ).add_to(m)
        
        # Centrer sur les rues de l'√©quipe
        if team_streets and team_streets[0] in geo:
            first_street = geo[team_streets[0]][0]
            if first_street:
                m.location = first_street[0]
        
        st_folium(m, height=650, width=None, returned_objects=[])
    
    with tab2:
        st.markdown("### üìã Checklist de collecte")
        
        # Liste interactive des rues
        for row in df_team:
            street = row['name']
            status = row['status']
            notes_count = row.get('notes', 0)
            
            # Carte de rue stylis√©e
            status_emoji = {'terminee': '‚úÖ', 'en_cours': 'üö∂', 'a_faire': '‚≠ï'}
            status_color = {'terminee': '#22c55e', 'en_cours': '#f59e0b', 'a_faire': '#ef4444'}
            
            with st.expander(f"{status_emoji.get(status, '‚≠ï')} **{street}** ({notes_count} notes)"):
                
                # Changement rapide de statut
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("‚≠ï √Ä faire", key=f"todo_{street}", width="stretch"):
                        db.set_status(street, 'a_faire')
                        st.rerun()
                with col2:
                    if st.button("üö∂ En cours", key=f"progress_{street}", width="stretch"):
                        db.set_status(street, 'en_cours')
                        st.rerun()
                with col3:
                    if st.button("‚úÖ Termin√©e", key=f"done_{street}", width="stretch"):
                        db.set_status(street, 'terminee')
                        st.rerun()
                
                st.markdown("---")
                
                # Ajout de note rapide
                st.markdown("**Ajouter une note:**")
                with st.form(f"note_{street}", clear_on_submit=True):
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        num = st.text_input("N¬∞", placeholder="123")
                    with col2:
                        note = st.text_input("Note", placeholder="Personne absente")
                    
                    if st.form_submit_button("‚ûï Ajouter"):
                        if num and note:
                            db.add_note_for_address(street, team_id, num, note)
                            st.success("Note ajout√©e!")
                            st.rerun()
                
                # Notes existantes
                notes = db.get_street_addresses_with_notes(street)
                if notes:  # Liste non vide
                    st.markdown("**Notes existantes:**")
                    for n in notes:
                        st.markdown(f"‚Ä¢ **{n['address_number']}** : {n['comment']}")
    
    with tab3:
        st.markdown("### üìä Votre historique")
        try:
            notes = db.get_team_notes(team_id)
            if notes:  # Liste non vide
                st.dataframe(to_dataframe(notes), width="stretch")
            else:
                st.info("Aucune note encore")
        except:
            st.info("Historique non disponible")

def page_benevole_v2(conn, geo):
    """Interface b√©n√©vole moderne v4.1 avec vue 'Mes rues'"""
    
    # V√©rifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        # Afficher la page de connexion b√©n√©vole
        return page_benevole(conn, geo)
    
    # Interface b√©n√©vole connect√© avec tabs
    st.header("üéÖ Espace B√©n√©vole")
    team_id = st.session_state.auth.get("team", "√âquipe inconnue")
    st.markdown(f"**√âquipe:** {team_id}")
    
    # Tabs pour b√©n√©voles
    tabs = st.tabs([
        "üèòÔ∏è Mes rues",
        "üó∫Ô∏è Carte de terrain", 
        "üìù Journal d'activit√©"
    ])
    
    with tabs[0]:
        # Nouvelle vue "Mes rues" v4.1
        page_benevole_mes_rues(conn)
    
    with tabs[1]:
        # Carte traditionnelle (r√©utilise l'ancienne interface)
        page_benevole(conn, geo)
    
    with tabs[2]:
        # Journal d'activit√© de l'√©quipe
        st.markdown("### üìù Journal d'activit√© de votre √©quipe")
        try:
            # Afficher les activit√©s r√©centes de l'√©quipe
            cursor = conn.execute("""
                SELECT action, details, created_at
                FROM activity_log
                WHERE team_id = ?
                ORDER BY created_at DESC
                LIMIT 20
            """, (team_id,))
            
            activities = cursor.fetchall()
            if activities:
                for activity in activities:
                    action, details, created_at = activity
                    st.markdown(f"**{created_at}** - {action}: {details}")
            else:
                st.info("Aucune activit√© enregistr√©e pour votre √©quipe")
                
        except Exception as e:
            st.info("Journal d'activit√© temporairement indisponible")
            st.caption(f"Erreur: {e}")

def page_gestionnaire_v2(conn, geo):
    """Interface gestionnaire moderne (ancien superviseur)"""
    st.header("üëî Tableau de Bord Gestionnaire")
    
    # V√©rifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        render_login_card("gestionnaire", conn)
        return
    
    # Dashboard moderne
    render_dashboard_gestionnaire(conn, geo)
    
    # Tabs
    tabs = st.tabs([
        "üìä Vue d'ensemble",
        "üë• √âquipes",
        "üó∫Ô∏è Assignation",
        "üì• Export",
        "üõ† Tech"
    ])
    
    with tabs[0]:
        # Carte g√©n√©rale
        st.markdown("### Carte g√©n√©rale")
        df_all = db.list_streets()
        if df_all:  # Liste non vide
            m = create_map(df_all, geo)
            st_folium(m, height=800, width=None, returned_objects=[])
        
        # Activit√© r√©cente
        st.markdown("### Activit√© r√©cente")
        try:
            recent = db.recent_activity(limit=10)
            if recent:  # Liste non vide
                st.dataframe(to_dataframe(recent), width="stretch")
            else:
                st.info("Aucune activit√© r√©cente")
        except:
            st.info("Historique d'activit√© non disponible")
    
    with tabs[1]:
        # Gestion des √©quipes
        st.subheader("üë• Gestion des √©quipes", anchor=False)
        
        # === Formulaire de cr√©ation d'√©quipe (robuste) ===
        with st.expander("‚ûï Cr√©er une nouvelle √©quipe", expanded=False):
            with st.form("create_team_form", clear_on_submit=True):
                team_id_in = st.text_input(
                    "Identifiant d'√©quipe", 
                    key="new_team_id", 
                    placeholder="Ex: EQUIPE1",
                    help="Lettres et chiffres uniquement, max 20 caract√®res"
                )
                team_name_in = st.text_input(
                    "Nom d'√©quipe", 
                    key="new_team_name", 
                    placeholder="Ex: √âquipe Centre",
                    help="Nom descriptif de l'√©quipe"
                )
                
                # Toggle pour afficher/masquer les mots de passe
                show_pw = st.checkbox("Afficher les mots de passe", value=False)
                pw_type = "default" if show_pw else "password"
                
                pwd_in = st.text_input(
                    "Mot de passe", 
                    type=pw_type, 
                    key="new_team_pwd", 
                    placeholder="Minimum 4 caract√®res",
                    help="Tout caract√®re accept√©, min 4 / max 128"
                )
                pwd_conf = st.text_input(
                    "Confirmer le mot de passe", 
                    type=pw_type, 
                    key="new_team_pwd_conf", 
                    placeholder="Retapez le mot de passe",
                    help="Doit correspondre au mot de passe ci-dessus"
                )
                
                submitted = st.form_submit_button("‚úÖ Cr√©er l'√©quipe", width="stretch")

            if submitted:
                # Validation avec validators.py
                ok_id, team_id = validate_and_clean_input("team_id", team_id_in)
                ok_name, team_name = validate_and_clean_input("text", team_name_in)
                ok_pw, password = validate_and_clean_input("password", pwd_in)
                
                if not ok_id:
                    st.error("‚ùå Identifiant d'√©quipe invalide (lettres/chiffres, max 20)")
                elif not ok_name:
                    st.error("‚ùå Nom d'√©quipe invalide ou vide")
                elif not ok_pw:
                    st.error("‚ùå Mot de passe invalide (minimum 4 caract√®res)")
                elif pwd_in != pwd_conf:
                    st.error("‚ùå Les mots de passe ne correspondent pas")
                else:
                    # Tentative de cr√©ation avec db.create_team
                    try:
                        created = db.create_team(team_id, team_name, password)
                        if created:
                            st.toast(f"‚úÖ √âquipe {team_id} cr√©√©e avec succ√®s", icon="‚úÖ")
                            st.rerun()
                        else:
                            st.error("‚ùå √âchec de cr√©ation (ID d√©j√† existant ?)")
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors de la cr√©ation: {e}")
        
        # === Liste des √©quipes (sans doublon de titre) ===
        try:
            teams_df = db.get_all_teams()
            if teams_df:  # Liste non vide
                st.dataframe(to_dataframe(teams_df), width="stretch")
            else:
                st.info("Aucune √©quipe cr√©√©e")
        except Exception as e:
            st.info("Liste des √©quipes non disponible")
    
    with tabs[2]:
        # Assignation v4.1
        page_assignations_v41(conn)
    
    with tabs[3]:
        # Export am√©lior√© v4.1
        page_export_gestionnaire_v41(conn)

    with tabs[4]:
        st.markdown("### üõ† Op√©rations techniques (prot√©g√©es)")

        # -- PIN stock√© dans secrets (config.toml -> [secrets] TECH_PIN="xxxx")
        try:
            TECH_PIN = st.secrets.get("TECH_PIN", "")
        except:
            TECH_PIN = ""  # Pas de fichier secrets.toml

        if "tech_ok" not in st.session_state:
            st.session_state.tech_ok = False

        if not st.session_state.tech_ok:
            pin = st.text_input("Entrer le PIN technique", type="password")
            if st.button("D√©verrouiller"):
                if TECH_PIN and pin == TECH_PIN:
                    st.session_state.tech_ok = True
                    st.success("Acc√®s technique d√©verrouill√©.")
                    st.rerun()
                else:
                    st.error("PIN invalide.")
            st.stop()

        st.info("‚ö†Ô∏è Ces actions sont lourdes et n'affectent pas les statuts/notes. Elles r√©g√©n√®rent les caches OSM.")

        # --- Reconstruire le cache g√©om√©trique (lourd)
        with st.expander("üîÑ Reconstruire cache OSM (g√©om√©tries)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirm = st.checkbox("Je comprends les implications")
            with col2:
                safety = st.text_input('√âcrire "REBUILD" pour confirmer')

            if st.button("Lancer la reconstruction"):
                if confirm and safety.strip().upper() == "REBUILD":
                    with st.spinner("Construction du cache‚Ä¶"):
                        build_geometry_cache()       # reconstruit le fichier osm_cache.json
                        st.cache_data.clear()        # purge cache Streamlit
                    st.success("‚úÖ Cache OSM mis √† jour (g√©om√©tries).")
                    st.rerun()
                else:
                    st.warning("Confirmation incompl√®te.")

        # --- Reconstruire/Importer le cache des adresses
        with st.expander("üìç Mettre √† jour les adresses (OSM)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirmA = st.checkbox("Je confirme")
            with col2:
                safetyA = st.text_input('√âcrire "IMPORT" pour confirmer')

            if st.button("Lancer la mise √† jour des adresses"):
                if confirmA and safetyA.strip().upper() == "IMPORT":
                    with st.spinner("T√©l√©chargement des adresses OSM‚Ä¶"):
                        build_addresses_cache()
                        addr_cache = load_addresses_cache()
                        count = db.import_addresses_from_cache(addr_cache)
                    st.success(f"‚úÖ {count} adresses import√©es depuis OSM.")
                    st.rerun()
                else:
                    st.warning("Confirmation incompl√®te.")

        # --- Gestion des backups
        with st.expander("üíæ Gestion des backups", expanded=False):
            backup_mgr = db.get_backup_manager(DB_PATH)
            
            col1, col2 = st.columns([2, 1])
            with col1:
                if st.button("üîÑ Cr√©er un backup manuel", width="stretch"):
                    backup_file = backup_mgr.create_backup("manual")
                    if backup_file:
                        st.success(f"Backup cr√©√© : {Path(backup_file).name}")
            
            with col2:
                if st.button("üìã Voir les backups", width="stretch"):
                    backups = backup_mgr.list_backups()
                    if backups:
                        for backup in backups[:5]:  # Montrer les 5 derniers
                            st.text(f"‚Ä¢ {backup['name']} ({backup['size']})")
                    else:
                        st.info("Aucun backup disponible")

def page_superviseur(conn, geo):
    """Interface superviseur"""
    st.header("üéØ Tableau de Bord Superviseur")
    
    # V√©rifier l'authentification
    if not st.session_state.auth or st.session_state.auth.get("role") != "supervisor":
        render_login_card("superviseur", conn)
        return
    
    # Dashboard moderne
    render_dashboard_gestionnaire(conn, geo)
    
    # Tabs
    tabs = st.tabs([
        "üìä Vue d'ensemble",
        "üë• √âquipes",
        "üó∫Ô∏è Assignation",
        "üì• Export",
        "üõ† Tech"
    ])
    
    with tabs[0]:
        # Carte g√©n√©rale
        st.markdown("### Carte g√©n√©rale")
        df_all = db.list_streets()
        if df_all:  # Liste non vide
            m = create_map(df_all, geo)
            st_folium(m, height=800, width=None, returned_objects=[])
        
        # Activit√© r√©cente
        st.markdown("### Activit√© r√©cente")
        recent = db.recent_activity(limit=10)
        if recent:  # Liste non vide
            st.dataframe(to_dataframe(recent), width="stretch")
    
    with tabs[1]:
        # Gestion des √©quipes
        st.markdown("### Gestion des √©quipes")
        
        with st.expander("Cr√©er une √©quipe"):
            with st.form("new_team", clear_on_submit=True):
                new_id = st.text_input("Identifiant")
                new_name = st.text_input("√âquipe")
                new_pass = st.text_input("Mot de passe", type="password")
                
                if st.form_submit_button("Cr√©er"):
                    if all([new_id, new_name, new_pass]):
                        if db.create_team(new_id, new_name, new_pass):
                            st.success(f"√âquipe {new_id} cr√©√©e")
                            st.rerun()
        
        # Liste des √©quipes
        teams_df = db.get_all_teams()
        if teams_df:  # Liste non vide
            st.dataframe(to_dataframe(teams_df), width="stretch")
    
    with tabs[2]:
        # Assignation
        st.markdown("### Assignation des rues")
        
        unassigned = db.get_unassigned_streets()
        
        if unassigned:  # Liste non vide
            with st.form("assign"):
                team = st.selectbox("√âquipe", db.teams())
                streets = st.multiselect("Rues", unassigned)
                
                if st.form_submit_button("Assigner"):
                    if team and streets:
                        db.assign_streets_to_team(streets, team)
                        st.success("Rues assign√©es!")
                        st.rerun()
        else:
            st.success("Toutes les rues sont assign√©es!")
        
        # Tableau des assignations
        df_all = db.list_streets()
        if df_all:  # Liste non vide
            st.dataframe(
                df_all[['name', 'sector', 'team', 'status']],
                width="stretch"
            )
    
    with tabs[3]:
        # Export
        st.markdown("### Export des donn√©es")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                "üì• Export rues (CSV)",
                db.export_to_csv(),
                "rapport_rues.csv",
                "text/csv",
                width="stretch"
            )
        
        with col2:
            st.download_button(
                "üì• Export notes (CSV)",
                db.export_notes_csv(),
                "rapport_notes.csv",
                "text/csv",
                width="stretch"
            )

    with tabs[4]:
        st.markdown("### üõ† Op√©rations techniques (prot√©g√©es)")

        # -- PIN stock√© dans secrets (config.toml -> [secrets] TECH_PIN="xxxx")  
        try:
            TECH_PIN = st.secrets.get("TECH_PIN", "")
        except:
            TECH_PIN = ""  # Pas de fichier secrets.toml

        if "tech_ok" not in st.session_state:
            st.session_state.tech_ok = False

        if not st.session_state.tech_ok:
            pin = st.text_input("Entrer le PIN technique", type="password")
            if st.button("D√©verrouiller"):
                if TECH_PIN and pin == TECH_PIN:
                    st.session_state.tech_ok = True
                    st.success("Acc√®s technique d√©verrouill√©.")
                    st.rerun()
                else:
                    st.error("PIN invalide.")
            st.stop()

        st.info("‚ö†Ô∏è Ces actions sont lourdes et n'affectent pas les statuts/notes. Elles r√©g√©n√®rent les caches OSM.")

        # --- Reconstruire le cache g√©om√©trique (lourd)
        with st.expander("üîÑ Reconstruire cache OSM (g√©om√©tries)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirm = st.checkbox("Je comprends les implications")
            with col2:
                safety = st.text_input('√âcrire "REBUILD" pour confirmer')

            if st.button("Lancer la reconstruction"):
                if confirm and safety.strip().upper() == "REBUILD":
                    with st.spinner("Construction du cache‚Ä¶"):
                        build_geometry_cache()       # reconstruit le fichier osm_cache.json
                        st.cache_data.clear()        # purge cache Streamlit
                    st.success("‚úÖ Cache OSM mis √† jour (g√©om√©tries).")
                    st.rerun()
                else:
                    st.warning("Confirmation incompl√®te.")

        # --- Reconstruire/Importer le cache des adresses
        with st.expander("üìç Mettre √† jour les adresses (OSM)", expanded=False):
            col1, col2 = st.columns([1,2])
            with col1:
                confirmA = st.checkbox("Je confirme")
            with col2:
                safetyA = st.text_input('√âcrire "IMPORT" pour confirmer')

            if st.button("Lancer la mise √† jour des adresses"):
                if confirmA and safetyA.strip().upper() == "IMPORT":
                    with st.spinner("T√©l√©chargement des adresses OSM‚Ä¶"):
                        build_addresses_cache()
                        addr_cache = load_addresses_cache()
                        count = db.import_addresses_from_cache(addr_cache)
                    st.success(f"‚úÖ {count} adresses import√©es depuis OSM.")
                    st.rerun()
                else:
                    st.warning("Confirmation incompl√®te.")

# ============================================
# MAIN
# ============================================

# ================================================================================
# NOUVELLES FONCTIONS v4.1 - SUPERVISEUR ET B√âN√âVOLE
# ================================================================================

def page_assignations_v41(conn):
    """Panneau d'assignations v4.1 pour superviseurs"""
    
    try:
        # ===== Bloc Assignations (refactor propre) =====
        st.subheader("üó∫Ô∏è Assignations par secteur", anchor=False)
        
        # Compteur de rues non assign√©es (banni√®re info)
        unassigned_count = db.get_unassigned_streets_count()
        if unassigned_count > 0:
            st.info(f"‚ö†Ô∏è {unassigned_count} rue(s) non assign√©e(s)")
        
        with st.container():
            c1, c2, c3 = st.columns([1, 1.2, 0.7], vertical_alignment="bottom")
            
            with c1:
                # R√©cup√©rer la liste des secteurs
                liste_secteurs = db.get_sectors_list()
                secteur = st.selectbox(
                    "SECTEUR √Ä ASSIGNER",
                    options=[""] + (liste_secteurs if liste_secteurs else []),
                    index=0,
                    key="assign_sector",
                    help="Choisissez le secteur √† assigner",
                    label_visibility="visible",
                )
            
            with c2:
                # R√©cup√©rer la liste des √©quipes
                teams = db.get_teams_list()
                liste_equipes = [f"{team[1]} ({team[0]})" for team in teams] if teams else []
                
                if liste_equipes:
                    team_display = st.selectbox(
                        "√âQUIPE", 
                        options=[""] + liste_equipes, 
                        index=0, 
                        key="assign_team"
                    )
                    # Extraire l'ID de l'√©quipe
                    team = ""
                    if team_display and team_display != "":
                        team = team_display.split("(")[-1].rstrip(")")
                else:
                    st.info("Aucune √©quipe disponible")
                    team = None
            
            with c3:
                disabled = not (secteur and team)
                if st.button("üéØ Assigner tout le secteur", width="stretch", disabled=disabled):
                    # Appel m√©tier : assigner toutes les rues non assign√©es du secteur √† l'√©quipe
                    if secteur and team:
                        try:
                            nb = db.bulk_assign_sector(secteur, team)
                            if nb > 0:
                                st.toast(f"‚úÖ {nb} rue(s) assign√©e(s) √† l'√©quipe {team}", icon="‚úÖ")
                                st.rerun()
                            else:
                                st.toast("‚ÑπÔ∏è Aucune rue non assign√©e dans ce secteur", icon="‚ÑπÔ∏è")
                        except Exception as e:
                            st.error(f"Erreur lors de l'assignation: {e}")
        
        # ===== Tableau d'√©tat (uniforme, sans style sp√©cial) =====
        st.markdown("### üìã √âtat des assignations")
        
        df = db.list_streets()
        if df:  # Liste non vide
            df_disp = df.assign(
                Statut=df["status"].map(STATUS_TO_LABEL).fillna("√Ä faire")
            ).rename(columns={
                "name": "Rue", 
                "sector": "Secteur", 
                "team": "√âquipe"
            })[["Rue", "Secteur", "√âquipe", "Statut"]]
            
            st.dataframe(df_disp, width="stretch")  # aucun Styler, aucun CSS cellule
        else:
            st.info("Aucune rue trouv√©e")
            
    except Exception as e:
        st.error(f"Erreur dans le panneau d'assignations: {e}")
        st.info("Fonctionnalit√© temporairement indisponible")

def page_export_gestionnaire_v41(conn):
    """Page d'export v4.1 avec nouvelles fonctionnalit√©s"""
    st.markdown("### üì• Export des donn√©es")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Export CSV standard
        try:
            st.download_button(
                "üì• Export CSV Standard",
                db.export_to_csv(),
                "rapport_rues.csv",
                "text/csv",
                width="stretch"
            )
        except Exception as e:
            st.button("üì• CSV (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    with col2:
        # Export Excel professionnel
        try:
            from reports import ReportGenerator
            generator = ReportGenerator(conn)
            excel_data = generator.generate_excel()
            st.download_button(
                "üìä Export Excel Pro",
                excel_data,
                "guignolee_2025_rapport.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width="stretch"
            )
        except ImportError:
            st.button("üìä Excel (Installer xlsxwriter)", disabled=True, width="stretch")
        except Exception as e:
            st.button("üìä Excel (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    with col3:
        # Export PDF professionnel
        try:
            from reports import ReportGenerator
            generator = ReportGenerator(conn)
            pdf_data = generator.generate_pdf()
            st.download_button(
                "üìÑ Export PDF Pro",
                pdf_data,
                "guignolee_2025_rapport.pdf",
                "application/pdf",
                width="stretch"
            )
        except ImportError:
            st.button("üìÑ PDF (Installer reportlab)", disabled=True, width="stretch")
        except Exception as e:
            st.button("üìÑ PDF (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    # Export CSV assignations (nouveau v4.1)
    st.markdown("---")
    st.markdown("### üìã Export sp√©cialis√©s v4.1")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Export CSV assignations
        try:
            assignations_data = db.get_assignations_export_data()
            if assignations_data:  # Liste non vide
                csv_data = pd.DataFrame(assignations_data).to_csv(index=False, encoding='utf-8')
                st.download_button(
                    "üìã Export CSV Assignations",
                    csv_data,
                    "assignations_secteurs.csv",
                    "text/csv",
                    width="stretch",
                    help="Colonnes: secteur, rue, √©quipe, statut"
                )
            else:
                st.button("üìã Assignations (Aucune donn√©e)", disabled=True, width="stretch")
        except Exception as e:
            st.button("üìã Assignations (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")
    
    with col2:
        # Export notes
        try:
            st.download_button(
                "üìù Export Notes",
                db.export_notes_csv(),
                "rapport_notes.csv",
                "text/csv",
                width="stretch"
            )
        except Exception as e:
            st.button("üìù Notes (Erreur)", disabled=True, width="stretch")
            st.caption(f"Erreur: {e}")

def page_benevole_mes_rues(conn):
    """Vue 'Mes rues' pour b√©n√©voles v4.1"""
    
    # R√©cup√©rer l'√©quipe du b√©n√©vole connect√©
    if not st.session_state.auth or st.session_state.auth.get("role") != "volunteer":
        st.warning("Acc√®s r√©serv√© aux b√©n√©voles connect√©s")
        return
    
    team_id = st.session_state.auth.get("team")
    if not team_id:
        st.error("√âquipe non identifi√©e")
        return
    
    st.markdown(f"### üèòÔ∏è Mes rues assign√©es - √âquipe {team_id}")
    
    try:
        # R√©cup√©rer les rues de l'√©quipe
        team_streets = db.get_team_streets(team_id)
        
        if not team_streets:  # Liste vide
            st.info("Aucune rue assign√©e √† votre √©quipe pour le moment.")
            return
        
        # Afficher les statistiques de l'√©quipe
        total_streets = len(team_streets)
        done_streets = len([s for s in team_streets if hasattr(s, 'status') and s.status == 'terminee'])
        in_progress = len([s for s in team_streets if hasattr(s, 'status') and s.status == 'en_cours'])
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total rues", total_streets)
        with col2:
            st.metric("Termin√©es", done_streets)
        with col3:
            st.metric("En cours", in_progress)
        with col4:
            progress = (done_streets / total_streets * 100) if total_streets > 0 else 0
            st.metric("Progression", f"{progress:.1f}%")
        
        st.markdown("---")
        
        # Affichage par rue avec actions
        for street in team_streets:
            if isinstance(street, str):
                street_name = street
            else:
                street_name = street.get("name", street)
            street_name = street['street_name']
            current_status = street['status']
            notes_count = street['notes_count']
            
            with st.expander(f"üèòÔ∏è {street_name} ({street['sector']}) - {current_status.replace('_', ' ').title()}", 
                           expanded=current_status == 'en_cours'):
                
                col1, col2, col3 = st.columns([2, 1, 1])
                
                with col1:
                    st.markdown(f"**Secteur:** {street['sector']}")
                    st.markdown(f"**Statut actuel:** {current_status.replace('_', ' ').title()}")
                    if notes_count > 0:
                        st.markdown(f"**Notes existantes:** {notes_count}")
                
                with col2:
                    # Bouton "En cours"
                    if st.button(
                        "üöÄ En cours", 
                        key=f"progress_{street_name}",
                        disabled=current_status == 'en_cours',
                        width="stretch"
                    ):
                        if db.update_street_status(street_name, 'en_cours', team_id):
                            st.toast(f"‚úÖ {street_name} marqu√©e en cours", icon="üöÄ")
                            st.rerun()
                        else:
                            st.error("Erreur lors de la mise √† jour")
                
                with col3:
                    # Bouton "Termin√©e"
                    if st.button(
                        "‚úÖ Termin√©e", 
                        key=f"done_{street_name}",
                        disabled=current_status == 'terminee',
                        width="stretch"
                    ):
                        if db.update_street_status(street_name, 'terminee', team_id):
                            st.toast(f"üéâ {street_name} termin√©e!", icon="üéâ")
                            st.rerun()
                        else:
                            st.error("Erreur lors de la mise √† jour")
                
                # Section notes
                st.markdown("**Gestion des notes:**")
                
                # Afficher les notes existantes
                existing_notes = db.get_street_notes_for_team(street_name, team_id)
                if existing_notes:
                    st.markdown("*Notes existantes:*")
                    for note in existing_notes:
                        st.markdown(f"‚Ä¢ **#{list(note.values())[0] if isinstance(note, dict) else note[0]}** : {list(note.values())[1] if isinstance(note, dict) else note[1]} _{list(note.values())[2] if isinstance(note, dict) else note[2]}_")
                
                # Ajouter une nouvelle note
                with st.form(f"note_form_{street_name}"):
                    col_addr, col_note = st.columns([1, 3])
                    with col_addr:
                        address_number = st.text_input(
                            "N¬∞ civique", 
                            key=f"addr_{street_name}",
                            placeholder="123A"
                        )
                    with col_note:
                        comment = st.text_area(
                            "Commentaire", 
                            key=f"comment_{street_name}",
                            placeholder="Ex: Absent, refus, don re√ßu...",
                            max_chars=500,
                            height=80
                        )
                    
                    if st.form_submit_button("üíæ Enregistrer note"):
                        if address_number and comment:
                            if db.add_street_note(street_name, team_id, address_number, comment):
                                st.toast(f"üìù Note ajout√©e pour {street_name} #{address_number}", icon="üìù")
                                st.rerun()
                            else:
                                st.error("Erreur lors de l'enregistrement de la note")
                        else:
                            st.warning("Veuillez remplir le num√©ro et le commentaire")
                            
    except Exception as e:
        st.error(f"Erreur lors du chargement de vos rues: {e}")
        st.info("Fonctionnalit√© temporairement indisponible")

def main():
    """Point d'entr√©e principal - Version 2.0 Guignol√©e"""
    
    # CSS moderne
    inject_css()
    
    # Connexion DB
    # Initialisation de la base de donn√©es
    db.init_db()
    
    # Compatibilit√© legacy pour les backups
    if 'conn' not in st.session_state:
        import sqlite3
        conn = sqlite3.connect(DB_PATH, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        st.session_state['conn'] = conn
    st.session_state['conn'] = conn
    
    # Cache g√©om√©trique
    @st.cache_data(ttl=None)
    def get_geo(_sig):
        data = load_geometry_cache()
        return data if data else {}
    
    sig = int(CACHE_FILE.stat().st_mtime_ns) if CACHE_FILE.exists() else 0
    geo = get_geo(sig)
    
    # Header festif
    render_header()
    
    # Navigation modernis√©e dans la sidebar
    with st.sidebar:
        # CSS pour la sidebar sans position absolue
        st.markdown("""
        <style>
        .css-1d391kg { padding-top: 1rem !important; }
        .stSidebar > div:first-child { padding-top: 1rem !important; }
        </style>
        """, unsafe_allow_html=True)
        
        # Logo en haut de la sidebar (position normale)
        logo_path = ASSETS / "logo.png"
        if logo_path.exists():
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.image(str(logo_path), width=150)
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
        else:
            # Placeholder centr√©
            st.markdown("""
            <div style="
                background: linear-gradient(135deg, #c41e3a, #165b33);
                border-radius: 15px;
                padding: 2rem;
                color: white;
                text-align: center;
                margin: 1rem 0;
                box-shadow: 0 4px 15px rgba(0,0,0,0.3);
            ">
                <div style="font-size: 2.5rem;">üéÅ</div>
                <div style="font-weight: bold; font-size: 1.2rem;">LOGO</div>
                <small>Espace r√©serv√©</small>
            </div>
            """, unsafe_allow_html=True)
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
        
        # Navigation
        st.markdown("### üéÑ Navigation")
        
        # Boutons de navigation stylis√©s
        if st.button("üè† Accueil", width="stretch"):
            st.session_state.page = "accueil"
            st.rerun()
        
        if st.button("üéÖ B√©n√©vole", width="stretch"):
            st.session_state.page = "benevole"
            st.rerun()
            
        if st.button("üëî Gestionnaire", width="stretch"):
            st.session_state.page = "gestionnaire"  
            st.rerun()
        
        # D√©connexion si connect√©
        if st.session_state.auth:
            st.markdown("---")
            if st.button("üö™ D√©connexion", width="stretch"):
                st.session_state.auth = None
                st.rerun()
        
        # Compteur temps r√©el
        st.markdown("---")
        stats = db.extended_stats()
        st.markdown(f"""
        <div style="text-align: center;">
            <h4>√âtat de la collecte</h4>
            <div style="font-size: 2rem; color: #FFD700;">
                {stats['done']}/{stats['total']}
            </div>
            <small>Rues compl√©t√©es</small>
        </div>
        """, unsafe_allow_html=True)
    
    # Routing pages
    page = st.session_state.get('page', 'accueil')
    
    if page == "accueil":
        page_accueil_v2(conn, geo)
    elif page == "benevole":
        page_benevole_v2(conn, geo)
    elif page == "gestionnaire":
        page_gestionnaire_v2(conn, geo)
    
    # Footer festif
    st.markdown("""
    <div style="
        text-align: center;
        padding: 2rem;
        margin-top: 3rem;
        border-top: 2px solid rgba(255,215,0,0.3);
        color: #8b92a4;
    ">
        <p>
            üéÑ Guignol√©e 2025 - Le Relais de Mascouche üéÑ<br>
            <small>Ensemble, redonnons espoir | üìû 450-474-4133</small>
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Banni√®re en bas de page
    if (ASSETS / "banner.png").exists():
        st.image(str(ASSETS / "banner.png"), width="stretch")

if __name__ == "__main__":
    main()

```
---8<--- guignomap/app.py END ---

---8<--- guignomap/backup.py BEGIN ---
```py
"""
Syst√®me de backup automatique pour GuignoMap
Sauvegarde la base de donn√©es et les caches
"""

import shutil
import sqlite3
from pathlib import Path
from datetime import datetime
import json
import zipfile

class BackupManager:
    def __init__(self, db_path):
        self.db_path = Path(db_path)
        self.backup_dir = self.db_path.parent / "backups"
        self.backup_dir.mkdir(exist_ok=True)
        self.max_backups = 7  # Garder 7 jours de backups
        
    def create_backup(self, reason="manual"):
        """Cr√©e un backup complet avec timestamp"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_{timestamp}_{reason}"
        backup_path = self.backup_dir / backup_name
        backup_path.mkdir(exist_ok=True)
        
        try:
            # Backup de la base de donn√©es
            db_backup = backup_path / "guigno_map.db"
            shutil.copy2(self.db_path, db_backup)
            
            # Backup des caches OSM
            for cache_file in ["osm_cache.json", "osm_addresses.json"]:
                cache_path = self.db_path.parent / cache_file
                if cache_path.exists():
                    shutil.copy2(cache_path, backup_path / cache_file)
            
            # Cr√©er un ZIP
            zip_path = self.backup_dir / f"{backup_name}.zip"
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file in backup_path.iterdir():
                    zipf.write(file, file.name)
            
            # Nettoyer le dossier temporaire
            shutil.rmtree(backup_path)
            
            # Nettoyer les vieux backups
            self._cleanup_old_backups()
            
            # Log le backup
            self._log_backup(timestamp, reason)
            
            print(f"‚úÖ Backup cr√©√© : {zip_path.name}")
            return str(zip_path)
            
        except Exception as e:
            print(f"‚ùå Erreur backup : {e}")
            if backup_path.exists():
                shutil.rmtree(backup_path)
            return None
    
    def restore_backup(self, backup_file):
        """Restaure un backup sp√©cifique"""
        backup_path = self.backup_dir / backup_file
        if not backup_path.exists():
            print(f"‚ùå Backup introuvable : {backup_file}")
            return False
            
        try:
            # Cr√©er un backup de s√©curit√© avant restauration
            self.create_backup("pre_restore")
            
            # Extraire le ZIP
            temp_dir = self.backup_dir / "temp_restore"
            with zipfile.ZipFile(backup_path, 'r') as zipf:
                zipf.extractall(temp_dir)
            
            # Restaurer les fichiers
            for file in temp_dir.iterdir():
                target = self.db_path.parent / file.name
                shutil.copy2(file, target)
            
            # Nettoyer
            shutil.rmtree(temp_dir)
            
            print(f"‚úÖ Backup restaur√© : {backup_file}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur restauration : {e}")
            return False
    
    def list_backups(self):
        """Liste tous les backups disponibles"""
        backups = []
        for file in self.backup_dir.glob("backup_*.zip"):
            stat = file.stat()
            backups.append({
                "name": file.name,
                "size": f"{stat.st_size / 1024 / 1024:.2f} MB",
                "date": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S")
            })
        return sorted(backups, key=lambda x: x["date"], reverse=True)
    
    def _cleanup_old_backups(self):
        """Supprime les backups de plus de 7 jours"""
        backups = sorted(self.backup_dir.glob("backup_*.zip"), key=lambda x: x.stat().st_mtime)
        while len(backups) > self.max_backups:
            oldest = backups.pop(0)
            oldest.unlink()
            print(f"üóëÔ∏è Ancien backup supprim√© : {oldest.name}")
    
    def _log_backup(self, timestamp, reason):
        """Log les backups dans un fichier"""
        log_file = self.backup_dir / "backup_log.json"
        log = []
        if log_file.exists():
            with open(log_file, 'r') as f:
                log = json.load(f)
        
        log.append({
            "timestamp": timestamp,
            "reason": reason,
            "date": datetime.now().isoformat()
        })
        
        # Garder seulement les 100 derniers logs
        log = log[-100:]
        
        with open(log_file, 'w') as f:
            json.dump(log, f, indent=2)

def auto_backup_before_critical(func):
    """D√©corateur pour backup automatique avant op√©rations critiques"""
    def wrapper(*args, **kwargs):
        # Trouver la connexion DB dans les arguments
        conn = None
        for arg in args:
            if hasattr(arg, 'execute'):  # C'est une connexion SQLite
                conn = arg
                break
        
        if conn:
            try:
                # Cr√©er un backup avant l'op√©ration
                db_path = Path(__file__).parent / "guigno_map.db"
                backup_mgr = BackupManager(db_path)
                backup_mgr.create_backup(f"auto_{func.__name__}")
            except:
                pass  # Ne pas bloquer l'op√©ration si le backup √©choue
        
        return func(*args, **kwargs)
    return wrapper
```
---8<--- guignomap/backup.py END ---

---8<--- guignomap/db.py BEGIN ---
```py
import sqlite3
import pandas as pd
import hashlib
import bcrypt
from backup import auto_backup_before_critical, BackupManager
from validators import validate_and_clean_input, InputValidator
from datetime import datetime
import json
from pathlib import Path
import os
import secrets
import string

# Sch√©ma am√©lior√© de la base de donn√©es
SCHEMA = """
-- Table des rues
CREATE TABLE IF NOT EXISTS streets (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    sector TEXT,
    team TEXT,
    status TEXT NOT NULL DEFAULT 'a_faire' 
        CHECK (status IN ('a_faire', 'en_cours', 'terminee'))
);

-- Table des √©quipes
CREATE TABLE IF NOT EXISTS teams (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    password_hash TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    active BOOLEAN DEFAULT 1
);

-- Table des notes/commentaires PAR ADRESSE
CREATE TABLE IF NOT EXISTS notes (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    street_name TEXT NOT NULL,
    team_id TEXT NOT NULL,
    address_number TEXT,
    comment TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (street_name) REFERENCES streets(name),
    FOREIGN KEY (team_id) REFERENCES teams(id)
);

-- Table d'activit√© (log)
CREATE TABLE IF NOT EXISTS activity_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    team_id TEXT,
    action TEXT NOT NULL,
    details TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Table des adresses OSM
CREATE TABLE IF NOT EXISTS addresses (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    street_name TEXT NOT NULL,
    house_number TEXT NOT NULL,
    latitude REAL,
    longitude REAL,
    osm_type TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (street_name) REFERENCES streets(name)
);

-- Index pour am√©liorer les performances
CREATE INDEX IF NOT EXISTS idx_streets_team ON streets(team);
CREATE INDEX IF NOT EXISTS idx_streets_status ON streets(status);
CREATE INDEX IF NOT EXISTS idx_notes_street ON notes(street_name);
CREATE INDEX IF NOT EXISTS idx_activity_created ON activity_log(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_addresses_street ON addresses(street_name);
CREATE INDEX IF NOT EXISTS idx_addresses_number ON addresses(house_number);
"""

def get_conn(db_path):
    """Cr√©e une connexion √† la base de donn√©es"""
    conn = sqlite3.connect(db_path, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    return conn

def init_db(conn):
    """Initialise la base de donn√©es avec le sch√©ma et les donn√©es initiales"""
    try:
        # Cr√©er les tables si elles n'existent pas
        conn.executescript(SCHEMA)
        conn.commit()
        
        # Cr√©er un compte admin par d√©faut s'il n'existe pas
        cursor = conn.execute("SELECT COUNT(*) FROM teams WHERE id = 'ADMIN'")
        if cursor.fetchone()[0] == 0:
            pwd = os.getenv("GM_ADMIN_PWD", "RELAIS2025")  # Par d√©faut RELAIS2025
            create_team(conn, 'ADMIN', 'Superviseur', pwd)
        
        # AUTO-IMPORT : Si aucune rue n'existe, importer automatiquement depuis OSM
        cursor = conn.execute("SELECT COUNT(*) FROM streets")
        if cursor.fetchone()[0] == 0:
            print("üîÑ Aucune rue trouv√©e. Import automatique depuis OpenStreetMap...")
            auto_import_streets(conn)
            
    except Exception as e:
        print(f"Erreur lors de l'initialisation de la DB: {e}")
        raise

@auto_backup_before_critical
def auto_import_streets(conn):
    """Import automatique des rues de Mascouche"""
    try:
        # Essayer d'abord avec OSM
        from osm import generate_streets_csv
        csv_data = generate_streets_csv("Mascouche")
        
        if csv_data:
            import io
            df = pd.read_csv(io.StringIO(csv_data.decode('utf-8')))
            
            if not df.empty:
                for _, row in df.iterrows():
                    conn.execute(
                        "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, ?, ?, 'a_faire')",
                        (row.get("name", ""), row.get("sector", ""), row.get("team", ""))
                    )
                conn.commit()
                print(f"‚úÖ {len(df)} rues import√©es automatiquement")
                log_activity(conn, None, "AUTO_IMPORT", f"Import automatique de {len(df)} rues")
                return
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de l'import OSM: {e}")
    
    # Fallback : Donn√©es de test si OSM √©choue
    print("üì¶ Import de donn√©es de test...")
    test_streets = [
        ("Mont√©e Masson", "Centre", ""),
        ("Chemin Sainte-Marie", "Centre", ""),
        ("Boulevard de Mascouche", "Centre", ""),
        ("Rue Dupras", "Centre", ""),
        ("Rue Saint-Pierre", "Centre", ""),
        ("Rue de l'√âglise", "Centre", ""),
        ("Avenue des √ârables", "Nord", ""),
        ("Rue des Pins", "Nord", ""),
        ("Rue Gravel", "Sud", ""),
        ("Rue Forget", "Sud", ""),
    ]
    
    for name, sector, team in test_streets:
        conn.execute(
            "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, ?, ?, 'a_faire')",
            (name, sector, team)
        )
    conn.commit()
    print(f"‚úÖ {len(test_streets)} rues de test import√©es")

# ---------- Fonctions pour les √©quipes ----------
def hash_password(password):
    """Hash un mot de passe avec bcrypt et salt automatique"""
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
    return hashed.decode('utf-8')

def create_team(conn, team_id, name, password):
    """Cr√©e une nouvelle √©quipe avec validation"""
    try:
        # Valider les entr√©es
        valid_id, clean_id = validate_and_clean_input("team_id", team_id)
        valid_name, clean_name = validate_and_clean_input("text", name)
        valid_pwd, _ = validate_and_clean_input("password", password)
        
        if not valid_id or not valid_name or not valid_pwd:
            return False
        
        conn.execute(
            "INSERT INTO teams (id, name, password_hash) VALUES (?, ?, ?)",
            (clean_id, clean_name, hash_password(password))
        )
        conn.commit()
        log_activity(conn, clean_id, "TEAM_CREATED", f"√âquipe {clean_name} cr√©√©e")
        return True
    except sqlite3.IntegrityError:
        return False

def verify_team(conn, team_id, password):
    """V√©rifie les identifiants d'une √©quipe avec bcrypt"""
    cursor = conn.execute(
        "SELECT password_hash FROM teams WHERE id = ? AND active = 1",
        (team_id,)
    )
    row = cursor.fetchone()
    if row:
        try:
            # Support ancien SHA256 pour migration
            stored_hash = row[0]
            if stored_hash.startswith('$2b$') or stored_hash.startswith('$2a$'):
                # Hash bcrypt
                return bcrypt.checkpw(password.encode('utf-8'), stored_hash.encode('utf-8'))
            else:
                # Ancien SHA256, v√©rifier et migrer
                if stored_hash == hashlib.sha256(password.encode()).hexdigest():
                    # Migrer vers bcrypt
                    new_hash = hash_password(password)
                    conn.execute("UPDATE teams SET password_hash = ? WHERE id = ?", (new_hash, team_id))
                    conn.commit()
                    return True
                return False
        except Exception as e:
            print(f"Erreur v√©rification mot de passe: {e}")
            return False
    return False

def migrate_all_passwords_to_bcrypt(conn):
    """Migration manuelle des mots de passe SHA256 vers bcrypt"""
    print("‚ö†Ô∏è Migration des mots de passe requise")
    print("Entrez les mots de passe actuels pour migration:")
    
    cursor = conn.execute("SELECT id, name FROM teams WHERE active = 1")
    teams = cursor.fetchall()
    
    for team_id, team_name in teams:
        if team_id == 'ADMIN':
            pwd = input(f"Mot de passe actuel pour {team_name} (ADMIN): ")
            if pwd:
                new_hash = hash_password(pwd)
                conn.execute("UPDATE teams SET password_hash = ? WHERE id = ?", (new_hash, team_id))
        
    conn.commit()
    print("‚úÖ Migration termin√©e")

def get_all_teams(conn):
    """R√©cup√®re toutes les √©quipes avec leurs statistiques"""
    query = """
    SELECT 
        t.id,
        t.name,
        t.created_at,
        COUNT(DISTINCT s.name) as streets_count,
        SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done_count,
        CASE 
            WHEN COUNT(s.name) > 0 
            THEN (SUM(CASE WHEN s.status = 'terminee' THEN 1.0 ELSE 0 END) / COUNT(s.name)) * 100
            ELSE 0 
        END as progress
    FROM teams t
    LEFT JOIN streets s ON t.id = s.team
    WHERE t.active = 1 AND t.id != 'ADMIN'
    GROUP BY t.id, t.name, t.created_at
    ORDER BY t.id
    """
    return pd.read_sql_query(query, conn)

@auto_backup_before_critical
def delete_team(conn, team_id):
    """D√©sactive une √©quipe"""
    conn.execute("UPDATE teams SET active = 0 WHERE id = ?", (team_id,))
    conn.execute("UPDATE streets SET team = NULL WHERE team = ?", (team_id,))
    conn.commit()
    log_activity(conn, None, "TEAM_DELETED", f"√âquipe {team_id} supprim√©e")

def teams(conn):
    """Liste des IDs d'√©quipes actives"""
    cursor = conn.execute(
        "SELECT id FROM teams WHERE active = 1 AND id != 'ADMIN' ORDER BY id"
    )
    return [row[0] for row in cursor.fetchall()]

# ---------- Fonctions pour les rues ----------
def list_streets(conn, team=None):
    """Liste les rues, optionnellement filtr√©es par √©quipe"""
    try:
        if team:
            query = """
                SELECT 
                    s.name, 
                    COALESCE(s.sector, '') as sector, 
                    COALESCE(s.team, '') as team, 
                    COALESCE(s.status, 'a_faire') as status,
                    COUNT(n.id) as notes,
                    COUNT(DISTINCT n.address_number) as addresses_with_notes
                FROM streets s
                LEFT JOIN notes n ON s.name = n.street_name
                WHERE s.team = ?
                GROUP BY s.name, s.sector, s.team, s.status
                ORDER BY 
                    CASE s.status 
                        WHEN 'a_faire' THEN 1 
                        WHEN 'en_cours' THEN 2 
                        WHEN 'terminee' THEN 3 
                    END, 
                    s.name
            """
            df = pd.read_sql_query(query, conn, params=(team,))
        else:
            query = """
                SELECT 
                    s.name, 
                    COALESCE(s.sector, '') as sector, 
                    COALESCE(s.team, '') as team, 
                    COALESCE(s.status, 'a_faire') as status,
                    COUNT(n.id) as notes,
                    COUNT(DISTINCT n.address_number) as addresses_with_notes
                FROM streets s
                LEFT JOIN notes n ON s.name = n.street_name
                GROUP BY s.name, s.sector, s.team, s.status
                ORDER BY 
                    s.team, 
                    CASE s.status 
                        WHEN 'a_faire' THEN 1 
                        WHEN 'en_cours' THEN 2 
                        WHEN 'terminee' THEN 3 
                    END, 
                    s.name
            """
            df = pd.read_sql_query(query, conn)
        
        # S'assurer que toutes les colonnes existent
        for col in ['name', 'sector', 'team', 'status', 'notes', 'addresses_with_notes']:
            if col not in df.columns:
                df[col] = '' if col in ['sector', 'team'] else ('a_faire' if col == 'status' else 0)
        
        return df
        
    except Exception as e:
        print(f"Erreur list_streets: {e}")
        # Retourner un DataFrame vide avec la structure attendue
        return pd.DataFrame(columns=['name', 'sector', 'team', 'status', 'notes', 'addresses_with_notes'])

def get_unassigned_streets(conn):
    """R√©cup√®re les rues non assign√©es"""
    query = """
        SELECT name, sector 
        FROM streets 
        WHERE team IS NULL OR team = ''
        ORDER BY sector, name
    """
    return pd.read_sql_query(query, conn)

def assign_streets_to_team(conn, street_names, team_id):
    """Assigne plusieurs rues √† une √©quipe en une transaction"""
    try:
        for street_name in street_names:
            conn.execute(
                "UPDATE streets SET team = ? WHERE name = ?",
                (team_id, street_name)
            )
        conn.commit()
        log_activity(conn, team_id, "STREETS_ASSIGNED", f"{len(street_names)} rues assign√©es")
        return True
    except Exception as e:
        conn.rollback()
        print(f"Erreur lors de l'assignation: {e}")
        return False

def set_status(conn, name, status):
    """Met √† jour le statut d'une rue avec validation"""
    valid_name, clean_name = validate_and_clean_input("street_name", name)
    clean_status = InputValidator.validate_status(status)
    
    if not valid_name:
        print("‚ùå Nom de rue invalide")
        return False
    
    conn.execute(
        "UPDATE streets SET status = ? WHERE name = ?",
        (clean_status, clean_name)
    )
    conn.commit()
    
    cursor = conn.execute("SELECT team FROM streets WHERE name = ?", (clean_name,))
    row = cursor.fetchone()
    if row:
        log_activity(conn, row[0], f"STATUS_{clean_status.upper()}", f"Rue {clean_name}")
    return True

# ---------- Fonctions pour les notes PAR ADRESSE ----------
def add_note_for_address(conn, street_name, team_id, address_number, comment):
    """Ajoute une note pour une adresse sp√©cifique avec validation"""
    # Valider toutes les entr√©es
    valid_street, clean_street = validate_and_clean_input("street_name", street_name)
    valid_team, clean_team = validate_and_clean_input("team_id", team_id)
    valid_addr, clean_addr = validate_and_clean_input("address", address_number)
    valid_note, clean_note = validate_and_clean_input("note", comment)
    
    if not all([valid_street, valid_team, valid_addr, valid_note]):
        print("‚ùå Donn√©es invalides pour la note")
        return False
    
    conn.execute(
        """INSERT INTO notes (street_name, team_id, address_number, comment) 
           VALUES (?, ?, ?, ?)""",
        (clean_street, clean_team, clean_addr, clean_note)
    )
    
    # Met automatiquement le statut √† "en_cours" si c'√©tait "a_faire"
    conn.execute(
        """UPDATE streets 
           SET status = CASE 
               WHEN status = 'a_faire' THEN 'en_cours' 
               ELSE status 
           END
           WHERE name = ?""",
        (clean_street,)
    )
    
    conn.commit()
    log_activity(conn, clean_team, "NOTE_ADDED", f"Note ajout√©e pour {clean_addr} {clean_street}")
    return True

def get_street_addresses_with_notes(conn, street_name):
    """R√©cup√®re toutes les adresses avec notes pour une rue"""
    query = """
        SELECT 
            n.address_number,
            n.comment,
            n.created_at,
            t.name as team_name
        FROM notes n
        JOIN teams t ON n.team_id = t.id
        WHERE n.street_name = ?
        ORDER BY 
            CAST(n.address_number AS INTEGER),
            n.created_at DESC
    """
    return pd.read_sql_query(query, conn, params=(street_name,))

def get_team_notes(conn, team_id):
    """R√©cup√®re toutes les notes d'une √©quipe"""
    query = """
        SELECT 
            street_name, 
            address_number, 
            comment, 
            created_at
        FROM notes
        WHERE team_id = ?
        ORDER BY created_at DESC
        LIMIT 50
    """
    return pd.read_sql_query(query, conn, params=(team_id,))

# ---------- Fonctions de statistiques ----------
def extended_stats(conn):
    """Statistiques √©tendues avec d√©tails par adresse"""
    cursor = conn.execute("""
        SELECT 
            COUNT(DISTINCT s.name) as total,
            SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done,
            SUM(CASE WHEN s.status = 'en_cours' THEN 1 ELSE 0 END) as partial,
            SUM(CASE WHEN s.status = 'a_faire' THEN 1 ELSE 0 END) as todo,
            COUNT(DISTINCT n.id) as total_notes,
            COUNT(DISTINCT n.address_number || n.street_name) as addresses_with_notes
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name
    """)
    row = cursor.fetchone()
    return {
        "total": row[0] or 0,
        "done": row[1] or 0,
        "partial": row[2] or 0,
        "todo": row[3] or 0,
        "total_notes": row[4] or 0,
        "addresses_with_notes": row[5] or 0
    }

def stats_by_team(conn):
    """Statistiques par √©quipe"""
    query = """
        SELECT 
            s.team,
            COUNT(DISTINCT s.name) as total,
            SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as done,
            SUM(CASE WHEN s.status = 'en_cours' THEN 1 ELSE 0 END) as partial,
            COUNT(DISTINCT n.id) as notes,
            ROUND(
                (SUM(CASE WHEN s.status = 'terminee' THEN 1.0 ELSE 0 END) / COUNT(*)) * 100, 
                1
            ) as progress
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name AND n.team_id = s.team
        WHERE s.team IS NOT NULL AND s.team != ''
        GROUP BY s.team
        ORDER BY progress DESC
    """
    return pd.read_sql_query(query, conn)

# ---------- Fonctions d'activit√© ----------
def recent_activity(conn, limit=10):
    """R√©cup√®re l'activit√© r√©cente"""
    query = """
        SELECT 
            datetime(created_at, 'localtime') as timestamp,
            COALESCE(team_id, 'SYSTEM') as team,
            action,
            details
        FROM activity_log
        ORDER BY created_at DESC
        LIMIT ?
    """
    return pd.read_sql_query(query, conn, params=(limit,))

# ---------- Fonctions d'export ----------
def export_to_csv(conn):
    """Exporte toutes les donn√©es en CSV"""
    query = """
        SELECT 
            s.name as rue,
            s.sector as secteur,
            s.team as equipe,
            s.status as statut,
            COUNT(DISTINCT n.id) as nombre_notes,
            COUNT(DISTINCT n.address_number) as adresses_avec_notes
        FROM streets s
        LEFT JOIN notes n ON s.name = n.street_name
        GROUP BY s.name, s.sector, s.team, s.status
        ORDER BY s.team, s.name
    """
    df = pd.read_sql_query(query, conn)
    return df.to_csv(index=False).encode('utf-8')

def export_notes_csv(conn):
    """Exporte toutes les notes en CSV avec adresses"""
    query = """
        SELECT 
            n.street_name as rue,
            n.address_number as numero,
            n.team_id as equipe,
            n.comment as commentaire,
            n.created_at as date_creation
        FROM notes n
        ORDER BY n.street_name, CAST(n.address_number AS INTEGER), n.created_at DESC
    """
    df = pd.read_sql_query(query, conn)
    return df.to_csv(index=False).encode('utf-8')

# ========================================
# NOUVELLES FONCTIONS POUR LES ADRESSES
# ========================================

@auto_backup_before_critical
def import_addresses_from_cache(conn, cache):
    """
    Importe les adresses depuis le cache OSM vers la base de donn√©es
    """
    try:
        # Vider la table existante
        conn.execute("DELETE FROM addresses")
        
        imported_count = 0
        skipped_count = 0
        
        for street_name, addresses in cache.items():
            # V√©rifier que la rue existe dans la DB
            cursor = conn.execute("SELECT COUNT(*) FROM streets WHERE name = ?", (street_name,))
            if cursor.fetchone()[0] == 0:
                # Si la rue n'existe pas, la cr√©er
                conn.execute(
                    "INSERT OR IGNORE INTO streets(name, sector, team, status) VALUES (?, '', '', 'a_faire')",
                    (street_name,)
                )
                print(f"‚ûï Rue ajout√©e: {street_name}")
            
            for addr in addresses:
                try:
                    # Validation des donn√©es
                    number = str(addr.get("number", "")).strip()
                    lat = addr.get("lat")
                    lon = addr.get("lon")
                    osm_type = addr.get("type", "unknown")
                    
                    if not number or lat is None or lon is None:
                        skipped_count += 1
                        continue
                    
                    conn.execute(
                        """INSERT INTO addresses (street_name, house_number, latitude, longitude, osm_type) 
                           VALUES (?, ?, ?, ?, ?)""",
                        (street_name, number, float(lat), float(lon), osm_type)
                    )
                    imported_count += 1
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur import adresse {addr}: {e}")
                    skipped_count += 1
        
        conn.commit()
        log_activity(conn, None, "ADDRESSES_IMPORTED", f"{imported_count} adresses import√©es, {skipped_count} ignor√©es")
        print(f"‚úÖ {imported_count} adresses import√©es en base de donn√©es ({skipped_count} ignor√©es)")
        return imported_count
        
    except Exception as e:
        conn.rollback()
        print(f"‚ùå Erreur import adresses: {e}")
        return 0

def get_addresses_for_street(conn, street_name):
    """
    R√©cup√®re toutes les adresses d'une rue depuis la base de donn√©es
    """
    query = """
        SELECT 
            house_number,
            latitude,
            longitude,
            osm_type,
            created_at
        FROM addresses
        WHERE street_name = ?
        ORDER BY CAST(house_number AS INTEGER)
    """
    return pd.read_sql_query(query, conn, params=(street_name,))

def get_addresses_stats(conn):
    """
    R√©cup√®re les statistiques des adresses
    """
    cursor = conn.execute("""
        SELECT 
            COUNT(DISTINCT street_name) as streets_with_addresses,
            COUNT(*) as total_addresses,
            COUNT(DISTINCT CASE WHEN osm_type = 'node' THEN id END) as node_addresses,
            COUNT(DISTINCT CASE WHEN osm_type = 'way' THEN id END) as way_addresses
        FROM addresses
    """)
    row = cursor.fetchone()
    return {
        "streets_with_addresses": row[0] or 0,
        "total_addresses": row[1] or 0,
        "node_addresses": row[2] or 0,
        "way_addresses": row[3] or 0
    }

def get_backup_manager(db_path):
    """Retourne une instance du gestionnaire de backup"""
    return BackupManager(db_path)

# ================================================================================
# NOUVELLES FONCTIONS v4.1 - SUPERVISEUR ET B√âN√âVOLE
# ================================================================================

def get_unassigned_streets_count(conn):
    """Compte les rues non assign√©es √† une √©quipe"""
    try:
        cursor = conn.execute("""
            SELECT COUNT(*) FROM streets 
            WHERE team IS NULL OR team = ''
        """)
        return cursor.fetchone()[0] or 0
    except Exception as e:
        print(f"Erreur get_unassigned_streets_count: {e}")
        return 0

def get_sectors_list(conn):
    """R√©cup√®re la liste des secteurs disponibles"""
    try:
        cursor = conn.execute("""
            SELECT DISTINCT sector FROM streets 
            WHERE sector IS NOT NULL AND sector != ''
            ORDER BY sector
        """)
        return [row[0] for row in cursor.fetchall()]
    except Exception as e:
        print(f"Erreur get_sectors_list: {e}")
        return []

def get_teams_list(conn):
    """R√©cup√®re la liste des √©quipes actives"""
    try:
        cursor = conn.execute("""
            SELECT id, name FROM teams 
            WHERE active = 1 AND id != 'ADMIN'
            ORDER BY name
        """)
        return [(row[0], row[1]) for row in cursor.fetchall()]
    except Exception as e:
        print(f"Erreur get_teams_list: {e}")
        return []

@auto_backup_before_critical
def bulk_assign_sector(conn, sector, team_id):
    """Assigne toutes les rues d'un secteur √† une √©quipe"""
    try:
        # Valider les entr√©es
        valid_sector, clean_sector = validate_and_clean_input("sector", sector)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        
        if not valid_sector or not valid_team:
            raise ValueError("Secteur ou √©quipe invalide")
        
        # V√©rifier que l'√©quipe existe
        cursor = conn.execute("SELECT COUNT(*) FROM teams WHERE id = ?", (clean_team,))
        if cursor.fetchone()[0] == 0:
            raise ValueError(f"√âquipe {clean_team} inexistante")
        
        # Effectuer l'assignation
        cursor = conn.execute("""
            UPDATE streets 
            SET team = ? 
            WHERE sector = ? AND (team IS NULL OR team = '')
        """, (clean_team, clean_sector))
        
        affected_rows = cursor.rowcount
        conn.commit()
        
        # Log de l'activit√©
        log_activity(conn, clean_team, "bulk_assign", 
                    f"Assignation secteur {clean_sector}: {affected_rows} rues")
        
        return affected_rows
        
    except Exception as e:
        print(f"Erreur bulk_assign_sector: {e}")
        return 0

def get_team_streets(conn, team_id):
    """R√©cup√®re les rues assign√©es √† une √©quipe"""
    try:
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        if not valid_team:
            return pd.DataFrame()
        
        query = """
            SELECT 
                s.name as street_name,
                s.sector,
                s.status,
                COUNT(n.id) as notes_count
            FROM streets s
            LEFT JOIN notes n ON s.name = n.street_name AND n.team_id = ?
            WHERE s.team = ?
            GROUP BY s.name, s.sector, s.status
            ORDER BY s.sector, s.name
        """
        return pd.read_sql_query(query, conn, params=(clean_team, clean_team))
        
    except Exception as e:
        print(f"Erreur get_team_streets: {e}")
        return pd.DataFrame()

@auto_backup_before_critical
def update_street_status(conn, street_name, new_status, team_id):
    """Met √† jour le statut d'une rue"""
    try:
        # Valider les entr√©es
        valid_street, clean_street = validate_and_clean_input("street_name", street_name)
        valid_status, clean_status = validate_and_clean_input("status", new_status)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        
        if not all([valid_street, valid_status, valid_team]):
            raise ValueError("Param√®tres invalides")
        
        # V√©rifier que la rue est assign√©e √† cette √©quipe
        cursor = conn.execute("""
            SELECT COUNT(*) FROM streets 
            WHERE name = ? AND team = ?
        """, (clean_street, clean_team))
        
        if cursor.fetchone()[0] == 0:
            raise ValueError(f"Rue {clean_street} non assign√©e √† l'√©quipe {clean_team}")
        
        # Mettre √† jour le statut
        conn.execute("""
            UPDATE streets 
            SET status = ? 
            WHERE name = ? AND team = ?
        """, (clean_status, clean_street, clean_team))
        
        conn.commit()
        
        # Log de l'activit√©
        log_activity(conn, clean_team, "status_update", 
                    f"Rue {clean_street}: {clean_status}")
        
        return True
        
    except Exception as e:
        print(f"Erreur update_street_status: {e}")
        return False

def get_assignations_export_data(conn):
    """R√©cup√®re les donn√©es d'assignation pour export CSV"""
    try:
        query = """
            SELECT 
                COALESCE(sector, 'Non d√©fini') as secteur,
                name as rue,
                COALESCE(team, 'Non assign√©e') as equipe,
                CASE status 
                    WHEN 'a_faire' THEN '√Ä faire'
                    WHEN 'en_cours' THEN 'En cours'
                    WHEN 'terminee' THEN 'Termin√©e'
                    ELSE status 
                END as statut
            FROM streets
            ORDER BY secteur, rue
        """
        return pd.read_sql_query(query, conn)
        
    except Exception as e:
        print(f"Erreur get_assignations_export_data: {e}")
        return pd.DataFrame()

def log_activity(conn, team_id, action, details):
    """Enregistre une activit√© dans le log"""
    try:
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        valid_action, clean_action = validate_and_clean_input("text", action)
        valid_details, clean_details = validate_and_clean_input("note", details)
        
        if not all([valid_team, valid_action, valid_details]):
            print("Param√®tres de log invalides")
            return
        
        conn.execute("""
            INSERT INTO activity_log (team_id, action, details)
            VALUES (?, ?, ?)
        """, (clean_team, clean_action, clean_details))
        
        conn.commit()
        
        # Log aussi dans un fichier texte pour backup
        log_dir = Path(__file__).parent / "logs"
        log_dir.mkdir(exist_ok=True)
        
        log_file = log_dir / "activity.log"
        with open(log_file, "a", encoding="utf-8") as f:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            f.write(f"{timestamp} | {clean_team} | {clean_action} | {clean_details}\n")
            
    except Exception as e:
        print(f"Erreur log_activity: {e}")

def get_street_notes_for_team(conn, street_name, team_id):
    """R√©cup√®re les notes d'une rue pour une √©quipe"""
    try:
        valid_street, clean_street = validate_and_clean_input("street_name", street_name)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        
        if not all([valid_street, valid_team]):
            return []
        
        cursor = conn.execute("""
            SELECT address_number, comment, created_at
            FROM notes
            WHERE street_name = ? AND team_id = ?
            ORDER BY created_at DESC
        """, (clean_street, clean_team))
        
        return cursor.fetchall()
        
    except Exception as e:
        print(f"Erreur get_street_notes_for_team: {e}")
        return []

@auto_backup_before_critical
def add_street_note(conn, street_name, team_id, address_number, comment):
    """Ajoute une note pour une adresse sp√©cifique"""
    try:
        # Valider les entr√©es
        valid_street, clean_street = validate_and_clean_input("street_name", street_name)
        valid_team, clean_team = validate_and_clean_input("team_id", team_id)
        valid_address, clean_address = validate_and_clean_input("address", address_number)
        valid_comment, clean_comment = validate_and_clean_input("note", comment)
        
        if not all([valid_street, valid_team, valid_address, valid_comment]):
            raise ValueError("Param√®tres invalides")
        
        # V√©rifier que la rue est assign√©e √† cette √©quipe
        cursor = conn.execute("""
            SELECT COUNT(*) FROM streets 
            WHERE name = ? AND team = ?
        """, (clean_street, clean_team))
        
        if cursor.fetchone()[0] == 0:
            raise ValueError(f"Rue {clean_street} non assign√©e √† l'√©quipe {clean_team}")
        
        # Ajouter la note
        conn.execute("""
            INSERT INTO notes (street_name, team_id, address_number, comment)
            VALUES (?, ?, ?, ?)
        """, (clean_street, clean_team, clean_address, clean_comment))
        
        conn.commit()
        
        # Log de l'activit√©
        log_activity(conn, clean_team, "note_added", 
                    f"Note ajout√©e - {clean_street} #{clean_address}")
        
        return True
        
    except Exception as e:
        print(f"Erreur add_street_note: {e}")
        return False
```
---8<--- guignomap/db.py END ---

---8<--- guignomap/osm.py BEGIN ---
```py
"""
Module OSM pour Guigno-Map
G√®re l'import et le cache des donn√©es OpenStreetMap pour Mascouche
"""

import io
import json
from pathlib import Path
import pandas as pd
import overpy

# Configuration
CACHE_FILE = Path(__file__).parent / "osm_cache.json"
ADDR_CACHE_FILE = Path(__file__).parent / "osm_addresses.json"

# Toutes les voies routi√®res nomm√©es de Mascouche
QUERY_STREETS_ALL = """
[out:json][timeout:300];
area["name"="Mascouche"]["boundary"="administrative"]->.a;
(
  way["highway"~"^(primary|secondary|tertiary|residential|service|unclassified|living_street|pedestrian|track|road|busway|footway|path)$"](area.a);
);
(._;>;);
out body;
"""
# Note: R√©cup√®re TOUS les types de voies incluant petites rues, all√©es, chemins pi√©tonniers

# Requ√™te pour les adresses
QUERY_ADDR_NODES = """
[out:json][timeout:180];
area["name"="Mascouche"]["boundary"="administrative"]->.a;
(
  node["addr:housenumber"]["addr:street"](area.a);
  way["addr:housenumber"]["addr:street"](area.a);
);
out tags center;
"""

def generate_streets_csv(city="Mascouche"):
    """
    G√©n√®re un CSV avec les noms des rues principales de la ville
    Filtre automatiquement les rues priv√©es et les petites ruelles
    """
    try:
        api = overpy.Overpass()
        result = api.query(QUERY_STREETS_ALL)
        
        streets = []
        for way in result.ways:
            name = way.tags.get("name")
            if not name:
                continue
            g = getattr(way, "geometry", None)
            # garder si on a une vraie g√©om√©trie (>= 2 points)
            if isinstance(g, list) and len(g) >= 2:
                streets.append(name)

        streets = sorted(set(streets))
        
        # Assigner automatiquement des secteurs bas√©s sur les patterns de noms
        sectors = []
        for street in streets:
            if any(word in street.lower() for word in ["mont√©e", "chemin", "boulevard"]):
                sectors.append("Principal")
            elif any(word in street.lower() for word in ["avenue", "place", "croissant"]):
                sectors.append("R√©sidentiel")
            elif "rue" in street.lower():
                sectors.append("Centre")
            else:
                sectors.append("")
        
        df = pd.DataFrame({
            "name": streets,
            "sector": sectors,
            "team": [""] * len(streets)
        })
        
        buf = io.StringIO()
        df.to_csv(buf, index=False)
        print(f"‚úÖ CSV g√©n√©r√© avec {len(streets)} rues principales")
        return buf.getvalue().encode("utf-8")
        
    except Exception as e:
        print(f"‚ùå Erreur OSM: {e}")
        # Retourner des donn√©es de test en cas d'erreur
        return create_fallback_csv()

def build_geometry_cache():
    """
    Construit le cache des g√©om√©tries pour TOUTES les voies de Mascouche
    Force la r√©solution compl√®te des nodes
    """
    try:
        print("üîÑ R√©cup√©ration compl√®te de toutes les voies de Mascouche...")
        
        # IMPORTANT: Configurer l'API pour r√©soudre automatiquement les nodes manquants
        api = overpy.Overpass()
        
        # Requ√™te am√©lior√©e qui force le retour des coordonn√©es
        query = """
        [out:json][timeout:300];
        area["name"="Mascouche"]["boundary"="administrative"]->.a;
        (
          way["highway"]["name"](area.a);
          way["highway"]["ref"](area.a);
        );
        (._;>;);
        out body;
        """
        
        print("üì° Connexion √† OpenStreetMap (cela peut prendre 30-60 secondes)...")
        result = api.query(query)
        
        geo = {}
        stats = {"total": 0, "avec_geo": 0, "sans_geo": 0}
        
        # Construire un dictionnaire des nodes pour acc√®s rapide
        nodes_dict = {}
        if hasattr(result, 'nodes'):
            for node in result.nodes:
                if hasattr(node, 'id') and hasattr(node, 'lat') and hasattr(node, 'lon'):
                    nodes_dict[node.id] = (float(node.lat), float(node.lon))
        
        print(f"üìç {len(nodes_dict)} nodes r√©cup√©r√©s")
        
        ways = result.ways if hasattr(result, 'ways') else []
        print(f"üìä {len(ways)} voies trouv√©es dans OpenStreetMap")
        
        for way in ways:
            try:
                # R√©cup√©rer le nom ou ref
                if not hasattr(way, 'tags'):
                    continue
                    
                name = way.tags.get("name")
                if not name:
                    ref = way.tags.get("ref")
                    if ref:
                        name = f"Autoroute {ref}"
                    else:
                        continue
                
                stats["total"] += 1
                coords = []
                
                # R√©cup√©rer les IDs des nodes
                if hasattr(way, 'nd_ids'):
                    # Si on a les IDs des nodes, les r√©soudre
                    for node_id in way.nd_ids:
                        if node_id in nodes_dict:
                            lat, lon = nodes_dict[node_id]
                            coords.append([lat, lon])
                elif hasattr(way, 'nodes'):
                    # Si on a directement les nodes
                    for node in way.nodes:
                        if hasattr(node, 'lat') and hasattr(node, 'lon'):
                            coords.append([float(node.lat), float(node.lon)])
                        elif hasattr(node, 'id') and node.id in nodes_dict:
                            lat, lon = nodes_dict[node.id]
                            coords.append([lat, lon])
                
                if len(coords) >= 2:
                    if name not in geo:
                        geo[name] = []
                    geo[name].append(coords)
                    stats["avec_geo"] += 1
                else:
                    stats["sans_geo"] += 1
                    
            except Exception as e:
                continue
        
        print(f"‚úÖ R√©sultat: {stats['avec_geo']} voies avec g√©om√©trie sur {stats['total']} trouv√©es")
        
        # Si on a r√©cup√©r√© des donn√©es, sauvegarder
        if geo:
            CACHE_FILE.write_text(json.dumps(geo, indent=2), encoding="utf-8")
            print(f"üíæ Cache cr√©√©: {len(geo)} voies sauvegard√©es dans osm_cache.json")
            
            # Importer aussi automatiquement dans la DB
            try:
                from pathlib import Path
                import sys
                sys.path.append(str(Path(__file__).parent))
                import db
                
                db_path = Path(__file__).parent / "guigno_map.db"
                conn = db.get_conn(db_path)
                
                # Ajouter les rues manquantes √† la DB
                for street_name in geo.keys():
                    cursor = conn.execute("SELECT COUNT(*) FROM streets WHERE name = ?", (street_name,))
                    if cursor.fetchone()[0] == 0:
                        conn.execute(
                            "INSERT INTO streets(name, sector, team, status) VALUES (?, '', '', 'a_faire')",
                            (street_name,)
                        )
                conn.commit()
                print(f"‚úÖ Rues import√©es dans la base de donn√©es")
            except Exception as e:
                print(f"‚ö†Ô∏è Import DB: {e}")
            
            return geo
        
        # Si aucune donn√©e, utiliser un fallback √©tendu
        print("‚ö†Ô∏è Aucune donn√©e OSM, utilisation du fallback local")
        return get_extended_fallback()
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return get_extended_fallback()

def get_fallback_geometry():
    """Fallback avec les principales voies de Mascouche"""
    return {
        "Autoroute 25": [[[45.70, -73.65], [45.78, -73.58]]],
        "Autoroute 640": [[[45.76, -73.70], [45.76, -73.55]]],
        "Mont√©e Masson": [[[45.730, -73.620], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.752, -73.590]]],
        "Chemin des Anglais": [[[45.74, -73.65], [45.75, -73.64]]],
        "Chemin Gascon": [[[45.75, -73.62], [45.76, -73.60]]],
        "Chemin Pincourt": [[[45.72, -73.64], [45.73, -73.63]]],
        "Chemin Newton": [[[45.73, -73.58], [45.74, -73.57]]],
        "Chemin Saint-Henri": [[[45.71, -73.61], [45.72, -73.60]]],
        "Chemin Saint-Pierre": [[[45.74, -73.59], [45.75, -73.58]]],
        "Avenue de la Gare": [[[45.745, -73.601], [45.748, -73.598]]],
        "Rue Dupras": [[[45.745, -73.602], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.749, -73.600]]],
        "Rue de l'√âglise": [[[45.747, -73.601], [45.750, -73.599]]],
        "Avenue des √ârables": [[[45.755, -73.605], [45.758, -73.600]]],
        "Rue des Pins": [[[45.756, -73.603], [45.759, -73.598]]],
        "Rue Brien": [[[45.738, -73.605], [45.741, -73.600]]],
        "Rue Boh√©mier": [[[45.742, -73.607], [45.745, -73.604]]]
    }

def get_extended_fallback():
    """Fallback √©tendu avec les principales voies de Mascouche"""
    fallback = {
        # Autoroutes
        "Autoroute 25": [[[45.70, -73.65], [45.72, -73.63], [45.74, -73.61], [45.76, -73.59], [45.78, -73.58]]],
        "Autoroute 640": [[[45.76, -73.70], [45.76, -73.65], [45.76, -73.60], [45.76, -73.55]]],
        
        # Chemins principaux
        "Mont√©e Masson": [[[45.730, -73.620], [45.740, -73.610], [45.750, -73.600], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.745, -73.605], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.747, -73.600], [45.752, -73.590]]],
        "Chemin des Anglais": [[[45.74, -73.65], [45.745, -73.645], [45.75, -73.64]]],
        "Chemin Gascon": [[[45.75, -73.62], [45.755, -73.615], [45.76, -73.60]]],
        "Chemin Pincourt": [[[45.72, -73.64], [45.725, -73.635], [45.73, -73.63]]],
        "Chemin Newton": [[[45.73, -73.58], [45.735, -73.575], [45.74, -73.57]]],
        "Chemin Saint-Henri": [[[45.71, -73.61], [45.715, -73.605], [45.72, -73.60]]],
        "Chemin Saint-Pierre": [[[45.74, -73.59], [45.745, -73.585], [45.75, -73.58]]],
        
        # Avenues
        "Avenue de la Gare": [[[45.745, -73.601], [45.747, -73.599], [45.748, -73.598]]],
        "Avenue Bourque": [[[45.742, -73.603], [45.744, -73.601], [45.746, -73.599]]],
        "Avenue Cr√©peau": [[[45.743, -73.602], [45.745, -73.600], [45.747, -73.598]]],
        "Avenue Garden": [[[45.751, -73.606], [45.753, -73.604], [45.755, -73.602]]],
        "Avenue de l'Esplanade": [[[45.748, -73.605], [45.750, -73.603], [45.752, -73.601]]],
        
        # Rues du centre
        "Rue Dupras": [[[45.745, -73.602], [45.747, -73.600], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.748, -73.602], [45.749, -73.600]]],
        "Rue de l'√âglise": [[[45.747, -73.601], [45.749, -73.599], [45.750, -73.598]]],
        "Rue Brien": [[[45.738, -73.605], [45.740, -73.603], [45.741, -73.600]]],
        "Rue Boh√©mier": [[[45.742, -73.607], [45.744, -73.605], [45.745, -73.604]]],
        
        # Rues r√©sidentielles
        "Rue des Pins": [[[45.756, -73.603], [45.758, -73.601], [45.759, -73.598]]],
        "Avenue des √ârables": [[[45.755, -73.605], [45.757, -73.603], [45.758, -73.600]]],
        "Rue Gravel": [[[45.738, -73.605], [45.740, -73.603], [45.741, -73.600]]]
    }
    
    # Sauvegarder le fallback
    CACHE_FILE.write_text(json.dumps(fallback, indent=2), encoding="utf-8")
    print(f"üíæ Fallback sauvegard√© avec {len(fallback)} voies principales")
    
    return fallback

def load_geometry_cache():
    """
    Charge le cache de g√©om√©tries depuis le fichier JSON
    Cr√©e un cache de base si le fichier n'existe pas
    """
    if not CACHE_FILE.exists():
        print("‚ö†Ô∏è Cache non trouv√©, construction en cours...")
        return build_geometry_cache()  # build_geometry_cache() g√®re d√©j√† le fallback en m√©moire
    
    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
            print(f"‚úÖ Cache charg√©: {len(cache)} rues")
            return cache
    except Exception as e:
        print(f"‚ùå Erreur chargement cache: {e}")
        # Ne pas √©crire de fallback sur disque ! Utiliser build_geometry_cache() qui g√®re le fallback en m√©moire
        return build_geometry_cache()

def create_fallback_csv():
    """
    Cr√©e un CSV de fallback avec quelques rues principales de Mascouche
    Utilis√© si l'API OSM est indisponible
    """
    fallback_streets = [
        ("Mont√©e Masson", "Principal"),
        ("Chemin Sainte-Marie", "Principal"),
        ("Boulevard de Mascouche", "Principal"),
        ("Chemin des Anglais", "Principal"),
        ("Rue Dupras", "Centre"),
        ("Rue Saint-Pierre", "Centre"),
        ("Rue de l'√âglise", "Centre"),
        ("Avenue des √ârables", "R√©sidentiel"),
        ("Rue des Pins", "R√©sidentiel"),
        ("Avenue Garden", "R√©sidentiel"),
    ]
    
    df = pd.DataFrame(fallback_streets, columns=["name", "sector"])
    df["team"] = ""
    
    buf = io.StringIO()
    df.to_csv(buf, index=False)
    print("‚ö†Ô∏è Mode fallback: 10 rues de test")
    return buf.getvalue().encode("utf-8")

def create_fallback_cache():
    """
    Cr√©e un cache minimal pour tests
    """
    fallback_geo = {
        "Mont√©e Masson": [[[45.730, -73.620], [45.750, -73.600], [45.765, -73.580]]],
        "Chemin Sainte-Marie": [[[45.735, -73.615], [45.748, -73.602], [45.755, -73.595]]],
        "Boulevard de Mascouche": [[[45.740, -73.610], [45.747, -73.600], [45.752, -73.590]]],
        "Rue Dupras": [[[45.745, -73.602], [45.748, -73.599]]],
        "Rue Saint-Pierre": [[[45.746, -73.604], [45.749, -73.600]]],
        "Rue de l'√âglise": [[[45.747, -73.601], [45.750, -73.599]]],
        "Avenue des √ârables": [[[45.755, -73.605], [45.758, -73.600]]],
        "Rue des Pins": [[[45.756, -73.603], [45.759, -73.598]]],
        "Avenue Garden": [[[45.753, -73.606], [45.756, -73.601]]],
        "Rue Gravel": [[[45.738, -73.605], [45.741, -73.600]]]
    }
    
    CACHE_FILE.write_text(json.dumps(fallback_geo, indent=2), encoding="utf-8")
    print("‚ö†Ô∏è Cache fallback cr√©√© avec 10 rues")

# Fonction utilitaire pour tests
def test_osm_connection():
    """
    Teste la connexion √† l'API Overpass
    """
    try:
        api = overpy.Overpass()
        # Requ√™te minimale pour tester
        result = api.query('[out:json];node(45.7475,-73.6005,45.7476,-73.6004);out;')
        print("‚úÖ Connexion OSM OK")
        return True
    except:
        print("‚ùå Connexion OSM √©chou√©e")
        return False

# ========================================
# NOUVELLES FONCTIONS POUR LES ADRESSES
# ========================================

def build_addresses_cache():
    """
    Construit le cache des adresses OSM pour Mascouche
    R√©cup√®re addr:housenumber + addr:street depuis OSM
    """
    try:
        api = overpy.Overpass()
        result = api.query(QUERY_ADDR_NODES)
        
        addresses = {}
        
        # Traiter les nodes avec adresses
        for node in result.nodes:
            house_number = node.tags.get("addr:housenumber")
            street_name = node.tags.get("addr:street")
            
            if house_number and street_name:
                if street_name not in addresses:
                    addresses[street_name] = []
                addresses[street_name].append({
                    "number": str(house_number),  # Forcer en string
                    "lat": float(node.lat),
                    "lon": float(node.lon),
                    "type": "node"
                })
        
        # Traiter les ways avec adresses
        for way in result.ways:
            num = way.tags.get("addr:housenumber")
            street = way.tags.get("addr:street")
            if not num or not street:
                continue
            
            # R√©cup√©rer le centre du way
            lat = getattr(way, "center_lat", None)
            lon = getattr(way, "center_lon", None)
            
            # Fallback si center_lat/lon non disponibles
            if lat is None or lon is None:
                nodes = getattr(way, "nodes", []) or []
                if nodes:
                    try:
                        valid_lats = []
                        valid_lons = []
                        for n in nodes:
                            if hasattr(n, 'lat') and hasattr(n, 'lon'):
                                if n.lat is not None and n.lon is not None:
                                    valid_lats.append(float(n.lat))
                                    valid_lons.append(float(n.lon))
                        if valid_lats and valid_lons:
                            lat = sum(valid_lats) / len(valid_lats)
                            lon = sum(valid_lons) / len(valid_lons)
                    except Exception as e:
                        print(f"Erreur calcul centre pour way: {e}")
                        continue
            
            if lat is not None and lon is not None:
                addresses.setdefault(street, []).append({
                    "number": str(num),
                    "lat": float(lat),
                    "lon": float(lon),
                    "type": "way"
                })
        
        # Trier les adresses par num√©ro pour chaque rue
        for street_name in addresses:
            try:
                # Tri num√©rique intelligent
                addresses[street_name].sort(
                    key=lambda x: (
                        int(''.join(filter(str.isdigit, x["number"]))) 
                        if any(c.isdigit() for c in x["number"]) 
                        else float('inf')
                    )
                )
            except:
                # Si le tri √©choue, garder l'ordre original
                pass
        
        # Sauvegarder le cache
        ADDR_CACHE_FILE.write_text(json.dumps(addresses, indent=2), encoding="utf-8")
        total_addresses = sum(len(addrs) for addrs in addresses.values())
        print(f"‚úÖ Cache adresses cr√©√©: {len(addresses)} rues, {total_addresses} adresses")
        return addresses
        
    except Exception as e:
        print(f"‚ùå Erreur construction cache adresses: {e}")
        # Cr√©er un cache vide en cas d'erreur
        ADDR_CACHE_FILE.write_text(json.dumps({}), encoding="utf-8")
        return {}

def load_addresses_cache():
    """
    Charge le cache d'adresses depuis le fichier JSON
    """
    if not ADDR_CACHE_FILE.exists():
        print("‚ö†Ô∏è Cache adresses non trouv√©")
        return {}
    
    try:
        with open(ADDR_CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
            total_addresses = sum(len(addrs) for addrs in cache.values())
            print(f"‚úÖ Cache adresses charg√©: {len(cache)} rues, {total_addresses} adresses")
            return cache
    except Exception as e:
        print(f"‚ùå Erreur chargement cache adresses: {e}")
        return {}
```
---8<--- guignomap/osm.py END ---

---8<--- guignomap/reports.py BEGIN ---
```py
"""
G√©n√©rateur de rapports Excel et PDF pour GuignoMap
"""

from pathlib import Path
from datetime import datetime
import pandas as pd
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, PageBreak, Image
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib.enums import TA_CENTER, TA_RIGHT
import xlsxwriter
from io import BytesIO

# Mapping des statuts pour l'affichage (√©vite imports circulaires)
STATUS_TO_LABEL = {"a_faire": "√Ä faire", "en_cours": "En cours", "terminee": "Termin√©e"}

class ReportGenerator:
    def __init__(self, conn):
        self.conn = conn
        self.styles = getSampleStyleSheet()
        self._setup_custom_styles()
    
    def _setup_custom_styles(self):
        """D√©finit les styles personnalis√©s pour PDF"""
        self.styles.add(ParagraphStyle(
            name='CustomTitle',
            parent=self.styles['Heading1'],
            fontSize=24,
            textColor=colors.HexColor('#8B0000'),
            spaceAfter=30,
            alignment=TA_CENTER
        ))
        
        self.styles.add(ParagraphStyle(
            name='SectionTitle',
            parent=self.styles['Heading2'],
            fontSize=16,
            textColor=colors.HexColor('#8B0000'),
            spaceAfter=12,
            spaceBefore=12
        ))
    
    def generate_excel(self):
        """G√©n√®re un rapport Excel professionnel"""
        output = BytesIO()
        workbook = xlsxwriter.Workbook(output, {'remove_timezone': True})
        
        # Styles Excel
        header_format = workbook.add_format({
            'bold': True,
            'bg_color': '#8B0000',
            'font_color': 'white',
            'align': 'center',
            'valign': 'vcenter',
            'border': 1
        })
        
        cell_format = workbook.add_format({
            'align': 'center',
            'valign': 'vcenter',
            'border': 1
        })
        
        status_formats = {
            'terminee': workbook.add_format({'bg_color': '#90EE90', 'border': 1}),
            'en_cours': workbook.add_format({'bg_color': '#FFE4B5', 'border': 1}),
            'a_faire': workbook.add_format({'bg_color': '#FFB6C1', 'border': 1})
        }
        
        # Feuille 1 : R√©sum√©
        summary_sheet = workbook.add_worksheet('R√©sum√© Guignol√©e 2025')
        summary_sheet.set_column(0, 4, 20)  # A:E
        
        # Titre
        title_format = workbook.add_format({
            'bold': True,
            'font_size': 20,
            'font_color': '#8B0000',
            'align': 'center'
        })
        summary_sheet.merge_range(0, 0, 0, 4, 'GUIGNOL√âE 2025 - RELAIS DE MASCOUCHE', title_format)  # A1:E1
        summary_sheet.merge_range(1, 0, 1, 4, f'Rapport g√©n√©r√© le {datetime.now().strftime("%d/%m/%Y √† %H:%M")}', cell_format)  # A2:E2
        
        # Stats globales
        from db import extended_stats
        stats = extended_stats(self.conn)
        
        row = 4
        summary_sheet.write(row, 0, 'STATISTIQUES GLOBALES', header_format)
        summary_sheet.merge_range(row, 1, row, 4, '', header_format)  # B{row+1}:E{row+1}
        
        row += 2
        summary_data = [
            ['Total des rues', stats['total']],
            ['Rues termin√©es', stats['done']],
            ['Rues en cours', stats.get('partial', 0)],
            ['Rues √† faire', stats.get('todo', 0)],
            ['Progression globale', f"{(stats['done']/stats['total']*100) if stats['total'] > 0 else 0:.1f}%"],
            ['Total des notes', stats.get('total_notes', 0)],
            ['Adresses avec notes', stats.get('addresses_with_notes', 0)]
        ]
        
        for label, value in summary_data:
            summary_sheet.write(row, 0, label, cell_format)
            summary_sheet.write(row, 1, value, cell_format)
            row += 1
        
        # Feuille 2 : D√©tail des rues
        streets_sheet = workbook.add_worksheet('D√©tail des rues')
        streets_sheet.set_column(0, 0, 30)
        streets_sheet.set_column(1, 4, 15)
        
        # Headers
        headers = ['Rue', 'Secteur', '√âquipe', 'Statut', 'Notes']
        for col, header in enumerate(headers):
            streets_sheet.write(0, col, header, header_format)
        
        # Donn√©es
        from db import list_streets
        df = list_streets(self.conn)
        
        for idx, row_data in enumerate(df.iterrows(), 1):
            _, row = row_data
            streets_sheet.write(idx, 0, row.get('name', ''), cell_format)
            streets_sheet.write(idx, 1, row.get('sector', ''), cell_format)
            streets_sheet.write(idx, 2, row.get('team', ''), cell_format)
            
            status = row.get('status', 'a_faire')
            format_to_use = status_formats.get(status, cell_format)
            status_label = STATUS_TO_LABEL.get(status, "√Ä faire")
            streets_sheet.write(idx, 3, status_label, format_to_use)
            
            streets_sheet.write(idx, 4, row.get('notes', 0), cell_format)
        
        # Feuille 3 : Performance des √©quipes
        teams_sheet = workbook.add_worksheet('Performance √©quipes')
        teams_sheet.set_column(0, 5, 15)
        
        from db import stats_by_team
        teams_df = stats_by_team(self.conn)
        
        if not teams_df.empty:
            headers = ['√âquipe', 'Total rues', 'Termin√©es', 'En cours', 'Notes', 'Progression %']
            for col, header in enumerate(headers):
                teams_sheet.write(0, col, header, header_format)
            
            for idx, row_data in enumerate(teams_df.iterrows(), 1):
                _, row = row_data
                teams_sheet.write(idx, 0, row.get('team', ''), cell_format)
                teams_sheet.write(idx, 1, row.get('total', 0), cell_format)
                teams_sheet.write(idx, 2, row.get('done', 0), cell_format)
                teams_sheet.write(idx, 3, row.get('partial', 0), cell_format)
                teams_sheet.write(idx, 4, row.get('notes', 0), cell_format)
                teams_sheet.write(idx, 5, f"{row.get('progress', 0):.1f}%", cell_format)
        
        workbook.close()
        output.seek(0)
        return output.getvalue()
    
    def generate_pdf(self):
        """G√©n√®re un rapport PDF professionnel"""
        output = BytesIO()
        doc = SimpleDocTemplate(output, pagesize=A4)
        story = []
        
        # Page de titre
        story.append(Paragraph("GUIGNOL√âE 2025", self.styles['CustomTitle']))
        story.append(Paragraph("Le Relais de Mascouche", self.styles['Title']))
        story.append(Spacer(1, 0.2*inch))
        story.append(Paragraph(f"Rapport g√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}", self.styles['Normal']))
        story.append(PageBreak())
        
        # R√©sum√©
        story.append(Paragraph("R√©sum√© de la collecte", self.styles['SectionTitle']))
        
        from db import extended_stats
        stats = extended_stats(self.conn)
        
        summary_data = [
            ['Statistique', 'Valeur'],
            ['Total des rues', str(stats['total'])],
            ['Rues termin√©es', str(stats['done'])],
            ['Rues en cours', str(stats.get('partial', 0))],
            ['Rues √† faire', str(stats.get('todo', 0))],
            ['Progression', f"{(stats['done']/stats['total']*100) if stats['total'] > 0 else 0:.1f}%"],
            ['Total notes', str(stats.get('total_notes', 0))]
        ]
        
        summary_table = Table(summary_data, colWidths=[3*inch, 2*inch])
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#8B0000')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 14),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(summary_table)
        story.append(PageBreak())
        
        # Performance des √©quipes
        story.append(Paragraph("Performance des √©quipes", self.styles['SectionTitle']))
        
        from db import stats_by_team
        teams_df = stats_by_team(self.conn)
        
        if not teams_df.empty:
            teams_data = [['√âquipe', 'Total', 'Termin√©es', 'En cours', 'Progression']]
            for _, row in teams_df.iterrows():
                teams_data.append([
                    row.get('team', ''),
                    str(row.get('total', 0)),
                    str(row.get('done', 0)),
                    str(row.get('partial', 0)),
                    f"{row.get('progress', 0):.1f}%"
                ])
            
            teams_table = Table(teams_data, colWidths=[2*inch, 1*inch, 1*inch, 1*inch, 1.5*inch])
            teams_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#8B0000')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            story.append(teams_table)
        
        doc.build(story)
        output.seek(0)
        return output.getvalue()
```
---8<--- guignomap/reports.py END ---

---8<--- guignomap/validators.py BEGIN ---
```py
"""
Validateurs et sanitizers pour GuignoMap
Protection contre injections et validation des formats
"""

import re
import html
from typing import Optional, Tuple

class InputValidator:
    """Classe de validation et sanitization des entr√©es"""
    
    @staticmethod
    def sanitize_text(text: str, max_length: int = 255) -> str:
        """Nettoie et limite un texte"""
        if not text:
            return ""
        # Supprimer les caract√®res de contr√¥le
        text = "".join(char for char in text if ord(char) >= 32 or char == '\n')
        # √âchapper le HTML
        text = html.escape(text)
        # Limiter la longueur
        return text[:max_length].strip()
    
    @staticmethod
    def sanitize_street_name(name: str) -> str:
        """Valide et nettoie un nom de rue"""
        if not name:
            return ""
        # Garder seulement lettres, chiffres, espaces, tirets, apostrophes, accents
        name = re.sub(r'[^a-zA-Z√Ä-√ø0-9\s\-\'\.]', '', name)
        return name[:100].strip()
    
    @staticmethod
    def sanitize_team_id(team_id: str) -> str:
        """Valide un ID d'√©quipe"""
        if not team_id:
            return ""
        # Format: LETTRES + CHIFFRES seulement, max 20 caract√®res
        team_id = re.sub(r'[^A-Z0-9]', '', team_id.upper())
        return team_id[:20]
    
    @staticmethod
    def sanitize_address_number(number: str) -> str:
        """Valide un num√©ro civique"""
        if not number:
            return ""
        # Garder chiffres et lettres (ex: 123A)
        number = re.sub(r'[^0-9A-Za-z\-]', '', number)
        return number[:10]
    
    @staticmethod
    def validate_password(password: str) -> Tuple[bool, str]:
        """Valide la force d'un mot de passe - minimum 4 caract√®res"""
        if password is None:
            return False, "Mot de passe requis"
        if len(password) < 4:
            return False, "Minimum 4 caract√®res"
        if len(password) > 128:
            return False, "Maximum 128 caract√®res"
        return True, "OK"
    
    @staticmethod
    def validate_sector(sector: str) -> str:
        """Valide un secteur"""
        valid_sectors = ['Principal', 'Centre', 'Nord', 'Sud', 'Est', 'Ouest', 'R√©sidentiel', '']
        if sector not in valid_sectors:
            return ''
        return sector
    
    @staticmethod
    def validate_status(status: str) -> str:
        """Valide un statut de rue"""
        valid_statuses = ['a_faire', 'en_cours', 'terminee']
        if status not in valid_statuses:
            return 'a_faire'
        return status
    
    @staticmethod
    def sanitize_note(note: str) -> str:
        """Nettoie une note/commentaire"""
        if not note:
            return ""
        # Supprimer caract√®res dangereux mais garder ponctuation basique
        note = re.sub(r'[<>\"\'`;]', '', note)
        return note[:500].strip()
    
    @staticmethod
    def is_sql_safe(text: str) -> bool:
        """V√©rifie qu'un texte ne contient pas de patterns SQL dangereux"""
        if not text:
            return True
        dangerous_patterns = [
            r'\bDROP\b', r'\bDELETE\b', r'\bINSERT\b', r'\bUPDATE\b',
            r'\bEXEC\b', r'\bEXECUTE\b', r'--', r'/\*', r'\*/', r';'
        ]
        text_upper = text.upper()
        for pattern in dangerous_patterns:
            if re.search(pattern, text_upper):
                return False
        return True

def validate_and_clean_input(input_type: str, value: str) -> Tuple[bool, str]:
    """Fonction principale de validation"""
    validator = InputValidator()
    
    if input_type == "team_id":
        clean = validator.sanitize_team_id(value)
        return bool(clean), clean
    
    elif input_type == "street_name":
        clean = validator.sanitize_street_name(value)
        if not validator.is_sql_safe(clean):
            return False, ""
        return bool(clean), clean
    
    elif input_type == "address":
        clean = validator.sanitize_address_number(value)
        return bool(clean), clean
    
    elif input_type == "note":
        clean = validator.sanitize_note(value)
        if not validator.is_sql_safe(clean):
            return False, ""
        return bool(clean), clean
    
    elif input_type == "sector":
        clean = validator.validate_sector(value)
        return True, clean
    
    elif input_type == "status":
        clean = validator.validate_status(value)
        return True, clean
    
    elif input_type == "password":
        valid, msg = validator.validate_password(value)
        return valid, value if valid else ""
    
    else:
        clean = validator.sanitize_text(value)
        return bool(clean), clean
```
---8<--- guignomap/validators.py END ---

---8<--- requirements.txt BEGIN ---
```txt
streamlit>=1.36.0
pandas>=2.2.0
folium==0.20.0
streamlit-folium>=0.21.0
overpy==0.7
bcrypt>=4.0.0
plotly>=5.18.0
xlsxwriter==3.2.8
reportlab==4.4.3

# Database - PostgreSQL
psycopg2-binary>=2.9.7
sqlalchemy==2.0.23
alembic==1.13.1

# Authentication - Argon2
passlib[argon2]==1.7.4

# Storage - S3/Cloud
boto3==1.34.144
```
---8<--- requirements.txt END ---

---8<--- scripts/export_repo_audit.py BEGIN ---
```py
# coding: utf-8
"""
Export d‚Äôaudit GuignoMap ‚Üí exports/export_audit_YYYYMMDD_HHMMSS.txt

Objectifs:
- Inclure 100% du contenu de TOUS les fichiers .py (src/, tests/, scripts/, guignomap/‚Ä¶)
- Inclure fichiers importants: config (toml/yaml/ini/json/sql), alembic.ini, migrations, requirements*, pyproject.toml, Dockerfile, .gitignore, README.md
- Exclure: backups, exports, caches, pycache, venv, .git, binaires, secrets (.streamlit/secrets.toml)
- Ajouter une section ENV avec: version Python, chemin ex√©cutable, plateforme, LISTE COMPLETE des paquets install√©s
Sortie: UTF-8 (LF), sans BOM
"""

from __future__ import annotations
from pathlib import Path
from datetime import datetime
import sys, platform, subprocess

ROOT = Path(__file__).resolve().parents[1]
OUTDIR = ROOT / "exports"
OUTDIR.mkdir(parents=True, exist_ok=True)
OUTFILE = OUTDIR / f"export_audit_{datetime.now():%Y%m%d_%H%M%S}.txt"

# Dossiers √† exclure totalement
EXCLUDE_DIRS = {
    ".git", ".github", ".venv", "venv", "env", ".vscode", "__pycache__", ".pytest_cache", ".mypy_cache",
    "node_modules", "storage_local", "backups", "exports", "logs", ".idea", ".DS_Store"
}

# Fichiers exactement exclus (secrets etc.)
EXCLUDE_FILES = {
    "secrets.toml",  # ne jamais sortir les secrets
    ".python-version"
}

# Extensions autoris√©es pour les fichiers non-.py, consid√©r√©s ‚Äúimportants √† auditer‚Äù
ALLOW_NONPY_EXTS = {
    ".toml", ".ini", ".cfg", ".conf", ".yml", ".yaml", ".json", ".sql",
    ".md", ".txt", ".ps1", ".bat", ".sh", ".dockerignore"
}

# Fichiers/chemins ‚Äúimportants‚Äù accept√©s m√™me sans extension (ou sp√©cifiques)
ALLOW_SPECIAL_PATHS = {
    "alembic.ini",
    "Dockerfile",
    ".gitignore",
    ".env.example",
    ".streamlit/config.toml",
    "requirements.txt",
    "requirements-dev.txt",
    "pyproject.toml",
}

# Pr√©fixes utiles (whitelist de zones pertinentes)
ALLOW_PREFIXES = [
    "src/",
    "tests/",
    "scripts/",
    "guignomap/",
    "src/database/migrations/",
]

# Ne PAS limiter la taille des .py (on les veut ENTIEREMENT)
MAX_NONPY_SIZE = 200 * 1024  # 200KB pour les non-.py (pour √©viter blobs inutiles)

def is_excluded_path(p: Path) -> bool:
    for part in p.parts:
        if part in EXCLUDE_DIRS:
            return True
    return False

def is_allowed_file(p: Path) -> bool:
    if p.name in EXCLUDE_FILES:
        return False

    rel = p.relative_to(ROOT).as_posix()

    # .py ‚Üí toujours inclus s'il est dans une zone pertinente
    if p.suffix.lower() == ".py":
        if any(rel == pre or rel.startswith(pre) for pre in ALLOW_PREFIXES):
            return True
        return False

    # Fichiers sp√©ciaux explicitement autoris√©s
    if rel in ALLOW_SPECIAL_PATHS:
        return True

    # Fichiers non-.py: extension autoris√©e ET dans une zone pertinente
    if p.suffix.lower() in ALLOW_NONPY_EXTS:
        if any(rel == pre or rel.startswith(pre) for pre in ALLOW_PREFIXES):
            return True

    return False

def read_text_utf8(p: Path) -> str:
    try:
        txt = p.read_text(encoding="utf-8", errors="replace")
    except Exception as e:
        txt = f"<<ERREUR LECTURE {p}: {e}>>"
    return txt.replace("\r\n", "\n").replace("\r", "\n")

def collect_files() -> list[Path]:
    files: list[Path] = []
    for p in ROOT.rglob("*"):
        if not p.is_file():
            continue
        if is_excluded_path(p):
            continue
        if not is_allowed_file(p):
            continue

        # Taille: .py = aucune limite; autres = borne raisonnable
        if p.suffix.lower() != ".py":
            try:
                if p.stat().st_size > MAX_NONPY_SIZE:
                    continue
            except Exception:
                continue

        files.append(p)

    files.sort(key=lambda x: x.relative_to(ROOT).as_posix().lower())
    return files

def get_installed_packages() -> list[str]:
    """Retourne une liste 'Nom==Version' tri√©e, en √©vitant les attributs priv√©s."""
    # 1) Tentative avec importlib.metadata (propre)
    try:
        from importlib.metadata import distributions
        pkgs = []
        for dist in distributions():
            meta = getattr(dist, "metadata", None)
            # meta est un email.message.Message (supporte .get)
            name = None
            if meta:
                name = meta.get("Name")
            ver = getattr(dist, "version", None)
            if name and ver:
                pkgs.append(f"{name}=={ver}")
        if pkgs:
            return sorted(pkgs, key=lambda s: s.lower())
    except Exception:
        pass

    # 2) Fallback avec pkg_resources (setuptools)
    try:
        import pkg_resources  # type: ignore
        pkgs = [f"{d.project_name}=={d.version}" for d in pkg_resources.working_set]
        if pkgs:
            return sorted(set(pkgs), key=lambda s: s.lower())
    except Exception:
        pass

    # 3) Dernier recours: pip freeze (synchronis√© avec l‚Äôenvironnement courant)
    try:
        out = subprocess.check_output([sys.executable, "-m", "pip", "freeze"], text=True, encoding="utf-8")
        pkgs = [line.strip() for line in out.splitlines() if line.strip()]
        if pkgs:
            return sorted(pkgs, key=lambda s: s.lower())
    except Exception as e:
        return [f"<<ERREUR INVENTAIRE DEPENDANCES: {e}>>"]

    return []

def env_section() -> str:
    lines: list[str] = []
    lines.append("## ENVIRONNEMENT")
    lines.append(f"- Python : {sys.version.splitlines()[0]}")
    lines.append(f"- Ex√©cutable : {sys.executable}")
    lines.append(f"- Plateforme : {platform.platform()}")

    # versions utiles si pr√©sentes
    try:
        import streamlit as _st
        lines.append(f"- streamlit : {_st.__version__}")
    except Exception:
        pass
    try:
        import sqlalchemy as _sa
        lines.append(f"- sqlalchemy : {_sa.__version__}")
    except Exception:
        pass
    try:
        import pandas as _pd
        lines.append(f"- pandas : {_pd.__version__}")
    except Exception:
        pass
    try:
        import boto3 as _b3
        lines.append(f"- boto3 : {_b3.__version__}")
    except Exception:
        pass
    try:
        import passlib as _pl  # noqa
        lines.append("- passlib : pr√©sent")
    except Exception:
        pass

    lines.append("")
    lines.append("### D√©pendances install√©es (inventaire)")
    pkgs = get_installed_packages() or ["<<Aucune d√©pendance d√©tect√©e>>"]
    lines.extend(pkgs)
    lines.append("")
    return "\n".join(lines)

def main() -> int:
    files = collect_files()

    header = [
        "# GuignoMap ‚Äî Export d‚Äôaudit COMPLET (code et config utiles)",
        f"# Date : {datetime.now():%Y-%m-%d %H:%M:%S}",
        f"# Racine : {ROOT}",
        "# Contenu : 100% des .py (zones pertinentes) + fichiers de config/migrations essentiels",
        "# Exclus : backups, exports, caches, venv, .git, binaires, secrets (.streamlit/secrets.toml)",
        ""
    ]

    with OUTFILE.open("w", encoding="utf-8", newline="\n") as out:
        out.write("\n".join(header) + "\n")
        out.write(env_section() + "\n")

        out.write("## INDEX DES FICHIERS INCLUS\n")
        for p in files:
            out.write(f"- {p.relative_to(ROOT).as_posix()}\n")

        out.write("\n## CONTENU DES FICHIERS\n")
        for p in files:
            rel = p.relative_to(ROOT).as_posix()
            out.write(f"\n---8<--- {rel} BEGIN ---\n")
            out.write("```" + (p.suffix.lower().lstrip(".") or "txt") + "\n")
            out.write(read_text_utf8(p))
            out.write("\n```\n")
            out.write(f"---8<--- {rel} END ---\n")

        out.write("\n## NOTE\n- Secrets exclus par conception (ex: .streamlit/secrets.toml)\n")
        out.write("- Tous les .py des zones pertinentes sont inclus en int√©gralit√©.\n")

    print(f"‚úÖ Export d‚Äôaudit √©crit : {OUTFILE}")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

```
---8<--- scripts/export_repo_audit.py END ---

---8<--- scripts/export_repo_min.py BEGIN ---
```py

```
---8<--- scripts/export_repo_min.py END ---

---8<--- scripts/export_repo_snapshot.py BEGIN ---
```py
# coding: utf-8
"""
Export complet du code GuignoMap ‚Üí exports/export_full_YYYYMMDD_HHMMSS.txt
- UTF-8 (sans BOM), normalise les fins de lignes.
- Inclut le contenu des fichiers code/texte utiles.
- Exclut .git, .venv, caches, binaires, gros fichiers.
- Ne lit jamais .streamlit/secrets.toml (s√©curit√©).
"""

from __future__ import annotations
import sys, os, io, time
from pathlib import Path
from datetime import datetime

ROOT = Path(__file__).resolve().parents[1]
OUTDIR = ROOT / "exports"
OUTDIR.mkdir(parents=True, exist_ok=True)
ts = datetime.now().strftime("%Y%m%d_%H%M%S")
OUTFILE = OUTDIR / f"export_full_{ts}.txt"

# Dossiers √† exclure
EXCLUDE_DIRS = {
    ".git", ".github", ".venv", ".vscode", "__pycache__", ".mypy_cache", ".pytest_cache",
    "node_modules", "dist", "build", "storage_local", ".idea"
}

# Fichiers √† exclure (par nom exact)
EXCLUDE_FILES = {
    "secrets.toml",  # ne jamais exposer des secrets
}

# Extensions √† inclure (code/texte)
INCLUDE_EXTS = {
    ".py", ".txt", ".md", ".ps1", ".bat", ".toml", ".ini", ".cfg",
    ".yml", ".yaml", ".json", ".sql"
}

# Extensions √† exclure d‚Äôoffice (binaires/pond√©reux)
BINARY_EXTS = {
    ".db", ".sqlite", ".sqlite3", ".pkl", ".zip", ".7z", ".rar", ".exe", ".dll",
    ".png", ".jpg", ".jpeg", ".gif", ".ico", ".pdf", ".parquet"
}

# Taille max (Ko) par fichier pour √©viter les √©normes blobs
SIZE_LIMIT_KB = 300  # ajuste si besoin

def should_skip(path: Path) -> bool:
    # Exclure par dossier
    for part in path.parts:
        if part in EXCLUDE_DIRS:
            return True
    # Exclure par extension binaire
    if path.suffix.lower() in BINARY_EXTS:
        return True
    # Exclure fichier secrets explicites
    if path.name in EXCLUDE_FILES:
        return True
    # Filtre d‚Äôextensions
    if path.suffix and path.suffix.lower() not in INCLUDE_EXTS:
        return True
    # Limite de taille
    try:
        if path.stat().st_size > SIZE_LIMIT_KB * 1024:
            return True
    except Exception:
        return True
    return False

def read_text_safely(path: Path) -> str:
    # Toujours lire en UTF-8 avec remplacement pour √©viter les caract√®res corrompus
    try:
        with open(path, "r", encoding="utf-8", errors="replace") as f:
            txt = f.read()
    except Exception as e:
        txt = f"<<ERREUR LECTURE {path}: {e}>>"
    # Normaliser fins de lignes
    return txt.replace("\r\n", "\n").replace("\r", "\n")

def main() -> int:
    files: list[Path] = []
    for p in ROOT.rglob("*"):
        if not p.is_file():
            continue
        if should_skip(p):
            continue
        files.append(p)

    files.sort(key=lambda x: str(x).lower())

    header = f"""# GuignoMap - Export de code COMPLET
# Date : {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
# Racine : {ROOT}
# Fichiers inclus : {len(files)}
# Encodage : UTF-8 (sans BOM)
# R√®gles : exclusions .git/.venv/binaires/gros fichiers, NO secrets.toml
"""

    with open(OUTFILE, "w", encoding="utf-8", newline="\n") as out:
        out.write(header + "\n")
        out.write("## INDEX\n")
        for p in files:
            rel = p.relative_to(ROOT)
            out.write(f"- {rel.as_posix()}\n")

        out.write("\n## CONTENU DES FICHIERS\n")
        for p in files:
            rel = p.relative_to(ROOT)
            out.write("\n")
            out.write(f"---8<--- {rel.as_posix()} BEGIN ---\n")
            out.write("```" + f"{p.suffix.lower().lstrip('.') or 'txt'}" + "\n")
            out.write(read_text_safely(p))
            out.write("\n```\n")
            out.write(f"---8<--- {rel.as_posix()} END ---\n")

        out.write("\n## STATISTIQUES\n")
        total_bytes = sum((p.stat().st_size for p in files), 0)
        out.write(f"- Total fichiers export√©s : {len(files)}\n")
        out.write(f"- Poids cumul√© (approx) : {total_bytes/1024:.1f} Ko\n")
        out.write(f"- Limite par fichier : {SIZE_LIMIT_KB} Ko\n")

    print(f"‚úÖ Export √©crit : {OUTFILE}")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

```
---8<--- scripts/export_repo_snapshot.py END ---

---8<--- scripts/fix_app_types.py BEGIN ---
```py
#!/usr/bin/env python3
"""
Script de migration automatique des types DataFrame vers List[Dict] dans app.py
Corrige les incompatibilit√©s entre l'ancien db.py et le nouveau db_v5.py
"""

import re
from pathlib import Path

def fix_app_py():
    """Corrige automatiquement les incompatibilit√©s de types dans app.py"""
    
    app_path = Path("guignomap/app.py")
    content = app_path.read_text(encoding='utf-8')
    
    # Corrections par regex
    corrections = [
        # 1. .empty sur listes -> len() == 0
        (r'if not (\w+)\.empty:', r'if \1:  # Liste non vide'),
        (r'if (\w+)\.empty:', r'if not \1:  # Liste vide'),
        
        # 2. .iterrows() -> enumerate() ou iteration directe
        (r'for _, (\w+) in (\w+)\.iterrows\(\):', r'for \1 in \2:'),
        (r'for (\w+), (\w+) in (\w+)\.iterrows\(\):', r'for \1, \2 in enumerate(\3):'),
        
        # 3. DataFrame['column'] -> list access pour unassigned
        (r"unassigned\['name'\]\.tolist\(\)", r"unassigned"),
        
        # 4. to_csv() sur listes -> DataFrame conversion
        (r'(\w+)\.to_csv\(([^)]+)\)', r'pd.DataFrame(\1).to_csv(\2)'),
        
        # 5. team_streets filtering (fonction get_team_streets retourne List[str])
        (r"team_streets\[team_streets\['status'\] == '(\w+)'\]", r"[s for s in team_streets if hasattr(s, 'status') and s.status == '\1']"),
        
        # 6. Acc√®s par index sur dictionnaires (notes)
        (r"note\[(\d+)\]", r"list(note.values())[\1] if isinstance(note, dict) else note[\1]"),
    ]
    
    for pattern, replacement in corrections:
        content = re.sub(pattern, replacement, content)
    
    # Corrections manuelles sp√©cifiques
    
    # Fix pour get_team_streets qui doit retourner les donn√©es compl√®tes, pas juste les noms
    content = content.replace(
        'def get_team_streets(team_id: str) -> List[str]:',
        'def get_team_streets(team_id: str) -> List[Dict[str, Any]]:'
    )
    
    # Fix pour l'utilisation de team_streets dans l'interface √©quipe
    content = re.sub(
        r'if team_streets\.empty:',
        'if not team_streets:',
        content
    )
    
    content = re.sub(
        r'done_streets = len\(team_streets\[team_streets\[\'status\'\] == \'terminee\'\]\)',
        'done_streets = len([s for s in team_streets if isinstance(s, dict) and s.get("status") == "terminee"])',
        content
    )
    
    content = re.sub(
        r'in_progress = len\(team_streets\[team_streets\[\'status\'\] == \'en_cours\'\]\)',
        'in_progress = len([s for s in team_streets if isinstance(s, dict) and s.get("status") == "en_cours"])',
        content
    )
    
    # Fix pour l'iteration sur team_streets
    content = re.sub(
        r'for street in team_streets:',
        'for street in team_streets:\n            if isinstance(street, str):\n                street_name = street\n            else:\n                street_name = street.get("name", street)',
        content
    )
    
    # Fix pour les notes dans l'affichage
    content = re.sub(
        r'st\.markdown\(f"‚Ä¢ \*\*#{note\[0\]}\*\* : {note\[1\]} _{note\[2\]}_"\)',
        'st.markdown(f"‚Ä¢ **#{note.get(\'address_number\', \'?\')}** : {note.get(\'comment\', \'\')} _{note.get(\'created_at\', \'\')}_ ")',
        content
    )
    
    # Sauvegarder
    app_path.write_text(content, encoding='utf-8')
    print("‚úÖ app.py corrig√© automatiquement")

if __name__ == "__main__":
    fix_app_py()
```
---8<--- scripts/fix_app_types.py END ---

---8<--- scripts/fix_specific.py BEGIN ---
```py
#!/usr/bin/env python3
"""
Script de correction fine pour les types de retour dans app.py
"""

import re
from pathlib import Path

def fix_specific_issues():
    """Corrige les probl√®mes sp√©cifiques identifi√©s"""
    
    app_path = Path("guignomap/app.py")
    content = app_path.read_text(encoding='utf-8')
    
    # 1. Revert les corrections sur DataFrames (list_streets retourne bien un DataFrame)
    content = re.sub(
        r'if df_all:  # Liste non vide',
        'if not df_all.empty:',
        content
    )
    
    content = re.sub(
        r'if not df_team:  # Liste vide',
        'if df_team.empty:',
        content
    )
    
    # 2. Fix team_streets access patterns
    content = re.sub(
        r'done_streets = len\(\[s for s in team_streets if hasattr\(s, \'status\'\) and s\.status == \'terminee\'\]\)',
        'done_streets = len([s for s in team_streets if s.get("status") == "terminee"])',
        content
    )
    
    content = re.sub(
        r'in_progress = len\(\[s for s in team_streets if hasattr\(s, \'status\'\) and s\.status == \'en_cours\'\]\)',
        'in_progress = len([s for s in team_streets if s.get("status") == "en_cours"])',
        content
    )
    
    # 3. Fix row access in iterrows (certains endroits ont encore des DataFrames)
    content = re.sub(
        r"for row in df_team:\s*street = row\['name'\]\s*status = row\['status'\]\s*notes_count = row\.get\('notes', 0\)",
        """for _, row in df_team.iterrows():
            street = row['name']
            status = row['status'] 
            notes_count = row.get('notes', 0)""",
        content, flags=re.MULTILINE
    )
    
    app_path.write_text(content, encoding='utf-8')
    print("‚úÖ Corrections sp√©cifiques appliqu√©es")

if __name__ == "__main__":
    fix_specific_issues()
```
---8<--- scripts/fix_specific.py END ---

---8<--- scripts/migrate_password_hashes.py BEGIN ---
```py
"""
Script de migration des hashes de mots de passe bcrypt ‚Üí Argon2
Migration paresseuse : les anciens hashes bcrypt sont migr√©s lors de la prochaine connexion
"""
import sys
import sqlite3
from pathlib import Path
from datetime import datetime

# Ajouter le r√©pertoire parent au PYTHONPATH pour les imports
sys.path.append(str(Path(__file__).parent.parent))

from src.auth.passwords import get_password_hash_info, is_bcrypt_hash, is_argon2_hash


def get_sqlite_connection():
    """Connexion √† la base SQLite existante"""
    sqlite_path = Path(__file__).parent.parent / "guignomap" / "guigno_map.db"
    if not sqlite_path.exists():
        print(f"‚ùå Base SQLite non trouv√©e: {sqlite_path}")
        return None
    
    conn = sqlite3.connect(str(sqlite_path))
    conn.row_factory = sqlite3.Row
    return conn


def analyze_password_hashes():
    """
    Analyse des hashes de mots de passe dans la base
    Identifie les √©quipes avec des hashes bcrypt qui n√©cessitent une migration
    """
    conn = get_sqlite_connection()
    if not conn:
        return
    
    try:
        print("üîç Analyse des hashes de mots de passe...")
        print("=" * 50)
        
        # R√©cup√©rer toutes les √©quipes
        cursor = conn.execute("SELECT id, name, password_hash, created_at FROM teams ORDER BY id")
        teams = cursor.fetchall()
        
        if not teams:
            print("‚ÑπÔ∏è Aucune √©quipe trouv√©e dans la base")
            return
        
        bcrypt_count = 0
        argon2_count = 0
        unknown_count = 0
        
        print(f"{'√âquipe':<15} {'Algorithme':<10} {'Statut':<20} {'Cr√©√© le'}")
        print("-" * 65)
        
        for team in teams:
            team_id = team['id']
            name = team['name']
            hash_value = team['password_hash']
            created_at = team['created_at']
            
            # Analyser le hash
            hash_info = get_password_hash_info(hash_value)
            algorithm = hash_info['algorithm']
            needs_update = hash_info['needs_update']
            
            if algorithm == 'bcrypt':
                bcrypt_count += 1
                status = "üîÑ √Ä migrer"
            elif algorithm == 'argon2':
                argon2_count += 1
                status = "‚úÖ Moderne" if not needs_update else "üîÑ √Ä mettre √† jour"
            else:
                unknown_count += 1
                status = "‚ùì Inconnu"
            
            print(f"{team_id:<15} {algorithm:<10} {status:<20} {created_at or 'N/A'}")
        
        print("-" * 65)
        print(f"\nüìä R√©sum√© de l'analyse:")
        print(f"   ‚Ä¢ Hashes bcrypt (√† migrer) : {bcrypt_count}")
        print(f"   ‚Ä¢ Hashes Argon2 (modernes) : {argon2_count}")
        print(f"   ‚Ä¢ Hashes inconnus          : {unknown_count}")
        print(f"   ‚Ä¢ Total √©quipes            : {len(teams)}")
        
        if bcrypt_count > 0:
            print(f"\nüí° Migration n√©cessaire:")
            print(f"   Les {bcrypt_count} √©quipe(s) avec bcrypt seront automatiquement")
            print(f"   migr√©es vers Argon2 lors de leur prochaine connexion r√©ussie.")
            print(f"   Aucune action manuelle n'est requise.")
        else:
            print(f"\nüéâ Toutes les √©quipes utilisent d√©j√† Argon2 !")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'analyse: {e}")
    finally:
        conn.close()


def generate_migration_report():
    """
    G√©n√®re un rapport d√©taill√© de migration
    """
    conn = get_sqlite_connection()
    if not conn:
        return
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = Path(__file__).parent.parent / f"password_migration_report_{timestamp}.txt"
    
    try:
        with open(report_path, 'w', encoding='utf-8') as report:
            report.write(f"Rapport de migration des mots de passe - {datetime.now()}\n")
            report.write("=" * 70 + "\n\n")
            
            # R√©cup√©rer toutes les √©quipes
            cursor = conn.execute("SELECT id, name, password_hash, created_at FROM teams ORDER BY id")
            teams = cursor.fetchall()
            
            teams_to_migrate = []
            
            for team in teams:
                team_id = team['id']
                name = team['name']
                hash_value = team['password_hash']
                created_at = team['created_at']
                
                hash_info = get_password_hash_info(hash_value)
                
                report.write(f"√âquipe: {team_id} ({name})\n")
                report.write(f"  Cr√©√©e: {created_at or 'Date inconnue'}\n")
                report.write(f"  Algorithme: {hash_info['algorithm']}\n")
                report.write(f"  N√©cessite mise √† jour: {hash_info['needs_update']}\n")
                
                if 'passlib_scheme' in hash_info:
                    report.write(f"  Sch√©ma passlib: {hash_info['passlib_scheme']}\n")
                
                if hash_info['algorithm'] == 'bcrypt':
                    teams_to_migrate.append(team_id)
                    report.write(f"  üîÑ MIGRATION REQUISE lors de la prochaine connexion\n")
                elif hash_info['algorithm'] == 'argon2':
                    report.write(f"  ‚úÖ Hash moderne\n")
                else:
                    report.write(f"  ‚ö†Ô∏è Hash de type inconnu\n")
                
                report.write("\n")
            
            report.write(f"R√âSUM√â DE MIGRATION\n")
            report.write("=" * 30 + "\n")
            report.write(f"√âquipes √† migrer: {len(teams_to_migrate)}\n")
            if teams_to_migrate:
                report.write(f"IDs concern√©s: {', '.join(teams_to_migrate)}\n")
            report.write(f"Total √©quipes: {len(teams)}\n\n")
            
            report.write("PROC√âDURE DE MIGRATION\n")
            report.write("=" * 30 + "\n")
            report.write("1. La migration est automatique et transparente\n")
            report.write("2. Elle se d√©clenche lors de la prochaine connexion r√©ussie\n")
            report.write("3. L'ancien hash bcrypt est remplac√© par un nouveau hash Argon2\n")
            report.write("4. Le mot de passe de l'utilisateur reste inchang√©\n")
            report.write("5. Aucune action manuelle n'est requise\n\n")
            
            report.write("POLITIQUE DE MOT DE PASSE\n")
            report.write("=" * 30 + "\n")
            report.write("‚Ä¢ Minimum 4 caract√®res (politique UI v4.1 conserv√©e)\n")
            report.write("‚Ä¢ Confirmation requise lors de la cr√©ation (UI)\n")
            report.write("‚Ä¢ Algorithme Argon2 pour nouveaux comptes\n")
            report.write("‚Ä¢ Compatibilit√© bcrypt maintenue\n")
        
        print(f"üìÑ Rapport g√©n√©r√©: {report_path}")
        
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©ration rapport: {e}")
    finally:
        conn.close()


def test_migration_functions():
    """
    Test des fonctions de migration avec des donn√©es d'exemple
    """
    print("üß™ Test des fonctions de migration...")
    
    try:
        from src.auth.passwords import create_test_hashes, verify_password, migrate_password_if_needed
        
        # Cr√©er des hashes de test
        test_password = "test123"
        hashes = create_test_hashes(test_password)
        
        print(f"\nüîë Mot de passe de test: {test_password}")
        print(f"Hash Argon2: {hashes['argon2'][:50]}...")
        print(f"Hash bcrypt: {hashes['bcrypt_legacy'][:50]}...")
        
        # Tester la v√©rification
        print(f"\n‚úÖ Tests de v√©rification:")
        
        # Test Argon2
        ok, needs_rehash = verify_password(test_password, hashes['argon2'])
        print(f"Argon2: OK={ok}, Rehash={needs_rehash}")
        
        # Test bcrypt
        ok, needs_rehash = verify_password(test_password, hashes['bcrypt_legacy'])
        print(f"bcrypt: OK={ok}, Rehash={needs_rehash}")
        
        # Test migration
        print(f"\nüîÑ Test de migration:")
        migrated, new_hash = migrate_password_if_needed(test_password, hashes['bcrypt_legacy'])
        print(f"Migration effectu√©e: {migrated}")
        if migrated:
            print(f"Nouveau hash: {new_hash[:50]}...")
        
        print(f"‚úÖ Tests termin√©s avec succ√®s")
        
    except Exception as e:
        print(f"‚ùå Erreur durant les tests: {e}")


def main():
    """Point d'entr√©e principal du script"""
    print("üîê Script de migration des mots de passe GuignoMap v5.0")
    print("bcrypt ‚Üí Argon2 avec migration paresseuse")
    print("=" * 60)
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "analyze":
            analyze_password_hashes()
        elif command == "report":
            generate_migration_report()
        elif command == "test":
            test_migration_functions()
        else:
            print(f"‚ùå Commande inconnue: {command}")
            print_usage()
    else:
        # Par d√©faut, faire l'analyse
        analyze_password_hashes()


def print_usage():
    """Affiche l'aide d'utilisation"""
    print("\nUtilisation:")
    print("  python scripts/migrate_password_hashes.py [commande]")
    print("\nCommandes disponibles:")
    print("  analyze  - Analyser les hashes actuels (d√©faut)")
    print("  report   - G√©n√©rer un rapport d√©taill√©")
    print("  test     - Tester les fonctions de migration")
    print("\nExemples:")
    print("  python scripts/migrate_password_hashes.py analyze")
    print("  python scripts/migrate_password_hashes.py report")


if __name__ == "__main__":
    main()
```
---8<--- scripts/migrate_password_hashes.py END ---

---8<--- scripts/migrate_sqlite_to_postgres.py BEGIN ---
```py
"""
Script de migration SQLite ‚Üí PostgreSQL pour GuignoMap v5.0
Copie toutes les donn√©es existantes de SQLite vers PostgreSQL
"""
import sqlite3
import sys
import os
from pathlib import Path

# Ajouter le r√©pertoire parent au PYTHONPATH pour les imports
sys.path.append(str(Path(__file__).parent.parent))

from src.database.connection import get_engine, execute_transaction
from src.database.models import Base, Street, Team, Note, ActivityLog, Address
from sqlalchemy.orm import sessionmaker
from datetime import datetime
import pandas as pd


def get_sqlite_connection():
    """Connexion en lecture seule √† la base SQLite existante"""
    sqlite_path = Path(__file__).parent.parent / "guignomap" / "guigno_map.db"
    if not sqlite_path.exists():
        print(f"‚ùå Base SQLite non trouv√©e: {sqlite_path}")
        return None
    
    conn = sqlite3.connect(str(sqlite_path))
    conn.row_factory = sqlite3.Row
    return conn


def create_postgres_tables():
    """Cr√©er les tables PostgreSQL via Alembic/SQLAlchemy"""
    try:
        engine = get_engine()
        Base.metadata.create_all(engine)
        print("‚úÖ Tables PostgreSQL cr√©√©es")
        return True
    except Exception as e:
        print(f"‚ùå Erreur cr√©ation tables PostgreSQL: {e}")
        return False


def copy_teams(sqlite_conn, postgres_session):
    """Copier les √©quipes SQLite ‚Üí PostgreSQL"""
    try:
        # Lire depuis SQLite
        teams_data = pd.read_sql_query("""
            SELECT id, name, password_hash, created_at, active 
            FROM teams 
            ORDER BY created_at
        """, sqlite_conn)
        
        if teams_data.empty:
            print("‚ÑπÔ∏è Aucune √©quipe √† migrer")
            return 0
        
        # Ins√©rer dans PostgreSQL
        count = 0
        for _, row in teams_data.iterrows():
            team = Team(
                id=row['id'],
                name=row['name'],
                password_hash=row['password_hash'],
                created_at=pd.to_datetime(row['created_at']) if row['created_at'] else datetime.utcnow(),
                active=bool(row['active'])
            )
            postgres_session.merge(team)  # merge pour √©viter les doublons
            count += 1
        
        postgres_session.commit()
        print(f"‚úÖ {count} √©quipes migr√©es")
        return count
        
    except Exception as e:
        postgres_session.rollback()
        print(f"‚ùå Erreur migration √©quipes: {e}")
        return 0


def copy_streets(sqlite_conn, postgres_session):
    """Copier les rues SQLite ‚Üí PostgreSQL"""
    try:
        # Lire depuis SQLite
        streets_data = pd.read_sql_query("""
            SELECT id, name, sector, team, status 
            FROM streets 
            ORDER BY id
        """, sqlite_conn)
        
        if streets_data.empty:
            print("‚ÑπÔ∏è Aucune rue √† migrer")
            return 0
        
        # Ins√©rer dans PostgreSQL
        count = 0
        for _, row in streets_data.iterrows():
            street = Street(
                id=row['id'] if row['id'] else None,
                name=row['name'],
                sector=row['sector'],
                team=row['team'],
                status=row['status'] or 'a_faire'
            )
            postgres_session.merge(street)
            count += 1
        
        postgres_session.commit()
        print(f"‚úÖ {count} rues migr√©es")
        return count
        
    except Exception as e:
        postgres_session.rollback()
        print(f"‚ùå Erreur migration rues: {e}")
        return 0


def copy_notes(sqlite_conn, postgres_session):
    """Copier les notes SQLite ‚Üí PostgreSQL"""
    try:
        # Lire depuis SQLite
        notes_data = pd.read_sql_query("""
            SELECT id, street_name, team_id, address_number, comment, created_at 
            FROM notes 
            ORDER BY created_at
        """, sqlite_conn)
        
        if notes_data.empty:
            print("‚ÑπÔ∏è Aucune note √† migrer")
            return 0
        
        # Ins√©rer dans PostgreSQL
        count = 0
        for _, row in notes_data.iterrows():
            note = Note(
                id=row['id'] if row['id'] else None,
                street_name=row['street_name'],
                team_id=row['team_id'],
                address_number=row['address_number'],
                comment=row['comment'],
                created_at=pd.to_datetime(row['created_at']) if row['created_at'] else datetime.utcnow()
            )
            postgres_session.merge(note)
            count += 1
        
        postgres_session.commit()
        print(f"‚úÖ {count} notes migr√©es")
        return count
        
    except Exception as e:
        postgres_session.rollback()
        print(f"‚ùå Erreur migration notes: {e}")
        return 0


def copy_activity_logs(sqlite_conn, postgres_session):
    """Copier les logs d'activit√© SQLite ‚Üí PostgreSQL"""
    try:
        # V√©rifier si la table existe
        cursor = sqlite_conn.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='activity_log'
        """)
        if not cursor.fetchone():
            print("‚ÑπÔ∏è Table activity_log non pr√©sente dans SQLite")
            return 0
        
        # Lire depuis SQLite
        logs_data = pd.read_sql_query("""
            SELECT id, team_id, action, details, created_at 
            FROM activity_log 
            ORDER BY created_at
        """, sqlite_conn)
        
        if logs_data.empty:
            print("‚ÑπÔ∏è Aucun log d'activit√© √† migrer")
            return 0
        
        # Ins√©rer dans PostgreSQL
        count = 0
        for _, row in logs_data.iterrows():
            log = ActivityLog(
                id=row['id'] if row['id'] else None,
                team_id=row['team_id'],
                action=row['action'],
                details=row['details'],
                created_at=pd.to_datetime(row['created_at']) if row['created_at'] else datetime.utcnow()
            )
            postgres_session.merge(log)
            count += 1
        
        postgres_session.commit()
        print(f"‚úÖ {count} logs d'activit√© migr√©s")
        return count
        
    except Exception as e:
        postgres_session.rollback()
        print(f"‚ùå Erreur migration logs: {e}")
        return 0


def copy_addresses(sqlite_conn, postgres_session):
    """Copier les adresses OSM SQLite ‚Üí PostgreSQL"""
    try:
        # V√©rifier si la table existe
        cursor = sqlite_conn.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='addresses'
        """)
        if not cursor.fetchone():
            print("‚ÑπÔ∏è Table addresses non pr√©sente dans SQLite")
            return 0
        
        # Lire depuis SQLite
        addresses_data = pd.read_sql_query("""
            SELECT id, street_name, house_number, latitude, longitude, osm_type, created_at 
            FROM addresses 
            ORDER BY created_at
        """, sqlite_conn)
        
        if addresses_data.empty:
            print("‚ÑπÔ∏è Aucune adresse √† migrer")
            return 0
        
        # Ins√©rer dans PostgreSQL
        count = 0
        for _, row in addresses_data.iterrows():
            address = Address(
                id=row['id'] if row['id'] else None,
                street_name=row['street_name'],
                house_number=row['house_number'],
                latitude=row['latitude'],
                longitude=row['longitude'],
                osm_type=row['osm_type'],
                created_at=pd.to_datetime(row['created_at']) if row['created_at'] else datetime.utcnow()
            )
            postgres_session.merge(address)
            count += 1
        
        postgres_session.commit()
        print(f"‚úÖ {count} adresses migr√©es")
        return count
        
    except Exception as e:
        postgres_session.rollback()
        print(f"‚ùå Erreur migration adresses: {e}")
        return 0


def main():
    """Migration compl√®te SQLite ‚Üí PostgreSQL"""
    print("üîÑ D√©but migration SQLite ‚Üí PostgreSQL...")
    
    # Connexions
    sqlite_conn = get_sqlite_connection()
    if not sqlite_conn:
        return False
    
    try:
        # Cr√©er les tables PostgreSQL
        if not create_postgres_tables():
            return False
        
        # Session PostgreSQL
        engine = get_engine()
        Session = sessionmaker(bind=engine)
        postgres_session = Session()
        
        # Migration par table
        total_migrated = 0
        total_migrated += copy_teams(sqlite_conn, postgres_session)
        total_migrated += copy_streets(sqlite_conn, postgres_session)
        total_migrated += copy_notes(sqlite_conn, postgres_session)
        total_migrated += copy_activity_logs(sqlite_conn, postgres_session)
        total_migrated += copy_addresses(sqlite_conn, postgres_session)
        
        postgres_session.close()
        sqlite_conn.close()
        
        print(f"üéâ Migration termin√©e ! {total_migrated} enregistrements migr√©s")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale migration: {e}")
        if 'postgres_session' in locals():
            postgres_session.close()
        sqlite_conn.close()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
```
---8<--- scripts/migrate_sqlite_to_postgres.py END ---

---8<--- scripts/validation_dataframe.ps1 BEGIN ---
```ps1
# =============================================================================
# SCRIPTS POWERSHELL - VALIDATION DATAFRAME
# =============================================================================

Write-Host "üîç AUDIT DATAFRAME - SCRIPTS DE VALIDATION" -ForegroundColor Green
Write-Host "=========================================" -ForegroundColor Green

Write-Host "`n1Ô∏è‚É£ PATTERNS DATAFRAME PROBL√âMATIQUES" -ForegroundColor Yellow
Write-Host "Recherche: .columns, .iterrows, .empty, .loc[], .iloc[]" -ForegroundColor Gray
Select-String -Path .\guignomap\app.py -Pattern '\.columns|\.iterrows|\.empty|\.loc\[|\.iloc\[' -CaseSensitive | 
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`n2Ô∏è‚É£ ASSIGNATIONS DE FONCTIONS DB" -ForegroundColor Yellow  
Write-Host "Recherche: variables = db.fonction()" -ForegroundColor Gray
Select-String -Path .\guignomap\app.py -Pattern '\s*\w+\s*=\s*db\.\w+\(' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`n3Ô∏è‚É£ UTILISATION ST.DATAFRAME" -ForegroundColor Yellow
Write-Host "Recherche: st.dataframe() pour v√©rifier les types" -ForegroundColor Gray  
Select-String -Path .\guignomap\app.py -Pattern 'st\.dataframe\(' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`n4Ô∏è‚É£ FONCTIONS DB QUI RETOURNENT DES DONN√âES" -ForegroundColor Yellow
Write-Host "Recherche: Fonctions db_v5 qui peuvent retourner listes vs DataFrames" -ForegroundColor Gray
Select-String -Path .\guignomap\db_v5.py -Pattern 'def (list_|get_|stats_|teams|recent_)' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`n5Ô∏è‚É£ IMPORTS PANDAS DANS APP.PY" -ForegroundColor Yellow  
Write-Host "Recherche: import pandas et pd.DataFrame" -ForegroundColor Gray
Select-String -Path .\guignomap\app.py -Pattern 'import pandas|pd\.DataFrame' -CaseSensitive |
  Select-Object LineNumber, Line | Format-Table -Auto

Write-Host "`n‚úÖ RAPPORT COMPLET G√âN√âR√â DANS: AUDIT_DATAFRAME.md" -ForegroundColor Green
```
---8<--- scripts/validation_dataframe.ps1 END ---

---8<--- src/auth/passwords.py BEGIN ---
```py
"""
Gestion des mots de passe avec Argon2 pour GuignoMap v5.0
Migration compatible depuis bcrypt + politique UI inchang√©e (min 4 + confirmation)
"""
from passlib.context import CryptContext
from typing import Tuple
import bcrypt


# Configuration passlib avec Argon2 comme algorithme principal
# Garde bcrypt pour la compatibilit√© ascendante (lecture uniquement)
pwd_context = CryptContext(
    schemes=["argon2", "bcrypt"],
    deprecated="auto",  # Marque bcrypt comme obsol√®te
    argon2__rounds=2,   # Param√®tres Argon2 pour performance/s√©curit√© √©quilibr√©e
    argon2__memory_cost=65536,  # 64 MB
    argon2__parallelism=1,
    argon2__hash_len=32
)


def hash_password(password: str) -> str:
    """
    Hash un mot de passe avec Argon2
    
    Args:
        password: Mot de passe en texte clair
        
    Returns:
        Hash Argon2 du mot de passe
    """
    return pwd_context.hash(password)


def verify_password(password: str, hashed: str) -> Tuple[bool, bool]:
    """
    V√©rifie un mot de passe contre son hash
    Supporte la migration automatique bcrypt ‚Üí Argon2
    
    Args:
        password: Mot de passe en texte clair
        hashed: Hash stock√© (bcrypt ou Argon2)
        
    Returns:
        Tuple (verification_ok, needs_rehash)
        - verification_ok: True si le mot de passe est correct
        - needs_rehash: True si le hash doit √™tre mis √† jour (migration paresseuse)
    """
    try:
        # V√©rification avec passlib (supporte bcrypt et Argon2)
        verification_ok = pwd_context.verify(password, hashed)
        
        if verification_ok:
            # V√©rifier si une mise √† jour du hash est n√©cessaire
            needs_rehash = pwd_context.needs_update(hashed)
            return True, needs_rehash
        else:
            return False, False
            
    except Exception as e:
        print(f"Erreur v√©rification mot de passe: {e}")
        return False, False


def is_bcrypt_hash(hashed: str) -> bool:
    """
    D√©termine si un hash est au format bcrypt
    
    Args:
        hashed: Hash √† v√©rifier
        
    Returns:
        True si c'est un hash bcrypt
    """
    return hashed.startswith('$2b$') or hashed.startswith('$2a$') or hashed.startswith('$2y$')


def is_argon2_hash(hashed: str) -> bool:
    """
    D√©termine si un hash est au format Argon2
    
    Args:
        hashed: Hash √† v√©rifier
        
    Returns:
        True si c'est un hash Argon2
    """
    return hashed.startswith('$argon2')


def migrate_password_if_needed(password: str, old_hash: str) -> Tuple[bool, str]:
    """
    Migration paresseuse d'un mot de passe bcrypt vers Argon2
    Appel√© lors d'une connexion r√©ussie
    
    Args:
        password: Mot de passe en texte clair (fourni lors de la connexion)
        old_hash: Hash actuel stock√©
        
    Returns:
        Tuple (migrated, new_hash)
        - migrated: True si une migration a eu lieu
        - new_hash: Nouveau hash Argon2 (ou old_hash si pas de migration)
    """
    verification_ok, needs_rehash = verify_password(password, old_hash)
    
    if verification_ok and needs_rehash:
        # Migration n√©cessaire : re-hasher avec Argon2
        new_hash = hash_password(password)
        print(f"üîÑ Migration hash bcrypt ‚Üí Argon2")
        return True, new_hash
    
    return False, old_hash


def validate_password_policy(password: str) -> Tuple[bool, str]:
    """
    Validation de la politique de mot de passe
    IMPORTANT: Garder la politique UI v4.1 (min 4 caract√®res + confirmation)
    
    Args:
        password: Mot de passe √† valider
        
    Returns:
        Tuple (valid, error_message)
    """
    if not password:
        return False, "Le mot de passe est requis"
    
    if len(password) < 4:
        return False, "Le mot de passe doit contenir au moins 4 caract√®res"
    
    # Note: La confirmation est g√©r√©e c√¥t√© UI, pas ici
    return True, ""


def get_password_hash_info(hashed: str) -> dict:
    """
    Informations sur un hash de mot de passe
    Utile pour diagnostics et migration
    
    Args:
        hashed: Hash √† analyser
        
    Returns:
        Dictionnaire avec les informations du hash
    """
    info = {
        'algorithm': 'unknown',
        'needs_update': False,
        'is_bcrypt': is_bcrypt_hash(hashed),
        'is_argon2': is_argon2_hash(hashed)
    }
    
    try:
        if is_bcrypt_hash(hashed):
            info['algorithm'] = 'bcrypt'
            info['needs_update'] = True  # Tous les bcrypt doivent migrer
        elif is_argon2_hash(hashed):
            info['algorithm'] = 'argon2'
            info['needs_update'] = pwd_context.needs_update(hashed)
        
        # Informations suppl√©mentaires via passlib
        hash_info = pwd_context.identify(hashed)
        if hash_info:
            info['passlib_scheme'] = hash_info
            
    except Exception as e:
        info['error'] = str(e)
    
    return info


# Fonctions de compatibilit√© avec l'ancien syst√®me bcrypt
def legacy_verify_bcrypt(password: str, bcrypt_hash: str) -> bool:
    """
    V√©rification directe bcrypt pour r√©trocompatibilit√©
    Utilis√© uniquement si passlib √©choue
    
    Args:
        password: Mot de passe en texte clair
        bcrypt_hash: Hash bcrypt √† v√©rifier
        
    Returns:
        True si le mot de passe correspond
    """
    try:
        return bcrypt.checkpw(password.encode('utf-8'), bcrypt_hash.encode('utf-8'))
    except Exception as e:
        print(f"Erreur v√©rification bcrypt legacy: {e}")
        return False


def create_test_hashes(password: str = "test123") -> dict:
    """
    Utilitaire pour cr√©er des hashes de test
    Aide au d√©veloppement et aux tests
    
    Args:
        password: Mot de passe de test
        
    Returns:
        Dictionnaire avec les diff√©rents hashes
    """
    return {
        'password': password,
        'argon2': hash_password(password),
        'bcrypt_legacy': bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
    }
```
---8<--- src/auth/passwords.py END ---

---8<--- src/config.py BEGIN ---
```py
"""
Configuration centralis√©e pour GuignoMap v5.0
Acc√®s aux secrets Streamlit et param√®tres applicatifs
"""
import streamlit as st
import os


def get_database_url():
    """R√©cup√®re l'URL de la base de donn√©es depuis les secrets"""
    try:
        return st.secrets["database"]["url"]
    except (KeyError, AttributeError):
        # Fallback pour d√©veloppement local ou tests
        return os.getenv("DATABASE_URL", "sqlite:///guigno_map.db")


def get_database_pool_config():
    """Configuration du pool de connexions PostgreSQL"""
    try:
        return {
            "pool_size": st.secrets["database"].get("pool_size", 5),
            "max_overflow": st.secrets["database"].get("max_overflow", 10)
        }
    except (KeyError, AttributeError):
        return {"pool_size": 5, "max_overflow": 10}


def get_s3_config():
    """Configuration S3 pour le stockage cloud"""
    try:
        return {
            "bucket": st.secrets["storage"]["s3_bucket"],
            "region": st.secrets["storage"]["s3_region"],
            "access_key": st.secrets["storage"]["s3_access_key"],
            "secret_key": st.secrets["storage"]["s3_secret_key"]
        }
    except (KeyError, AttributeError):
        return {
            "bucket": os.getenv("S3_BUCKET", "guignomap-dev"),
            "region": os.getenv("S3_REGION", "us-east-1"),
            "access_key": os.getenv("S3_ACCESS_KEY", ""),
            "secret_key": os.getenv("S3_SECRET_KEY", "")
        }


def get_cdn_base_url():
    """URL de base CDN pour les assets (optionnel)"""
    try:
        return st.secrets["storage"].get("cdn_base_url", "")
    except (KeyError, AttributeError):
        return os.getenv("CDN_BASE_URL", "")
```
---8<--- src/config.py END ---

---8<--- src/database/connection.py BEGIN ---
```py
"""
Connexion PostgreSQL avec SQLAlchemy pour GuignoMap v5.0
Engine + QueuePool + cache Streamlit + retry logic
"""
import time
import functools
import streamlit as st
from sqlalchemy import create_engine, text
from sqlalchemy.pool import QueuePool
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import SQLAlchemyError
from src.config import get_database_url, get_database_pool_config


def db_retry(max_retries=3, backoff_factor=1):
    """
    D√©corateur retry exponentiel pour op√©rations DB critiques
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except SQLAlchemyError as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        wait_time = backoff_factor * (2 ** attempt)
                        print(f"Retry DB operation {func.__name__} in {wait_time}s (attempt {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                    else:
                        print(f"Max retries reached for {func.__name__}")
                        break
            raise last_exception
        return wrapper
    return decorator


@st.cache_resource
def get_engine():
    """
    Engine PostgreSQL avec cache Streamlit et configuration pool
    Conform√©ment au plan v5.0
    """
    database_url = get_database_url()
    pool_config = get_database_pool_config()
    
    # Configuration PostgreSQL avec QueuePool
    engine = create_engine(
        database_url,
        poolclass=QueuePool,
        pool_size=pool_config["pool_size"],
        max_overflow=pool_config["max_overflow"],
        pool_pre_ping=True,
        pool_recycle=300,
        echo=False  # Set to True for SQL debugging
    )
    
    return engine


def get_session():
    """Fabrique de session SQLAlchemy"""
    engine = get_engine()
    Session = sessionmaker(bind=engine)
    return Session()


@db_retry(max_retries=3)
def test_connection():
    """Test de connexion √† la base PostgreSQL"""
    try:
        engine = get_engine()
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1 as test"))
            return result.fetchone()[0] == 1
    except Exception as e:
        print(f"Erreur test connexion DB: {e}")
        return False


@db_retry(max_retries=3)
def execute_query(query, params=None):
    """
    Ex√©cution de requ√™te avec retry automatique
    Pour transition progressive vers SQLAlchemy
    """
    engine = get_engine()
    with engine.connect() as conn:
        if params:
            return conn.execute(text(query), params)
        else:
            return conn.execute(text(query))


@db_retry(max_retries=3)  
def execute_transaction(queries_and_params):
    """
    Ex√©cution de transaction multi-requ√™tes avec retry
    queries_and_params: liste de tuples (query, params)
    """
    engine = get_engine()
    with engine.begin() as conn:
        results = []
        for query, params in queries_and_params:
            if params:
                result = conn.execute(text(query), params)
            else:
                result = conn.execute(text(query))
            results.append(result)
        return results
```
---8<--- src/database/connection.py END ---

---8<--- src/database/db_v5.py BEGIN ---
```py
"""
GuignoMap v5.0 - Database operation            admin_exists = session.execute(
                text("SELECT COUNT(*) FROM teams WHERE id = 'ADMIN'")
            ).scalar() or 0
            
            if admin_exists > 0:h SQLAlchemy
Migration from raw sqlite3 to SQLAlchemy + PostgreSQL support
"""
import os
import pandas as pd
import hashlib
import bcrypt
from datetime import datetime
import json
from pathlib import Path
import secrets
import string
from typing import Optional, List, Dict, Any

from sqlalchemy import text, and_, or_
from src.database.connection import get_session, db_retry
from src.database.models import Street, Team, Note, ActivityLog, Address
from backup import auto_backup_before_critical, BackupManager
from validators import validate_and_clean_input, InputValidator


# =============================================================================
# CONFIGURATION & CONSTANTES
# =============================================================================

# Sch√©ma de migration - utilis√© pour v√©rifier les tables existantes
REQUIRED_TABLES = ['streets', 'teams', 'notes', 'activity_log', 'addresses']


# =============================================================================
# FONCTIONS DE CONNEXION ET INITIALISATION
# =============================================================================

@db_retry(max_retries=3)
def init_db():
    """Initialise la base de donn√©es avec les donn√©es initiales"""
    try:
        with get_session() as session:
            # V√©rifier si admin existe
            admin_exists = session.execute(
                text("SELECT COUNT(*) FROM teams WHERE id = 'ADMIN'")
            ).scalar()
            
            if admin_exists == 0:
                pwd = os.getenv("GM_ADMIN_PWD", "RELAIS2025")
                create_team('ADMIN', 'Superviseur', pwd)
            
            # Auto-import des rues si vide
            streets_count = session.execute(
                text("SELECT COUNT(*) FROM streets")
            ).scalar()
            
            if streets_count == 0:
                print("üîÑ Aucune rue trouv√©e. Import automatique depuis OpenStreetMap...")
                auto_import_streets()
                
    except Exception as e:
        print(f"‚ùå Erreur init_db: {e}")
        raise


def auto_import_streets():
    """Import automatique des rues depuis OSM cache"""
    try:
        from osm import load_geometry_cache
        
        with get_session() as session:
            cache = load_geometry_cache()
            if not cache:
                print("‚ö†Ô∏è Aucun cache OSM trouv√©. Utilisez 'Construire carte' dans l'admin.")
                return
            
            imported = 0
            for street_name in cache.keys():
                if street_name and street_name.strip():
                    # V√©rifier si existe d√©j√†
                    exists = session.execute(
                        text("SELECT COUNT(*) FROM streets WHERE name = :name"),
                        {"name": street_name.strip()}
                    ).scalar()
                    
                    if exists == 0:
                        session.execute(text("""
                            INSERT INTO streets (name, status) 
                            VALUES (:name, 'a_faire')
                        """), {"name": street_name.strip()})
                        imported += 1
            
            session.commit()
            print(f"‚úÖ {imported} rues import√©es depuis OSM")
            
    except Exception as e:
        print(f"‚ùå Erreur auto_import_streets: {e}")


# =============================================================================
# GESTION DES √âQUIPES ET AUTHENTIFICATION
# =============================================================================

def hash_password(password: str) -> str:
    """Hash un mot de passe avec bcrypt"""
    return bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')


@db_retry(max_retries=2)
def create_team(team_id: str, name: str, password: str) -> bool:
    """Cr√©e une nouvelle √©quipe"""
    try:
        with get_session() as session:
            # V√©rifier si l'√©quipe existe d√©j√†
            exists = session.execute(
                text("SELECT COUNT(*) FROM teams WHERE id = :id"),
                {"id": team_id}
            ).scalar() or 0
            
            if exists > 0:
                return False
            
            password_hash = hash_password(password)
            session.execute(text("""
                INSERT INTO teams (id, name, password_hash, created_at, active)
                VALUES (:id, :name, :hash, CURRENT_TIMESTAMP, 1)
            """), {
                "id": team_id,
                "name": name, 
                "hash": password_hash
            })
            session.commit()
            
            # Log de l'activit√©
            log_activity(session, team_id, 'create_team', f"√âquipe '{name}' cr√©√©e")
            
            return True
            
    except Exception as e:
        print(f"‚ùå Erreur create_team: {e}")
        return False


@db_retry(max_retries=2)
def verify_team(team_id: str, password: str) -> bool:
    """V√©rifie les identifiants d'une √©quipe"""
    try:
        with get_session() as session:
            result = session.execute(
                text("SELECT password_hash FROM teams WHERE id = :id AND active = 1"),
                {"id": team_id}
            ).first()
            
            if not result:
                return False
            
            stored_hash = result[0]
            
            # Support bcrypt (nouveau) et MD5 legacy (migration)
            if stored_hash.startswith('$2b$'):
                # bcrypt
                return bcrypt.checkpw(password.encode('utf-8'), stored_hash.encode('utf-8'))
            else:
                # MD5 legacy - migrer automatiquement
                if hashlib.md5(password.encode()).hexdigest() == stored_hash:
                    # Migrer vers bcrypt
                    new_hash = hash_password(password)
                    session.execute(
                        text("UPDATE teams SET password_hash = :hash WHERE id = :id"),
                        {"hash": new_hash, "id": team_id}
                    )
                    session.commit()
                    return True
                return False
                
    except Exception as e:
        print(f"‚ùå Erreur verify_team: {e}")
        return False


def get_all_teams() -> List[Dict[str, Any]]:
    """R√©cup√®re toutes les √©quipes actives"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT id, name, created_at, 
                       (SELECT COUNT(*) FROM streets WHERE team = teams.id) as assigned_streets
                FROM teams 
                WHERE active = 1 
                ORDER BY name
            """))
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"‚ùå Erreur get_all_teams: {e}")
        return []


def teams() -> List[str]:
    """R√©cup√®re la liste des IDs d'√©quipes actives"""
    try:
        with get_session() as session:
            result = session.execute(
                text("SELECT id FROM teams WHERE active = 1 ORDER BY name")
            )
            return [row[0] for row in result]
            
    except Exception as e:
        print(f"‚ùå Erreur teams: {e}")
        return []


@auto_backup_before_critical
def delete_team(team_id: str) -> bool:
    """Supprime une √©quipe (soft delete)"""
    try:
        with get_session() as session:
            session.execute(
                text("UPDATE teams SET active = 0 WHERE id = :id"),
                {"id": team_id}
            )
            session.commit()
            return True
            
    except Exception as e:
        print(f"‚ùå Erreur delete_team: {e}")
        return False


# =============================================================================
# GESTION DES RUES ET STATUTS  
# =============================================================================

def list_streets(team: Optional[str] = None) -> pd.DataFrame:
    """Liste les rues avec filtrage optionnel par √©quipe"""
    try:
        with get_session() as session:
            if team:
                query = text("""
                    SELECT id, name, sector, team, status
                    FROM streets 
                    WHERE team = :team
                    ORDER BY name
                """)
                result = session.execute(query, {"team": team})
            else:
                query = text("""
                    SELECT id, name, sector, team, status
                    FROM streets 
                    ORDER BY name
                """)
                result = session.execute(query)
            
            # Convertir en DataFrame
            rows = [dict(row._mapping) for row in result]
            return pd.DataFrame(rows) if rows else pd.DataFrame(columns=['id', 'name', 'sector', 'team', 'status'])
            
    except Exception as e:
        print(f"‚ùå Erreur list_streets: {e}")
        return pd.DataFrame(columns=['id', 'name', 'sector', 'team', 'status'])


def get_unassigned_streets() -> List[str]:
    """R√©cup√®re les rues non assign√©es √† une √©quipe"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT name FROM streets 
                WHERE team IS NULL OR team = ''
                ORDER BY name
            """))
            return [row[0] for row in result]
            
    except Exception as e:
        print(f"‚ùå Erreur get_unassigned_streets: {e}")
        return []


@auto_backup_before_critical
def assign_streets_to_team(street_names: List[str], team_id: str) -> int:
    """Assigne plusieurs rues √† une √©quipe"""
    try:
        with get_session() as session:
            count = 0
            for street_name in street_names:
                # V√©rifier si la rue existe et n'est pas assign√©e
                existing = session.execute(text("""
                    SELECT COUNT(*) FROM streets 
                    WHERE name = :name AND (team IS NULL OR team = '')
                """), {"name": street_name}).scalar() or 0
                
                if existing > 0:
                    session.execute(text("""
                        UPDATE streets 
                        SET team = :team 
                        WHERE name = :name AND (team IS NULL OR team = '')
                    """), {"team": team_id, "name": street_name})
                    count += 1
            
            session.commit()
            
            # Log de l'activit√©
            if count > 0:
                log_activity(session, team_id, 'assign_streets', 
                           f"{count} rues assign√©es √† l'√©quipe")
            
            return count
            
    except Exception as e:
        print(f"‚ùå Erreur assign_streets_to_team: {e}")
        return 0


@auto_backup_before_critical
def set_status(name: str, status: str) -> bool:
    """Met √† jour le statut d'une rue"""
    try:
        # Validation du statut
        valid_statuses = ['a_faire', 'en_cours', 'terminee']
        if status not in valid_statuses:
            return False
        
        with get_session() as session:
            # V√©rifier si la rue existe
            exists = session.execute(
                text("SELECT COUNT(*) FROM streets WHERE name = :name"),
                {"name": name}
            ).scalar() or 0
            
            if exists > 0:
                session.execute(text("""
                    UPDATE streets 
                    SET status = :status 
                    WHERE name = :name
                """), {"status": status, "name": name})
                
                session.commit()
                
                # Log de l'activit√©
                team = session.execute(
                    text("SELECT team FROM streets WHERE name = :name"),
                    {"name": name}
                ).scalar()
                
                if team:
                    log_activity(session, team, 'status_change', 
                               f"Rue '{name}' -> {status}")
                
                return True
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur set_status: {e}")
        return False


# =============================================================================
# GESTION DES NOTES ET ADRESSES
# =============================================================================

@auto_backup_before_critical
def add_note_for_address(street_name: str, team_id: str, address_number: str, comment: str) -> bool:
    """Ajoute une note pour une adresse sp√©cifique"""
    try:
        # Validation et nettoyage
        _, comment = validate_and_clean_input("comment", comment)
        _, address_number = validate_and_clean_input("address_number", address_number)
        
        with get_session() as session:
            session.execute(text("""
                INSERT INTO notes (street_name, team_id, address_number, comment, created_at)
                VALUES (:street, :team, :addr, :comment, CURRENT_TIMESTAMP)
            """), {
                "street": street_name,
                "team": team_id,
                "addr": address_number,
                "comment": comment
            })
            session.commit()
            
            # Log de l'activit√©
            log_activity(session, team_id, 'add_note', 
                       f"Note ajout√©e: {street_name} #{address_number}")
            
            return True
            
    except Exception as e:
        print(f"‚ùå Erreur add_note_for_address: {e}")
        return False


def get_street_addresses_with_notes(street_name: str) -> List[Dict[str, Any]]:
    """R√©cup√®re les adresses avec notes pour une rue"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT address_number, comment, team_id, created_at
                FROM notes 
                WHERE street_name = :street
                ORDER BY CAST(address_number AS INTEGER), created_at DESC
            """), {"street": street_name})
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"‚ùå Erreur get_street_addresses_with_notes: {e}")
        return []


def get_team_notes(team_id: str) -> List[Dict[str, Any]]:
    """R√©cup√®re toutes les notes d'une √©quipe"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT street_name, address_number, comment, created_at
                FROM notes 
                WHERE team_id = :team
                ORDER BY created_at DESC
            """), {"team": team_id})
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"‚ùå Erreur get_team_notes: {e}")
        return []


# =============================================================================
# STATISTIQUES ET RAPPORTS
# =============================================================================

def extended_stats() -> Dict[str, Any]:
    """Statistiques √©tendues de l'application"""
    try:
        with get_session() as session:
            # Stats de base
            total_streets = session.execute(text("SELECT COUNT(*) FROM streets")).scalar() or 0
            assigned_streets = session.execute(text("SELECT COUNT(*) FROM streets WHERE team IS NOT NULL AND team != ''")).scalar() or 0
            completed_streets = session.execute(text("SELECT COUNT(*) FROM streets WHERE status = 'terminee'")).scalar() or 0
            in_progress_streets = session.execute(text("SELECT COUNT(*) FROM streets WHERE status = 'en_cours'")).scalar() or 0
            
            # Stats par statut
            status_counts = session.execute(text("""
                SELECT status, COUNT(*) as count
                FROM streets 
                GROUP BY status
            """))
            status_data = {row[0]: row[1] for row in status_counts}
            
            return {
                'total_streets': total_streets,
                'assigned_streets': assigned_streets,
                'unassigned_streets': total_streets - assigned_streets,
                'completed_streets': completed_streets,
                'in_progress_streets': in_progress_streets,
                'todo_streets': total_streets - completed_streets - in_progress_streets,
                'completion_rate': (completed_streets / total_streets * 100) if total_streets > 0 else 0,
                'status_breakdown': status_data
            }
            
    except Exception as e:
        print(f"‚ùå Erreur extended_stats: {e}")
        return {}


def stats_by_team() -> List[Dict[str, Any]]:
    """Statistiques par √©quipe"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT 
                    t.id,
                    t.name,
                    COUNT(s.id) as total_streets,
                    SUM(CASE WHEN s.status = 'terminee' THEN 1 ELSE 0 END) as completed,
                    SUM(CASE WHEN s.status = 'en_cours' THEN 1 ELSE 0 END) as in_progress,
                    SUM(CASE WHEN s.status = 'a_faire' THEN 1 ELSE 0 END) as todo
                FROM teams t
                LEFT JOIN streets s ON s.team = t.id
                WHERE t.active = 1
                GROUP BY t.id, t.name
                ORDER BY t.name
            """))
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"‚ùå Erreur stats_by_team: {e}")
        return []


def recent_activity(limit: int = 10) -> List[Dict[str, Any]]:
    """Activit√© r√©cente dans l'application"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT team_id, action, details, created_at
                FROM activity_log 
                ORDER BY created_at DESC 
                LIMIT :limit
            """), {"limit": limit})
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"‚ùå Erreur recent_activity: {e}")
        return []


def export_to_csv() -> str:
    """Exporte les donn√©es vers CSV"""
    try:
        from datetime import datetime
        
        df = list_streets()
        if df.empty:
            return ""
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        export_dir = Path(__file__).parent.parent / "exports"
        export_dir.mkdir(exist_ok=True)
        
        filename = f"guignomap_export_{timestamp}.csv"
        filepath = export_dir / filename
        
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        return str(filepath)
        
    except Exception as e:
        print(f"‚ùå Erreur export_to_csv: {e}")
        return ""


# =============================================================================
# LOG D'ACTIVIT√â
# =============================================================================

def log_activity(session, team_id: str, action: str, details: str):
    """Log une activit√© dans la base de donn√©es"""
    try:
        session.execute(text("""
            INSERT INTO activity_log (team_id, action, details, created_at)
            VALUES (:team, :action, :details, CURRENT_TIMESTAMP)
        """), {
            "team": team_id,
            "action": action,
            "details": details
        })
        # Note: commit fait par la fonction appelante
        
    except Exception as e:
        print(f"‚ùå Erreur log_activity: {e}")


# =============================================================================
# FONCTIONS MANQUANTES POUR COMPATIBILIT√â APP.PY
# =============================================================================

def get_team_streets(team_id: str) -> List[Dict[str, Any]]:
    """R√©cup√®re les rues assign√©es √† une √©quipe avec tous les d√©tails"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT id, name, sector, team, status
                FROM streets 
                WHERE team = :team 
                ORDER BY name
            """), {"team": team_id})
            return [dict(row._mapping) for row in result]
    except Exception as e:
        print(f"‚ùå Erreur get_team_streets: {e}")
        return []


def get_unassigned_streets_count() -> int:
    """Compte les rues non assign√©es"""
    try:
        with get_session() as session:
            count = session.execute(text("""
                SELECT COUNT(*) FROM streets 
                WHERE team IS NULL OR team = ''
            """)).scalar() or 0
            return count
    except Exception as e:
        print(f"‚ùå Erreur get_unassigned_streets_count: {e}")
        return 0


def get_sectors_list() -> List[str]:
    """R√©cup√®re la liste des secteurs"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT DISTINCT sector FROM streets 
                WHERE sector IS NOT NULL AND sector != ''
                ORDER BY sector
            """))
            return [row[0] for row in result]
    except Exception as e:
        print(f"‚ùå Erreur get_sectors_list: {e}")
        return []


def get_teams_list() -> List[str]:
    """R√©cup√®re la liste des √©quipes (alias pour teams())"""
    return teams()


def bulk_assign_sector(sector: str, team_id: str) -> int:
    """Assigne toutes les rues d'un secteur √† une √©quipe"""
    try:
        with get_session() as session:
            # R√©cup√©rer les rues non assign√©es du secteur
            result = session.execute(text("""
                SELECT name FROM streets 
                WHERE sector = :sector AND (team IS NULL OR team = '')
            """), {"sector": sector})
            
            street_names = [row[0] for row in result]
            
            if street_names:
                return assign_streets_to_team(street_names, team_id)
            return 0
            
    except Exception as e:
        print(f"‚ùå Erreur bulk_assign_sector: {e}")
        return 0


def get_assignations_export_data() -> List[Dict[str, Any]]:
    """Donn√©es pour export des assignations"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT s.name as street_name, s.sector, s.team, s.status,
                       t.name as team_name
                FROM streets s
                LEFT JOIN teams t ON s.team = t.id
                ORDER BY s.name
            """))
            return [dict(row._mapping) for row in result]
    except Exception as e:
        print(f"‚ùå Erreur get_assignations_export_data: {e}")
        return []


def export_notes_csv() -> str:
    """Exporte les notes vers CSV"""
    try:
        from datetime import datetime
        
        with get_session() as session:
            result = session.execute(text("""
                SELECT n.street_name, n.team_id, n.address_number, 
                       n.comment, n.created_at,
                       t.name as team_name
                FROM notes n
                LEFT JOIN teams t ON n.team_id = t.id
                ORDER BY n.created_at DESC
            """))
            
            if not result:
                return ""
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            export_dir = Path(__file__).parent.parent / "exports"
            export_dir.mkdir(exist_ok=True)
            
            filename = f"notes_export_{timestamp}.csv"
            filepath = export_dir / filename
            
            import pandas as pd
            df = pd.DataFrame([dict(row._mapping) for row in result])
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            
            return str(filepath)
            
    except Exception as e:
        print(f"‚ùå Erreur export_notes_csv: {e}")
        return ""


def import_addresses_from_cache(addr_cache: Dict) -> int:
    """Importe les adresses depuis le cache OSM"""
    try:
        with get_session() as session:
            imported = 0
            
            for street_name, addresses in addr_cache.items():
                if isinstance(addresses, list):
                    for addr in addresses:
                        # Ins√©rer l'adresse si elle n'existe pas
                        exists = session.execute(text("""
                            SELECT COUNT(*) FROM addresses 
                            WHERE street_name = :street AND house_number = :num
                        """), {"street": street_name, "num": str(addr)}).scalar() or 0
                        
                        if exists == 0:
                            session.execute(text("""
                                INSERT INTO addresses (street_name, house_number)
                                VALUES (:street, :num)
                            """), {"street": street_name, "num": str(addr)})
                            imported += 1
            
            session.commit()
            return imported
            
    except Exception as e:
        print(f"‚ùå Erreur import_addresses_from_cache: {e}")
        return 0


def update_street_status(street_name: str, status: str, team_id: str) -> bool:
    """Met √† jour le statut d'une rue (alias pour set_status)"""
    return set_status(street_name, status)


def get_street_notes_for_team(street_name: str, team_id: str) -> List[Dict[str, Any]]:
    """R√©cup√®re les notes d'une rue pour une √©quipe sp√©cifique"""
    try:
        with get_session() as session:
            result = session.execute(text("""
                SELECT address_number, comment, created_at
                FROM notes 
                WHERE street_name = :street AND team_id = :team
                ORDER BY created_at DESC
            """), {"street": street_name, "team": team_id})
            
            return [dict(row._mapping) for row in result]
            
    except Exception as e:
        print(f"‚ùå Erreur get_street_notes_for_team: {e}")
        return []


def add_street_note(street_name: str, team_id: str, address_number: str, comment: str) -> bool:
    """Ajoute une note pour une rue (alias pour add_note_for_address)"""
    return add_note_for_address(street_name, team_id, address_number, comment)


# =============================================================================
# COMPATIBILIT√â LEGACY
# =============================================================================

def get_backup_manager(db_path=None):
    """Compatibilit√© avec backup.py - retourne le BackupManager"""
    # Pour l'instant, utilise encore l'ancien syst√®me de backup
    # TODO: Migrer le backup vers SQLAlchemy dans Phase 2
    if db_path is None:
        db_path = Path(__file__).parent / "guigno_map.db"
    return BackupManager(db_path)


# =============================================================================
# MIGRATION PASSWORD LEGACY
# =============================================================================

def migrate_all_passwords_to_bcrypt():
    """Migre tous les mots de passe MD5 vers bcrypt"""
    try:
        with get_session() as session:
            # R√©cup√©rer toutes les √©quipes avec hash MD5
            result = session.execute(text("""
                SELECT id, password_hash 
                FROM teams 
                WHERE password_hash NOT LIKE '$2b$%' AND active = 1
            """))
            
            migrated = 0
            for row in result:
                team_id, old_hash = row
                print(f"‚ö†Ô∏è √âquipe {team_id} a un hash MD5 legacy")
                print("La migration automatique se fera lors de la prochaine connexion")
                # Note: la migration se fait automatiquement dans verify_team()
                
            print(f"‚úÖ {migrated} mots de passe √† migrer d√©tect√©s")
            
    except Exception as e:
        print(f"‚ùå Erreur migrate_all_passwords_to_bcrypt: {e}")
```
---8<--- src/database/db_v5.py END ---

---8<--- src/database/migrations/env.py BEGIN ---
```py
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

# Import our models and config
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))

from src.database.models import Base
from src.config import get_database_url

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
target_metadata = Base.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = get_database_url()
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    # Use our custom database URL instead of config
    configuration = config.get_section(config.config_ini_section, {})
    configuration["sqlalchemy.url"] = get_database_url()
    
    connectable = engine_from_config(
        configuration,
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()

```
---8<--- src/database/migrations/env.py END ---

---8<--- src/database/models.py BEGIN ---
```py
"""
Mod√®les SQLAlchemy pour GuignoMap v5.0
Bas√©s sur le sch√©ma SQLite existant pour compatibilit√©
"""
from sqlalchemy import Column, Integer, String, Text, DateTime, Boolean, ForeignKey, Float
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime

Base = declarative_base()


class Street(Base):
    __tablename__ = 'streets'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    name = Column(Text, nullable=False, unique=True)
    sector = Column(Text)
    team = Column(Text)
    status = Column(Text, nullable=False, default='a_faire')
    
    # Relations
    notes = relationship("Note", back_populates="street", cascade="all, delete-orphan")
    addresses = relationship("Address", back_populates="street", cascade="all, delete-orphan")


class Team(Base):
    __tablename__ = 'teams'
    
    id = Column(Text, primary_key=True)
    name = Column(Text, nullable=False)
    password_hash = Column(Text, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)
    active = Column(Boolean, default=True)


class Note(Base):
    __tablename__ = 'notes'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    street_name = Column(Text, ForeignKey('streets.name'), nullable=False)
    team_id = Column(Text, ForeignKey('teams.id'), nullable=False)
    address_number = Column(Text)
    comment = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relations
    street = relationship("Street", back_populates="notes")


class ActivityLog(Base):
    __tablename__ = 'activity_log'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    team_id = Column(Text)
    action = Column(Text, nullable=False)
    details = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)


class Address(Base):
    __tablename__ = 'addresses'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    street_name = Column(Text, ForeignKey('streets.name'), nullable=False)
    house_number = Column(Text, nullable=False)
    latitude = Column(Float)
    longitude = Column(Float)
    osm_type = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relations
    street = relationship("Street", back_populates="addresses")
```
---8<--- src/database/models.py END ---

---8<--- src/storage/__init__.py BEGIN ---
```py
"""
Adapter de stockage pour GuignoMap v5.0
S√©lection automatique entre cloud S3 et local selon configuration
"""
import os
from typing import Optional, Dict, Any
from pathlib import Path

try:
    from src.storage.cloud import (
        upload_osm_cache as cloud_upload_osm_cache,
        download_osm_cache as cloud_download_osm_cache,
        upload_backup_to_cloud as cloud_upload_backup,
        list_cloud_backups as cloud_list_backups,
        download_backup_from_cloud as cloud_download_backup
    )
    CLOUD_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è Stockage cloud non disponible: {e}")
    CLOUD_AVAILABLE = False

from src.storage.local import (
    upload_osm_cache as local_upload_osm_cache,
    download_osm_cache as local_download_osm_cache,
    upload_backup_to_cloud as local_upload_backup,
    list_cloud_backups as local_list_backups,
    download_backup_from_cloud as local_download_backup
)


def is_cloud_storage_enabled() -> bool:
    """
    D√©termine si le stockage cloud est activ√©
    V√©rifie la pr√©sence des secrets S3 et la disponibilit√© des libs
    """
    if not CLOUD_AVAILABLE:
        return False
    
    try:
        from src.config import get_s3_config
        config = get_s3_config()
        
        # V√©rifier que les cl√©s essentielles sont pr√©sentes et non vides
        required_keys = ['bucket', 'access_key', 'secret_key']
        for key in required_keys:
            if not config.get(key) or config[key] in ['', 'xxx']:
                return False
        
        return True
    except Exception:
        return False


def get_storage_backend() -> str:
    """Retourne 'cloud' ou 'local' selon la configuration"""
    return 'cloud' if is_cloud_storage_enabled() else 'local'


# API unifi√©e pour le stockage
def upload_osm_cache(cache_data: Dict[Any, Any]) -> bool:
    """Upload du cache OSM (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("üì° Upload cache OSM vers S3...")
        return cloud_upload_osm_cache(cache_data)
    else:
        print("üíæ Sauvegarde cache OSM en local...")
        return local_upload_osm_cache(cache_data)


def download_osm_cache() -> Optional[Dict[Any, Any]]:
    """Download du cache OSM (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("üì° T√©l√©chargement cache OSM depuis S3...")
        return cloud_download_osm_cache()
    else:
        print("üíæ Lecture cache OSM local...")
        return local_download_osm_cache()


def upload_backup(backup_path: Path) -> bool:
    """Upload d'un backup (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("üì° Upload backup vers S3...")
        return cloud_upload_backup(backup_path)
    else:
        print("üíæ Copie backup en local...")
        return local_upload_backup(backup_path)


def list_backups() -> list:
    """Liste des backups disponibles (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("üì° Liste backups S3...")
        return cloud_list_backups()
    else:
        print("üíæ Liste backups locaux...")
        return local_list_backups()


def download_backup(backup_key: str, local_path: Path) -> bool:
    """Download d'un backup (cloud ou local selon config)"""
    if is_cloud_storage_enabled():
        print("üì° T√©l√©chargement backup depuis S3...")
        return cloud_download_backup(backup_key, local_path)
    else:
        print("üíæ Copie backup depuis local...")
        return local_download_backup(backup_key, local_path)


def get_storage_info() -> Dict[str, Any]:
    """Informations sur le backend de stockage actuel"""
    backend = get_storage_backend()
    info = {
        'backend': backend,
        'cloud_available': CLOUD_AVAILABLE,
        'cloud_enabled': is_cloud_storage_enabled()
    }
    
    if backend == 'cloud':
        try:
            from src.config import get_s3_config
            config = get_s3_config()
            info.update({
                'bucket': config.get('bucket', ''),
                'region': config.get('region', ''),
                'cdn_enabled': bool(config.get('cdn_base_url', ''))
            })
        except:
            pass
    
    return info
```
---8<--- src/storage/__init__.py END ---

---8<--- src/storage/cloud.py BEGIN ---
```py
"""
Stockage cloud S3 pour GuignoMap v5.0
Client boto3 pour osm_cache.json et backups
"""
import boto3
import json
import io
import os
import streamlit as st
from typing import Optional, Dict, Any, BinaryIO
from pathlib import Path
from datetime import datetime
from src.config import get_s3_config, get_cdn_base_url


class S3StorageClient:
    """Client S3 pour g√©rer osm_cache.json et backups"""
    
    def __init__(self):
        self.config = get_s3_config()
        self.cdn_base_url = get_cdn_base_url()
        self._client = None
    
    @property
    def client(self):
        """Client S3 avec lazy loading et cache Streamlit"""
        if self._client is None:
            try:
                self._client = boto3.client(
                    's3',
                    region_name=self.config['region'],
                    aws_access_key_id=self.config['access_key'],
                    aws_secret_access_key=self.config['secret_key']
                )
            except Exception as e:
                print(f"Erreur initialisation client S3: {e}")
                raise
        return self._client
    
    def upload_json_file(self, key: str, data: Dict[Any, Any], metadata: Optional[Dict[str, str]] = None) -> bool:
        """
        Upload d'un fichier JSON vers S3
        """
        try:
            json_content = json.dumps(data, ensure_ascii=False, indent=2)
            json_bytes = json_content.encode('utf-8')
            
            extra_args = {
                'ContentType': 'application/json',
                'ContentEncoding': 'utf-8'
            }
            
            if metadata:
                extra_args['Metadata'] = metadata
            
            self.client.put_object(
                Bucket=self.config['bucket'],
                Key=key,
                Body=json_bytes,
                **extra_args
            )
            
            print(f"‚úÖ JSON upload√© vers S3: {key}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur upload JSON S3 {key}: {e}")
            return False
    
    def download_json_file(self, key: str) -> Optional[Dict[Any, Any]]:
        """
        Download d'un fichier JSON depuis S3
        """
        try:
            response = self.client.get_object(
                Bucket=self.config['bucket'],
                Key=key
            )
            
            content = response['Body'].read().decode('utf-8')
            data = json.loads(content)
            
            print(f"‚úÖ JSON t√©l√©charg√© depuis S3: {key}")
            return data
            
        except self.client.exceptions.NoSuchKey:
            print(f"‚ÑπÔ∏è Fichier JSON S3 non trouv√©: {key}")
            return None
        except Exception as e:
            print(f"‚ùå Erreur download JSON S3 {key}: {e}")
            return None
    
    def upload_backup(self, backup_file_path: Path, s3_key: Optional[str] = None) -> bool:
        """
        Upload d'un fichier backup vers S3
        """
        try:
            if not backup_file_path.exists():
                print(f"‚ùå Fichier backup non trouv√©: {backup_file_path}")
                return False
            
            # G√©n√©rer la cl√© S3 si non fournie
            if not s3_key:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                s3_key = f"backups/{backup_file_path.stem}_{timestamp}{backup_file_path.suffix}"
            
            # Upload avec streaming pour gros fichiers
            with open(backup_file_path, 'rb') as f:
                self.client.upload_fileobj(
                    f,
                    self.config['bucket'],
                    s3_key,
                    ExtraArgs={
                        'ContentType': 'application/zip',
                        'Metadata': {
                            'original_filename': backup_file_path.name,
                            'upload_timestamp': datetime.utcnow().isoformat()
                        }
                    }
                )
            
            print(f"‚úÖ Backup upload√© vers S3: {s3_key}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur upload backup S3: {e}")
            return False
    
    def download_backup(self, s3_key: str, local_path: Path) -> bool:
        """
        Download d'un backup depuis S3
        """
        try:
            # Cr√©er le r√©pertoire parent si n√©cessaire
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Download avec streaming
            with open(local_path, 'wb') as f:
                self.client.download_fileobj(
                    self.config['bucket'],
                    s3_key,
                    f
                )
            
            print(f"‚úÖ Backup t√©l√©charg√© depuis S3: {s3_key} ‚Üí {local_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur download backup S3 {s3_key}: {e}")
            return False
    
    def list_backups(self, prefix: str = "backups/") -> list:
        """
        Liste des backups disponibles sur S3
        """
        try:
            response = self.client.list_objects_v2(
                Bucket=self.config['bucket'],
                Prefix=prefix
            )
            
            backups = []
            if 'Contents' in response:
                for obj in response['Contents']:
                    backups.append({
                        'key': obj['Key'],
                        'size': obj['Size'],
                        'last_modified': obj['LastModified'],
                        'filename': Path(obj['Key']).name
                    })
                
                # Trier par date de modification (plus r√©cent en premier)
                backups.sort(key=lambda x: x['last_modified'], reverse=True)
            
            return backups
            
        except Exception as e:
            print(f"‚ùå Erreur liste backups S3: {e}")
            return []
    
    def delete_file(self, key: str) -> bool:
        """
        Suppression d'un fichier sur S3
        """
        try:
            self.client.delete_object(
                Bucket=self.config['bucket'],
                Key=key
            )
            print(f"‚úÖ Fichier supprim√© de S3: {key}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur suppression S3 {key}: {e}")
            return False
    
    def file_exists(self, key: str) -> bool:
        """
        V√©rifier si un fichier existe sur S3
        """
        try:
            self.client.head_object(
                Bucket=self.config['bucket'],
                Key=key
            )
            return True
        except self.client.exceptions.NoSuchKey:
            return False
        except Exception as e:
            print(f"‚ùå Erreur v√©rification existence S3 {key}: {e}")
            return False
    
    def get_public_url(self, key: str, expires_in: int = 3600) -> Optional[str]:
        """
        G√©n√©rer URL publique sign√©e pour un fichier S3
        """
        try:
            # Si CDN configur√©, utiliser l'URL CDN
            if self.cdn_base_url:
                return f"{self.cdn_base_url.rstrip('/')}/{key}"
            
            # Sinon, g√©n√©rer URL sign√©e S3
            url = self.client.generate_presigned_url(
                'get_object',
                Params={'Bucket': self.config['bucket'], 'Key': key},
                ExpiresIn=expires_in
            )
            return url
            
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration URL publique S3 {key}: {e}")
            return None


# Instance globale pour cache Streamlit
@st.cache_resource
def get_s3_client() -> S3StorageClient:
    """Factory avec cache Streamlit pour client S3"""
    return S3StorageClient()


# API simplifi√©e pour les fonctions m√©tier
def upload_osm_cache(cache_data: Dict[Any, Any]) -> bool:
    """Upload du cache OSM vers S3"""
    client = get_s3_client()
    return client.upload_json_file(
        "osm_cache.json", 
        cache_data,
        metadata={
            'type': 'osm_cache',
            'updated_at': datetime.utcnow().isoformat()
        }
    )


def download_osm_cache() -> Optional[Dict[Any, Any]]:
    """Download du cache OSM depuis S3"""
    client = get_s3_client()
    return client.download_json_file("osm_cache.json")


def upload_backup_to_cloud(backup_path: Path) -> bool:
    """Upload d'un backup vers S3"""
    client = get_s3_client()
    return client.upload_backup(backup_path)


def list_cloud_backups() -> list:
    """Liste des backups cloud disponibles"""
    client = get_s3_client()
    return client.list_backups()


def download_backup_from_cloud(s3_key: str, local_path: Path) -> bool:
    """Download d'un backup depuis S3"""
    client = get_s3_client()
    return client.download_backup(s3_key, local_path)
```
---8<--- src/storage/cloud.py END ---

---8<--- src/storage/local.py BEGIN ---
```py
"""
Stockage local pour GuignoMap v5.0  
Fallback avec API identique √† cloud.py
"""
import json
import shutil
import os
from typing import Optional, Dict, Any
from pathlib import Path
from datetime import datetime


class LocalStorageClient:
    """Client stockage local avec API identique au client S3"""
    
    def __init__(self, base_path: Optional[Path] = None):
        # R√©pertoire de base pour le stockage local
        if base_path is None:
            base_path = Path(__file__).parent.parent.parent / "storage_local"
        
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
        
        # Sous-r√©pertoires
        self.backups_dir = self.base_path / "backups"
        self.backups_dir.mkdir(exist_ok=True)
    
    def upload_json_file(self, key: str, data: Dict[Any, Any], metadata: Optional[Dict[str, str]] = None) -> bool:
        """
        Sauvegarde d'un fichier JSON en local
        """
        try:
            file_path = self.base_path / key
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Sauvegarder les donn√©es JSON
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # Sauvegarder les m√©tadonn√©es si fournies
            if metadata:
                metadata_path = file_path.with_suffix('.metadata.json')
                with open(metadata_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ JSON sauv√© localement: {file_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur sauvegarde JSON local {key}: {e}")
            return False
    
    def download_json_file(self, key: str) -> Optional[Dict[Any, Any]]:
        """
        Lecture d'un fichier JSON local
        """
        try:
            file_path = self.base_path / key
            
            if not file_path.exists():
                print(f"‚ÑπÔ∏è Fichier JSON local non trouv√©: {file_path}")
                return None
            
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"‚úÖ JSON lu localement: {file_path}")
            return data
            
        except Exception as e:
            print(f"‚ùå Erreur lecture JSON local {key}: {e}")
            return None
    
    def upload_backup(self, backup_file_path: Path, s3_key: Optional[str] = None) -> bool:
        """
        Copie d'un fichier backup vers le r√©pertoire local
        """
        try:
            if not backup_file_path.exists():
                print(f"‚ùå Fichier backup non trouv√©: {backup_file_path}")
                return False
            
            # G√©n√©rer le nom de destination si non fourni
            if not s3_key:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                dest_name = f"{backup_file_path.stem}_{timestamp}{backup_file_path.suffix}"
            else:
                # Extraire le nom du fichier de la cl√© S3
                dest_name = Path(s3_key).name
            
            dest_path = self.backups_dir / dest_name
            
            # Copier le fichier
            shutil.copy2(backup_file_path, dest_path)
            
            # Cr√©er un fichier de m√©tadonn√©es
            metadata = {
                'original_filename': backup_file_path.name,
                'original_path': str(backup_file_path),
                'upload_timestamp': datetime.utcnow().isoformat(),
                'size': backup_file_path.stat().st_size
            }
            
            metadata_path = dest_path.with_suffix(dest_path.suffix + '.metadata.json')
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ Backup copi√© localement: {dest_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur copie backup local: {e}")
            return False
    
    def download_backup(self, s3_key: str, local_path: Path) -> bool:
        """
        Copie d'un backup depuis le stockage local
        """
        try:
            # Trouver le fichier source
            source_name = Path(s3_key).name
            source_path = self.backups_dir / source_name
            
            if not source_path.exists():
                print(f"‚ùå Backup local non trouv√©: {source_path}")
                return False
            
            # Cr√©er le r√©pertoire de destination
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Copier le fichier
            shutil.copy2(source_path, local_path)
            
            print(f"‚úÖ Backup copi√© depuis local: {source_path} ‚Üí {local_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur copie backup depuis local {s3_key}: {e}")
            return False
    
    def list_backups(self, prefix: str = "backups/") -> list:
        """
        Liste des backups disponibles en local
        """
        try:
            backups = []
            
            # Lister tous les fichiers (sauf m√©tadonn√©es)
            for backup_file in self.backups_dir.glob("*"):
                if backup_file.is_file() and not backup_file.name.endswith('.metadata.json'):
                    # Lire les m√©tadonn√©es si disponibles
                    metadata_path = backup_file.with_suffix(backup_file.suffix + '.metadata.json')
                    metadata = {}
                    if metadata_path.exists():
                        try:
                            with open(metadata_path, 'r', encoding='utf-8') as f:
                                metadata = json.load(f)
                        except:
                            pass
                    
                    stat = backup_file.stat()
                    backups.append({
                        'key': f"backups/{backup_file.name}",
                        'size': stat.st_size,
                        'last_modified': datetime.fromtimestamp(stat.st_mtime),
                        'filename': backup_file.name,
                        'metadata': metadata
                    })
            
            # Trier par date de modification (plus r√©cent en premier)
            backups.sort(key=lambda x: x['last_modified'], reverse=True)
            return backups
            
        except Exception as e:
            print(f"‚ùå Erreur liste backups locaux: {e}")
            return []
    
    def delete_file(self, key: str) -> bool:
        """
        Suppression d'un fichier local
        """
        try:
            file_path = self.base_path / key
            
            if file_path.exists():
                file_path.unlink()
                
                # Supprimer les m√©tadonn√©es si elles existent
                metadata_path = file_path.with_suffix('.metadata.json')
                if metadata_path.exists():
                    metadata_path.unlink()
                
                print(f"‚úÖ Fichier supprim√© localement: {file_path}")
                return True
            else:
                print(f"‚ÑπÔ∏è Fichier local non trouv√©: {file_path}")
                return False
            
        except Exception as e:
            print(f"‚ùå Erreur suppression fichier local {key}: {e}")
            return False
    
    def file_exists(self, key: str) -> bool:
        """
        V√©rifier si un fichier existe en local
        """
        file_path = self.base_path / key
        return file_path.exists()
    
    def get_public_url(self, key: str, expires_in: int = 3600) -> Optional[str]:
        """
        G√©n√©rer un chemin local pour un fichier (pas d'URL publique)
        """
        file_path = self.base_path / key
        if file_path.exists():
            return f"file://{file_path.absolute()}"
        return None


# Instance globale pour le stockage local
_local_client = None

def get_local_client() -> LocalStorageClient:
    """Factory pour client de stockage local"""
    global _local_client
    if _local_client is None:
        _local_client = LocalStorageClient()
    return _local_client


# API simplifi√©e pour les fonctions m√©tier (identique √† cloud.py)
def upload_osm_cache(cache_data: Dict[Any, Any]) -> bool:
    """Upload du cache OSM en local"""
    client = get_local_client()
    return client.upload_json_file(
        "osm_cache.json", 
        cache_data,
        metadata={
            'type': 'osm_cache',
            'updated_at': datetime.utcnow().isoformat()
        }
    )


def download_osm_cache() -> Optional[Dict[Any, Any]]:
    """Download du cache OSM depuis local"""
    client = get_local_client()
    return client.download_json_file("osm_cache.json")


def upload_backup_to_cloud(backup_path: Path) -> bool:
    """Upload d'un backup en local"""
    client = get_local_client()
    return client.upload_backup(backup_path)


def list_cloud_backups() -> list:
    """Liste des backups locaux disponibles"""
    client = get_local_client()
    return client.list_backups()


def download_backup_from_cloud(s3_key: str, local_path: Path) -> bool:
    """Download d'un backup depuis local"""
    client = get_local_client()
    return client.download_backup(s3_key, local_path)
```
---8<--- src/storage/local.py END ---

---8<--- src/utils/__init__.py BEGIN ---
```py
# Utils module for GuignoMap
```
---8<--- src/utils/__init__.py END ---

---8<--- src/utils/adapters.py BEGIN ---
```py
import pandas as pd
from typing import Any, Iterable

def to_dataframe(records: Any) -> pd.DataFrame:
    if isinstance(records, pd.DataFrame):
        return records
    # RowMapping unique
    try:
        if hasattr(records, "keys") and hasattr(records, "__getitem__"):
            return pd.DataFrame([dict(records)])
    except Exception:
        pass
    # S√©quences (list[dict]/list[Row]/list[ORM])
    if isinstance(records, Iterable):
        items = list(records)
        if items and not isinstance(items[0], dict):
            dicts = []
            for r in items:
                if hasattr(r, "__dict__"):
                    d = {k:v for k,v in r.__dict__.items() if not k.startswith("_sa_")}
                    dicts.append(d)
                else:
                    try: dicts.append(dict(r))
                    except Exception: dicts.append({"value": r})
            return pd.DataFrame(dicts)
        return pd.DataFrame(items)
    return pd.DataFrame([])
```
---8<--- src/utils/adapters.py END ---

---8<--- tests/manual/test_db_connection.py BEGIN ---
```py
import os
import sys
import socket
import psycopg2

def test_connection_with_ip():
    """Test connection with direct IPv6 address"""
    # Configuration manuelle avec l'adresse IPv6 r√©solue
    ipv6_host = "2600:1f11:4e2:e202:6514:7431:494f:c00f"
    
    connection_string = f"postgresql://postgres:4everSab!2304@[{ipv6_host}]:5432/postgres"
    
    print(f"Test de connexion avec IPv6 directe: {ipv6_host}")
    
    try:
        conn = psycopg2.connect(connection_string)
        print("‚úÖ Connexion IPv6 r√©ussie!")
        
        with conn.cursor() as cursor:
            cursor.execute("SELECT version();")
            version = cursor.fetchone()[0]
            print(f"Version PostgreSQL: {version}")
        
        conn.close()
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur de connexion IPv6: {e}")
        return False

def test_connection_with_hostname():
    """Test connection with hostname via custom DNS"""
    import socket
    
    # Forcer IPv4 si possible
    try:
        socket.setdefaulttimeout(10)
        original_getaddrinfo = socket.getaddrinfo
        
        def custom_getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):
            if host == "db.kdxqspmfycnwzzrmhzpa.supabase.co":
                # Retourner directement l'IPv6 connue
                return [(socket.AF_INET6, socket.SOCK_STREAM, 6, '', 
                        ('2600:1f11:4e2:e202:6514:7431:494f:c00f', port, 0, 0))]
            return original_getaddrinfo(host, port, family, type, proto, flags)
        
        socket.getaddrinfo = custom_getaddrinfo
        
        connection_string = "postgresql://postgres:4everSab!2304@db.kdxqspmfycnwzzrmhzpa.supabase.co:5432/postgres"
        
        print("Test de connexion avec hostname (DNS custom)")
        conn = psycopg2.connect(connection_string)
        print("‚úÖ Connexion hostname r√©ussie!")
        
        with conn.cursor() as cursor:
            cursor.execute("SELECT version();")
            version = cursor.fetchone()[0]
            print(f"Version PostgreSQL: {version}")
        
        conn.close()
        socket.getaddrinfo = original_getaddrinfo
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur de connexion hostname: {e}")
        socket.getaddrinfo = original_getaddrinfo
        return False

if __name__ == "__main__":
    print("=== Test de connectivit√© Supabase PostgreSQL ===")
    
    print("\n1. Test avec adresse IPv6 directe:")
    ipv6_success = test_connection_with_ip()
    
    print("\n2. Test avec hostname (DNS custom):")
    hostname_success = test_connection_with_hostname()
    
    if ipv6_success or hostname_success:
        print("\n‚úÖ Au moins une m√©thode de connexion fonctionne!")
    else:
        print("\n‚ùå Aucune m√©thode de connexion ne fonctionne")
        print("Probl√®me potentiel: connectivit√© IPv6 ou firewall")
```
---8<--- tests/manual/test_db_connection.py END ---

---8<--- tests/manual/test_db_simple.py BEGIN ---
```py
#!/usr/bin/env python3
"""Test simple de connexion base de donn√©es"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_db_simple():
    try:
        from src.database.connection import get_engine, test_connection
        
        print("=== Test de connexion base de donn√©es ===")
        
        # Test avec la fonction d√©di√©e
        print("1. Test avec test_connection():")
        test_connection()
        
        # Test manuel avec engine
        print("\n2. Test manuel avec engine:")
        engine = get_engine()
        print(f"‚úÖ Engine cr√©√©: {engine.url}")
        
        # Tester la connexion
        with engine.connect() as conn:
            result = conn.execute("SELECT 1 as test")
            test_value = result.fetchone()[0]
            print(f"‚úÖ Connexion r√©ussie! Test query result: {test_value}")
        
        print("‚úÖ Connexion base de donn√©es fonctionnelle!")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur de connexion: {e}")
        return False

if __name__ == "__main__":
    success = test_db_simple()
    sys.exit(0 if success else 1)
```
---8<--- tests/manual/test_db_simple.py END ---

## NOTE
- Secrets exclus par conception (ex: .streamlit/secrets.toml)
- Tous les .py des zones pertinentes sont inclus en int√©gralit√©.
